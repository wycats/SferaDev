/**
 * Generated by Kubb (https://kubb.dev/).
 * Do not edit manually.
 */

import type { ErrorWrapper, FetcherConfig } from "../utils/fetcher";
import client from "../utils/fetcher";
import type {
	ActiveCallbacksActiveCallbacksGetQueryResponse,
	ActiveCallbacksSettingsGetQueryResponse,
	AddAllowedIpAddAllowedIpPost422,
	AddAllowedIpAddAllowedIpPostMutationRequest,
	AddAllowedIpAddAllowedIpPostMutationResponse,
	AddMcpServerV1McpServerPost422,
	AddMcpServerV1McpServerPostHeaderParams,
	AddMcpServerV1McpServerPostMutationRequest,
	AddMcpServerV1McpServerPostMutationResponse,
	AddMessagesThreadsThreadIdMessagesPost422,
	AddMessagesThreadsThreadIdMessagesPostMutationResponse,
	AddMessagesThreadsThreadIdMessagesPostPathParams,
	AddMessagesV1ThreadsThreadIdMessagesPost422,
	AddMessagesV1ThreadsThreadIdMessagesPostMutationResponse,
	AddMessagesV1ThreadsThreadIdMessagesPostPathParams,
	AddNewModelModelNewPost422,
	AddNewModelModelNewPostMutationRequest,
	AddNewModelModelNewPostMutationResponse,
	AddTeamCallbacksTeamTeamIdCallbackPost422,
	AddTeamCallbacksTeamTeamIdCallbackPostHeaderParams,
	AddTeamCallbacksTeamTeamIdCallbackPostMutationRequest,
	AddTeamCallbacksTeamTeamIdCallbackPostMutationResponse,
	AddTeamCallbacksTeamTeamIdCallbackPostPathParams,
	AnthropicResponseV1MessagesPostMutationResponse,
	ApplyGuardrailApplyGuardrailPost422,
	ApplyGuardrailApplyGuardrailPostMutationRequest,
	ApplyGuardrailApplyGuardrailPostMutationResponse,
	ApplyGuardrailGuardrailsApplyGuardrailPost422,
	ApplyGuardrailGuardrailsApplyGuardrailPostMutationRequest,
	ApplyGuardrailGuardrailsApplyGuardrailPostMutationResponse,
	AudioSpeechAudioSpeechPostMutationResponse,
	AudioSpeechV1AudioSpeechPostMutationResponse,
	AudioTranscriptionsAudioTranscriptionsPost422,
	AudioTranscriptionsAudioTranscriptionsPostMutationResponse,
	AudioTranscriptionsV1AudioTranscriptionsPost422,
	AudioTranscriptionsV1AudioTranscriptionsPostMutationResponse,
	AuthorizeAuthorizeGet422,
	AuthorizeAuthorizeGetQueryParams,
	AuthorizeAuthorizeGetQueryResponse,
	AuthorizeMcpServerNameAuthorizeGet422,
	AuthorizeMcpServerNameAuthorizeGetPathParams,
	AuthorizeMcpServerNameAuthorizeGetQueryParams,
	AuthorizeMcpServerNameAuthorizeGetQueryResponse,
	AvailableEnterpriseUsersUserAvailableUsersGetQueryResponse,
	BlockKeyKeyBlockPost422,
	BlockKeyKeyBlockPostHeaderParams,
	BlockKeyKeyBlockPostMutationRequest,
	BlockKeyKeyBlockPostMutationResponse,
	BlockTeamTeamBlockPost422,
	BlockTeamTeamBlockPostMutationRequest,
	BlockTeamTeamBlockPostMutationResponse,
	BlockUserCustomerBlockPost422,
	BlockUserCustomerBlockPostMutationRequest,
	BlockUserCustomerBlockPostMutationResponse,
	BudgetSettingsBudgetSettingsGet422,
	BudgetSettingsBudgetSettingsGetQueryParams,
	BudgetSettingsBudgetSettingsGetQueryResponse,
	BulkTeamMemberAddTeamBulkMemberAddPost422,
	BulkTeamMemberAddTeamBulkMemberAddPostMutationRequest,
	BulkTeamMemberAddTeamBulkMemberAddPostMutationResponse,
	BulkUserUpdateUserBulkUpdatePost422,
	BulkUserUpdateUserBulkUpdatePostHeaderParams,
	BulkUserUpdateUserBulkUpdatePostMutationRequest,
	BulkUserUpdateUserBulkUpdatePostMutationResponse,
	CacheDeleteCacheDeletePostMutationResponse,
	CacheFlushallCacheFlushallPostMutationResponse,
	CachePingCachePingGetQueryResponse,
	CacheRedisInfoCacheRedisInfoGetQueryResponse,
	CalculateSpendSpendCalculatePost422,
	CalculateSpendSpendCalculatePostMutationRequest,
	CalculateSpendSpendCalculatePostMutationResponse,
	CallbackCallbackGet422,
	CallbackCallbackGetQueryParams,
	CallbackCallbackGetQueryResponse,
	CallToolRestApiMcpRestToolsCallPostMutationResponse,
	CancelBatchBatchesBatchIdCancelPost422,
	CancelBatchBatchesBatchIdCancelPostMutationResponse,
	CancelBatchBatchesBatchIdCancelPostPathParams,
	CancelBatchBatchesBatchIdCancelPostQueryParams,
	CancelBatchProviderV1BatchesBatchIdCancelPost422,
	CancelBatchProviderV1BatchesBatchIdCancelPostMutationResponse,
	CancelBatchProviderV1BatchesBatchIdCancelPostPathParams,
	CancelBatchV1BatchesBatchIdCancelPost422,
	CancelBatchV1BatchesBatchIdCancelPostMutationResponse,
	CancelBatchV1BatchesBatchIdCancelPostPathParams,
	CancelBatchV1BatchesBatchIdCancelPostQueryParams,
	CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost422,
	CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostMutationResponse,
	CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams,
	CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost422,
	CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostMutationResponse,
	CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams,
	CancelResponseOpenaiV1ResponsesResponseIdCancelPost422,
	CancelResponseOpenaiV1ResponsesResponseIdCancelPostMutationResponse,
	CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams,
	CancelResponseResponsesResponseIdCancelPost422,
	CancelResponseResponsesResponseIdCancelPostMutationResponse,
	CancelResponseResponsesResponseIdCancelPostPathParams,
	CancelResponseV1ResponsesResponseIdCancelPost422,
	CancelResponseV1ResponsesResponseIdCancelPostMutationResponse,
	CancelResponseV1ResponsesResponseIdCancelPostPathParams,
	ChatCompletionChatCompletionsPost422,
	ChatCompletionChatCompletionsPostMutationRequest,
	ChatCompletionChatCompletionsPostMutationResponse,
	ChatCompletionEnginesModelChatCompletionsPost422,
	ChatCompletionEnginesModelChatCompletionsPostMutationRequest,
	ChatCompletionEnginesModelChatCompletionsPostMutationResponse,
	ChatCompletionEnginesModelChatCompletionsPostPathParams,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost400,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost401,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost403,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost404,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost408,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost422,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost429,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost500,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost503,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequest,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationResponse,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams,
	ChatCompletionV1ChatCompletionsPost422,
	ChatCompletionV1ChatCompletionsPostMutationRequest,
	ChatCompletionV1ChatCompletionsPostMutationResponse,
	CloudzeroDryRunExportCloudzeroDryRunPost422,
	CloudzeroDryRunExportCloudzeroDryRunPostMutationRequest,
	CloudzeroDryRunExportCloudzeroDryRunPostMutationResponse,
	CloudzeroExportCloudzeroExportPost422,
	CloudzeroExportCloudzeroExportPostMutationRequest,
	CloudzeroExportCloudzeroExportPostMutationResponse,
	CompletionCompletionsPost422,
	CompletionCompletionsPostMutationResponse,
	CompletionCompletionsPostQueryParams,
	CompletionEnginesModelCompletionsPost422,
	CompletionEnginesModelCompletionsPostMutationResponse,
	CompletionEnginesModelCompletionsPostPathParams,
	CompletionOpenaiDeploymentsModelCompletionsPost422,
	CompletionOpenaiDeploymentsModelCompletionsPostMutationResponse,
	CompletionOpenaiDeploymentsModelCompletionsPostPathParams,
	CompletionV1CompletionsPost422,
	CompletionV1CompletionsPostMutationResponse,
	CompletionV1CompletionsPostQueryParams,
	ConvertPromptFileToJsonUtilsDotpromptJsonConverterPost422,
	ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostMutationResponse,
	CountTokensV1MessagesCountTokensPostMutationResponse,
	CreateAssistantAssistantsPostMutationResponse,
	CreateAssistantV1AssistantsPostMutationResponse,
	CreateBatchBatchesPost422,
	CreateBatchBatchesPostMutationResponse,
	CreateBatchBatchesPostQueryParams,
	CreateBatchProviderV1BatchesPost422,
	CreateBatchProviderV1BatchesPostMutationResponse,
	CreateBatchProviderV1BatchesPostPathParams,
	CreateBatchV1BatchesPost422,
	CreateBatchV1BatchesPostMutationResponse,
	CreateBatchV1BatchesPostQueryParams,
	CreateContainerContainersPostMutationResponse,
	CreateContainerV1ContainersPostMutationResponse,
	CreateCredentialCredentialsPost422,
	CreateCredentialCredentialsPostMutationRequest,
	CreateCredentialCredentialsPostMutationResponse,
	CreateFileFilesPost422,
	CreateFileFilesPostMutationResponse,
	CreateFileFilesPostQueryParams,
	CreateFileProviderV1FilesPost422,
	CreateFileProviderV1FilesPostMutationResponse,
	CreateFileProviderV1FilesPostPathParams,
	CreateFileV1FilesPost422,
	CreateFileV1FilesPostMutationResponse,
	CreateFileV1FilesPostQueryParams,
	CreateFineTuningJobFineTuningJobsPost422,
	CreateFineTuningJobFineTuningJobsPostMutationRequest,
	CreateFineTuningJobFineTuningJobsPostMutationResponse,
	CreateFineTuningJobV1FineTuningJobsPost422,
	CreateFineTuningJobV1FineTuningJobsPostMutationRequest,
	CreateFineTuningJobV1FineTuningJobsPostMutationResponse,
	CreateGroupScimV2GroupsPost422,
	CreateGroupScimV2GroupsPostMutationRequest,
	CreateGroupScimV2GroupsPostMutationResponse,
	CreateGroupScimV2GroupsPostQueryParams,
	CreateGuardrailGuardrailsPost422,
	CreateGuardrailGuardrailsPostMutationRequest,
	CreateGuardrailGuardrailsPostMutationResponse,
	CreatePassThroughEndpointsConfigPassThroughEndpointPost422,
	CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationRequest,
	CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationResponse,
	CreatePromptPromptsPost422,
	CreatePromptPromptsPostMutationRequest,
	CreatePromptPromptsPostMutationResponse,
	CreateSearchToolSearchToolsPost422,
	CreateSearchToolSearchToolsPostMutationRequest,
	CreateSearchToolSearchToolsPostMutationResponse,
	CreateThreadsThreadsPostMutationResponse,
	CreateThreadsV1ThreadsPostMutationResponse,
	CreateUserScimV2UsersPost422,
	CreateUserScimV2UsersPostMutationRequest,
	CreateUserScimV2UsersPostMutationResponse,
	CreateUserScimV2UsersPostQueryParams,
	DeleteAllowedIpDeleteAllowedIpPost422,
	DeleteAllowedIpDeleteAllowedIpPostMutationRequest,
	DeleteAllowedIpDeleteAllowedIpPostMutationResponse,
	DeleteAssistantAssistantsAssistantIdDelete422,
	DeleteAssistantAssistantsAssistantIdDeleteMutationResponse,
	DeleteAssistantAssistantsAssistantIdDeletePathParams,
	DeleteAssistantV1AssistantsAssistantIdDelete422,
	DeleteAssistantV1AssistantsAssistantIdDeleteMutationResponse,
	DeleteAssistantV1AssistantsAssistantIdDeletePathParams,
	DeleteBudgetBudgetDeletePost422,
	DeleteBudgetBudgetDeletePostMutationRequest,
	DeleteBudgetBudgetDeletePostMutationResponse,
	DeleteContainerContainersContainerIdDelete422,
	DeleteContainerContainersContainerIdDeleteMutationResponse,
	DeleteContainerContainersContainerIdDeletePathParams,
	DeleteContainerV1ContainersContainerIdDelete422,
	DeleteContainerV1ContainersContainerIdDeleteMutationResponse,
	DeleteContainerV1ContainersContainerIdDeletePathParams,
	DeleteCredentialCredentialsCredentialNameDelete422,
	DeleteCredentialCredentialsCredentialNameDeleteMutationResponse,
	DeleteCredentialCredentialsCredentialNameDeletePathParams,
	DeleteEndUserCustomerDeletePost422,
	DeleteEndUserCustomerDeletePostMutationRequest,
	DeleteEndUserCustomerDeletePostMutationResponse,
	DeleteFileFilesFileIdDelete422,
	DeleteFileFilesFileIdDeleteMutationResponse,
	DeleteFileFilesFileIdDeletePathParams,
	DeleteFileFilesFileIdDeleteQueryParams,
	DeleteFileProviderV1FilesFileIdDelete422,
	DeleteFileProviderV1FilesFileIdDeleteMutationResponse,
	DeleteFileProviderV1FilesFileIdDeletePathParams,
	DeleteFileV1FilesFileIdDelete422,
	DeleteFileV1FilesFileIdDeleteMutationResponse,
	DeleteFileV1FilesFileIdDeletePathParams,
	DeleteFileV1FilesFileIdDeleteQueryParams,
	DeleteGroupScimV2GroupsGroupIdDelete422,
	DeleteGroupScimV2GroupsGroupIdDeleteMutationResponse,
	DeleteGroupScimV2GroupsGroupIdDeletePathParams,
	DeleteGroupScimV2GroupsGroupIdDeleteQueryParams,
	DeleteGuardrailGuardrailsGuardrailIdDelete422,
	DeleteGuardrailGuardrailsGuardrailIdDeleteMutationResponse,
	DeleteGuardrailGuardrailsGuardrailIdDeletePathParams,
	DeleteKeyFnKeyDeletePost422,
	DeleteKeyFnKeyDeletePostHeaderParams,
	DeleteKeyFnKeyDeletePostMutationRequest,
	DeleteKeyFnKeyDeletePostMutationResponse,
	DeleteModelModelDeletePost422,
	DeleteModelModelDeletePostMutationRequest,
	DeleteModelModelDeletePostMutationResponse,
	DeleteOrganizationOrganizationDeleteDelete422,
	DeleteOrganizationOrganizationDeleteDeleteMutationRequest,
	DeleteOrganizationOrganizationDeleteDeleteMutationResponse,
	DeletePassThroughEndpointsConfigPassThroughEndpointDelete422,
	DeletePassThroughEndpointsConfigPassThroughEndpointDeleteMutationResponse,
	DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams,
	DeletePromptPromptsPromptIdDelete422,
	DeletePromptPromptsPromptIdDeleteMutationResponse,
	DeletePromptPromptsPromptIdDeletePathParams,
	DeleteResponseOpenaiV1ResponsesResponseIdDelete422,
	DeleteResponseOpenaiV1ResponsesResponseIdDeleteMutationResponse,
	DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams,
	DeleteResponseResponsesResponseIdDelete422,
	DeleteResponseResponsesResponseIdDeleteMutationResponse,
	DeleteResponseResponsesResponseIdDeletePathParams,
	DeleteResponseV1ResponsesResponseIdDelete422,
	DeleteResponseV1ResponsesResponseIdDeleteMutationResponse,
	DeleteResponseV1ResponsesResponseIdDeletePathParams,
	DeleteSearchToolSearchToolsSearchToolIdDelete422,
	DeleteSearchToolSearchToolsSearchToolIdDeleteMutationResponse,
	DeleteSearchToolSearchToolsSearchToolIdDeletePathParams,
	DeleteTagTagDeletePost422,
	DeleteTagTagDeletePostMutationRequest,
	DeleteTagTagDeletePostMutationResponse,
	DeleteTeamTeamDeletePost422,
	DeleteTeamTeamDeletePostHeaderParams,
	DeleteTeamTeamDeletePostMutationRequest,
	DeleteTeamTeamDeletePostMutationResponse,
	DeleteUserScimV2UsersUserIdDelete422,
	DeleteUserScimV2UsersUserIdDeleteMutationResponse,
	DeleteUserScimV2UsersUserIdDeletePathParams,
	DeleteUserScimV2UsersUserIdDeleteQueryParams,
	DeleteUserUserDeletePost422,
	DeleteUserUserDeletePostHeaderParams,
	DeleteUserUserDeletePostMutationRequest,
	DeleteUserUserDeletePostMutationResponse,
	DeleteVectorStoreVectorStoreDeletePost422,
	DeleteVectorStoreVectorStoreDeletePostMutationRequest,
	DeleteVectorStoreVectorStoreDeletePostMutationResponse,
	DeprecatedInfoOrganizationOrganizationInfoPost422,
	DeprecatedInfoOrganizationOrganizationInfoPostMutationRequest,
	DeprecatedInfoOrganizationOrganizationInfoPostMutationResponse,
	DisableTeamLoggingTeamTeamIdDisableLoggingPost422,
	DisableTeamLoggingTeamTeamIdDisableLoggingPostMutationResponse,
	DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams,
	DynamicMcpRouteMcpServerNameMcpPatch2MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch2PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch3MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch3PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch4MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch4PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch5MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch5PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch422,
	DynamicMcpRouteMcpServerNameMcpPatch2422,
	DynamicMcpRouteMcpServerNameMcpPatch3422,
	DynamicMcpRouteMcpServerNameMcpPatch4422,
	DynamicMcpRouteMcpServerNameMcpPatch5422,
	DynamicMcpRouteMcpServerNameMcpPatchMutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatchPathParams,
	EditMcpServerV1McpServerPut422,
	EditMcpServerV1McpServerPutHeaderParams,
	EditMcpServerV1McpServerPutMutationRequest,
	EditMcpServerV1McpServerPutMutationResponse,
	EmbeddingsEmbeddingsPost422,
	EmbeddingsEmbeddingsPostMutationRequest,
	EmbeddingsEmbeddingsPostMutationResponse,
	EmbeddingsEnginesModelEmbeddingsPost422,
	EmbeddingsEnginesModelEmbeddingsPostMutationRequest,
	EmbeddingsEnginesModelEmbeddingsPostMutationResponse,
	EmbeddingsEnginesModelEmbeddingsPostPathParams,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPost422,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequest,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationResponse,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams,
	EmbeddingsV1EmbeddingsPost422,
	EmbeddingsV1EmbeddingsPostMutationRequest,
	EmbeddingsV1EmbeddingsPostMutationResponse,
	EndUserInfoCustomerInfoGet422,
	EndUserInfoCustomerInfoGetQueryParams,
	EndUserInfoCustomerInfoGetQueryResponse,
	FetchAllMcpServersV1McpServerGetQueryResponse,
	FetchMcpServerV1McpServerServerIdGet422,
	FetchMcpServerV1McpServerServerIdGetPathParams,
	FetchMcpServerV1McpServerServerIdGetQueryResponse,
	GenerateKeyFnKeyGeneratePost422,
	GenerateKeyFnKeyGeneratePostHeaderParams,
	GenerateKeyFnKeyGeneratePostMutationRequest,
	GenerateKeyFnKeyGeneratePostMutationResponse,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePost422,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParams,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequest,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationResponse,
	GetActiveTasksStatsDebugAsyncioTasksGetQueryResponse,
	GetAssistantsAssistantsGetQueryResponse,
	GetAssistantsV1AssistantsGetQueryResponse,
	GetAuditLogByIdAuditIdGet404,
	GetAuditLogByIdAuditIdGet422,
	GetAuditLogByIdAuditIdGet500,
	GetAuditLogByIdAuditIdGetPathParams,
	GetAuditLogByIdAuditIdGetQueryResponse,
	GetAuditLogsAuditGet422,
	GetAuditLogsAuditGetQueryParams,
	GetAuditLogsAuditGetQueryResponse,
	GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetQueryResponse,
	GetCacheSettingsCacheSettingsGetQueryResponse,
	GetCloudzeroSettingsCloudzeroSettingsGetQueryResponse,
	GetCostDiscountConfigConfigCostDiscountConfigGetQueryResponse,
	GetCredentialCredentialsByModelModelIdGet422,
	GetCredentialCredentialsByModelModelIdGetPathParams,
	GetCredentialCredentialsByModelModelIdGetQueryResponse,
	GetCredentialCredentialsByNameCredentialNameGet422,
	GetCredentialCredentialsByNameCredentialNameGetPathParams,
	GetCredentialCredentialsByNameCredentialNameGetQueryParams,
	GetCredentialCredentialsByNameCredentialNameGetQueryResponse,
	GetCredentialsCredentialsGetQueryResponse,
	GetDailyActiveUsersTagDauGet422,
	GetDailyActiveUsersTagDauGetQueryParams,
	GetDailyActiveUsersTagDauGetQueryResponse,
	GetDefaultTeamSettingsGetDefaultTeamSettingsGetQueryResponse,
	GetDistinctUserAgentTagsTagDistinctGetQueryResponse,
	GetEmailEventSettingsEmailEventSettingsGetQueryResponse,
	GetFileContentFilesFileIdContentGet422,
	GetFileContentFilesFileIdContentGetPathParams,
	GetFileContentFilesFileIdContentGetQueryParams,
	GetFileContentFilesFileIdContentGetQueryResponse,
	GetFileContentProviderV1FilesFileIdContentGet422,
	GetFileContentProviderV1FilesFileIdContentGetPathParams,
	GetFileContentProviderV1FilesFileIdContentGetQueryResponse,
	GetFileContentV1FilesFileIdContentGet422,
	GetFileContentV1FilesFileIdContentGetPathParams,
	GetFileContentV1FilesFileIdContentGetQueryParams,
	GetFileContentV1FilesFileIdContentGetQueryResponse,
	GetFileFilesFileIdGet422,
	GetFileFilesFileIdGetPathParams,
	GetFileFilesFileIdGetQueryParams,
	GetFileFilesFileIdGetQueryResponse,
	GetFileProviderV1FilesFileIdGet422,
	GetFileProviderV1FilesFileIdGetPathParams,
	GetFileProviderV1FilesFileIdGetQueryResponse,
	GetFileV1FilesFileIdGet422,
	GetFileV1FilesFileIdGetPathParams,
	GetFileV1FilesFileIdGetQueryParams,
	GetFileV1FilesFileIdGetQueryResponse,
	GetGlobalSpendReportGlobalSpendReportGet422,
	GetGlobalSpendReportGlobalSpendReportGetQueryParams,
	GetGlobalSpendReportGlobalSpendReportGetQueryResponse,
	GetGroupScimV2GroupsGroupIdGet422,
	GetGroupScimV2GroupsGroupIdGetPathParams,
	GetGroupScimV2GroupsGroupIdGetQueryParams,
	GetGroupScimV2GroupsGroupIdGetQueryResponse,
	GetGroupsScimV2GroupsGet422,
	GetGroupsScimV2GroupsGetQueryParams,
	GetGroupsScimV2GroupsGetQueryResponse,
	GetGuardrailInfoGuardrailsGuardrailIdGet422,
	GetGuardrailInfoGuardrailsGuardrailIdGetPathParams,
	GetGuardrailInfoGuardrailsGuardrailIdGetQueryResponse,
	GetGuardrailInfoGuardrailsGuardrailIdInfoGet422,
	GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams,
	GetGuardrailInfoGuardrailsGuardrailIdInfoGetQueryResponse,
	GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetQueryResponse,
	GetInternalUserSettingsGetInternalUserSettingsGetQueryResponse,
	GetMcpAccessGroupsV1McpAccessGroupsGetQueryResponse,
	GetMcpToolsV1McpToolsGetQueryResponse,
	GetMessagesThreadsThreadIdMessagesGet422,
	GetMessagesThreadsThreadIdMessagesGetPathParams,
	GetMessagesThreadsThreadIdMessagesGetQueryResponse,
	GetMessagesV1ThreadsThreadIdMessagesGet422,
	GetMessagesV1ThreadsThreadIdMessagesGetPathParams,
	GetMessagesV1ThreadsThreadIdMessagesGetQueryResponse,
	GetMonthlyActiveUsersTagMauGet422,
	GetMonthlyActiveUsersTagMauGetQueryParams,
	GetMonthlyActiveUsersTagMauGetQueryResponse,
	GetPassThroughEndpointsConfigPassThroughEndpointGet422,
	GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams,
	GetPassThroughEndpointsConfigPassThroughEndpointGetQueryResponse,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet422,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryResponse,
	GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGet422,
	GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams,
	GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryResponse,
	GetPromptInfoPromptsPromptIdGet422,
	GetPromptInfoPromptsPromptIdGetPathParams,
	GetPromptInfoPromptsPromptIdGetQueryResponse,
	GetPromptInfoPromptsPromptIdInfoGet422,
	GetPromptInfoPromptsPromptIdInfoGetPathParams,
	GetPromptInfoPromptsPromptIdInfoGetQueryResponse,
	GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetQueryResponse,
	GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet422,
	GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams,
	GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetQueryResponse,
	GetResponseInputItemsResponsesResponseIdInputItemsGet422,
	GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams,
	GetResponseInputItemsResponsesResponseIdInputItemsGetQueryResponse,
	GetResponseInputItemsV1ResponsesResponseIdInputItemsGet422,
	GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams,
	GetResponseInputItemsV1ResponsesResponseIdInputItemsGetQueryResponse,
	GetResponseOpenaiV1ResponsesResponseIdGet422,
	GetResponseOpenaiV1ResponsesResponseIdGetPathParams,
	GetResponseOpenaiV1ResponsesResponseIdGetQueryResponse,
	GetResponseResponsesResponseIdGet422,
	GetResponseResponsesResponseIdGetPathParams,
	GetResponseResponsesResponseIdGetQueryResponse,
	GetResponseV1ResponsesResponseIdGet422,
	GetResponseV1ResponsesResponseIdGetPathParams,
	GetResponseV1ResponsesResponseIdGetQueryResponse,
	GetRobotsRobotsTxtGetQueryResponse,
	GetRouterSettingsRouterSettingsGetQueryResponse,
	GetRoutesRoutesGetQueryResponse,
	GetSearchToolInfoSearchToolsSearchToolIdGet422,
	GetSearchToolInfoSearchToolsSearchToolIdGetPathParams,
	GetSearchToolInfoSearchToolsSearchToolIdGetQueryResponse,
	GetServiceProviderConfigScimV2ServiceProviderConfigGet422,
	GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams,
	GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryResponse,
	GetSsoSettingsGetSsoSettingsGetQueryResponse,
	GetTagDailyActivityTagDailyActivityGet422,
	GetTagDailyActivityTagDailyActivityGetQueryParams,
	GetTagDailyActivityTagDailyActivityGetQueryResponse,
	GetTagSummaryTagSummaryGet422,
	GetTagSummaryTagSummaryGetQueryParams,
	GetTagSummaryTagSummaryGetQueryResponse,
	GetTeamCallbacksTeamTeamIdCallbackGet422,
	GetTeamCallbacksTeamTeamIdCallbackGetPathParams,
	GetTeamCallbacksTeamTeamIdCallbackGetQueryResponse,
	GetTeamDailyActivityTeamDailyActivityGet422,
	GetTeamDailyActivityTeamDailyActivityGetQueryParams,
	GetTeamDailyActivityTeamDailyActivityGetQueryResponse,
	GetThreadThreadsThreadIdGet422,
	GetThreadThreadsThreadIdGetPathParams,
	GetThreadThreadsThreadIdGetQueryResponse,
	GetThreadV1ThreadsThreadIdGet422,
	GetThreadV1ThreadsThreadIdGetPathParams,
	GetThreadV1ThreadsThreadIdGetQueryResponse,
	GetUiConfigLitellmWellKnownLitellmUiConfigGetQueryResponse,
	GetUiConfigWellKnownLitellmUiConfigGetQueryResponse,
	GetUiThemeSettingsGetUiThemeSettingsGetQueryResponse,
	GetUserDailyActivityAggregatedUserDailyActivityAggregatedGet422,
	GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams,
	GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryResponse,
	GetUserDailyActivityUserDailyActivityGet422,
	GetUserDailyActivityUserDailyActivityGetQueryParams,
	GetUserDailyActivityUserDailyActivityGetQueryResponse,
	GetUserScimV2UsersUserIdGet422,
	GetUserScimV2UsersUserIdGetPathParams,
	GetUserScimV2UsersUserIdGetQueryParams,
	GetUserScimV2UsersUserIdGetQueryResponse,
	GetUsersScimV2UsersGet422,
	GetUsersScimV2UsersGetQueryParams,
	GetUsersScimV2UsersGetQueryResponse,
	GetUsersUserListGet422,
	GetUsersUserListGetQueryParams,
	GetUsersUserListGetQueryResponse,
	GetVectorStoreInfoVectorStoreInfoPost422,
	GetVectorStoreInfoVectorStoreInfoPostMutationRequest,
	GetVectorStoreInfoVectorStoreInfoPostMutationResponse,
	GetWeeklyActiveUsersTagWauGet422,
	GetWeeklyActiveUsersTagWauGetQueryParams,
	GetWeeklyActiveUsersTagWauGetQueryResponse,
	GlobalSpendResetGlobalSpendResetPostMutationResponse,
	GlobalViewSpendTagsGlobalSpendTagsGet422,
	GlobalViewSpendTagsGlobalSpendTagsGetQueryParams,
	GlobalViewSpendTagsGlobalSpendTagsGetQueryResponse,
	GoogleCountTokensModelsModelNameCountTokensPost422,
	GoogleCountTokensModelsModelNameCountTokensPostMutationResponse,
	GoogleCountTokensModelsModelNameCountTokensPostPathParams,
	GoogleCountTokensV1BetaModelsModelNameCountTokensPost422,
	GoogleCountTokensV1BetaModelsModelNameCountTokensPostMutationResponse,
	GoogleCountTokensV1BetaModelsModelNameCountTokensPostPathParams,
	GoogleGenerateContentModelsModelNameGenerateContentPost422,
	GoogleGenerateContentModelsModelNameGenerateContentPostMutationResponse,
	GoogleGenerateContentModelsModelNameGenerateContentPostPathParams,
	GoogleGenerateContentV1BetaModelsModelNameGenerateContentPost422,
	GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostMutationResponse,
	GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParams,
	GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPost422,
	GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostMutationResponse,
	GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams,
	GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost422,
	GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostMutationResponse,
	GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParams,
	HealthCheckAllMcpServersV1McpServerHealthGetQueryResponse,
	HealthCheckHistoryEndpointHealthHistoryGet422,
	HealthCheckHistoryEndpointHealthHistoryGetQueryParams,
	HealthCheckHistoryEndpointHealthHistoryGetQueryResponse,
	HealthCheckMcpServerV1McpServerServerIdHealthGet422,
	HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams,
	HealthCheckMcpServerV1McpServerServerIdHealthGetQueryResponse,
	HealthEndpointHealthGet422,
	HealthEndpointHealthGetQueryParams,
	HealthEndpointHealthGetQueryResponse,
	HealthLivelinessHealthLivelinessGetQueryResponse,
	HealthLivelinessHealthLivenessGetQueryResponse,
	HealthLivelinessOptionsHealthLivelinessOptionsMutationResponse,
	HealthLivelinessOptionsHealthLivenessOptionsMutationResponse,
	HealthReadinessHealthReadinessGetQueryResponse,
	HealthReadinessOptionsHealthReadinessOptionsMutationResponse,
	HealthServicesEndpointHealthServicesGet422,
	HealthServicesEndpointHealthServicesGetQueryParams,
	HealthServicesEndpointHealthServicesGetQueryResponse,
	HomeGetQueryResponse,
	ImageEditApiImagesEditsPost422,
	ImageEditApiImagesEditsPostMutationResponse,
	ImageEditApiImagesEditsPostQueryParams,
	ImageEditApiOpenaiDeploymentsModelImagesEditsPost422,
	ImageEditApiOpenaiDeploymentsModelImagesEditsPostMutationResponse,
	ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams,
	ImageEditApiV1ImagesEditsPost422,
	ImageEditApiV1ImagesEditsPostMutationResponse,
	ImageEditApiV1ImagesEditsPostQueryParams,
	ImageGenerationImagesGenerationsPost422,
	ImageGenerationImagesGenerationsPostMutationResponse,
	ImageGenerationImagesGenerationsPostQueryParams,
	ImageGenerationOpenaiDeploymentsModelImagesGenerationsPost422,
	ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostMutationResponse,
	ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams,
	ImageGenerationV1ImagesGenerationsPost422,
	ImageGenerationV1ImagesGenerationsPostMutationResponse,
	ImageGenerationV1ImagesGenerationsPostQueryParams,
	IndexCreateV1IndexesPost422,
	IndexCreateV1IndexesPostMutationRequest,
	IndexCreateV1IndexesPostMutationResponse,
	InfoBudgetBudgetInfoPost422,
	InfoBudgetBudgetInfoPostMutationRequest,
	InfoBudgetBudgetInfoPostMutationResponse,
	InfoKeyFnKeyInfoGet422,
	InfoKeyFnKeyInfoGetQueryParams,
	InfoKeyFnKeyInfoGetQueryResponse,
	InfoOrganizationOrganizationInfoGet422,
	InfoOrganizationOrganizationInfoGetQueryParams,
	InfoOrganizationOrganizationInfoGetQueryResponse,
	InfoTagTagInfoPost422,
	InfoTagTagInfoPostMutationRequest,
	InfoTagTagInfoPostMutationResponse,
	InitCloudzeroSettingsCloudzeroInitPost422,
	InitCloudzeroSettingsCloudzeroInitPostMutationRequest,
	InitCloudzeroSettingsCloudzeroInitPostMutationResponse,
	KeyAliasesKeyAliasesGetQueryResponse,
	KeyHealthKeyHealthPostMutationResponse,
	LatestHealthChecksEndpointHealthLatestGetQueryResponse,
	ListAvailableTeamsTeamAvailableGet422,
	ListAvailableTeamsTeamAvailableGetQueryParams,
	ListAvailableTeamsTeamAvailableGetQueryResponse,
	ListBatchesBatchesGet422,
	ListBatchesBatchesGetQueryParams,
	ListBatchesBatchesGetQueryResponse,
	ListBatchesProviderV1BatchesGet422,
	ListBatchesProviderV1BatchesGetPathParams,
	ListBatchesProviderV1BatchesGetQueryParams,
	ListBatchesProviderV1BatchesGetQueryResponse,
	ListBatchesV1BatchesGet422,
	ListBatchesV1BatchesGetQueryParams,
	ListBatchesV1BatchesGetQueryResponse,
	ListBudgetBudgetListGetQueryResponse,
	ListCallbacksCallbacksListGetQueryResponse,
	ListContainersContainersGetQueryResponse,
	ListContainersV1ContainersGetQueryResponse,
	ListEndUserCustomerListGetQueryResponse,
	ListFilesFilesGet422,
	ListFilesFilesGetQueryParams,
	ListFilesFilesGetQueryResponse,
	ListFilesProviderV1FilesGet422,
	ListFilesProviderV1FilesGetPathParams,
	ListFilesProviderV1FilesGetQueryParams,
	ListFilesProviderV1FilesGetQueryResponse,
	ListFilesV1FilesGet422,
	ListFilesV1FilesGetQueryParams,
	ListFilesV1FilesGetQueryResponse,
	ListFineTuningJobsFineTuningJobsGet422,
	ListFineTuningJobsFineTuningJobsGetQueryParams,
	ListFineTuningJobsFineTuningJobsGetQueryResponse,
	ListFineTuningJobsV1FineTuningJobsGet422,
	ListFineTuningJobsV1FineTuningJobsGetQueryParams,
	ListFineTuningJobsV1FineTuningJobsGetQueryResponse,
	ListGuardrailsGuardrailsListGetQueryResponse,
	ListGuardrailsV2V2GuardrailsListGetQueryResponse,
	ListKeysKeyListGet422,
	ListKeysKeyListGetQueryParams,
	ListKeysKeyListGetQueryResponse,
	ListOrganizationOrganizationListGetQueryResponse,
	ListPromptsPromptsListGetQueryResponse,
	ListSearchToolsSearchToolsListGetQueryResponse,
	ListTagsTagListGetQueryResponse,
	ListTeamTeamListGet422,
	ListTeamTeamListGetQueryParams,
	ListTeamTeamListGetQueryResponse,
	ListTeamV2V2TeamListGet422,
	ListTeamV2V2TeamListGetQueryParams,
	ListTeamV2V2TeamListGetQueryResponse,
	ListToolRestApiMcpRestToolsListGet422,
	ListToolRestApiMcpRestToolsListGetQueryParams,
	ListToolRestApiMcpRestToolsListGetQueryResponse,
	ListVectorStoresVectorStoreListGet422,
	ListVectorStoresVectorStoreListGetQueryParams,
	ListVectorStoresVectorStoreListGetQueryResponse,
	ModelGroupInfoModelGroupInfoGet422,
	ModelGroupInfoModelGroupInfoGetQueryParams,
	ModelGroupInfoModelGroupInfoGetQueryResponse,
	ModelInfoModelsModelIdGet422,
	ModelInfoModelsModelIdGetPathParams,
	ModelInfoModelsModelIdGetQueryResponse,
	ModelInfoV1ModelInfoGet422,
	ModelInfoV1ModelInfoGetQueryParams,
	ModelInfoV1ModelInfoGetQueryResponse,
	ModelInfoV1ModelsModelIdGet422,
	ModelInfoV1ModelsModelIdGetPathParams,
	ModelInfoV1ModelsModelIdGetQueryResponse,
	ModelInfoV1V1ModelInfoGet422,
	ModelInfoV1V1ModelInfoGetQueryParams,
	ModelInfoV1V1ModelInfoGetQueryResponse,
	ModelListModelsGet422,
	ModelListModelsGetQueryParams,
	ModelListModelsGetQueryResponse,
	ModelListV1ModelsGet422,
	ModelListV1ModelsGetQueryParams,
	ModelListV1ModelsGetQueryResponse,
	ModerationsModerationsPostMutationResponse,
	ModerationsV1ModerationsPostMutationResponse,
	NewBudgetBudgetNewPost422,
	NewBudgetBudgetNewPostMutationRequest,
	NewBudgetBudgetNewPostMutationResponse,
	NewEndUserCustomerNewPost422,
	NewEndUserCustomerNewPostMutationRequest,
	NewEndUserCustomerNewPostMutationResponse,
	NewOrganizationOrganizationNewPost422,
	NewOrganizationOrganizationNewPostMutationRequest,
	NewOrganizationOrganizationNewPostMutationResponse,
	NewTagTagNewPost422,
	NewTagTagNewPostMutationRequest,
	NewTagTagNewPostMutationResponse,
	NewTeamTeamNewPost422,
	NewTeamTeamNewPostHeaderParams,
	NewTeamTeamNewPostMutationRequest,
	NewTeamTeamNewPostMutationResponse,
	NewUserUserNewPost422,
	NewUserUserNewPostMutationRequest,
	NewUserUserNewPostMutationResponse,
	NewVectorStoreVectorStoreNewPost422,
	NewVectorStoreVectorStoreNewPostMutationRequest,
	NewVectorStoreVectorStoreNewPostMutationResponse,
	OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet422,
	OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams,
	OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetQueryResponse,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet422,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryResponse,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet422,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetQueryResponse,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceGet422,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryResponse,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet422,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetQueryResponse,
	OcrOcrPostMutationResponse,
	OcrV1OcrPostMutationResponse,
	OpenidConfigurationWellKnownOpenidConfigurationGetQueryResponse,
	OrganizationMemberAddOrganizationMemberAddPost422,
	OrganizationMemberAddOrganizationMemberAddPostMutationRequest,
	OrganizationMemberAddOrganizationMemberAddPostMutationResponse,
	OrganizationMemberDeleteOrganizationMemberDeleteDelete422,
	OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequest,
	OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationResponse,
	OrganizationMemberUpdateOrganizationMemberUpdatePatch422,
	OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationRequest,
	OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationResponse,
	PatchGroupScimV2GroupsGroupIdPatch422,
	PatchGroupScimV2GroupsGroupIdPatchMutationRequest,
	PatchGroupScimV2GroupsGroupIdPatchMutationResponse,
	PatchGroupScimV2GroupsGroupIdPatchPathParams,
	PatchGroupScimV2GroupsGroupIdPatchQueryParams,
	PatchGuardrailGuardrailsGuardrailIdPatch422,
	PatchGuardrailGuardrailsGuardrailIdPatchMutationRequest,
	PatchGuardrailGuardrailsGuardrailIdPatchMutationResponse,
	PatchGuardrailGuardrailsGuardrailIdPatchPathParams,
	PatchModelModelModelIdUpdatePatch422,
	PatchModelModelModelIdUpdatePatchMutationRequest,
	PatchModelModelModelIdUpdatePatchMutationResponse,
	PatchModelModelModelIdUpdatePatchPathParams,
	PatchPromptPromptsPromptIdPatch422,
	PatchPromptPromptsPromptIdPatchMutationRequest,
	PatchPromptPromptsPromptIdPatchMutationResponse,
	PatchPromptPromptsPromptIdPatchPathParams,
	PatchUserScimV2UsersUserIdPatch422,
	PatchUserScimV2UsersUserIdPatchMutationRequest,
	PatchUserScimV2UsersUserIdPatchMutationResponse,
	PatchUserScimV2UsersUserIdPatchPathParams,
	PatchUserScimV2UsersUserIdPatchQueryParams,
	ProviderBudgetsProviderBudgetsGetQueryResponse,
	PublicModelHubInfoPublicModelHubInfoGetQueryResponse,
	PublicModelHubPublicModelHubGetQueryResponse,
	RegenerateKeyFnKeyKeyRegeneratePost422,
	RegenerateKeyFnKeyKeyRegeneratePostHeaderParams,
	RegenerateKeyFnKeyKeyRegeneratePostMutationRequest,
	RegenerateKeyFnKeyKeyRegeneratePostMutationResponse,
	RegenerateKeyFnKeyKeyRegeneratePostPathParams,
	RegenerateKeyFnKeyRegeneratePost422,
	RegenerateKeyFnKeyRegeneratePostHeaderParams,
	RegenerateKeyFnKeyRegeneratePostMutationRequest,
	RegenerateKeyFnKeyRegeneratePostMutationResponse,
	RegenerateKeyFnKeyRegeneratePostQueryParams,
	RegisterClientMcpServerNameRegisterPost422,
	RegisterClientMcpServerNameRegisterPostMutationResponse,
	RegisterClientMcpServerNameRegisterPostPathParams,
	RegisterClientRegisterPost422,
	RegisterClientRegisterPostMutationResponse,
	RegisterClientRegisterPostQueryParams,
	RemoveMcpServerV1McpServerServerIdDelete422,
	RemoveMcpServerV1McpServerServerIdDeleteHeaderParams,
	RemoveMcpServerV1McpServerServerIdDeleteMutationResponse,
	RemoveMcpServerV1McpServerServerIdDeletePathParams,
	RerankRerankPostMutationResponse,
	RerankV1RerankPostMutationResponse,
	RerankV2RerankPostMutationResponse,
	ResetEventSettingsEmailEventSettingsResetPostMutationResponse,
	ResponsesApiOpenaiV1ResponsesPostMutationResponse,
	ResponsesApiResponsesPostMutationResponse,
	ResponsesApiV1ResponsesPostMutationResponse,
	RetrieveBatchBatchesBatchIdGet422,
	RetrieveBatchBatchesBatchIdGetPathParams,
	RetrieveBatchBatchesBatchIdGetQueryParams,
	RetrieveBatchBatchesBatchIdGetQueryResponse,
	RetrieveBatchProviderV1BatchesBatchIdGet422,
	RetrieveBatchProviderV1BatchesBatchIdGetPathParams,
	RetrieveBatchProviderV1BatchesBatchIdGetQueryResponse,
	RetrieveBatchV1BatchesBatchIdGet422,
	RetrieveBatchV1BatchesBatchIdGetPathParams,
	RetrieveBatchV1BatchesBatchIdGetQueryParams,
	RetrieveBatchV1BatchesBatchIdGetQueryResponse,
	RetrieveContainerContainersContainerIdGet422,
	RetrieveContainerContainersContainerIdGetPathParams,
	RetrieveContainerContainersContainerIdGetQueryResponse,
	RetrieveContainerV1ContainersContainerIdGet422,
	RetrieveContainerV1ContainersContainerIdGetPathParams,
	RetrieveContainerV1ContainersContainerIdGetQueryResponse,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGet422,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryResponse,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet422,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryResponse,
	RunThreadThreadsThreadIdRunsPost422,
	RunThreadThreadsThreadIdRunsPostMutationResponse,
	RunThreadThreadsThreadIdRunsPostPathParams,
	RunThreadV1ThreadsThreadIdRunsPost422,
	RunThreadV1ThreadsThreadIdRunsPostMutationResponse,
	RunThreadV1ThreadsThreadIdRunsPostPathParams,
	SearchSearchPost422,
	SearchSearchPostMutationResponse,
	SearchSearchPostQueryParams,
	SearchSearchSearchToolNamePost422,
	SearchSearchSearchToolNamePostMutationResponse,
	SearchSearchSearchToolNamePostPathParams,
	SearchV1SearchPost422,
	SearchV1SearchPostMutationResponse,
	SearchV1SearchPostQueryParams,
	SearchV1SearchSearchToolNamePost422,
	SearchV1SearchSearchToolNamePostMutationResponse,
	SearchV1SearchSearchToolNamePostPathParams,
	SharedHealthCheckStatusEndpointHealthSharedStatusGetQueryResponse,
	SupportedOpenaiParamsUtilsSupportedOpenaiParamsGet422,
	SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams,
	SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryResponse,
	TeamInfoTeamInfoGet422,
	TeamInfoTeamInfoGetQueryParams,
	TeamInfoTeamInfoGetQueryResponse,
	TeamMemberAddTeamMemberAddPost422,
	TeamMemberAddTeamMemberAddPostMutationRequest,
	TeamMemberAddTeamMemberAddPostMutationResponse,
	TeamMemberDeleteTeamMemberDeletePost422,
	TeamMemberDeleteTeamMemberDeletePostMutationRequest,
	TeamMemberDeleteTeamMemberDeletePostMutationResponse,
	TeamMemberPermissionsTeamPermissionsListGet422,
	TeamMemberPermissionsTeamPermissionsListGetQueryParams,
	TeamMemberPermissionsTeamPermissionsListGetQueryResponse,
	TeamMemberUpdateTeamMemberUpdatePost422,
	TeamMemberUpdateTeamMemberUpdatePostMutationRequest,
	TeamMemberUpdateTeamMemberUpdatePostMutationResponse,
	TeamModelAddTeamModelAddPost422,
	TeamModelAddTeamModelAddPostMutationRequest,
	TeamModelAddTeamModelAddPostMutationResponse,
	TeamModelDeleteTeamModelDeletePost422,
	TeamModelDeleteTeamModelDeletePostMutationRequest,
	TeamModelDeleteTeamModelDeletePostMutationResponse,
	TestCacheConnectionCacheSettingsTestPost422,
	TestCacheConnectionCacheSettingsTestPostMutationRequest,
	TestCacheConnectionCacheSettingsTestPostMutationResponse,
	TestConnectionMcpRestTestConnectionPost422,
	TestConnectionMcpRestTestConnectionPostMutationRequest,
	TestConnectionMcpRestTestConnectionPostMutationResponse,
	TestEndpointTestGetQueryResponse,
	TestModelConnectionHealthTestConnectionPost422,
	TestModelConnectionHealthTestConnectionPostMutationRequest,
	TestModelConnectionHealthTestConnectionPostMutationResponse,
	TestSearchToolConnectionSearchToolsTestConnectionPost422,
	TestSearchToolConnectionSearchToolsTestConnectionPostMutationRequest,
	TestSearchToolConnectionSearchToolsTestConnectionPostMutationResponse,
	TestToolsListMcpRestTestToolsListPost422,
	TestToolsListMcpRestTestToolsListPostMutationRequest,
	TestToolsListMcpRestTestToolsListPostMutationResponse,
	TokenCounterUtilsTokenCounterPost422,
	TokenCounterUtilsTokenCounterPostMutationRequest,
	TokenCounterUtilsTokenCounterPostMutationResponse,
	TokenCounterUtilsTokenCounterPostQueryParams,
	TokenEndpointMcpServerNameTokenPost422,
	TokenEndpointMcpServerNameTokenPostMutationResponse,
	TokenEndpointMcpServerNameTokenPostPathParams,
	TokenEndpointTokenPost422,
	TokenEndpointTokenPostMutationResponse,
	TokenEndpointTokenPostQueryParams,
	TransformRequestUtilsTransformRequestPost422,
	TransformRequestUtilsTransformRequestPostMutationRequest,
	TransformRequestUtilsTransformRequestPostMutationResponse,
	UnblockKeyKeyUnblockPost422,
	UnblockKeyKeyUnblockPostHeaderParams,
	UnblockKeyKeyUnblockPostMutationRequest,
	UnblockKeyKeyUnblockPostMutationResponse,
	UnblockTeamTeamUnblockPost422,
	UnblockTeamTeamUnblockPostMutationRequest,
	UnblockTeamTeamUnblockPostMutationResponse,
	UnblockUserCustomerUnblockPost422,
	UnblockUserCustomerUnblockPostMutationRequest,
	UnblockUserCustomerUnblockPostMutationResponse,
	UpdateBudgetBudgetUpdatePost422,
	UpdateBudgetBudgetUpdatePostMutationRequest,
	UpdateBudgetBudgetUpdatePostMutationResponse,
	UpdateCacheSettingsCacheSettingsPost422,
	UpdateCacheSettingsCacheSettingsPostMutationRequest,
	UpdateCacheSettingsCacheSettingsPostMutationResponse,
	UpdateCloudzeroSettingsCloudzeroSettingsPut422,
	UpdateCloudzeroSettingsCloudzeroSettingsPutMutationRequest,
	UpdateCloudzeroSettingsCloudzeroSettingsPutMutationResponse,
	UpdateCostDiscountConfigConfigCostDiscountConfigPatch422,
	UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequest,
	UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationResponse,
	UpdateCredentialCredentialsCredentialNamePatch422,
	UpdateCredentialCredentialsCredentialNamePatchMutationRequest,
	UpdateCredentialCredentialsCredentialNamePatchMutationResponse,
	UpdateCredentialCredentialsCredentialNamePatchPathParams,
	UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch422,
	UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequest,
	UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationResponse,
	UpdateEndUserCustomerUpdatePost422,
	UpdateEndUserCustomerUpdatePostMutationRequest,
	UpdateEndUserCustomerUpdatePostMutationResponse,
	UpdateEventSettingsEmailEventSettingsPatch422,
	UpdateEventSettingsEmailEventSettingsPatchMutationRequest,
	UpdateEventSettingsEmailEventSettingsPatchMutationResponse,
	UpdateGroupScimV2GroupsGroupIdPut422,
	UpdateGroupScimV2GroupsGroupIdPutMutationRequest,
	UpdateGroupScimV2GroupsGroupIdPutMutationResponse,
	UpdateGroupScimV2GroupsGroupIdPutPathParams,
	UpdateGroupScimV2GroupsGroupIdPutQueryParams,
	UpdateGuardrailGuardrailsGuardrailIdPut422,
	UpdateGuardrailGuardrailsGuardrailIdPutMutationRequest,
	UpdateGuardrailGuardrailsGuardrailIdPutMutationResponse,
	UpdateGuardrailGuardrailsGuardrailIdPutPathParams,
	UpdateInternalUserSettingsUpdateInternalUserSettingsPatch422,
	UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequest,
	UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationResponse,
	UpdateKeyFnKeyUpdatePost422,
	UpdateKeyFnKeyUpdatePostHeaderParams,
	UpdateKeyFnKeyUpdatePostMutationRequest,
	UpdateKeyFnKeyUpdatePostMutationResponse,
	UpdateModelModelUpdatePost422,
	UpdateModelModelUpdatePostMutationRequest,
	UpdateModelModelUpdatePostMutationResponse,
	UpdateOrganizationOrganizationUpdatePatchMutationResponse,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost422,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequest,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationResponse,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams,
	UpdatePromptPromptsPromptIdPut422,
	UpdatePromptPromptsPromptIdPutMutationRequest,
	UpdatePromptPromptsPromptIdPutMutationResponse,
	UpdatePromptPromptsPromptIdPutPathParams,
	UpdatePublicModelGroupsModelGroupMakePublicPost422,
	UpdatePublicModelGroupsModelGroupMakePublicPostMutationRequest,
	UpdatePublicModelGroupsModelGroupMakePublicPostMutationResponse,
	UpdateSearchToolSearchToolsSearchToolIdPut422,
	UpdateSearchToolSearchToolsSearchToolIdPutMutationRequest,
	UpdateSearchToolSearchToolsSearchToolIdPutMutationResponse,
	UpdateSearchToolSearchToolsSearchToolIdPutPathParams,
	UpdateSsoSettingsUpdateSsoSettingsPatch422,
	UpdateSsoSettingsUpdateSsoSettingsPatchMutationRequest,
	UpdateSsoSettingsUpdateSsoSettingsPatchMutationResponse,
	UpdateTagTagUpdatePost422,
	UpdateTagTagUpdatePostMutationRequest,
	UpdateTagTagUpdatePostMutationResponse,
	UpdateTeamMemberPermissionsTeamPermissionsUpdatePost422,
	UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequest,
	UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationResponse,
	UpdateTeamTeamUpdatePost422,
	UpdateTeamTeamUpdatePostHeaderParams,
	UpdateTeamTeamUpdatePostMutationRequest,
	UpdateTeamTeamUpdatePostMutationResponse,
	UpdateUiThemeSettingsUpdateUiThemeSettingsPatch422,
	UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequest,
	UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationResponse,
	UpdateUsefulLinksModelHubUpdateUsefulLinksPost422,
	UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequest,
	UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationResponse,
	UpdateUserScimV2UsersUserIdPut422,
	UpdateUserScimV2UsersUserIdPutMutationRequest,
	UpdateUserScimV2UsersUserIdPutMutationResponse,
	UpdateUserScimV2UsersUserIdPutPathParams,
	UpdateUserScimV2UsersUserIdPutQueryParams,
	UpdateVectorStoreVectorStoreUpdatePost422,
	UpdateVectorStoreVectorStoreUpdatePostMutationRequest,
	UpdateVectorStoreVectorStoreUpdatePostMutationResponse,
	UploadLogoUploadLogoPost422,
	UploadLogoUploadLogoPostMutationResponse,
	UserInfoUserInfoGet422,
	UserInfoUserInfoGetQueryParams,
	UserInfoUserInfoGetQueryResponse,
	UserUpdateUserUpdatePost422,
	UserUpdateUserUpdatePostMutationRequest,
	UserUpdateUserUpdatePostMutationResponse,
	ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost422,
	ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequest,
	ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationResponse,
	VectorStoreCreateV1VectorStoresPostMutationResponse,
	VectorStoreCreateVectorStoresPostMutationResponse,
	VectorStoreSearchV1VectorStoresVectorStoreIdSearchPost422,
	VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostMutationResponse,
	VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams,
	VectorStoreSearchVectorStoresVectorStoreIdSearchPost422,
	VectorStoreSearchVectorStoresVectorStoreIdSearchPostMutationResponse,
	VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams,
	VideoContentV1VideosVideoIdContentGet422,
	VideoContentV1VideosVideoIdContentGetPathParams,
	VideoContentV1VideosVideoIdContentGetQueryResponse,
	VideoContentVideosVideoIdContentGet422,
	VideoContentVideosVideoIdContentGetPathParams,
	VideoContentVideosVideoIdContentGetQueryResponse,
	VideoGenerationV1VideosPost422,
	VideoGenerationV1VideosPostMutationResponse,
	VideoGenerationVideosPost422,
	VideoGenerationVideosPostMutationResponse,
	VideoListV1VideosGetQueryResponse,
	VideoListVideosGetQueryResponse,
	VideoRemixV1VideosVideoIdRemixPost422,
	VideoRemixV1VideosVideoIdRemixPostMutationResponse,
	VideoRemixV1VideosVideoIdRemixPostPathParams,
	VideoRemixVideosVideoIdRemixPost422,
	VideoRemixVideosVideoIdRemixPostMutationResponse,
	VideoRemixVideosVideoIdRemixPostPathParams,
	VideoStatusV1VideosVideoIdGet422,
	VideoStatusV1VideosVideoIdGetPathParams,
	VideoStatusV1VideosVideoIdGetQueryResponse,
	VideoStatusVideosVideoIdGet422,
	VideoStatusVideosVideoIdGetPathParams,
	VideoStatusVideosVideoIdGetQueryResponse,
	ViewSpendLogsSpendLogsGet422,
	ViewSpendLogsSpendLogsGetQueryParams,
	ViewSpendLogsSpendLogsGetQueryResponse,
	ViewSpendTagsSpendTagsGet422,
	ViewSpendTagsSpendTagsGetQueryParams,
	ViewSpendTagsSpendTagsGetQueryResponse,
	WebsocketVertexAiLivePassthroughEndpointQueryParams,
	WebsocketVertexAiLivePassthroughEndpointQueryResponse,
	WebsocketWebsocketEndpoint2QueryParams,
	WebsocketWebsocketEndpoint2QueryResponse,
	WebsocketWebsocketEndpointQueryParams,
	WebsocketWebsocketEndpointQueryResponse,
} from "./types";

/**
 * @description Use `/model/info` - to get detailed model information, example - pricing, mode, etc.This is just for compatibility with openai projects like aider.Query Parameters:- include_metadata: Include additional metadata in the response with fallback information- fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")                Defaults to "general" when include_metadata=true
 * @summary Model List
 * {@link /models}
 */
export async function modelListModelsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelListModelsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelListModelsGetQueryResponse,
		ErrorWrapper<ModelListModelsGet422>,
		null,
		Record<string, string>,
		ModelListModelsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/models`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Use `/model/info` - to get detailed model information, example - pricing, mode, etc.This is just for compatibility with openai projects like aider.Query Parameters:- include_metadata: Include additional metadata in the response with fallback information- fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")                Defaults to "general" when include_metadata=true
 * @summary Model List
 * {@link /v1/models}
 */
export async function modelListV1ModelsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelListV1ModelsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelListV1ModelsGetQueryResponse,
		ErrorWrapper<ModelListV1ModelsGet422>,
		null,
		Record<string, string>,
		ModelListV1ModelsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/models`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Retrieve information about a specific model accessible to your API key.Returns model details only if the model is available to your API key/team.Returns 404 if the model doesn't exist or is not accessible.Follows OpenAI API specification for individual model retrieval.https://platform.openai.com/docs/api-reference/models/retrieve
 * @summary Model Info
 * {@link /models/:model_id}
 */
export async function modelInfoModelsModelIdGet({
	pathParams,
	config = {},
}: {
	pathParams: ModelInfoModelsModelIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		ModelInfoModelsModelIdGetQueryResponse,
		ErrorWrapper<ModelInfoModelsModelIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ModelInfoModelsModelIdGetPathParams
	>({ method: "GET", url: `/models/${pathParams["model_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Retrieve information about a specific model accessible to your API key.Returns model details only if the model is available to your API key/team.Returns 404 if the model doesn't exist or is not accessible.Follows OpenAI API specification for individual model retrieval.https://platform.openai.com/docs/api-reference/models/retrieve
 * @summary Model Info
 * {@link /v1/models/:model_id}
 */
export async function modelInfoV1ModelsModelIdGet({
	pathParams,
	config = {},
}: {
	pathParams: ModelInfoV1ModelsModelIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		ModelInfoV1ModelsModelIdGetQueryResponse,
		ErrorWrapper<ModelInfoV1ModelsModelIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ModelInfoV1ModelsModelIdGetPathParams
	>({ method: "GET", url: `/v1/models/${pathParams["model_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /openai/deployments/:model/chat/completions}
 */
export async function chatCompletionOpenaiDeploymentsModelChatCompletionsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams;
	body: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationResponse,
		ErrorWrapper<
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost400
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost401
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost403
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost404
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost408
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost422
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost429
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost500
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost503
		>,
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/chat/completions`,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /engines/:model/chat/completions}
 */
export async function chatCompletionEnginesModelChatCompletionsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: ChatCompletionEnginesModelChatCompletionsPostPathParams;
	body: ChatCompletionEnginesModelChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		ChatCompletionEnginesModelChatCompletionsPostMutationResponse,
		ErrorWrapper<ChatCompletionEnginesModelChatCompletionsPost422>,
		ChatCompletionEnginesModelChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		ChatCompletionEnginesModelChatCompletionsPostPathParams
	>({
		method: "POST",
		url: `/engines/${pathParams["model"]}/chat/completions`,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /chat/completions}
 */
export async function chatCompletionChatCompletionsPost({
	body,
	config = {},
}: {
	body: ChatCompletionChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ChatCompletionChatCompletionsPostMutationResponse,
		ErrorWrapper<ChatCompletionChatCompletionsPost422>,
		ChatCompletionChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/chat/completions`, body, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /v1/chat/completions}
 */
export async function chatCompletionV1ChatCompletionsPost({
	body,
	config = {},
}: {
	body: ChatCompletionV1ChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ChatCompletionV1ChatCompletionsPostMutationResponse,
		ErrorWrapper<ChatCompletionV1ChatCompletionsPost422>,
		ChatCompletionV1ChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/chat/completions`, body, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /openai/deployments/:model/completions}
 */
export async function completionOpenaiDeploymentsModelCompletionsPost({
	pathParams,
	config = {},
}: {
	pathParams: CompletionOpenaiDeploymentsModelCompletionsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		CompletionOpenaiDeploymentsModelCompletionsPostMutationResponse,
		ErrorWrapper<CompletionOpenaiDeploymentsModelCompletionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CompletionOpenaiDeploymentsModelCompletionsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/completions`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /engines/:model/completions}
 */
export async function completionEnginesModelCompletionsPost({
	pathParams,
	config = {},
}: {
	pathParams: CompletionEnginesModelCompletionsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		CompletionEnginesModelCompletionsPostMutationResponse,
		ErrorWrapper<CompletionEnginesModelCompletionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CompletionEnginesModelCompletionsPostPathParams
	>({ method: "POST", url: `/engines/${pathParams["model"]}/completions`, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /completions}
 */
export async function completionCompletionsPost({
	queryParams,
	config = {},
}: {
	queryParams?: CompletionCompletionsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CompletionCompletionsPostMutationResponse,
		ErrorWrapper<CompletionCompletionsPost422>,
		null,
		Record<string, string>,
		CompletionCompletionsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/completions`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /v1/completions}
 */
export async function completionV1CompletionsPost({
	queryParams,
	config = {},
}: {
	queryParams?: CompletionV1CompletionsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CompletionV1CompletionsPostMutationResponse,
		ErrorWrapper<CompletionV1CompletionsPost422>,
		null,
		Record<string, string>,
		CompletionV1CompletionsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/completions`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /openai/deployments/:model/embeddings}
 */
export async function embeddingsOpenaiDeploymentsModelEmbeddingsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams;
	body: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsOpenaiDeploymentsModelEmbeddingsPost422>,
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/embeddings`,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /engines/:model/embeddings}
 */
export async function embeddingsEnginesModelEmbeddingsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: EmbeddingsEnginesModelEmbeddingsPostPathParams;
	body: EmbeddingsEnginesModelEmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		EmbeddingsEnginesModelEmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsEnginesModelEmbeddingsPost422>,
		EmbeddingsEnginesModelEmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		EmbeddingsEnginesModelEmbeddingsPostPathParams
	>({ method: "POST", url: `/engines/${pathParams["model"]}/embeddings`, body, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /embeddings}
 */
export async function embeddingsEmbeddingsPost({
	body,
	config = {},
}: {
	body: EmbeddingsEmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EmbeddingsEmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsEmbeddingsPost422>,
		EmbeddingsEmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/embeddings`, body, ...requestConfig });
	return data;
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /v1/embeddings}
 */
export async function embeddingsV1EmbeddingsPost({
	body,
	config = {},
}: {
	body: EmbeddingsV1EmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EmbeddingsV1EmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsV1EmbeddingsPost422>,
		EmbeddingsV1EmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/embeddings`, body, ...requestConfig });
	return data;
}

/**
 * @description The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.Quick Start```curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'```
 * @summary Moderations
 * {@link /moderations}
 */
export async function moderationsModerationsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModerationsModerationsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/moderations`, ...requestConfig });
	return data;
}

/**
 * @description The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.Quick Start```curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'```
 * @summary Moderations
 * {@link /v1/moderations}
 */
export async function moderationsV1ModerationsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModerationsV1ModerationsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/moderations`, ...requestConfig });
	return data;
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createSpeech
 * @summary Audio Speech
 * {@link /audio/speech}
 */
export async function audioSpeechAudioSpeechPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AudioSpeechAudioSpeechPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/audio/speech`, ...requestConfig });
	return data;
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createSpeech
 * @summary Audio Speech
 * {@link /v1/audio/speech}
 */
export async function audioSpeechV1AudioSpeechPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AudioSpeechV1AudioSpeechPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/audio/speech`, ...requestConfig });
	return data;
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 * @summary Audio Transcriptions
 * {@link /audio/transcriptions}
 */
export async function audioTranscriptionsAudioTranscriptionsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		AudioTranscriptionsAudioTranscriptionsPostMutationResponse,
		ErrorWrapper<AudioTranscriptionsAudioTranscriptionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/audio/transcriptions`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 * @summary Audio Transcriptions
 * {@link /v1/audio/transcriptions}
 */
export async function audioTranscriptionsV1AudioTranscriptionsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		AudioTranscriptionsV1AudioTranscriptionsPostMutationResponse,
		ErrorWrapper<AudioTranscriptionsV1AudioTranscriptionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/audio/transcriptions`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Returns a list of assistants.API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 * @summary Get Assistants
 * {@link /assistants}
 */
export async function getAssistantsAssistantsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAssistantsAssistantsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/assistants`, ...requestConfig });
	return data;
}

/**
 * @description Create assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Create Assistant
 * {@link /assistants}
 */
export async function createAssistantAssistantsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateAssistantAssistantsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/assistants`, ...requestConfig });
	return data;
}

/**
 * @description Returns a list of assistants.API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 * @summary Get Assistants
 * {@link /v1/assistants}
 */
export async function getAssistantsV1AssistantsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAssistantsV1AssistantsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/assistants`, ...requestConfig });
	return data;
}

/**
 * @description Create assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Create Assistant
 * {@link /v1/assistants}
 */
export async function createAssistantV1AssistantsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateAssistantV1AssistantsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/assistants`, ...requestConfig });
	return data;
}

/**
 * @description Delete assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Delete Assistant
 * {@link /assistants/:assistant_id}
 */
export async function deleteAssistantAssistantsAssistantIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteAssistantAssistantsAssistantIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["assistant_id"]) {
		throw new Error(`Missing required path parameter: assistant_id`);
	}
	const data = await request<
		DeleteAssistantAssistantsAssistantIdDeleteMutationResponse,
		ErrorWrapper<DeleteAssistantAssistantsAssistantIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteAssistantAssistantsAssistantIdDeletePathParams
	>({ method: "DELETE", url: `/assistants/${pathParams["assistant_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Delete assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Delete Assistant
 * {@link /v1/assistants/:assistant_id}
 */
export async function deleteAssistantV1AssistantsAssistantIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteAssistantV1AssistantsAssistantIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["assistant_id"]) {
		throw new Error(`Missing required path parameter: assistant_id`);
	}
	const data = await request<
		DeleteAssistantV1AssistantsAssistantIdDeleteMutationResponse,
		ErrorWrapper<DeleteAssistantV1AssistantsAssistantIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteAssistantV1AssistantsAssistantIdDeletePathParams
	>({ method: "DELETE", url: `/v1/assistants/${pathParams["assistant_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Create a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 * @summary Create Threads
 * {@link /threads}
 */
export async function createThreadsThreadsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateThreadsThreadsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/threads`, ...requestConfig });
	return data;
}

/**
 * @description Create a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 * @summary Create Threads
 * {@link /v1/threads}
 */
export async function createThreadsV1ThreadsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateThreadsV1ThreadsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/threads`, ...requestConfig });
	return data;
}

/**
 * @description Retrieves a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 * @summary Get Thread
 * {@link /threads/:thread_id}
 */
export async function getThreadThreadsThreadIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetThreadThreadsThreadIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetThreadThreadsThreadIdGetQueryResponse,
		ErrorWrapper<GetThreadThreadsThreadIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetThreadThreadsThreadIdGetPathParams
	>({ method: "GET", url: `/threads/${pathParams["thread_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Retrieves a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 * @summary Get Thread
 * {@link /v1/threads/:thread_id}
 */
export async function getThreadV1ThreadsThreadIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetThreadV1ThreadsThreadIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetThreadV1ThreadsThreadIdGetQueryResponse,
		ErrorWrapper<GetThreadV1ThreadsThreadIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetThreadV1ThreadsThreadIdGetPathParams
	>({ method: "GET", url: `/v1/threads/${pathParams["thread_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Create a message.API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 * @summary Add Messages
 * {@link /threads/:thread_id/messages}
 */
export async function addMessagesThreadsThreadIdMessagesPost({
	pathParams,
	config = {},
}: {
	pathParams: AddMessagesThreadsThreadIdMessagesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		AddMessagesThreadsThreadIdMessagesPostMutationResponse,
		ErrorWrapper<AddMessagesThreadsThreadIdMessagesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		AddMessagesThreadsThreadIdMessagesPostPathParams
	>({ method: "POST", url: `/threads/${pathParams["thread_id"]}/messages`, ...requestConfig });
	return data;
}

/**
 * @description Returns a list of messages for a given thread.API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 * @summary Get Messages
 * {@link /threads/:thread_id/messages}
 */
export async function getMessagesThreadsThreadIdMessagesGet({
	pathParams,
	config = {},
}: {
	pathParams: GetMessagesThreadsThreadIdMessagesGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetMessagesThreadsThreadIdMessagesGetQueryResponse,
		ErrorWrapper<GetMessagesThreadsThreadIdMessagesGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetMessagesThreadsThreadIdMessagesGetPathParams
	>({ method: "GET", url: `/threads/${pathParams["thread_id"]}/messages`, ...requestConfig });
	return data;
}

/**
 * @description Create a message.API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 * @summary Add Messages
 * {@link /v1/threads/:thread_id/messages}
 */
export async function addMessagesV1ThreadsThreadIdMessagesPost({
	pathParams,
	config = {},
}: {
	pathParams: AddMessagesV1ThreadsThreadIdMessagesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		AddMessagesV1ThreadsThreadIdMessagesPostMutationResponse,
		ErrorWrapper<AddMessagesV1ThreadsThreadIdMessagesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		AddMessagesV1ThreadsThreadIdMessagesPostPathParams
	>({ method: "POST", url: `/v1/threads/${pathParams["thread_id"]}/messages`, ...requestConfig });
	return data;
}

/**
 * @description Returns a list of messages for a given thread.API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 * @summary Get Messages
 * {@link /v1/threads/:thread_id/messages}
 */
export async function getMessagesV1ThreadsThreadIdMessagesGet({
	pathParams,
	config = {},
}: {
	pathParams: GetMessagesV1ThreadsThreadIdMessagesGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetMessagesV1ThreadsThreadIdMessagesGetQueryResponse,
		ErrorWrapper<GetMessagesV1ThreadsThreadIdMessagesGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetMessagesV1ThreadsThreadIdMessagesGetPathParams
	>({ method: "GET", url: `/v1/threads/${pathParams["thread_id"]}/messages`, ...requestConfig });
	return data;
}

/**
 * @description Create a run.API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 * @summary Run Thread
 * {@link /threads/:thread_id/runs}
 */
export async function runThreadThreadsThreadIdRunsPost({
	pathParams,
	config = {},
}: {
	pathParams: RunThreadThreadsThreadIdRunsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		RunThreadThreadsThreadIdRunsPostMutationResponse,
		ErrorWrapper<RunThreadThreadsThreadIdRunsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RunThreadThreadsThreadIdRunsPostPathParams
	>({ method: "POST", url: `/threads/${pathParams["thread_id"]}/runs`, ...requestConfig });
	return data;
}

/**
 * @description Create a run.API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 * @summary Run Thread
 * {@link /v1/threads/:thread_id/runs}
 */
export async function runThreadV1ThreadsThreadIdRunsPost({
	pathParams,
	config = {},
}: {
	pathParams: RunThreadV1ThreadsThreadIdRunsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		RunThreadV1ThreadsThreadIdRunsPostMutationResponse,
		ErrorWrapper<RunThreadV1ThreadsThreadIdRunsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RunThreadV1ThreadsThreadIdRunsPostPathParams
	>({ method: "POST", url: `/v1/threads/${pathParams["thread_id"]}/runs`, ...requestConfig });
	return data;
}

/**
 * @description Args:    request: TokenCountRequest    call_endpoint: bool - When set to "True" it will call the token counting endpoint - e.g Anthropic or Google AI Studio Token Counting APIs.Returns:    TokenCountResponse
 * @summary Token Counter
 * {@link /utils/token_counter}
 */
export async function tokenCounterUtilsTokenCounterPost({
	body,
	queryParams,
	config = {},
}: {
	body: TokenCounterUtilsTokenCounterPostMutationRequest;
	queryParams?: TokenCounterUtilsTokenCounterPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TokenCounterUtilsTokenCounterPostMutationResponse,
		ErrorWrapper<TokenCounterUtilsTokenCounterPost422>,
		TokenCounterUtilsTokenCounterPostMutationRequest,
		Record<string, string>,
		TokenCounterUtilsTokenCounterPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/utils/token_counter`, queryParams, body, ...requestConfig });
	return data;
}

/**
 * @description Returns supported openai params for a given litellm model namee.g. `gpt-4` vs `gpt-3.5-turbo`Example curl:```curl -X GET --location 'http://localhost:4000/utils/supported_openai_params?model=gpt-3.5-turbo-16k'         --header 'Authorization: Bearer sk-1234'```
 * @summary Supported Openai Params
 * {@link /utils/supported_openai_params}
 */
export async function supportedOpenaiParamsUtilsSupportedOpenaiParamsGet({
	queryParams,
	config = {},
}: {
	queryParams: SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryResponse,
		ErrorWrapper<SupportedOpenaiParamsUtilsSupportedOpenaiParamsGet422>,
		null,
		Record<string, string>,
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/utils/supported_openai_params`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Transform Request
 * {@link /utils/transform_request}
 */
export async function transformRequestUtilsTransformRequestPost({
	body,
	config = {},
}: {
	body: TransformRequestUtilsTransformRequestPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TransformRequestUtilsTransformRequestPostMutationResponse,
		ErrorWrapper<TransformRequestUtilsTransformRequestPost422>,
		TransformRequestUtilsTransformRequestPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/utils/transform_request`, body, ...requestConfig });
	return data;
}

/**
 * @description Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)Parameters:    litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)    - When litellm_model_id is passed, it will return the info for that specific model    - When litellm_model_id is not passed, it will return the info for all modelsReturns:    Returns a dictionary containing information about each model.Example Response:```json{    "data": [                {                    "model_name": "fake-openai-endpoint",                    "litellm_params": {                        "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",                        "model": "openai/fake"                    },                    "model_info": {                        "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",                        "db_model": false                    }                }            ]}```
 * @summary Model Info V1
 * {@link /v1/model/info}
 */
export async function modelInfoV1V1ModelInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelInfoV1V1ModelInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelInfoV1V1ModelInfoGetQueryResponse,
		ErrorWrapper<ModelInfoV1V1ModelInfoGet422>,
		null,
		Record<string, string>,
		ModelInfoV1V1ModelInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/model/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)Parameters:    litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)    - When litellm_model_id is passed, it will return the info for that specific model    - When litellm_model_id is not passed, it will return the info for all modelsReturns:    Returns a dictionary containing information about each model.Example Response:```json{    "data": [                {                    "model_name": "fake-openai-endpoint",                    "litellm_params": {                        "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",                        "model": "openai/fake"                    },                    "model_info": {                        "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",                        "db_model": false                    }                }            ]}```
 * @summary Model Info V1
 * {@link /model/info}
 */
export async function modelInfoV1ModelInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelInfoV1ModelInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelInfoV1ModelInfoGetQueryResponse,
		ErrorWrapper<ModelInfoV1ModelInfoGet422>,
		null,
		Record<string, string>,
		ModelInfoV1ModelInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/model/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get information about all the deployments on litellm proxy, including config.yaml descriptions (except api key and api base)- /model_group/info returns all model groups. End users of proxy should use /model_group/info since those models will be used for /chat/completions, /embeddings, etc.- /model_group/info?model_group=rerank-english-v3.0 returns all model groups for a specific model group (`model_name` in config.yaml)Example Request (All Models):```shellcurl -X 'GET'     'http://localhost:4000/model_group/info'     -H 'accept: application/json'     -H 'x-api-key: sk-1234'```Example Request (Specific Model Group):```shellcurl -X 'GET'     'http://localhost:4000/model_group/info?model_group=rerank-english-v3.0'     -H 'accept: application/json'     -H 'Authorization: Bearer sk-1234'```Example Request (Specific Wildcard Model Group): (e.g. `model_name: openai/*` on config.yaml)```shellcurl -X 'GET'     'http://localhost:4000/model_group/info?model_group=openai/tts-1'-H 'accept: application/json'     -H 'Authorization: Bearersk-1234'```Learn how to use and set wildcard models [here](https://docs.litellm.ai/docs/wildcard_routing)Example Response:```json    {        "data": [            {            "model_group": "rerank-english-v3.0",            "providers": [                "cohere"            ],            "max_input_tokens": null,            "max_output_tokens": null,            "input_cost_per_token": 0.0,            "output_cost_per_token": 0.0,            "mode": null,            "tpm": null,            "rpm": null,            "supports_parallel_function_calling": false,            "supports_vision": false,            "supports_function_calling": false,            "supported_openai_params": [                "stream",                "temperature",                "max_tokens",                "logit_bias",                "top_p",                "frequency_penalty",                "presence_penalty",                "stop",                "n",                "extra_headers"            ]            },            {            "model_group": "gpt-3.5-turbo",            "providers": [                "openai"            ],            "max_input_tokens": 16385.0,            "max_output_tokens": 4096.0,            "input_cost_per_token": 1.5e-06,            "output_cost_per_token": 2e-06,            "mode": "chat",            "tpm": null,            "rpm": null,            "supports_parallel_function_calling": false,            "supports_vision": false,            "supports_function_calling": true,            "supported_openai_params": [                "frequency_penalty",                "logit_bias",                "logprobs",                "top_logprobs",                "max_tokens",                "max_completion_tokens",                "n",                "presence_penalty",                "seed",                "stop",                "stream",                "stream_options",                "temperature",                "top_p",                "tools",                "tool_choice",                "function_call",                "functions",                "max_retries",                "extra_headers",                "parallel_tool_calls",                "response_format"            ]            },            {            "model_group": "llava-hf",            "providers": [                "openai"            ],            "max_input_tokens": null,            "max_output_tokens": null,            "input_cost_per_token": 0.0,            "output_cost_per_token": 0.0,            "mode": null,            "tpm": null,            "rpm": null,            "supports_parallel_function_calling": false,            "supports_vision": true,            "supports_function_calling": false,            "supported_openai_params": [                "frequency_penalty",                "logit_bias",                "logprobs",                "top_logprobs",                "max_tokens",                "max_completion_tokens",                "n",                "presence_penalty",                "seed",                "stop",                "stream",                "stream_options",                "temperature",                "top_p",                "tools",                "tool_choice",                "function_call",                "functions",                "max_retries",                "extra_headers",                "parallel_tool_calls",                "response_format"            ]            }        ]        }```
 * @summary Model Group Info
 * {@link /model_group/info}
 */
export async function modelGroupInfoModelGroupInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelGroupInfoModelGroupInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelGroupInfoModelGroupInfoGetQueryResponse,
		ErrorWrapper<ModelGroupInfoModelGroupInfoGet422>,
		null,
		Record<string, string>,
		ModelGroupInfoModelGroupInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/model_group/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Home
 * {@link /}
 */
export async function homeGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HomeGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/`, ...requestConfig });
	return data;
}

/**
 * @description Get a list of available routes in the FastAPI application.
 * @summary Get Routes
 * {@link /routes}
 */
export async function getRoutesRoutesGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetRoutesRoutesGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/routes`, ...requestConfig });
	return data;
}

/**
 * @description Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses```bashcurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{    "model": "gpt-4o",    "input": "Tell me about AI"}'```
 * @summary Responses Api
 * {@link /openai/v1/responses}
 */
export async function responsesApiOpenaiV1ResponsesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResponsesApiOpenaiV1ResponsesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/openai/v1/responses`, ...requestConfig });
	return data;
}

/**
 * @description Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses```bashcurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{    "model": "gpt-4o",    "input": "Tell me about AI"}'```
 * @summary Responses Api
 * {@link /responses}
 */
export async function responsesApiResponsesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResponsesApiResponsesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/responses`, ...requestConfig });
	return data;
}

/**
 * @description Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses```bashcurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{    "model": "gpt-4o",    "input": "Tell me about AI"}'```
 * @summary Responses Api
 * {@link /v1/responses}
 */
export async function responsesApiV1ResponsesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResponsesApiV1ResponsesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/responses`, ...requestConfig });
	return data;
}

/**
 * @description Get a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get```bashcurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Get Response
 * {@link /openai/v1/responses/:response_id}
 */
export async function getResponseOpenaiV1ResponsesResponseIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseOpenaiV1ResponsesResponseIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseOpenaiV1ResponsesResponseIdGetQueryResponse,
		ErrorWrapper<GetResponseOpenaiV1ResponsesResponseIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseOpenaiV1ResponsesResponseIdGetPathParams
	>({ method: "GET", url: `/openai/v1/responses/${pathParams["response_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Delete a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete```bashcurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Delete Response
 * {@link /openai/v1/responses/:response_id}
 */
export async function deleteResponseOpenaiV1ResponsesResponseIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		DeleteResponseOpenaiV1ResponsesResponseIdDeleteMutationResponse,
		ErrorWrapper<DeleteResponseOpenaiV1ResponsesResponseIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams
	>({
		method: "DELETE",
		url: `/openai/v1/responses/${pathParams["response_id"]}`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Get a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get```bashcurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Get Response
 * {@link /responses/:response_id}
 */
export async function getResponseResponsesResponseIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseResponsesResponseIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseResponsesResponseIdGetQueryResponse,
		ErrorWrapper<GetResponseResponsesResponseIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseResponsesResponseIdGetPathParams
	>({ method: "GET", url: `/responses/${pathParams["response_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Delete a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete```bashcurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Delete Response
 * {@link /responses/:response_id}
 */
export async function deleteResponseResponsesResponseIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteResponseResponsesResponseIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		DeleteResponseResponsesResponseIdDeleteMutationResponse,
		ErrorWrapper<DeleteResponseResponsesResponseIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteResponseResponsesResponseIdDeletePathParams
	>({ method: "DELETE", url: `/responses/${pathParams["response_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Get a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get```bashcurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Get Response
 * {@link /v1/responses/:response_id}
 */
export async function getResponseV1ResponsesResponseIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseV1ResponsesResponseIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseV1ResponsesResponseIdGetQueryResponse,
		ErrorWrapper<GetResponseV1ResponsesResponseIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseV1ResponsesResponseIdGetPathParams
	>({ method: "GET", url: `/v1/responses/${pathParams["response_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Delete a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete```bashcurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Delete Response
 * {@link /v1/responses/:response_id}
 */
export async function deleteResponseV1ResponsesResponseIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteResponseV1ResponsesResponseIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		DeleteResponseV1ResponsesResponseIdDeleteMutationResponse,
		ErrorWrapper<DeleteResponseV1ResponsesResponseIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteResponseV1ResponsesResponseIdDeletePathParams
	>({ method: "DELETE", url: `/v1/responses/${pathParams["response_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description List input items for a response.
 * @summary Get Response Input Items
 * {@link /openai/v1/responses/:response_id/input_items}
 */
export async function getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetQueryResponse,
		ErrorWrapper<GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams
	>({
		method: "GET",
		url: `/openai/v1/responses/${pathParams["response_id"]}/input_items`,
		...requestConfig,
	});
	return data;
}

/**
 * @description List input items for a response.
 * @summary Get Response Input Items
 * {@link /responses/:response_id/input_items}
 */
export async function getResponseInputItemsResponsesResponseIdInputItemsGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseInputItemsResponsesResponseIdInputItemsGetQueryResponse,
		ErrorWrapper<GetResponseInputItemsResponsesResponseIdInputItemsGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams
	>({
		method: "GET",
		url: `/responses/${pathParams["response_id"]}/input_items`,
		...requestConfig,
	});
	return data;
}

/**
 * @description List input items for a response.
 * @summary Get Response Input Items
 * {@link /v1/responses/:response_id/input_items}
 */
export async function getResponseInputItemsV1ResponsesResponseIdInputItemsGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetQueryResponse,
		ErrorWrapper<GetResponseInputItemsV1ResponsesResponseIdInputItemsGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams
	>({
		method: "GET",
		url: `/v1/responses/${pathParams["response_id"]}/input_items`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel```bashcurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"```
 * @summary Cancel Response
 * {@link /openai/v1/responses/:response_id/cancel}
 */
export async function cancelResponseOpenaiV1ResponsesResponseIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostMutationResponse,
		ErrorWrapper<CancelResponseOpenaiV1ResponsesResponseIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams
	>({
		method: "POST",
		url: `/openai/v1/responses/${pathParams["response_id"]}/cancel`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel```bashcurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"```
 * @summary Cancel Response
 * {@link /responses/:response_id/cancel}
 */
export async function cancelResponseResponsesResponseIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelResponseResponsesResponseIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		CancelResponseResponsesResponseIdCancelPostMutationResponse,
		ErrorWrapper<CancelResponseResponsesResponseIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelResponseResponsesResponseIdCancelPostPathParams
	>({ method: "POST", url: `/responses/${pathParams["response_id"]}/cancel`, ...requestConfig });
	return data;
}

/**
 * @description Cancel a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel```bashcurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"```
 * @summary Cancel Response
 * {@link /v1/responses/:response_id/cancel}
 */
export async function cancelResponseV1ResponsesResponseIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelResponseV1ResponsesResponseIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		CancelResponseV1ResponsesResponseIdCancelPostMutationResponse,
		ErrorWrapper<CancelResponseV1ResponsesResponseIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelResponseV1ResponsesResponseIdCancelPostPathParams
	>({ method: "POST", url: `/v1/responses/${pathParams["response_id"]}/cancel`, ...requestConfig });
	return data;
}

/**
 * @description Create large batches of API requests for asynchronous processing.This is the equivalent of POST https://api.openai.com/v1/batchSupports Identical Params as: https://platform.openai.com/docs/api-reference/batchExample Curl```curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "input_file_id": "file-abc123",        "endpoint": "/v1/chat/completions",        "completion_window": "24h"}'```
 * @summary Create Batch
 * {@link /batches}
 */
export async function createBatchBatchesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateBatchBatchesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateBatchBatchesPostMutationResponse,
		ErrorWrapper<CreateBatchBatchesPost422>,
		null,
		Record<string, string>,
		CreateBatchBatchesPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/batches`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Lists This is the equivalent of GET https://api.openai.com/v1/batches/Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/listExample Curl```curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary List Batches
 * {@link /batches}
 */
export async function listBatchesBatchesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListBatchesBatchesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListBatchesBatchesGetQueryResponse,
		ErrorWrapper<ListBatchesBatchesGet422>,
		null,
		Record<string, string>,
		ListBatchesBatchesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/batches`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Create large batches of API requests for asynchronous processing.This is the equivalent of POST https://api.openai.com/v1/batchSupports Identical Params as: https://platform.openai.com/docs/api-reference/batchExample Curl```curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "input_file_id": "file-abc123",        "endpoint": "/v1/chat/completions",        "completion_window": "24h"}'```
 * @summary Create Batch
 * {@link /v1/batches}
 */
export async function createBatchV1BatchesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateBatchV1BatchesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateBatchV1BatchesPostMutationResponse,
		ErrorWrapper<CreateBatchV1BatchesPost422>,
		null,
		Record<string, string>,
		CreateBatchV1BatchesPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/batches`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Lists This is the equivalent of GET https://api.openai.com/v1/batches/Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/listExample Curl```curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary List Batches
 * {@link /v1/batches}
 */
export async function listBatchesV1BatchesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListBatchesV1BatchesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListBatchesV1BatchesGetQueryResponse,
		ErrorWrapper<ListBatchesV1BatchesGet422>,
		null,
		Record<string, string>,
		ListBatchesV1BatchesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/batches`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Create large batches of API requests for asynchronous processing.This is the equivalent of POST https://api.openai.com/v1/batchSupports Identical Params as: https://platform.openai.com/docs/api-reference/batchExample Curl```curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "input_file_id": "file-abc123",        "endpoint": "/v1/chat/completions",        "completion_window": "24h"}'```
 * @summary Create Batch
 * {@link /:provider/v1/batches}
 */
export async function createBatchProviderV1BatchesPost({
	pathParams,
	config = {},
}: {
	pathParams: CreateBatchProviderV1BatchesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		CreateBatchProviderV1BatchesPostMutationResponse,
		ErrorWrapper<CreateBatchProviderV1BatchesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CreateBatchProviderV1BatchesPostPathParams
	>({ method: "POST", url: `/${pathParams["provider"]}/v1/batches`, ...requestConfig });
	return data;
}

/**
 * @description Lists This is the equivalent of GET https://api.openai.com/v1/batches/Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/listExample Curl```curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary List Batches
 * {@link /:provider/v1/batches}
 */
export async function listBatchesProviderV1BatchesGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: ListBatchesProviderV1BatchesGetPathParams;
	queryParams?: ListBatchesProviderV1BatchesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		ListBatchesProviderV1BatchesGetQueryResponse,
		ErrorWrapper<ListBatchesProviderV1BatchesGet422>,
		null,
		Record<string, string>,
		ListBatchesProviderV1BatchesGetQueryParams,
		ListBatchesProviderV1BatchesGetPathParams
	>({ method: "GET", url: `/${pathParams["provider"]}/v1/batches`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Retrieves a batch.This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieveExample Curl```curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary Retrieve Batch
 * {@link /batches/:batch_id}
 */
export async function retrieveBatchBatchesBatchIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveBatchBatchesBatchIdGetPathParams;
	queryParams?: RetrieveBatchBatchesBatchIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		RetrieveBatchBatchesBatchIdGetQueryResponse,
		ErrorWrapper<RetrieveBatchBatchesBatchIdGet422>,
		null,
		Record<string, string>,
		RetrieveBatchBatchesBatchIdGetQueryParams,
		RetrieveBatchBatchesBatchIdGetPathParams
	>({ method: "GET", url: `/batches/${pathParams["batch_id"]}`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Retrieves a batch.This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieveExample Curl```curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary Retrieve Batch
 * {@link /v1/batches/:batch_id}
 */
export async function retrieveBatchV1BatchesBatchIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveBatchV1BatchesBatchIdGetPathParams;
	queryParams?: RetrieveBatchV1BatchesBatchIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		RetrieveBatchV1BatchesBatchIdGetQueryResponse,
		ErrorWrapper<RetrieveBatchV1BatchesBatchIdGet422>,
		null,
		Record<string, string>,
		RetrieveBatchV1BatchesBatchIdGetQueryParams,
		RetrieveBatchV1BatchesBatchIdGetPathParams
	>({ method: "GET", url: `/v1/batches/${pathParams["batch_id"]}`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Retrieves a batch.This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieveExample Curl```curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary Retrieve Batch
 * {@link /:provider/v1/batches/:batch_id}
 */
export async function retrieveBatchProviderV1BatchesBatchIdGet({
	pathParams,
	config = {},
}: {
	pathParams: RetrieveBatchProviderV1BatchesBatchIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		RetrieveBatchProviderV1BatchesBatchIdGetQueryResponse,
		ErrorWrapper<RetrieveBatchProviderV1BatchesBatchIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RetrieveBatchProviderV1BatchesBatchIdGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["provider"]}/v1/batches/${pathParams["batch_id"]}`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a batch.This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancelSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancelExample Curl```curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST```
 * @summary Cancel Batch
 * {@link /batches/:batch_id/cancel}
 */
export async function cancelBatchBatchesBatchIdCancelPost({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: CancelBatchBatchesBatchIdCancelPostPathParams;
	queryParams?: CancelBatchBatchesBatchIdCancelPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		CancelBatchBatchesBatchIdCancelPostMutationResponse,
		ErrorWrapper<CancelBatchBatchesBatchIdCancelPost422>,
		null,
		Record<string, string>,
		CancelBatchBatchesBatchIdCancelPostQueryParams,
		CancelBatchBatchesBatchIdCancelPostPathParams
	>({
		method: "POST",
		url: `/batches/${pathParams["batch_id"]}/cancel`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a batch.This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancelSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancelExample Curl```curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST```
 * @summary Cancel Batch
 * {@link /v1/batches/:batch_id/cancel}
 */
export async function cancelBatchV1BatchesBatchIdCancelPost({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: CancelBatchV1BatchesBatchIdCancelPostPathParams;
	queryParams?: CancelBatchV1BatchesBatchIdCancelPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		CancelBatchV1BatchesBatchIdCancelPostMutationResponse,
		ErrorWrapper<CancelBatchV1BatchesBatchIdCancelPost422>,
		null,
		Record<string, string>,
		CancelBatchV1BatchesBatchIdCancelPostQueryParams,
		CancelBatchV1BatchesBatchIdCancelPostPathParams
	>({
		method: "POST",
		url: `/v1/batches/${pathParams["batch_id"]}/cancel`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a batch.This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancelSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancelExample Curl```curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST```
 * @summary Cancel Batch
 * {@link /:provider/v1/batches/:batch_id/cancel}
 */
export async function cancelBatchProviderV1BatchesBatchIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelBatchProviderV1BatchesBatchIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		CancelBatchProviderV1BatchesBatchIdCancelPostMutationResponse,
		ErrorWrapper<CancelBatchProviderV1BatchesBatchIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelBatchProviderV1BatchesBatchIdCancelPostPathParams
	>({
		method: "POST",
		url: `/${pathParams["provider"]}/v1/batches/${pathParams["batch_id"]}/cancel`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Public Model Hub
 * {@link /public/model_hub}
 */
export async function publicModelHubPublicModelHubGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		PublicModelHubPublicModelHubGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/public/model_hub`, ...requestConfig });
	return data;
}

/**
 * @summary Public Model Hub Info
 * {@link /public/model_hub/info}
 */
export async function publicModelHubInfoPublicModelHubInfoGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		PublicModelHubInfoPublicModelHubInfoGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/public/model_hub/info`, ...requestConfig });
	return data;
}

/**
 * @summary Rerank
 * {@link /rerank}
 */
export async function rerankRerankPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RerankRerankPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/rerank`, ...requestConfig });
	return data;
}

/**
 * @summary Rerank
 * {@link /v1/rerank}
 */
export async function rerankV1RerankPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RerankV1RerankPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/rerank`, ...requestConfig });
	return data;
}

/**
 * @summary Rerank
 * {@link /v2/rerank}
 */
export async function rerankV2RerankPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RerankV2RerankPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v2/rerank`, ...requestConfig });
	return data;
}

/**
 * @description OCR endpoint for extracting text from documents and images.Follows the Mistral OCR API spec:https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocrExample:```bashcurl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "mistral/mistral-ocr-latest",        "document": {            "type": "document_url",            "document_url": "https://arxiv.org/pdf/2201.04234"        }    }'```
 * @summary Ocr
 * {@link /ocr}
 */
export async function ocrOcrPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OcrOcrPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/ocr`, ...requestConfig });
	return data;
}

/**
 * @description OCR endpoint for extracting text from documents and images.Follows the Mistral OCR API spec:https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocrExample:```bashcurl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "mistral/mistral-ocr-latest",        "document": {            "type": "document_url",            "document_url": "https://arxiv.org/pdf/2201.04234"        }    }'```
 * @summary Ocr
 * {@link /v1/ocr}
 */
export async function ocrV1OcrPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OcrV1OcrPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/ocr`, ...requestConfig });
	return data;
}

/**
 * @description Video list endpoint for retrieving a list of videos.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"```
 * @summary Video List
 * {@link /videos}
 */
export async function videoListVideosGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VideoListVideosGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/videos`, ...requestConfig });
	return data;
}

/**
 * @description Video generation endpoint for creating videos from text prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "sora-2",        "prompt": "A beautiful sunset over the ocean"    }'```
 * @summary Video Generation
 * {@link /videos}
 */
export async function videoGenerationVideosPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		VideoGenerationVideosPostMutationResponse,
		ErrorWrapper<VideoGenerationVideosPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/videos`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Video list endpoint for retrieving a list of videos.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"```
 * @summary Video List
 * {@link /v1/videos}
 */
export async function videoListV1VideosGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VideoListV1VideosGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/videos`, ...requestConfig });
	return data;
}

/**
 * @description Video generation endpoint for creating videos from text prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "sora-2",        "prompt": "A beautiful sunset over the ocean"    }'```
 * @summary Video Generation
 * {@link /v1/videos}
 */
export async function videoGenerationV1VideosPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		VideoGenerationV1VideosPostMutationResponse,
		ErrorWrapper<VideoGenerationV1VideosPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/videos`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Video status endpoint for retrieving video status and metadata.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"```
 * @summary Video Status
 * {@link /videos/:video_id}
 */
export async function videoStatusVideosVideoIdGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoStatusVideosVideoIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoStatusVideosVideoIdGetQueryResponse,
		ErrorWrapper<VideoStatusVideosVideoIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoStatusVideosVideoIdGetPathParams
	>({ method: "GET", url: `/videos/${pathParams["video_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Video status endpoint for retrieving video status and metadata.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"```
 * @summary Video Status
 * {@link /v1/videos/:video_id}
 */
export async function videoStatusV1VideosVideoIdGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoStatusV1VideosVideoIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoStatusV1VideosVideoIdGetQueryResponse,
		ErrorWrapper<VideoStatusV1VideosVideoIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoStatusV1VideosVideoIdGetPathParams
	>({ method: "GET", url: `/v1/videos/${pathParams["video_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Video content endpoint for downloading video content.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4```
 * @summary Video Content
 * {@link /videos/:video_id/content}
 */
export async function videoContentVideosVideoIdContentGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoContentVideosVideoIdContentGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoContentVideosVideoIdContentGetQueryResponse,
		ErrorWrapper<VideoContentVideosVideoIdContentGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoContentVideosVideoIdContentGetPathParams
	>({ method: "GET", url: `/videos/${pathParams["video_id"]}/content`, ...requestConfig });
	return data;
}

/**
 * @description Video content endpoint for downloading video content.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4```
 * @summary Video Content
 * {@link /v1/videos/:video_id/content}
 */
export async function videoContentV1VideosVideoIdContentGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoContentV1VideosVideoIdContentGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoContentV1VideosVideoIdContentGetQueryResponse,
		ErrorWrapper<VideoContentV1VideosVideoIdContentGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoContentV1VideosVideoIdContentGetPathParams
	>({ method: "GET", url: `/v1/videos/${pathParams["video_id"]}/content`, ...requestConfig });
	return data;
}

/**
 * @description Video remix endpoint for remixing existing videos with new prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "prompt": "A new version with different colors"    }'```
 * @summary Video Remix
 * {@link /videos/:video_id/remix}
 */
export async function videoRemixVideosVideoIdRemixPost({
	pathParams,
	config = {},
}: {
	pathParams: VideoRemixVideosVideoIdRemixPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoRemixVideosVideoIdRemixPostMutationResponse,
		ErrorWrapper<VideoRemixVideosVideoIdRemixPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoRemixVideosVideoIdRemixPostPathParams
	>({ method: "POST", url: `/videos/${pathParams["video_id"]}/remix`, ...requestConfig });
	return data;
}

/**
 * @description Video remix endpoint for remixing existing videos with new prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "prompt": "A new version with different colors"    }'```
 * @summary Video Remix
 * {@link /v1/videos/:video_id/remix}
 */
export async function videoRemixV1VideosVideoIdRemixPost({
	pathParams,
	config = {},
}: {
	pathParams: VideoRemixV1VideosVideoIdRemixPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoRemixV1VideosVideoIdRemixPostMutationResponse,
		ErrorWrapper<VideoRemixV1VideosVideoIdRemixPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoRemixV1VideosVideoIdRemixPostPathParams
	>({ method: "POST", url: `/v1/videos/${pathParams["video_id"]}/remix`, ...requestConfig });
	return data;
}

/**
 * @description Container list endpoint for retrieving a list of containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"```Or specify provider via header or query param:```bashcurl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"```
 * @summary List Containers
 * {@link /containers}
 */
export async function listContainersContainersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListContainersContainersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/containers`, ...requestConfig });
	return data;
}

/**
 * @description Container creation endpoint for creating new containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "name": "My Container",        "expires_after": {            "anchor": "last_active_at",            "minutes": 20        }    }'```Or specify provider via header:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{        "name": "My Container"    }'```
 * @summary Create Container
 * {@link /containers}
 */
export async function createContainerContainersPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateContainerContainersPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/containers`, ...requestConfig });
	return data;
}

/**
 * @description Container list endpoint for retrieving a list of containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"```Or specify provider via header or query param:```bashcurl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"```
 * @summary List Containers
 * {@link /v1/containers}
 */
export async function listContainersV1ContainersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListContainersV1ContainersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/containers`, ...requestConfig });
	return data;
}

/**
 * @description Container creation endpoint for creating new containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "name": "My Container",        "expires_after": {            "anchor": "last_active_at",            "minutes": 20        }    }'```Or specify provider via header:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{        "name": "My Container"    }'```
 * @summary Create Container
 * {@link /v1/containers}
 */
export async function createContainerV1ContainersPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateContainerV1ContainersPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/containers`, ...requestConfig });
	return data;
}

/**
 * @description Container retrieve endpoint for getting details of a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Retrieve Container
 * {@link /containers/:container_id}
 */
export async function retrieveContainerContainersContainerIdGet({
	pathParams,
	config = {},
}: {
	pathParams: RetrieveContainerContainersContainerIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		RetrieveContainerContainersContainerIdGetQueryResponse,
		ErrorWrapper<RetrieveContainerContainersContainerIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RetrieveContainerContainersContainerIdGetPathParams
	>({ method: "GET", url: `/containers/${pathParams["container_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Container delete endpoint for deleting a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Delete Container
 * {@link /containers/:container_id}
 */
export async function deleteContainerContainersContainerIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteContainerContainersContainerIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		DeleteContainerContainersContainerIdDeleteMutationResponse,
		ErrorWrapper<DeleteContainerContainersContainerIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteContainerContainersContainerIdDeletePathParams
	>({ method: "DELETE", url: `/containers/${pathParams["container_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Container retrieve endpoint for getting details of a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Retrieve Container
 * {@link /v1/containers/:container_id}
 */
export async function retrieveContainerV1ContainersContainerIdGet({
	pathParams,
	config = {},
}: {
	pathParams: RetrieveContainerV1ContainersContainerIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		RetrieveContainerV1ContainersContainerIdGetQueryResponse,
		ErrorWrapper<RetrieveContainerV1ContainersContainerIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RetrieveContainerV1ContainersContainerIdGetPathParams
	>({ method: "GET", url: `/v1/containers/${pathParams["container_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Container delete endpoint for deleting a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Delete Container
 * {@link /v1/containers/:container_id}
 */
export async function deleteContainerV1ContainersContainerIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteContainerV1ContainersContainerIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		DeleteContainerV1ContainersContainerIdDeleteMutationResponse,
		ErrorWrapper<DeleteContainerV1ContainersContainerIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteContainerV1ContainersContainerIdDeletePathParams
	>({ method: "DELETE", url: `/v1/containers/${pathParams["container_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /search}
 */
export async function searchSearchPost({
	queryParams,
	config = {},
}: {
	queryParams?: SearchSearchPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SearchSearchPostMutationResponse,
		ErrorWrapper<SearchSearchPost422>,
		null,
		Record<string, string>,
		SearchSearchPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/search`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /v1/search}
 */
export async function searchV1SearchPost({
	queryParams,
	config = {},
}: {
	queryParams?: SearchV1SearchPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SearchV1SearchPostMutationResponse,
		ErrorWrapper<SearchV1SearchPost422>,
		null,
		Record<string, string>,
		SearchV1SearchPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/search`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /search/:search_tool_name}
 */
export async function searchSearchSearchToolNamePost({
	pathParams,
	config = {},
}: {
	pathParams: SearchSearchSearchToolNamePostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_name"]) {
		throw new Error(`Missing required path parameter: search_tool_name`);
	}
	const data = await request<
		SearchSearchSearchToolNamePostMutationResponse,
		ErrorWrapper<SearchSearchSearchToolNamePost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		SearchSearchSearchToolNamePostPathParams
	>({ method: "POST", url: `/search/${pathParams["search_tool_name"]}`, ...requestConfig });
	return data;
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /v1/search/:search_tool_name}
 */
export async function searchV1SearchSearchToolNamePost({
	pathParams,
	config = {},
}: {
	pathParams: SearchV1SearchSearchToolNamePostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_name"]) {
		throw new Error(`Missing required path parameter: search_tool_name`);
	}
	const data = await request<
		SearchV1SearchSearchToolNamePostMutationResponse,
		ErrorWrapper<SearchV1SearchSearchToolNamePost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		SearchV1SearchSearchToolNamePostPathParams
	>({ method: "POST", url: `/v1/search/${pathParams["search_tool_name"]}`, ...requestConfig });
	return data;
}

/**
 * @summary Image Generation
 * {@link /openai/deployments/:model/images/generations}
 */
export async function imageGenerationOpenaiDeploymentsModelImagesGenerationsPost({
	pathParams,
	config = {},
}: {
	pathParams: ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostMutationResponse,
		ErrorWrapper<ImageGenerationOpenaiDeploymentsModelImagesGenerationsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/images/generations`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Image Generation
 * {@link /images/generations}
 */
export async function imageGenerationImagesGenerationsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageGenerationImagesGenerationsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ImageGenerationImagesGenerationsPostMutationResponse,
		ErrorWrapper<ImageGenerationImagesGenerationsPost422>,
		null,
		Record<string, string>,
		ImageGenerationImagesGenerationsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/images/generations`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Image Generation
 * {@link /v1/images/generations}
 */
export async function imageGenerationV1ImagesGenerationsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageGenerationV1ImagesGenerationsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ImageGenerationV1ImagesGenerationsPostMutationResponse,
		ErrorWrapper<ImageGenerationV1ImagesGenerationsPost422>,
		null,
		Record<string, string>,
		ImageGenerationV1ImagesGenerationsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/images/generations`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create```bashcurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'```
 * @summary Image Edit Api
 * {@link /openai/deployments/:model/images/edits}
 */
export async function imageEditApiOpenaiDeploymentsModelImagesEditsPost({
	pathParams,
	config = {},
}: {
	pathParams: ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostMutationResponse,
		ErrorWrapper<ImageEditApiOpenaiDeploymentsModelImagesEditsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/images/edits`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create```bashcurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'```
 * @summary Image Edit Api
 * {@link /images/edits}
 */
export async function imageEditApiImagesEditsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageEditApiImagesEditsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ImageEditApiImagesEditsPostMutationResponse,
		ErrorWrapper<ImageEditApiImagesEditsPost422>,
		null,
		Record<string, string>,
		ImageEditApiImagesEditsPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/images/edits`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create```bashcurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'```
 * @summary Image Edit Api
 * {@link /v1/images/edits}
 */
export async function imageEditApiV1ImagesEditsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageEditApiV1ImagesEditsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ImageEditApiV1ImagesEditsPostMutationResponse,
		ErrorWrapper<ImageEditApiV1ImagesEditsPost422>,
		null,
		Record<string, string>,
		ImageEditApiV1ImagesEditsPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/images/edits`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Creates a fine-tuning job which begins the process of creating a new model from a given dataset.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobsSupports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/createExample Curl:```curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{    "model": "gpt-3.5-turbo",    "training_file": "file-abc123",    "hyperparameters": {      "n_epochs": 4    }  }'```
 * @summary  (Enterprise) Create Fine-Tuning Job
 * {@link /fine_tuning/jobs}
 */
export async function createFineTuningJobFineTuningJobsPost({
	body,
	config = {},
}: {
	body: CreateFineTuningJobFineTuningJobsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateFineTuningJobFineTuningJobsPostMutationResponse,
		ErrorWrapper<CreateFineTuningJobFineTuningJobsPost422>,
		CreateFineTuningJobFineTuningJobsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/fine_tuning/jobs`, body, ...requestConfig });
	return data;
}

/**
 * @description Lists fine-tuning jobs for the organization.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobsSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `after`: Identifier for the last job from the previous pagination request.- `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 * @summary  (Enterprise) List Fine-Tuning Jobs
 * {@link /fine_tuning/jobs}
 */
export async function listFineTuningJobsFineTuningJobsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFineTuningJobsFineTuningJobsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFineTuningJobsFineTuningJobsGetQueryResponse,
		ErrorWrapper<ListFineTuningJobsFineTuningJobsGet422>,
		null,
		Record<string, string>,
		ListFineTuningJobsFineTuningJobsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/fine_tuning/jobs`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Creates a fine-tuning job which begins the process of creating a new model from a given dataset.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobsSupports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/createExample Curl:```curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{    "model": "gpt-3.5-turbo",    "training_file": "file-abc123",    "hyperparameters": {      "n_epochs": 4    }  }'```
 * @summary  (Enterprise) Create Fine-Tuning Job
 * {@link /v1/fine_tuning/jobs}
 */
export async function createFineTuningJobV1FineTuningJobsPost({
	body,
	config = {},
}: {
	body: CreateFineTuningJobV1FineTuningJobsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateFineTuningJobV1FineTuningJobsPostMutationResponse,
		ErrorWrapper<CreateFineTuningJobV1FineTuningJobsPost422>,
		CreateFineTuningJobV1FineTuningJobsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/fine_tuning/jobs`, body, ...requestConfig });
	return data;
}

/**
 * @description Lists fine-tuning jobs for the organization.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobsSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `after`: Identifier for the last job from the previous pagination request.- `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 * @summary  (Enterprise) List Fine-Tuning Jobs
 * {@link /v1/fine_tuning/jobs}
 */
export async function listFineTuningJobsV1FineTuningJobsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFineTuningJobsV1FineTuningJobsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFineTuningJobsV1FineTuningJobsGetQueryResponse,
		ErrorWrapper<ListFineTuningJobsV1FineTuningJobsGet422>,
		null,
		Record<string, string>,
		ListFineTuningJobsV1FineTuningJobsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/fine_tuning/jobs`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Retrieves a fine-tuning job.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}Supported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 * @summary  (Enterprise) Retrieve Fine-Tuning Job
 * {@link /fine_tuning/jobs/:fine_tuning_job_id}
 */
export async function retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams;
	queryParams?: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryResponse,
		ErrorWrapper<RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGet422>,
		null,
		Record<string, string>,
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams,
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams
	>({
		method: "GET",
		url: `/fine_tuning/jobs/${pathParams["fine_tuning_job_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Retrieves a fine-tuning job.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}Supported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 * @summary  (Enterprise) Retrieve Fine-Tuning Job
 * {@link /v1/fine_tuning/jobs/:fine_tuning_job_id}
 */
export async function retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams;
	queryParams?: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryResponse,
		ErrorWrapper<RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet422>,
		null,
		Record<string, string>,
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams,
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams
	>({
		method: "GET",
		url: `/v1/fine_tuning/jobs/${pathParams["fine_tuning_job_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a fine-tuning job.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancelSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 * @summary  (Enterprise) Cancel Fine-Tuning Jobs
 * {@link /fine_tuning/jobs/:fine_tuning_job_id/cancel}
 */
export async function cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostMutationResponse,
		ErrorWrapper<CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams
	>({
		method: "POST",
		url: `/fine_tuning/jobs/${pathParams["fine_tuning_job_id"]}/cancel`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Cancel a fine-tuning job.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancelSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 * @summary  (Enterprise) Cancel Fine-Tuning Jobs
 * {@link /v1/fine_tuning/jobs/:fine_tuning_job_id/cancel}
 */
export async function cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostMutationResponse,
		ErrorWrapper<CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams
	>({
		method: "POST",
		url: `/v1/fine_tuning/jobs/${pathParams["fine_tuning_job_id"]}/cancel`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Search a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/search
 * @summary Vector Store Search
 * {@link /vector_stores/:vector_store_id/search}
 */
export async function vectorStoreSearchVectorStoresVectorStoreIdSearchPost({
	pathParams,
	config = {},
}: {
	pathParams: VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["vector_store_id"]) {
		throw new Error(`Missing required path parameter: vector_store_id`);
	}
	const data = await request<
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostMutationResponse,
		ErrorWrapper<VectorStoreSearchVectorStoresVectorStoreIdSearchPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams
	>({
		method: "POST",
		url: `/vector_stores/${pathParams["vector_store_id"]}/search`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Search a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/search
 * @summary Vector Store Search
 * {@link /v1/vector_stores/:vector_store_id/search}
 */
export async function vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost({
	pathParams,
	config = {},
}: {
	pathParams: VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["vector_store_id"]) {
		throw new Error(`Missing required path parameter: vector_store_id`);
	}
	const data = await request<
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostMutationResponse,
		ErrorWrapper<VectorStoreSearchV1VectorStoresVectorStoreIdSearchPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams
	>({
		method: "POST",
		url: `/v1/vector_stores/${pathParams["vector_store_id"]}/search`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Create a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/create
 * @summary Vector Store Create
 * {@link /vector_stores}
 */
export async function vectorStoreCreateVectorStoresPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VectorStoreCreateVectorStoresPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_stores`, ...requestConfig });
	return data;
}

/**
 * @description Create a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/create
 * @summary Vector Store Create
 * {@link /v1/vector_stores}
 */
export async function vectorStoreCreateV1VectorStoresPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VectorStoreCreateV1VectorStoresPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/vector_stores`, ...requestConfig });
	return data;
}

/**
 * @description Create an index. Just writes the index to the database.```bashcurl -L -X POST 'http://0.0.0.0:4000/indexes/create'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -H 'LiteLLM-Beta: indexes_beta=v1'         -d '{         "index_name": "dall-e-3",        "vector_store_index": "real-index-name",        "vector_store_name": "azure-ai-search"    }'```
 * @summary Index Create
 * {@link /v1/indexes}
 */
export async function indexCreateV1IndexesPost({
	body,
	config = {},
}: {
	body: IndexCreateV1IndexesPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		IndexCreateV1IndexesPostMutationResponse,
		ErrorWrapper<IndexCreateV1IndexesPost422>,
		IndexCreateV1IndexesPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/indexes`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Get Credentials
 * {@link /credentials}
 */
export async function getCredentialsCredentialsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCredentialsCredentialsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/credentials`, ...requestConfig });
	return data;
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.Stores credential in DB.Reloads credentials in memory.
 * @summary Create Credential
 * {@link /credentials}
 */
export async function createCredentialCredentialsPost({
	body,
	config = {},
}: {
	body: CreateCredentialCredentialsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateCredentialCredentialsPostMutationResponse,
		ErrorWrapper<CreateCredentialCredentialsPost422>,
		CreateCredentialCredentialsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/credentials`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Get Credential
 * {@link /credentials/by_model/:model_id}
 */
export async function getCredentialCredentialsByModelModelIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetCredentialCredentialsByModelModelIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		GetCredentialCredentialsByModelModelIdGetQueryResponse,
		ErrorWrapper<GetCredentialCredentialsByModelModelIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetCredentialCredentialsByModelModelIdGetPathParams
	>({ method: "GET", url: `/credentials/by_model/${pathParams["model_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Get Credential
 * {@link /credentials/by_name/:credential_name}
 */
export async function getCredentialCredentialsByNameCredentialNameGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetCredentialCredentialsByNameCredentialNameGetPathParams;
	queryParams?: GetCredentialCredentialsByNameCredentialNameGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}
	const data = await request<
		GetCredentialCredentialsByNameCredentialNameGetQueryResponse,
		ErrorWrapper<GetCredentialCredentialsByNameCredentialNameGet422>,
		null,
		Record<string, string>,
		GetCredentialCredentialsByNameCredentialNameGetQueryParams,
		GetCredentialCredentialsByNameCredentialNameGetPathParams
	>({
		method: "GET",
		url: `/credentials/by_name/${pathParams["credential_name"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Delete Credential
 * {@link /credentials/:credential_name}
 */
export async function deleteCredentialCredentialsCredentialNameDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteCredentialCredentialsCredentialNameDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}
	const data = await request<
		DeleteCredentialCredentialsCredentialNameDeleteMutationResponse,
		ErrorWrapper<DeleteCredentialCredentialsCredentialNameDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteCredentialCredentialsCredentialNameDeletePathParams
	>({ method: "DELETE", url: `/credentials/${pathParams["credential_name"]}`, ...requestConfig });
	return data;
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Update Credential
 * {@link /credentials/:credential_name}
 */
export async function updateCredentialCredentialsCredentialNamePatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdateCredentialCredentialsCredentialNamePatchPathParams;
	body: UpdateCredentialCredentialsCredentialNamePatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}
	const data = await request<
		UpdateCredentialCredentialsCredentialNamePatchMutationResponse,
		ErrorWrapper<UpdateCredentialCredentialsCredentialNamePatch422>,
		UpdateCredentialCredentialsCredentialNamePatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdateCredentialCredentialsCredentialNamePatchPathParams
	>({
		method: "PATCH",
		url: `/credentials/${pathParams["credential_name"]}`,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Get all MCP tools available for the current key, including those from access groups
 * @summary Get Mcp Tools
 * {@link /v1/mcp/tools}
 */
export async function getMcpToolsV1McpToolsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetMcpToolsV1McpToolsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/tools`, ...requestConfig });
	return data;
}

/**
 * @description Get all available MCP access groups from the database AND config
 * @summary Get Mcp Access Groups
 * {@link /v1/mcp/access_groups}
 */
export async function getMcpAccessGroupsV1McpAccessGroupsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetMcpAccessGroupsV1McpAccessGroupsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/access_groups`, ...requestConfig });
	return data;
}

/**
 * @description Perform health check on a specific MCP server
 * @summary Health Check Mcp Server
 * {@link /v1/mcp/server/:server_id/health}
 */
export async function healthCheckMcpServerV1McpServerServerIdHealthGet({
	pathParams,
	config = {},
}: {
	pathParams: HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["server_id"]) {
		throw new Error(`Missing required path parameter: server_id`);
	}
	const data = await request<
		HealthCheckMcpServerV1McpServerServerIdHealthGetQueryResponse,
		ErrorWrapper<HealthCheckMcpServerV1McpServerServerIdHealthGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams
	>({ method: "GET", url: `/v1/mcp/server/${pathParams["server_id"]}/health`, ...requestConfig });
	return data;
}

/**
 * @description Perform health check on all accessible MCP servers
 * @summary Health Check All Mcp Servers
 * {@link /v1/mcp/server/health}
 */
export async function healthCheckAllMcpServersV1McpServerHealthGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthCheckAllMcpServersV1McpServerHealthGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/server/health`, ...requestConfig });
	return data;
}

/**
 * @description Returns the mcp server list with associated teams
 * @summary Fetch All Mcp Servers
 * {@link /v1/mcp/server}
 */
export async function fetchAllMcpServersV1McpServerGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		FetchAllMcpServersV1McpServerGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/server`, ...requestConfig });
	return data;
}

/**
 * @description Allows creation of mcp servers
 * @summary Add Mcp Server
 * {@link /v1/mcp/server}
 */
export async function addMcpServerV1McpServerPost({
	body,
	headers,
	config = {},
}: {
	body?: AddMcpServerV1McpServerPostMutationRequest;
	headers?: AddMcpServerV1McpServerPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AddMcpServerV1McpServerPostMutationResponse,
		ErrorWrapper<AddMcpServerV1McpServerPost422>,
		AddMcpServerV1McpServerPostMutationRequest,
		AddMcpServerV1McpServerPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/mcp/server`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Allows deleting mcp serves in the db
 * @summary Edit Mcp Server
 * {@link /v1/mcp/server}
 */
export async function editMcpServerV1McpServerPut({
	body,
	headers,
	config = {},
}: {
	body: EditMcpServerV1McpServerPutMutationRequest;
	headers?: EditMcpServerV1McpServerPutHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EditMcpServerV1McpServerPutMutationResponse,
		ErrorWrapper<EditMcpServerV1McpServerPut422>,
		EditMcpServerV1McpServerPutMutationRequest,
		EditMcpServerV1McpServerPutHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "PUT",
		url: `/v1/mcp/server`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Returns the mcp server info
 * @summary Fetch Mcp Server
 * {@link /v1/mcp/server/:server_id}
 */
export async function fetchMcpServerV1McpServerServerIdGet({
	pathParams,
	config = {},
}: {
	pathParams: FetchMcpServerV1McpServerServerIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["server_id"]) {
		throw new Error(`Missing required path parameter: server_id`);
	}
	const data = await request<
		FetchMcpServerV1McpServerServerIdGetQueryResponse,
		ErrorWrapper<FetchMcpServerV1McpServerServerIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		FetchMcpServerV1McpServerServerIdGetPathParams
	>({ method: "GET", url: `/v1/mcp/server/${pathParams["server_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Allows deleting mcp serves in the db
 * @summary Remove Mcp Server
 * {@link /v1/mcp/server/:server_id}
 */
export async function removeMcpServerV1McpServerServerIdDelete({
	pathParams,
	headers,
	config = {},
}: {
	pathParams: RemoveMcpServerV1McpServerServerIdDeletePathParams;
	headers?: RemoveMcpServerV1McpServerServerIdDeleteHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["server_id"]) {
		throw new Error(`Missing required path parameter: server_id`);
	}
	const data = await request<
		RemoveMcpServerV1McpServerServerIdDeleteMutationResponse,
		ErrorWrapper<RemoveMcpServerV1McpServerServerIdDelete422>,
		null,
		RemoveMcpServerV1McpServerServerIdDeleteHeaderParams,
		Record<string, string>,
		RemoveMcpServerV1McpServerServerIdDeletePathParams
	>({
		method: "DELETE",
		url: `/v1/mcp/server/${pathParams["server_id"]}`,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Use `{PROXY_BASE_URL}/anthropic/v1/messages` instead - [Docs](https://docs.litellm.ai/docs/anthropic_completion).This was a BETA endpoint that calls 100+ LLMs in the anthropic format.
 * @summary Anthropic Response
 * {@link /v1/messages}
 */
export async function anthropicResponseV1MessagesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AnthropicResponseV1MessagesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/messages`, ...requestConfig });
	return data;
}

/**
 * @description Count tokens for Anthropic Messages API format.This endpoint follows the Anthropic Messages API token counting specification.It accepts the same parameters as the /v1/messages endpoint but returnstoken counts instead of generating a response.Example usage:```curl -X POST "http://localhost:4000/v1/messages/count_tokens?beta=true"       -H "Content-Type: application/json"       -H "Authorization: Bearer your-key"       -d '{    "model": "claude-3-sonnet-20240229",    "messages": [{"role": "user", "content": "Hello Claude!"}]  }'```Returns: {"input_tokens": <number>}
 * @summary Count Tokens
 * {@link /v1/messages/count_tokens}
 */
export async function countTokensV1MessagesCountTokensPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CountTokensV1MessagesCountTokensPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/messages/count_tokens`, ...requestConfig });
	return data;
}

/**
 * @summary Google Generate Content
 * {@link /models/:model_name:generateContent}
 */
export async function googleGenerateContentModelsModelNameGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleGenerateContentModelsModelNameGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleGenerateContentModelsModelNameGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleGenerateContentModelsModelNameGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleGenerateContentModelsModelNameGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/models/${pathParams["model_name"]}:generateContent`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Google Generate Content
 * {@link /v1beta/models/:model_name:generateContent}
 */
export async function googleGenerateContentV1BetaModelsModelNameGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleGenerateContentV1BetaModelsModelNameGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/v1beta/models/${pathParams["model_name"]}:generateContent`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Google Stream Generate Content
 * {@link /models/:model_name:streamGenerateContent}
 */
export async function googleStreamGenerateContentModelsModelNameStreamGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/models/${pathParams["model_name"]}:streamGenerateContent`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Google Stream Generate Content
 * {@link /v1beta/models/:model_name:streamGenerateContent}
 */
export async function googleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/v1beta/models/${pathParams["model_name"]}:streamGenerateContent`,
		...requestConfig,
	});
	return data;
}

/**
 * @description ```jsonreturn {    "totalTokens": 31,    "totalBillableCharacters": 96,    "promptTokensDetails": [        {        "modality": "TEXT",        "tokenCount": 31        }    ]}```
 * @summary Google Count Tokens
 * {@link /models/:model_name:countTokens}
 */
export async function googleCountTokensModelsModelNameCountTokensPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleCountTokensModelsModelNameCountTokensPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleCountTokensModelsModelNameCountTokensPostMutationResponse,
		ErrorWrapper<GoogleCountTokensModelsModelNameCountTokensPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleCountTokensModelsModelNameCountTokensPostPathParams
	>({ method: "POST", url: `/models/${pathParams["model_name"]}:countTokens`, ...requestConfig });
	return data;
}

/**
 * @description ```jsonreturn {    "totalTokens": 31,    "totalBillableCharacters": 96,    "promptTokensDetails": [        {        "modality": "TEXT",        "tokenCount": 31        }    ]}```
 * @summary Google Count Tokens
 * {@link /v1beta/models/:model_name:countTokens}
 */
export async function googleCountTokensV1BetaModelsModelNameCountTokensPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleCountTokensV1BetaModelsModelNameCountTokensPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleCountTokensV1BetaModelsModelNameCountTokensPostMutationResponse,
		ErrorWrapper<GoogleCountTokensV1BetaModelsModelNameCountTokensPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleCountTokensV1BetaModelsModelNameCountTokensPostPathParams
	>({
		method: "POST",
		url: `/v1beta/models/${pathParams["model_name"]}:countTokens`,
		...requestConfig,
	});
	return data;
}

/**
 * @description GET configured pass through endpoint.If no endpoint_id given, return all configured endpoints.
 * @summary Get Pass Through Endpoints
 * {@link /config/pass_through_endpoint/team/:team_id}
 */
export async function getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams;
	queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryResponse,
		ErrorWrapper<GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet422>,
		null,
		Record<string, string>,
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams,
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams
	>({
		method: "GET",
		url: `/config/pass_through_endpoint/team/${pathParams["team_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description GET configured pass through endpoint.If no endpoint_id given, return all configured endpoints.
 * @summary Get Pass Through Endpoints
 * {@link /config/pass_through_endpoint}
 */
export async function getPassThroughEndpointsConfigPassThroughEndpointGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetPassThroughEndpointsConfigPassThroughEndpointGetQueryResponse,
		ErrorWrapper<GetPassThroughEndpointsConfigPassThroughEndpointGet422>,
		null,
		Record<string, string>,
		GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/config/pass_through_endpoint`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Create new pass-through endpoint
 * @summary Create Pass Through Endpoints
 * {@link /config/pass_through_endpoint}
 */
export async function createPassThroughEndpointsConfigPassThroughEndpointPost({
	body,
	config = {},
}: {
	body: CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationResponse,
		ErrorWrapper<CreatePassThroughEndpointsConfigPassThroughEndpointPost422>,
		CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/config/pass_through_endpoint`, body, ...requestConfig });
	return data;
}

/**
 * @description Delete a pass-through endpoint by ID.Returns - the deleted endpoint
 * @summary Delete Pass Through Endpoints
 * {@link /config/pass_through_endpoint}
 */
export async function deletePassThroughEndpointsConfigPassThroughEndpointDelete({
	queryParams,
	config = {},
}: {
	queryParams: DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeletePassThroughEndpointsConfigPassThroughEndpointDeleteMutationResponse,
		ErrorWrapper<DeletePassThroughEndpointsConfigPassThroughEndpointDelete422>,
		null,
		Record<string, string>,
		DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams,
		Record<string, string>
	>({ method: "DELETE", url: `/config/pass_through_endpoint`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Update a pass-through endpoint by ID.
 * @summary Update Pass Through Endpoints
 * {@link /config/pass_through_endpoint/:endpoint_id}
 */
export async function updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams;
	body: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["endpoint_id"]) {
		throw new Error(`Missing required path parameter: endpoint_id`);
	}
	const data = await request<
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationResponse,
		ErrorWrapper<UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost422>,
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams
	>({
		method: "POST",
		url: `/config/pass_through_endpoint/${pathParams["endpoint_id"]}`,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description [DEPRECATED] use `/health/liveliness` instead.A test endpoint that pings the proxy server to check if it's healthy.Parameters:    request (Request): The incoming request.Returns:    dict: A dictionary containing the route of the request URL.
 * @summary Test Endpoint
 * {@link /test}
 */
export async function testEndpointTestGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestEndpointTestGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/test`, ...requestConfig });
	return data;
}

/**
 * @description Use this admin-only endpoint to check if the service is healthy.Example:```curl -L -X GET 'http://0.0.0.0:4000/health/services?service=datadog'     -H 'Authorization: Bearer sk-1234'```
 * @summary Health Services Endpoint
 * {@link /health/services}
 */
export async function healthServicesEndpointHealthServicesGet({
	queryParams,
	config = {},
}: {
	queryParams: HealthServicesEndpointHealthServicesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthServicesEndpointHealthServicesGetQueryResponse,
		ErrorWrapper<HealthServicesEndpointHealthServicesGet422>,
		null,
		Record<string, string>,
		HealthServicesEndpointHealthServicesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/health/services`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description  USE `/health/liveliness` to health check the proxy See more  https://docs.litellm.ai/docs/proxy/healthCheck the health of all the endpoints in config.yamlTo run health checks in the background, add this to config.yaml:```general_settings:    # ... other settings    background_health_checks: True```else, the health checks will be run on models when /health is called.
 * @summary Health Endpoint
 * {@link /health}
 */
export async function healthEndpointHealthGet({
	queryParams,
	config = {},
}: {
	queryParams?: HealthEndpointHealthGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthEndpointHealthGetQueryResponse,
		ErrorWrapper<HealthEndpointHealthGet422>,
		null,
		Record<string, string>,
		HealthEndpointHealthGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/health`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get health check history for modelsReturns historical health check data with optional filtering.
 * @summary Health Check History Endpoint
 * {@link /health/history}
 */
export async function healthCheckHistoryEndpointHealthHistoryGet({
	queryParams,
	config = {},
}: {
	queryParams?: HealthCheckHistoryEndpointHealthHistoryGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthCheckHistoryEndpointHealthHistoryGetQueryResponse,
		ErrorWrapper<HealthCheckHistoryEndpointHealthHistoryGet422>,
		null,
		Record<string, string>,
		HealthCheckHistoryEndpointHealthHistoryGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/health/history`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get the latest health check status for all modelsReturns the most recent health check result for each model.
 * @summary Latest Health Checks Endpoint
 * {@link /health/latest}
 */
export async function latestHealthChecksEndpointHealthLatestGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		LatestHealthChecksEndpointHealthLatestGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/latest`, ...requestConfig });
	return data;
}

/**
 * @description Get the status of shared health check coordination across pods.Returns information about Redis connectivity, lock status, and cache status.
 * @summary Shared Health Check Status Endpoint
 * {@link /health/shared-status}
 */
export async function sharedHealthCheckStatusEndpointHealthSharedStatusGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SharedHealthCheckStatusEndpointHealthSharedStatusGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/shared-status`, ...requestConfig });
	return data;
}

/**
 * @description Returns a list of litellm level settingsThis is useful for debugging and ensuring the proxy server is configured correctly.Response schema:```{    "alerting": _alerting,    "litellm.callbacks": litellm_callbacks,    "litellm.input_callback": litellm_input_callbacks,    "litellm.failure_callback": litellm_failure_callbacks,    "litellm.success_callback": litellm_success_callbacks,    "litellm._async_success_callback": litellm_async_success_callbacks,    "litellm._async_failure_callback": litellm_async_failure_callbacks,    "litellm._async_input_callback": litellm_async_input_callbacks,    "all_litellm_callbacks": all_litellm_callbacks,    "num_callbacks": len(all_litellm_callbacks),    "num_alerting": _num_alerting,    "litellm.request_timeout": litellm.request_timeout,}```
 * @summary Active Callbacks
 * {@link /active/callbacks}
 */
export async function activeCallbacksActiveCallbacksGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ActiveCallbacksActiveCallbacksGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/active/callbacks`, ...requestConfig });
	return data;
}

/**
 * @description Returns a list of litellm level settingsThis is useful for debugging and ensuring the proxy server is configured correctly.Response schema:```{    "alerting": _alerting,    "litellm.callbacks": litellm_callbacks,    "litellm.input_callback": litellm_input_callbacks,    "litellm.failure_callback": litellm_failure_callbacks,    "litellm.success_callback": litellm_success_callbacks,    "litellm._async_success_callback": litellm_async_success_callbacks,    "litellm._async_failure_callback": litellm_async_failure_callbacks,    "litellm._async_input_callback": litellm_async_input_callbacks,    "all_litellm_callbacks": all_litellm_callbacks,    "num_callbacks": len(all_litellm_callbacks),    "num_alerting": _num_alerting,    "litellm.request_timeout": litellm.request_timeout,}```
 * @summary Active Callbacks
 * {@link /settings}
 */
export async function activeCallbacksSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ActiveCallbacksSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/settings`, ...requestConfig });
	return data;
}

/**
 * @description Unprotected endpoint for checking if worker can receive requests
 * @summary Health Readiness
 * {@link /health/readiness}
 */
export async function healthReadinessHealthReadinessGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthReadinessHealthReadinessGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/readiness`, ...requestConfig });
	return data;
}

/**
 * @description Options endpoint for health/readiness check.
 * @summary Health Readiness Options
 * {@link /health/readiness}
 */
export async function healthReadinessOptionsHealthReadinessOptions({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthReadinessOptionsHealthReadinessOptionsMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "OPTIONS", url: `/health/readiness`, ...requestConfig });
	return data;
}

/**
 * @description Unprotected endpoint for checking if worker is alive
 * @summary Health Liveliness
 * {@link /health/liveness}
 */
export async function healthLivelinessHealthLivenessGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessHealthLivenessGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/liveness`, ...requestConfig });
	return data;
}

/**
 * @description Options endpoint for health/liveliness check.
 * @summary Health Liveliness Options
 * {@link /health/liveness}
 */
export async function healthLivelinessOptionsHealthLivenessOptions({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessOptionsHealthLivenessOptionsMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "OPTIONS", url: `/health/liveness`, ...requestConfig });
	return data;
}

/**
 * @description Unprotected endpoint for checking if worker is alive
 * @summary Health Liveliness
 * {@link /health/liveliness}
 */
export async function healthLivelinessHealthLivelinessGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessHealthLivelinessGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/liveliness`, ...requestConfig });
	return data;
}

/**
 * @description Options endpoint for health/liveliness check.
 * @summary Health Liveliness Options
 * {@link /health/liveliness}
 */
export async function healthLivelinessOptionsHealthLivelinessOptions({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessOptionsHealthLivelinessOptionsMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "OPTIONS", url: `/health/liveliness`, ...requestConfig });
	return data;
}

/**
 * @description Test a direct connection to a specific model.This endpoint allows you to verify if your proxy can successfully connect to a specific model.It's useful for troubleshooting model connectivity issues without going through the full proxy routing.Example:```bashcurl -X POST 'http://localhost:4000/health/test_connection' \  -H 'Authorization: Bearer sk-1234' \  -H 'Content-Type: application/json' \  -d '{    "litellm_params": {        "model": "gpt-4",        "custom_llm_provider": "azure_ai",        "litellm_credential_name": null,        "api_key": "6xxxxxxx",        "api_base": "https://litellm8397336933.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21",    },    "mode": "chat"  }'```Returns:    dict: A dictionary containing the health check result with either success information or error details.
 * @summary Test Model Connection
 * {@link /health/test_connection}
 */
export async function testModelConnectionHealthTestConnectionPost({
	body,
	config = {},
}: {
	body?: TestModelConnectionHealthTestConnectionPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestModelConnectionHealthTestConnectionPostMutationResponse,
		ErrorWrapper<TestModelConnectionHealthTestConnectionPost422>,
		TestModelConnectionHealthTestConnectionPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/health/test_connection`, body, ...requestConfig });
	return data;
}

/**
 * @description Generate an API key based on the provided data.Docs: https://docs.litellm.ai/docs/proxy/virtual_keysParameters:- duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- key_alias: Optional[str] - User defined key alias- key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.- team_id: Optional[str] - The team id of the key- user_id: Optional[str] - The user id of the key- organization_id: Optional[str] - The organization id of the key. If not set, and team_id is set, the organization id will be the same as the team id. If conflict, an error will be raised.- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.- models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)- aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models- config: Optional[dict] - any key-specific configs, overrides config in config.yaml- spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend- send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key- max_budget: Optional[float] - Specify max budget for a given key.- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.- metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- guardrails: Optional[List[str]] - List of active guardrails for the key- permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.- model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.- model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.- tpm_limit_type: Optional[str] - Type of tpm limit. Options: "best_effort_throughput" (no error if we're overallocating tpm), "guaranteed_throughput" (raise an error if we're overallocating tpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".- rpm_limit_type: Optional[str] - Type of rpm limit. Options: "best_effort_throughput" (no error if we're overallocating rpm), "guaranteed_throughput" (raise an error if we're overallocating rpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request- blocked: Optional[bool] - Whether the key is blocked.- rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)- tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)- soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]- allowed_passthrough_routes: Optional[list] - List of allowed pass through endpoints for the key. Store the actual endpoint or store a wildcard pattern for a set of endpoints. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through endpoints the key can access, without specifying the routes. If allowed_routes is specified, allowed_pass_through_endpoints is ignored.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- key_type: Optional[str] - Type of key that determines default allowed routes. Options: "llm_api" (can call LLM API routes), "management" (can call management routes), "read_only" (can only call info/read routes), "default" (uses default allowed routes). Defaults to "default".- prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.- auto_rotate: Optional[bool] - Whether this key should be automatically rotated (regenerated)- rotation_interval: Optional[str] - How often to auto-rotate this key (e.g., '30s', '30m', '30h', '30d'). Required if auto_rotate=True.- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.Examples:1. Allow users to turn on/off pii masking```bashcurl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "permissions": {"allow_pii_controls": true}}'```Returns:- key: (str) The generated api key- expires: (datetime) Datetime object for when key expires.- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * @summary Generate Key Fn
 * {@link /key/generate}
 */
export async function generateKeyFnKeyGeneratePost({
	body,
	headers,
	config = {},
}: {
	body?: GenerateKeyFnKeyGeneratePostMutationRequest;
	headers?: GenerateKeyFnKeyGeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GenerateKeyFnKeyGeneratePostMutationResponse,
		ErrorWrapper<GenerateKeyFnKeyGeneratePost422>,
		GenerateKeyFnKeyGeneratePostMutationRequest,
		GenerateKeyFnKeyGeneratePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/generate`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Generate a Service Account API key based on the provided data. This key does not belong to any user. It belongs to the team.Why use a service account key?- Prevent key from being deleted when user is deleted.- Apply team limits, not team member limits to key.Docs: https://docs.litellm.ai/docs/proxy/virtual_keysParameters:- duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- key_alias: Optional[str] - User defined key alias- key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.- team_id: Optional[str] - The team id of the key- user_id: Optional[str] - [NON-FUNCTIONAL] THIS WILL BE IGNORED. The user id of the key- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.- models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)- aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models- config: Optional[dict] - any key-specific configs, overrides config in config.yaml- spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend- send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key- max_budget: Optional[float] - Specify max budget for a given key.- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.- metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- guardrails: Optional[List[str]] - List of active guardrails for the key- permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.- model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.- model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.- tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request- blocked: Optional[bool] - Whether the key is blocked.- rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)- tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)- soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.Examples:- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.1. Allow users to turn on/off pii masking```bashcurl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "permissions": {"allow_pii_controls": true}}'```Returns:- key: (str) The generated api key- expires: (datetime) Datetime object for when key expires.- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * @summary Generate Service Account Key Fn
 * {@link /key/service-account/generate}
 */
export async function generateServiceAccountKeyFnKeyServiceAccountGeneratePost({
	body,
	headers,
	config = {},
}: {
	body?: GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequest;
	headers?: GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationResponse,
		ErrorWrapper<GenerateServiceAccountKeyFnKeyServiceAccountGeneratePost422>,
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequest,
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/service-account/generate`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Update an existing API key's parameters.Parameters:- key: str - The key to update- key_alias: Optional[str] - User-friendly key alias- user_id: Optional[str] - User ID associated with key- team_id: Optional[str] - Team ID associated with key- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.- models: Optional[list] - Model_name's a user is allowed to call- tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)- spend: Optional[float] - Amount spent by key- max_budget: Optional[float] - Max budget for key- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)- soft_budget: Optional[float] - [TODO] Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.- max_parallel_requests: Optional[int] - Rate limit for parallel requests- metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}- tpm_limit: Optional[int] - Tokens per minute limit- rpm_limit: Optional[int] - Requests per minute limit- model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}- model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}- tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- allowed_cache_controls: Optional[list] - List of allowed cache control values- duration: Optional[str] - Key validity duration ("30d", "1h", etc.)- permissions: Optional[dict] - Key-specific permissions- send_invite_email: Optional[bool] - Send invite email to user_id- guardrails: Optional[List[str]] - List of active guardrails for the key- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- blocked: Optional[bool] - Whether the key is blocked- aliases: Optional[dict] - Model aliases for the key - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)- config: Optional[dict] - [DEPRECATED PARAM] Key-specific config.- temp_budget_increase: Optional[float] - Temporary budget increase for the key (Enterprise only).- temp_budget_expiry: Optional[str] - Expiry time for the temporary budget increase (Enterprise only).- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]- allowed_passthrough_routes: Optional[list] - List of allowed pass through routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through routes the key can access, without specifying the routes. If allowed_routes is specified, allowed_passthrough_routes is ignored.- prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- auto_rotate: Optional[bool] - Whether this key should be automatically rotated- rotation_interval: Optional[str] - How often to rotate this key (e.g., '30d', '90d'). Required if auto_rotate=True- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.Example:```bashcurl --location 'http://0.0.0.0:4000/key/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "key": "sk-1234",    "key_alias": "my-key",    "user_id": "user-1234",    "team_id": "team-1234",    "max_budget": 100,    "metadata": {"any_key": "any-val"},}'```
 * @summary Update Key Fn
 * {@link /key/update}
 */
export async function updateKeyFnKeyUpdatePost({
	body,
	headers,
	config = {},
}: {
	body: UpdateKeyFnKeyUpdatePostMutationRequest;
	headers?: UpdateKeyFnKeyUpdatePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateKeyFnKeyUpdatePostMutationResponse,
		ErrorWrapper<UpdateKeyFnKeyUpdatePost422>,
		UpdateKeyFnKeyUpdatePostMutationRequest,
		UpdateKeyFnKeyUpdatePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/update`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Delete a key from the key management system.Parameters::- keys (List[str]): A list of keys or hashed keys to delete. Example {"keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}- key_aliases (List[str]): A list of key aliases to delete. Can be passed instead of `keys`.Example {"key_aliases": ["alias1", "alias2"]}Returns:- deleted_keys (List[str]): A list of deleted keys. Example {"deleted_keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}Example:```bashcurl --location 'http://0.0.0.0:4000/key/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "keys": ["sk-QWrxEynunsNpV1zT48HIrw"]}'```Raises:    HTTPException: If an error occurs during key deletion.
 * @summary Delete Key Fn
 * {@link /key/delete}
 */
export async function deleteKeyFnKeyDeletePost({
	body,
	headers,
	config = {},
}: {
	body?: DeleteKeyFnKeyDeletePostMutationRequest;
	headers?: DeleteKeyFnKeyDeletePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteKeyFnKeyDeletePostMutationResponse,
		ErrorWrapper<DeleteKeyFnKeyDeletePost422>,
		DeleteKeyFnKeyDeletePostMutationRequest,
		DeleteKeyFnKeyDeletePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/delete`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Retrieve information about a key.Parameters:    key: Optional[str] = Query parameter representing the key in the request    user_api_key_dict: UserAPIKeyAuth = Dependency representing the user's API keyReturns:    Dict containing the key and its associated informationExample Curl:```curl -X GET "http://0.0.0.0:4000/key/info?key=sk-02Wr4IAlN3NvPXvL5JVvDA" -H "Authorization: Bearer sk-1234"```Example Curl - if no key is passed, it will use the Key Passed in Authorization Header```curl -X GET "http://0.0.0.0:4000/key/info" -H "Authorization: Bearer sk-02Wr4IAlN3NvPXvL5JVvDA"```
 * @summary Info Key Fn
 * {@link /key/info}
 */
export async function infoKeyFnKeyInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: InfoKeyFnKeyInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoKeyFnKeyInfoGetQueryResponse,
		ErrorWrapper<InfoKeyFnKeyInfoGet422>,
		null,
		Record<string, string>,
		InfoKeyFnKeyInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/key/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Regenerate an existing API key while optionally updating its parameters.Parameters:- key: str (path parameter) - The key to regenerate- data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update    - key: Optional[str] - The key to regenerate.    - new_master_key: Optional[str] - The new master key to use, if key is the master key.    - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.    - key_alias: Optional[str] - User-friendly key alias    - user_id: Optional[str] - User ID associated with key    - team_id: Optional[str] - Team ID associated with key    - models: Optional[list] - Model_name's a user is allowed to call    - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)    - spend: Optional[float] - Amount spent by key    - max_budget: Optional[float] - Max budget for key    - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}    - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)    - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.    - max_parallel_requests: Optional[int] - Rate limit for parallel requests    - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}    - tpm_limit: Optional[int] - Tokens per minute limit    - rpm_limit: Optional[int] - Requests per minute limit    - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}    - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}    - allowed_cache_controls: Optional[list] - List of allowed cache control values    - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)    - permissions: Optional[dict] - Key-specific permissions    - guardrails: Optional[List[str]] - List of active guardrails for the key    - blocked: Optional[bool] - Whether the key is blockedReturns:- GenerateKeyResponse containing the new key and its updated parametersExample:```bashcurl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "max_budget": 100,    "metadata": {"team": "core-infra"},    "models": ["gpt-4", "gpt-3.5-turbo"]}'```Note: This is an Enterprise feature. It requires a premium license to use.
 * @summary Regenerate Key Fn
 * {@link /key/regenerate}
 */
export async function regenerateKeyFnKeyRegeneratePost({
	body,
	queryParams,
	headers,
	config = {},
}: {
	body?: RegenerateKeyFnKeyRegeneratePostMutationRequest;
	queryParams?: RegenerateKeyFnKeyRegeneratePostQueryParams;
	headers?: RegenerateKeyFnKeyRegeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RegenerateKeyFnKeyRegeneratePostMutationResponse,
		ErrorWrapper<RegenerateKeyFnKeyRegeneratePost422>,
		RegenerateKeyFnKeyRegeneratePostMutationRequest,
		RegenerateKeyFnKeyRegeneratePostHeaderParams,
		RegenerateKeyFnKeyRegeneratePostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/regenerate`,
		queryParams,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Regenerate an existing API key while optionally updating its parameters.Parameters:- key: str (path parameter) - The key to regenerate- data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update    - key: Optional[str] - The key to regenerate.    - new_master_key: Optional[str] - The new master key to use, if key is the master key.    - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.    - key_alias: Optional[str] - User-friendly key alias    - user_id: Optional[str] - User ID associated with key    - team_id: Optional[str] - Team ID associated with key    - models: Optional[list] - Model_name's a user is allowed to call    - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)    - spend: Optional[float] - Amount spent by key    - max_budget: Optional[float] - Max budget for key    - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}    - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)    - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.    - max_parallel_requests: Optional[int] - Rate limit for parallel requests    - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}    - tpm_limit: Optional[int] - Tokens per minute limit    - rpm_limit: Optional[int] - Requests per minute limit    - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}    - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}    - allowed_cache_controls: Optional[list] - List of allowed cache control values    - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)    - permissions: Optional[dict] - Key-specific permissions    - guardrails: Optional[List[str]] - List of active guardrails for the key    - blocked: Optional[bool] - Whether the key is blockedReturns:- GenerateKeyResponse containing the new key and its updated parametersExample:```bashcurl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "max_budget": 100,    "metadata": {"team": "core-infra"},    "models": ["gpt-4", "gpt-3.5-turbo"]}'```Note: This is an Enterprise feature. It requires a premium license to use.
 * @summary Regenerate Key Fn
 * {@link /key/:key/regenerate}
 */
export async function regenerateKeyFnKeyKeyRegeneratePost({
	pathParams,
	body,
	headers,
	config = {},
}: {
	pathParams: RegenerateKeyFnKeyKeyRegeneratePostPathParams;
	body?: RegenerateKeyFnKeyKeyRegeneratePostMutationRequest;
	headers?: RegenerateKeyFnKeyKeyRegeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["key"]) {
		throw new Error(`Missing required path parameter: key`);
	}
	const data = await request<
		RegenerateKeyFnKeyKeyRegeneratePostMutationResponse,
		ErrorWrapper<RegenerateKeyFnKeyKeyRegeneratePost422>,
		RegenerateKeyFnKeyKeyRegeneratePostMutationRequest,
		RegenerateKeyFnKeyKeyRegeneratePostHeaderParams,
		Record<string, string>,
		RegenerateKeyFnKeyKeyRegeneratePostPathParams
	>({
		method: "POST",
		url: `/key/${pathParams["key"]}/regenerate`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description List all keys for a given user / team / organization.Returns:    {        "keys": List[str] or List[UserAPIKeyAuth],        "total_count": int,        "current_page": int,        "total_pages": int,    }
 * @summary List Keys
 * {@link /key/list}
 */
export async function listKeysKeyListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListKeysKeyListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListKeysKeyListGetQueryResponse,
		ErrorWrapper<ListKeysKeyListGet422>,
		null,
		Record<string, string>,
		ListKeysKeyListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/key/list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Lists all key aliasesReturns:    {        "aliases": List[str]    }
 * @summary Key Aliases
 * {@link /key/aliases}
 */
export async function keyAliasesKeyAliasesGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		KeyAliasesKeyAliasesGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/key/aliases`, ...requestConfig });
	return data;
}

/**
 * @description Block an Virtual key from making any requests.Parameters:- key: str - The key to block. Can be either the unhashed key (sk-...) or the hashed key value Example:```bashcurl --location 'http://0.0.0.0:4000/key/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"}'```Note: This is an admin-only endpoint. Only proxy admins can block keys.
 * @summary Block Key
 * {@link /key/block}
 */
export async function blockKeyKeyBlockPost({
	body,
	headers,
	config = {},
}: {
	body: BlockKeyKeyBlockPostMutationRequest;
	headers?: BlockKeyKeyBlockPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BlockKeyKeyBlockPostMutationResponse,
		ErrorWrapper<BlockKeyKeyBlockPost422>,
		BlockKeyKeyBlockPostMutationRequest,
		BlockKeyKeyBlockPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/block`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Unblock a Virtual key to allow it to make requests again.Parameters:- key: str - The key to unblock. Can be either the unhashed key (sk-...) or the hashed key valueExample:```bashcurl --location 'http://0.0.0.0:4000/key/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"}'```Note: This is an admin-only endpoint. Only proxy admins can unblock keys.
 * @summary Unblock Key
 * {@link /key/unblock}
 */
export async function unblockKeyKeyUnblockPost({
	body,
	headers,
	config = {},
}: {
	body: UnblockKeyKeyUnblockPostMutationRequest;
	headers?: UnblockKeyKeyUnblockPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UnblockKeyKeyUnblockPostMutationResponse,
		ErrorWrapper<UnblockKeyKeyUnblockPost422>,
		UnblockKeyKeyUnblockPostMutationRequest,
		UnblockKeyKeyUnblockPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/unblock`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Check the health of the keyChecks:- If key based logging is configured correctly - sends a test logUsage Pass the key in the request header```bashcurl -X POST "http://localhost:4000/key/health"      -H "Authorization: Bearer sk-1234"      -H "Content-Type: application/json"```Response when logging callbacks are setup correctly:```json{  "key": "healthy",  "logging_callbacks": {    "callbacks": [      "gcs_bucket"    ],    "status": "healthy",    "details": "No logger exceptions triggered, system is healthy. Manually check if logs were sent to ['gcs_bucket']"  }}```Response when logging callbacks are not setup correctly:```json{  "key": "unhealthy",  "logging_callbacks": {    "callbacks": [      "gcs_bucket"    ],    "status": "unhealthy",    "details": "Logger exceptions triggered, system is unhealthy: Failed to load vertex credentials. Check to see if credentials containing partial/invalid information."  }}```
 * @summary Key Health
 * {@link /key/health}
 */
export async function keyHealthKeyHealthPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		KeyHealthKeyHealthPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/key/health`, ...requestConfig });
	return data;
}

/**
 * @description Use this to create a new INTERNAL user with a budget.Internal Users can access LiteLLM Admin UI to make keys, request access to models.This creates a new user and generates a new api key for the new user. The new api key is returned.Returns user id, budget + new key.Parameters:- user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.- user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.- teams: Optional[list] - specify a list of team id's a user belongs to.- user_email: Optional[str] - Specify a user email.- send_invite_email: Optional[bool] - Specify if an invite email should be sent.- user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`- max_budget: Optional[float] - Specify max budget for a given user.- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").- models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models). Set to ['no-default-models'] to block all model access. Restricting user to only team-based model access.- tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)- rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)- auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response- aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)- config: Optional[dict] - [DEPRECATED PARAM] User-specific config.- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-- blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.- guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user- permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.- metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.- soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.- model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)- model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)- model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)- spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").- team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None. - duration: Optional[str] - Duration for the key auto-created on `/user/new`. Default is None.- key_alias: Optional[str] - Alias for the key auto-created on `/user/new`. Default is None.- sso_user_id: Optional[str] - The id of the user in the SSO provider.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.- prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.- organizations: List[str] - List of organization id's the user is a member ofReturns:- key: (str) The generated api key for the user- expires: (datetime) Datetime object for when key expires.- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.- max_budget: (float|None) Max budget for given user.Usage Example ```shell curl -X POST "http://localhost:4000/user/new"      -H "Content-Type: application/json"      -H "Authorization: Bearer sk-1234"      -d '{     "username": "new_user",     "email": "new_user@example.com" }'```
 * @summary New User
 * {@link /user/new}
 */
export async function newUserUserNewPost({
	body,
	config = {},
}: {
	body?: NewUserUserNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewUserUserNewPostMutationResponse,
		ErrorWrapper<NewUserUserNewPost422>,
		NewUserUserNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/user/new`, body, ...requestConfig });
	return data;
}

/**
 * @description [10/07/2024]Note: To get all users (+pagination), use `/user/list` endpoint.Use this to get user information. (user row + all user key info)Example request```curl -X GET 'http://localhost:4000/user/info?user_id=krrish7%40berri.ai'     --header 'Authorization: Bearer sk-1234'```
 * @summary User Info
 * {@link /user/info}
 */
export async function userInfoUserInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: UserInfoUserInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UserInfoUserInfoGetQueryResponse,
		ErrorWrapper<UserInfoUserInfoGet422>,
		null,
		Record<string, string>,
		UserInfoUserInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Example curl ```curl --location 'http://0.0.0.0:4000/user/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "user_id": "test-litellm-user-4",    "user_role": "proxy_admin_viewer"}'```Parameters:    - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.    - user_email: Optional[str] - Specify a user email.    - password: Optional[str] - Specify a user password.    - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.    - teams: Optional[list] - specify a list of team id's a user belongs to.    - send_invite_email: Optional[bool] - Specify if an invite email should be sent.    - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`    - max_budget: Optional[float] - Specify max budget for a given user.    - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").    - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)    - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)    - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)    - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response    - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)    - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.    - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-    - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.    - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user    - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.    - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }    - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.    - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.    - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)    - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)    - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)    - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").    - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.     - duration: Optional[str] - [NOT IMPLEMENTED].    - key_alias: Optional[str] - [NOT IMPLEMENTED].    - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.    - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.
 * @summary User Update
 * {@link /user/update}
 */
export async function userUpdateUserUpdatePost({
	body,
	config = {},
}: {
	body?: UserUpdateUserUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UserUpdateUserUpdatePostMutationResponse,
		ErrorWrapper<UserUpdateUserUpdatePost422>,
		UserUpdateUserUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/user/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Bulk update multiple users at once.This endpoint allows updating multiple users in a single request. Each user updateis processed independently - if some updates fail, others will still succeed.Parameters:- users: Optional[List[UpdateUserRequest]] - List of specific user update requests- all_users: Optional[bool] - Set to true to update all users in the system- user_updates: Optional[UpdateUserRequest] - Updates to apply when all_users=TrueReturns:- results: List of individual update results- total_requested: Total number of users requested for update- successful_updates: Number of successful updates- failed_updates: Number of failed updatesExample request for specific users:```bashcurl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "users": [        {            "user_id": "user1",            "user_role": "internal_user",            "max_budget": 100.0        },        {            "user_email": "user2@example.com",             "user_role": "internal_user_viewer",            "max_budget": 50.0        }    ]}'```Example request for all users:```bashcurl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "all_users": true,    "user_updates": {        "user_role": "internal_user",        "max_budget": 50.0    }}'```
 * @summary Bulk User Update
 * {@link /user/bulk_update}
 */
export async function bulkUserUpdateUserBulkUpdatePost({
	body,
	headers,
	config = {},
}: {
	body?: BulkUserUpdateUserBulkUpdatePostMutationRequest;
	headers?: BulkUserUpdateUserBulkUpdatePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BulkUserUpdateUserBulkUpdatePostMutationResponse,
		ErrorWrapper<BulkUserUpdateUserBulkUpdatePost422>,
		BulkUserUpdateUserBulkUpdatePostMutationRequest,
		BulkUserUpdateUserBulkUpdatePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/user/bulk_update`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Get a paginated list of users with filtering and sorting options.Parameters:    role: Optional[str]        Filter users by role. Can be one of:        - proxy_admin        - proxy_admin_viewer        - internal_user        - internal_user_viewer    user_ids: Optional[str]        Get list of users by user_ids. Comma separated list of user_ids.    sso_ids: Optional[str]        Get list of users by sso_ids. Comma separated list of sso_ids.    user_email: Optional[str]        Filter users by partial email match    team: Optional[str]        Filter users by team id. Will match if user has this team in their teams array.    page: int        The page number to return    page_size: int        The number of items per page    sort_by: Optional[str]        Column to sort by (e.g. 'user_id', 'user_email', 'created_at', 'spend')    sort_order: Optional[str]        Sort order ('asc' or 'desc')
 * @summary Get Users
 * {@link /user/list}
 */
export async function getUsersUserListGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUsersUserListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUsersUserListGetQueryResponse,
		ErrorWrapper<GetUsersUserListGet422>,
		null,
		Record<string, string>,
		GetUsersUserListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description delete user and associated user keys```curl --location 'http://0.0.0.0:4000/user/delete' --header 'Authorization: Bearer sk-1234' --header 'Content-Type: application/json' --data-raw '{    "user_ids": ["45e3e396-ee08-4a61-a88e-16b3ce7e0849"]}'```Parameters:- user_ids: List[str] - The list of user id's to be deleted.
 * @summary Delete User
 * {@link /user/delete}
 */
export async function deleteUserUserDeletePost({
	body,
	headers,
	config = {},
}: {
	body: DeleteUserUserDeletePostMutationRequest;
	headers?: DeleteUserUserDeletePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteUserUserDeletePostMutationResponse,
		ErrorWrapper<DeleteUserUserDeletePost422>,
		DeleteUserUserDeletePostMutationRequest,
		DeleteUserUserDeletePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/user/delete`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description [BETA] This is a beta endpoint. It will change.Meant to optimize querying spend data for analytics for a user.Returns:(by date)- spend- prompt_tokens- completion_tokens- cache_read_input_tokens- cache_creation_input_tokens- total_tokens- api_requests- breakdown by model, api_key, provider
 * @summary Get User Daily Activity
 * {@link /user/daily/activity}
 */
export async function getUserDailyActivityUserDailyActivityGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUserDailyActivityUserDailyActivityGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUserDailyActivityUserDailyActivityGetQueryResponse,
		ErrorWrapper<GetUserDailyActivityUserDailyActivityGet422>,
		null,
		Record<string, string>,
		GetUserDailyActivityUserDailyActivityGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/daily/activity`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Aggregated analytics for a user's daily activity without pagination.Returns the same response shape as the paginated endpoint with page metadata set to single-page.
 * @summary Get User Daily Activity Aggregated
 * {@link /user/daily/activity/aggregated}
 */
export async function getUserDailyActivityAggregatedUserDailyActivityAggregatedGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryResponse,
		ErrorWrapper<GetUserDailyActivityAggregatedUserDailyActivityAggregatedGet422>,
		null,
		Record<string, string>,
		GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/daily/activity/aggregated`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Allow users to create a new team. Apply user permissions to their team. [Detailed Doc on setting team budgets](https://docs.litellm.ai/docs/proxy/team_budgets)Parameters:- team_alias: Optional[str] - User defined team alias- team_id: Optional[str] - The team id of the user. If none passed, we'll generate it.- members_with_roles: List[{"role": "admin" or "user", "user_id": "<user-id>"}] - A list of users and their roles in the team. Get user_id when making a new user via `/user/new`.- team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]- metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"extra_info": "some info"}- model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit for this team - applied across all keys for this team. - model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit for this team - applied across all keys for this team.- tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit- rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit- rpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of RPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating RPM, or "best_effort_throughput" for best effort enforcement.- tpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of TPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating TPM, or "best_effort_throughput" for best effort enforcement.- max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget- budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)- models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.- blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.- members: Optional[List] - Control team members via `/team/member/add` and `/team/member/delete`.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)- guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.- team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.- team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.- team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"- prompts: Optional[List[str]] - List of allowed prompts for the team. If specified, the team will only be able to use these specific prompts.- allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.Returns:- team_id: (str) Unique team id - used for tracking spend across multiple keys for same team id._deprecated_params:- admins: list - A list of user_id's for the admin role- users: list - A list of user_id's for the user roleExample Request:```curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{  "team_alias": "my-new-team_2",  "members_with_roles": [{"role": "admin", "user_id": "user-1234"},    {"role": "user", "user_id": "user-2434"}]}'``` ```curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{            "team_alias": "QA Prod Bot",            "max_budget": 0.000000001,            "budget_duration": "1d"        }'```
 * @summary New Team
 * {@link /team/new}
 */
export async function newTeamTeamNewPost({
	body,
	headers,
	config = {},
}: {
	body?: NewTeamTeamNewPostMutationRequest;
	headers?: NewTeamTeamNewPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewTeamTeamNewPostMutationResponse,
		ErrorWrapper<NewTeamTeamNewPost422>,
		NewTeamTeamNewPostMutationRequest,
		NewTeamTeamNewPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/team/new`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Use `/team/member_add` AND `/team/member/delete` to add/remove new team membersYou can now update team budget / rate limits via /team/updateParameters:- team_id: str - The team id of the user. Required param.- team_alias: Optional[str] - User defined team alias- team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]- metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit- rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit- max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget- budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)- models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)- guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.- team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.- team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.- team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"- allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.- model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit per model for this team. Example: {"gpt-4": 100, "gpt-3.5-turbo": 200}- model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit per model for this team. Example: {"gpt-4": 10000, "gpt-3.5-turbo": 20000}Example - update team TPM Limit- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.```curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",    "tpm_limit": 100}'```Example - Update Team `max_budget` budget```curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",    "max_budget": 10}'```
 * @summary Update Team
 * {@link /team/update}
 */
export async function updateTeamTeamUpdatePost({
	body,
	headers,
	config = {},
}: {
	body: UpdateTeamTeamUpdatePostMutationRequest;
	headers?: UpdateTeamTeamUpdatePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateTeamTeamUpdatePostMutationResponse,
		ErrorWrapper<UpdateTeamTeamUpdatePost422>,
		UpdateTeamTeamUpdatePostMutationRequest,
		UpdateTeamTeamUpdatePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/team/update`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Add new members (either via user_email or user_id) to a teamIf user doesn't exist, new user row will also be added to User TableOnly proxy_admin or admin of team, allowed to access this endpoint.```curl -X POST 'http://0.0.0.0:4000/team/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{"team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849", "member": {"role": "user", "user_id": "krrish247652@berri.ai"}}'```
 * @summary Team Member Add
 * {@link /team/member_add}
 */
export async function teamMemberAddTeamMemberAddPost({
	body,
	config = {},
}: {
	body: TeamMemberAddTeamMemberAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberAddTeamMemberAddPostMutationResponse,
		ErrorWrapper<TeamMemberAddTeamMemberAddPost422>,
		TeamMemberAddTeamMemberAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/member_add`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA]delete members (either via user_email or user_id) from a teamIf user doesn't exist, an exception will be raised```curl -X POST 'http://0.0.0.0:8000/team/member_delete' -H 'Authorization: Bearer sk-1234' -H 'Content-Type: application/json' -d '{    "team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",    "user_id": "krrish247652@berri.ai"}'```
 * @summary Team Member Delete
 * {@link /team/member_delete}
 */
export async function teamMemberDeleteTeamMemberDeletePost({
	body,
	config = {},
}: {
	body: TeamMemberDeleteTeamMemberDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberDeleteTeamMemberDeletePostMutationResponse,
		ErrorWrapper<TeamMemberDeleteTeamMemberDeletePost422>,
		TeamMemberDeleteTeamMemberDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/member_delete`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA]Update team member budgets and team member role
 * @summary Team Member Update
 * {@link /team/member_update}
 */
export async function teamMemberUpdateTeamMemberUpdatePost({
	body,
	config = {},
}: {
	body: TeamMemberUpdateTeamMemberUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberUpdateTeamMemberUpdatePostMutationResponse,
		ErrorWrapper<TeamMemberUpdateTeamMemberUpdatePost422>,
		TeamMemberUpdateTeamMemberUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/member_update`, body, ...requestConfig });
	return data;
}

/**
 * @description Bulk add multiple members to a team at once.This endpoint reuses the same logic as /team/member_add but provides a bulk-friendly response format.Parameters:- team_id: str - The ID of the team to add members to- members: List[Member] - List of members to add to the team- all_users: Optional[bool] - Flag to add all users on Proxy to the team- max_budget_in_team: Optional[float] - Maximum budget allocated to each user within the teamReturns:- results: List of individual member addition results- total_requested: Total number of members requested for addition- successful_additions: Number of successful additions  - failed_additions: Number of failed additions- updated_team: The updated team objectExample request:```bashcurl --location 'http://0.0.0.0:4000/team/bulk_member_add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234",    "members": [        {            "user_id": "user1",            "role": "user"        },        {            "user_email": "user2@example.com",            "role": "admin"        }    ],    "max_budget_in_team": 100.0}'```
 * @summary Bulk Team Member Add
 * {@link /team/bulk_member_add}
 */
export async function bulkTeamMemberAddTeamBulkMemberAddPost({
	body,
	config = {},
}: {
	body: BulkTeamMemberAddTeamBulkMemberAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BulkTeamMemberAddTeamBulkMemberAddPostMutationResponse,
		ErrorWrapper<BulkTeamMemberAddTeamBulkMemberAddPost422>,
		BulkTeamMemberAddTeamBulkMemberAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/bulk_member_add`, body, ...requestConfig });
	return data;
}

/**
 * @description delete team and associated team keysParameters:- team_ids: List[str] - Required. List of team IDs to delete. Example: ["team-1234", "team-5678"]```curl --location 'http://0.0.0.0:4000/team/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "team_ids": ["8d916b1c-510d-4894-a334-1c16a93344f5"]}'```
 * @summary Delete Team
 * {@link /team/delete}
 */
export async function deleteTeamTeamDeletePost({
	body,
	headers,
	config = {},
}: {
	body: DeleteTeamTeamDeletePostMutationRequest;
	headers?: DeleteTeamTeamDeletePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteTeamTeamDeletePostMutationResponse,
		ErrorWrapper<DeleteTeamTeamDeletePost422>,
		DeleteTeamTeamDeletePostMutationRequest,
		DeleteTeamTeamDeletePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/team/delete`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description get info on team + related keysParameters:- team_id: str - Required. The unique identifier of the team to get info on.```curl --location 'http://localhost:4000/team/info?team_id=your_team_id_here'     --header 'Authorization: Bearer your_api_key_here'```
 * @summary Team Info
 * {@link /team/info}
 */
export async function teamInfoTeamInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: TeamInfoTeamInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamInfoTeamInfoGetQueryResponse,
		ErrorWrapper<TeamInfoTeamInfoGet422>,
		null,
		Record<string, string>,
		TeamInfoTeamInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Blocks all calls from keys with this team id.Parameters:- team_id: str - Required. The unique identifier of the team to block.Example:```curl --location 'http://0.0.0.0:4000/team/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234"}'```Returns:- The updated team record with blocked=True
 * @summary Block Team
 * {@link /team/block}
 */
export async function blockTeamTeamBlockPost({
	body,
	config = {},
}: {
	body: BlockTeamTeamBlockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BlockTeamTeamBlockPostMutationResponse,
		ErrorWrapper<BlockTeamTeamBlockPost422>,
		BlockTeamTeamBlockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/block`, body, ...requestConfig });
	return data;
}

/**
 * @description Blocks all calls from keys with this team id.Parameters:- team_id: str - Required. The unique identifier of the team to unblock.Example:```curl --location 'http://0.0.0.0:4000/team/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234"}'```
 * @summary Unblock Team
 * {@link /team/unblock}
 */
export async function unblockTeamTeamUnblockPost({
	body,
	config = {},
}: {
	body: UnblockTeamTeamUnblockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UnblockTeamTeamUnblockPostMutationResponse,
		ErrorWrapper<UnblockTeamTeamUnblockPost422>,
		UnblockTeamTeamUnblockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/unblock`, body, ...requestConfig });
	return data;
}

/**
 * @summary List Available Teams
 * {@link /team/available}
 */
export async function listAvailableTeamsTeamAvailableGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListAvailableTeamsTeamAvailableGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListAvailableTeamsTeamAvailableGetQueryResponse,
		ErrorWrapper<ListAvailableTeamsTeamAvailableGet422>,
		null,
		Record<string, string>,
		ListAvailableTeamsTeamAvailableGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/available`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get a paginated list of teams with filtering and sorting options.Parameters:    user_id: Optional[str]        Only return teams which this user belongs to    organization_id: Optional[str]        Only return teams which belong to this organization    team_id: Optional[str]        Filter teams by exact team_id match    team_alias: Optional[str]        Filter teams by partial team_alias match    page: int        The page number to return    page_size: int        The number of items per page    sort_by: Optional[str]        Column to sort by (e.g. 'team_id', 'team_alias', 'created_at')    sort_order: str        Sort order ('asc' or 'desc')
 * @summary List Team V2
 * {@link /v2/team/list}
 */
export async function listTeamV2V2TeamListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListTeamV2V2TeamListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListTeamV2V2TeamListGetQueryResponse,
		ErrorWrapper<ListTeamV2V2TeamListGet422>,
		null,
		Record<string, string>,
		ListTeamV2V2TeamListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v2/team/list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description ```curl --location --request GET 'http://0.0.0.0:4000/team/list'         --header 'Authorization: Bearer sk-1234'```Parameters:- user_id: str - Optional. If passed will only return teams that the user_id is a member of.- organization_id: str - Optional. If passed will only return teams that belong to the organization_id. Pass 'default_organization' to get all teams without organization_id.
 * @summary List Team
 * {@link /team/list}
 */
export async function listTeamTeamListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListTeamTeamListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListTeamTeamListGetQueryResponse,
		ErrorWrapper<ListTeamTeamListGet422>,
		null,
		Record<string, string>,
		ListTeamTeamListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Add models to a team's allowed model list. Only proxy admin or team admin can add models.Parameters:- team_id: str - Required. The team to add models to- models: List[str] - Required. List of models to add to the teamExample Request:```curl --location 'http://0.0.0.0:4000/team/model/add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234",    "models": ["gpt-4", "claude-2"]}'```
 * @summary Team Model Add
 * {@link /team/model/add}
 */
export async function teamModelAddTeamModelAddPost({
	body,
	config = {},
}: {
	body: TeamModelAddTeamModelAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamModelAddTeamModelAddPostMutationResponse,
		ErrorWrapper<TeamModelAddTeamModelAddPost422>,
		TeamModelAddTeamModelAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/model/add`, body, ...requestConfig });
	return data;
}

/**
 * @description Remove models from a team's allowed model list. Only proxy admin or team admin can remove models.Parameters:- team_id: str - Required. The team to remove models from- models: List[str] - Required. List of models to remove from the teamExample Request:```curl --location 'http://0.0.0.0:4000/team/model/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234",    "models": ["gpt-4"]}'```
 * @summary Team Model Delete
 * {@link /team/model/delete}
 */
export async function teamModelDeleteTeamModelDeletePost({
	body,
	config = {},
}: {
	body: TeamModelDeleteTeamModelDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamModelDeleteTeamModelDeletePostMutationResponse,
		ErrorWrapper<TeamModelDeleteTeamModelDeletePost422>,
		TeamModelDeleteTeamModelDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/model/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description Get the team member permissions for a team
 * @summary Team Member Permissions
 * {@link /team/permissions_list}
 */
export async function teamMemberPermissionsTeamPermissionsListGet({
	queryParams,
	config = {},
}: {
	queryParams?: TeamMemberPermissionsTeamPermissionsListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberPermissionsTeamPermissionsListGetQueryResponse,
		ErrorWrapper<TeamMemberPermissionsTeamPermissionsListGet422>,
		null,
		Record<string, string>,
		TeamMemberPermissionsTeamPermissionsListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/permissions_list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Update the team member permissions for a team
 * @summary Update Team Member Permissions
 * {@link /team/permissions_update}
 */
export async function updateTeamMemberPermissionsTeamPermissionsUpdatePost({
	body,
	config = {},
}: {
	body: UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationResponse,
		ErrorWrapper<UpdateTeamMemberPermissionsTeamPermissionsUpdatePost422>,
		UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/permissions_update`, body, ...requestConfig });
	return data;
}

/**
 * @description Get daily activity for specific teams or all teams.Args:    team_ids (Optional[str]): Comma-separated list of team IDs to filter by. If not provided, returns data for all teams.    start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).    end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).    model (Optional[str]): Filter by model name.    api_key (Optional[str]): Filter by API key.    page (int): Page number for pagination.    page_size (int): Number of items per page.    exclude_team_ids (Optional[str]): Comma-separated list of team IDs to exclude.Returns:    SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 * @summary Get Team Daily Activity
 * {@link /team/daily/activity}
 */
export async function getTeamDailyActivityTeamDailyActivityGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetTeamDailyActivityTeamDailyActivityGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetTeamDailyActivityTeamDailyActivityGetQueryResponse,
		ErrorWrapper<GetTeamDailyActivityTeamDailyActivityGet422>,
		null,
		Record<string, string>,
		GetTeamDailyActivityTeamDailyActivityGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/daily/activity`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Return SCIM Service Provider Configuration.
 * @summary Get Service Provider Config
 * {@link /scim/v2/ServiceProviderConfig}
 */
export async function getServiceProviderConfigScimV2ServiceProviderConfigGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryResponse,
		ErrorWrapper<GetServiceProviderConfigScimV2ServiceProviderConfigGet422>,
		null,
		Record<string, string>,
		GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/scim/v2/ServiceProviderConfig`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get a list of users according to SCIM v2 protocol
 * @summary Get Users
 * {@link /scim/v2/Users}
 */
export async function getUsersScimV2UsersGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUsersScimV2UsersGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUsersScimV2UsersGetQueryResponse,
		ErrorWrapper<GetUsersScimV2UsersGet422>,
		null,
		Record<string, string>,
		GetUsersScimV2UsersGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/scim/v2/Users`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Create a user according to SCIM v2 protocol
 * @summary Create User
 * {@link /scim/v2/Users}
 */
export async function createUserScimV2UsersPost({
	body,
	queryParams,
	config = {},
}: {
	body: CreateUserScimV2UsersPostMutationRequest;
	queryParams?: CreateUserScimV2UsersPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateUserScimV2UsersPostMutationResponse,
		ErrorWrapper<CreateUserScimV2UsersPost422>,
		CreateUserScimV2UsersPostMutationRequest,
		Record<string, string>,
		CreateUserScimV2UsersPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/scim/v2/Users`, queryParams, body, ...requestConfig });
	return data;
}

/**
 * @description Get a single user by ID according to SCIM v2 protocol
 * @summary Get User
 * {@link /scim/v2/Users/:user_id}
 */
export async function getUserScimV2UsersUserIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetUserScimV2UsersUserIdGetPathParams;
	queryParams?: GetUserScimV2UsersUserIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		GetUserScimV2UsersUserIdGetQueryResponse,
		ErrorWrapper<GetUserScimV2UsersUserIdGet422>,
		null,
		Record<string, string>,
		GetUserScimV2UsersUserIdGetQueryParams,
		GetUserScimV2UsersUserIdGetPathParams
	>({
		method: "GET",
		url: `/scim/v2/Users/${pathParams["user_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Update a user according to SCIM v2 protocol (full replacement)
 * @summary Update User
 * {@link /scim/v2/Users/:user_id}
 */
export async function updateUserScimV2UsersUserIdPut({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: UpdateUserScimV2UsersUserIdPutPathParams;
	body: UpdateUserScimV2UsersUserIdPutMutationRequest;
	queryParams?: UpdateUserScimV2UsersUserIdPutQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		UpdateUserScimV2UsersUserIdPutMutationResponse,
		ErrorWrapper<UpdateUserScimV2UsersUserIdPut422>,
		UpdateUserScimV2UsersUserIdPutMutationRequest,
		Record<string, string>,
		UpdateUserScimV2UsersUserIdPutQueryParams,
		UpdateUserScimV2UsersUserIdPutPathParams
	>({
		method: "PUT",
		url: `/scim/v2/Users/${pathParams["user_id"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Delete a user according to SCIM v2 protocol
 * @summary Delete User
 * {@link /scim/v2/Users/:user_id}
 */
export async function deleteUserScimV2UsersUserIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteUserScimV2UsersUserIdDeletePathParams;
	queryParams?: DeleteUserScimV2UsersUserIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		DeleteUserScimV2UsersUserIdDeleteMutationResponse,
		ErrorWrapper<DeleteUserScimV2UsersUserIdDelete422>,
		null,
		Record<string, string>,
		DeleteUserScimV2UsersUserIdDeleteQueryParams,
		DeleteUserScimV2UsersUserIdDeletePathParams
	>({
		method: "DELETE",
		url: `/scim/v2/Users/${pathParams["user_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Patch a user according to SCIM v2 protocol
 * @summary Patch User
 * {@link /scim/v2/Users/:user_id}
 */
export async function patchUserScimV2UsersUserIdPatch({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: PatchUserScimV2UsersUserIdPatchPathParams;
	body: PatchUserScimV2UsersUserIdPatchMutationRequest;
	queryParams?: PatchUserScimV2UsersUserIdPatchQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		PatchUserScimV2UsersUserIdPatchMutationResponse,
		ErrorWrapper<PatchUserScimV2UsersUserIdPatch422>,
		PatchUserScimV2UsersUserIdPatchMutationRequest,
		Record<string, string>,
		PatchUserScimV2UsersUserIdPatchQueryParams,
		PatchUserScimV2UsersUserIdPatchPathParams
	>({
		method: "PATCH",
		url: `/scim/v2/Users/${pathParams["user_id"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Get a list of groups according to SCIM v2 protocol
 * @summary Get Groups
 * {@link /scim/v2/Groups}
 */
export async function getGroupsScimV2GroupsGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetGroupsScimV2GroupsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetGroupsScimV2GroupsGetQueryResponse,
		ErrorWrapper<GetGroupsScimV2GroupsGet422>,
		null,
		Record<string, string>,
		GetGroupsScimV2GroupsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/scim/v2/Groups`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Create a group according to SCIM v2 protocol
 * @summary Create Group
 * {@link /scim/v2/Groups}
 */
export async function createGroupScimV2GroupsPost({
	body,
	queryParams,
	config = {},
}: {
	body: CreateGroupScimV2GroupsPostMutationRequest;
	queryParams?: CreateGroupScimV2GroupsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateGroupScimV2GroupsPostMutationResponse,
		ErrorWrapper<CreateGroupScimV2GroupsPost422>,
		CreateGroupScimV2GroupsPostMutationRequest,
		Record<string, string>,
		CreateGroupScimV2GroupsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/scim/v2/Groups`, queryParams, body, ...requestConfig });
	return data;
}

/**
 * @description Get a single group by ID according to SCIM v2 protocol
 * @summary Get Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function getGroupScimV2GroupsGroupIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetGroupScimV2GroupsGroupIdGetPathParams;
	queryParams?: GetGroupScimV2GroupsGroupIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		GetGroupScimV2GroupsGroupIdGetQueryResponse,
		ErrorWrapper<GetGroupScimV2GroupsGroupIdGet422>,
		null,
		Record<string, string>,
		GetGroupScimV2GroupsGroupIdGetQueryParams,
		GetGroupScimV2GroupsGroupIdGetPathParams
	>({
		method: "GET",
		url: `/scim/v2/Groups/${pathParams["group_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Update a group according to SCIM v2 protocol
 * @summary Update Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function updateGroupScimV2GroupsGroupIdPut({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: UpdateGroupScimV2GroupsGroupIdPutPathParams;
	body: UpdateGroupScimV2GroupsGroupIdPutMutationRequest;
	queryParams?: UpdateGroupScimV2GroupsGroupIdPutQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		UpdateGroupScimV2GroupsGroupIdPutMutationResponse,
		ErrorWrapper<UpdateGroupScimV2GroupsGroupIdPut422>,
		UpdateGroupScimV2GroupsGroupIdPutMutationRequest,
		Record<string, string>,
		UpdateGroupScimV2GroupsGroupIdPutQueryParams,
		UpdateGroupScimV2GroupsGroupIdPutPathParams
	>({
		method: "PUT",
		url: `/scim/v2/Groups/${pathParams["group_id"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Delete a group according to SCIM v2 protocol
 * @summary Delete Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function deleteGroupScimV2GroupsGroupIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteGroupScimV2GroupsGroupIdDeletePathParams;
	queryParams?: DeleteGroupScimV2GroupsGroupIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		DeleteGroupScimV2GroupsGroupIdDeleteMutationResponse,
		ErrorWrapper<DeleteGroupScimV2GroupsGroupIdDelete422>,
		null,
		Record<string, string>,
		DeleteGroupScimV2GroupsGroupIdDeleteQueryParams,
		DeleteGroupScimV2GroupsGroupIdDeletePathParams
	>({
		method: "DELETE",
		url: `/scim/v2/Groups/${pathParams["group_id"]}`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Patch a group according to SCIM v2 protocol
 * @summary Patch Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function patchGroupScimV2GroupsGroupIdPatch({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: PatchGroupScimV2GroupsGroupIdPatchPathParams;
	body: PatchGroupScimV2GroupsGroupIdPatchMutationRequest;
	queryParams?: PatchGroupScimV2GroupsGroupIdPatchQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		PatchGroupScimV2GroupsGroupIdPatchMutationResponse,
		ErrorWrapper<PatchGroupScimV2GroupsGroupIdPatch422>,
		PatchGroupScimV2GroupsGroupIdPatchMutationRequest,
		Record<string, string>,
		PatchGroupScimV2GroupsGroupIdPatchQueryParams,
		PatchGroupScimV2GroupsGroupIdPatchPathParams
	>({
		method: "PATCH",
		url: `/scim/v2/Groups/${pathParams["group_id"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Allow orgs to own teamsSet org level budgets + model access.Only admins can create orgs.# Parameters- organization_alias: *str* - The name of the organization.- models: *List* - The models the organization has access to.- budget_id: *Optional[str]* - The id for a budget (tpm/rpm/max budget) for the organization.### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###- max_budget: *Optional[float]* - Max budget for org- tpm_limit: *Optional[int]* - Max tpm limit for org- rpm_limit: *Optional[int]* - Max rpm limit for org- model_rpm_limit: *Optional[Dict[str, int]]* - The RPM (Requests Per Minute) limit per model for this organization.- model_tpm_limit: *Optional[Dict[str, int]]* - The TPM (Tokens Per Minute) limit per model for this organization.- max_parallel_requests: *Optional[int]* - [Not Implemented Yet] Max parallel requests for org- soft_budget: *Optional[float]* - [Not Implemented Yet] Get a slack alert when this soft budget is reached. Don't block requests.- model_max_budget: *Optional[dict]* - Max budget for a specific model- budget_duration: *Optional[str]* - Frequency of reseting org budget- metadata: *Optional[dict]* - Metadata for organization, store information for organization. Example metadata - {"extra_info": "some info"}- blocked: *bool* - Flag indicating if the org is blocked or not - will stop all calls from keys with this org_id.- tags: *Optional[List[str]]* - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- organization_id: *Optional[str]* - The organization id of the team. Default is None. Create via `/organization/new`.- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)- object_permission: Optional[LiteLLM_ObjectPermissionBase] - organization-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.Case 1: Create new org **without** a budget_id```bashcurl --location 'http://0.0.0.0:4000/organization/new' --header 'Authorization: Bearer sk-1234' --header 'Content-Type: application/json' --data '{    "organization_alias": "my-secret-org",    "models": ["model1", "model2"],    "max_budget": 100}'```Case 2: Create new org **with** a budget_id```bashcurl --location 'http://0.0.0.0:4000/organization/new' --header 'Authorization: Bearer sk-1234' --header 'Content-Type: application/json' --data '{    "organization_alias": "my-secret-org",    "models": ["model1", "model2"],    "budget_id": "428eeaa8-f3ac-4e85-a8fb-7dc8d7aa8689"}'```
 * @summary New Organization
 * {@link /organization/new}
 */
export async function newOrganizationOrganizationNewPost({
	body,
	config = {},
}: {
	body: NewOrganizationOrganizationNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewOrganizationOrganizationNewPostMutationResponse,
		ErrorWrapper<NewOrganizationOrganizationNewPost422>,
		NewOrganizationOrganizationNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/organization/new`, body, ...requestConfig });
	return data;
}

/**
 * @description Update an organization
 * @summary Update Organization
 * {@link /organization/update}
 */
export async function updateOrganizationOrganizationUpdatePatch({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateOrganizationOrganizationUpdatePatchMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/organization/update`, ...requestConfig });
	return data;
}

/**
 * @description Delete an organization# Parameters:- organization_ids: List[str] - The organization ids to delete.
 * @summary Delete Organization
 * {@link /organization/delete}
 */
export async function deleteOrganizationOrganizationDeleteDelete({
	body,
	config = {},
}: {
	body: DeleteOrganizationOrganizationDeleteDeleteMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteOrganizationOrganizationDeleteDeleteMutationResponse,
		ErrorWrapper<DeleteOrganizationOrganizationDeleteDelete422>,
		DeleteOrganizationOrganizationDeleteDeleteMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "DELETE", url: `/organization/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description ```curl --location --request GET 'http://0.0.0.0:4000/organization/list'         --header 'Authorization: Bearer sk-1234'```
 * @summary List Organization
 * {@link /organization/list}
 */
export async function listOrganizationOrganizationListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListOrganizationOrganizationListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/organization/list`, ...requestConfig });
	return data;
}

/**
 * @description Get the org specific information
 * @summary Info Organization
 * {@link /organization/info}
 */
export async function infoOrganizationOrganizationInfoGet({
	queryParams,
	config = {},
}: {
	queryParams: InfoOrganizationOrganizationInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoOrganizationOrganizationInfoGetQueryResponse,
		ErrorWrapper<InfoOrganizationOrganizationInfoGet422>,
		null,
		Record<string, string>,
		InfoOrganizationOrganizationInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/organization/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description DEPRECATED: Use GET /organization/info instead
 * @summary Deprecated Info Organization
 * {@link /organization/info}
 */
export async function deprecatedInfoOrganizationOrganizationInfoPost({
	body,
	config = {},
}: {
	body: DeprecatedInfoOrganizationOrganizationInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeprecatedInfoOrganizationOrganizationInfoPostMutationResponse,
		ErrorWrapper<DeprecatedInfoOrganizationOrganizationInfoPost422>,
		DeprecatedInfoOrganizationOrganizationInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/organization/info`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA]Add new members (either via user_email or user_id) to an organizationIf user doesn't exist, new user row will also be added to User TableOnly proxy_admin or org_admin of organization, allowed to access this endpoint.# Parameters:- organization_id: str (required)- member: Union[List[Member], Member] (required)    - role: Literal[LitellmUserRoles] (required)    - user_id: Optional[str]    - user_email: Optional[str]Note: Either user_id or user_email must be provided for each member.Example:```curl -X POST 'http://0.0.0.0:4000/organization/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{    "organization_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",    "member": {        "role": "internal_user",        "user_id": "krrish247652@berri.ai"    },    "max_budget_in_organization": 100.0}'```The following is executed in this function:1. Check if organization exists2. Creates a new Internal User if the user_id or user_email is not found in LiteLLM_UserTable3. Add Internal User to the `LiteLLM_OrganizationMembership` table
 * @summary Organization Member Add
 * {@link /organization/member_add}
 */
export async function organizationMemberAddOrganizationMemberAddPost({
	body,
	config = {},
}: {
	body: OrganizationMemberAddOrganizationMemberAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OrganizationMemberAddOrganizationMemberAddPostMutationResponse,
		ErrorWrapper<OrganizationMemberAddOrganizationMemberAddPost422>,
		OrganizationMemberAddOrganizationMemberAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/organization/member_add`, body, ...requestConfig });
	return data;
}

/**
 * @description Update a member's role in an organization
 * @summary Organization Member Update
 * {@link /organization/member_update}
 */
export async function organizationMemberUpdateOrganizationMemberUpdatePatch({
	body,
	config = {},
}: {
	body: OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationResponse,
		ErrorWrapper<OrganizationMemberUpdateOrganizationMemberUpdatePatch422>,
		OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/organization/member_update`, body, ...requestConfig });
	return data;
}

/**
 * @description Delete a member from an organization
 * @summary Organization Member Delete
 * {@link /organization/member_delete}
 */
export async function organizationMemberDeleteOrganizationMemberDeleteDelete({
	body,
	config = {},
}: {
	body: OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationResponse,
		ErrorWrapper<OrganizationMemberDeleteOrganizationMemberDeleteDelete422>,
		OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "DELETE", url: `/organization/member_delete`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA] Reject calls with this end-user idParameters:- user_ids (List[str], required): The unique `user_id`s for the users to block    (any /chat/completion call with this user={end-user-id} param, will be rejected.)    ```    curl -X POST "http://0.0.0.0:8000/user/block"    -H "Authorization: Bearer sk-1234"    -d '{    "user_ids": [<user_id>, ...]    }'    ```
 * @summary Block User
 * {@link /customer/block}
 */
export async function blockUserCustomerBlockPost({
	body,
	config = {},
}: {
	body: BlockUserCustomerBlockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BlockUserCustomerBlockPostMutationResponse,
		ErrorWrapper<BlockUserCustomerBlockPost422>,
		BlockUserCustomerBlockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/block`, body, ...requestConfig });
	return data;
}

/**
 * @description [BETA] Unblock calls with this user idExample```curl -X POST "http://0.0.0.0:8000/user/unblock"-H "Authorization: Bearer sk-1234"-d '{"user_ids": [<user_id>, ...]}'```
 * @summary Unblock User
 * {@link /customer/unblock}
 */
export async function unblockUserCustomerUnblockPost({
	body,
	config = {},
}: {
	body: UnblockUserCustomerUnblockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UnblockUserCustomerUnblockPostMutationResponse,
		ErrorWrapper<UnblockUserCustomerUnblockPost422>,
		UnblockUserCustomerUnblockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/unblock`, body, ...requestConfig });
	return data;
}

/**
 * @description Allow creating a new Customer Parameters:- user_id: str - The unique identifier for the user.- alias: Optional[str] - A human-friendly alias for the user.- blocked: bool - Flag to allow or disallow requests for this end-user. Default is False.- max_budget: Optional[float] - The maximum budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.- budget_id: Optional[str] - The identifier for an existing budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.- allowed_model_region: Optional[Union[Literal["eu"], Literal["us"]]] - Require all user requests to use models in this specific region.- default_model: Optional[str] - If no equivalent model in the allowed region, default all requests to this model.- metadata: Optional[dict] = Metadata for customer, store information for customer. Example metadata = {"data_training_opt_out": True}- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- tpm_limit: Optional[int] - [Not Implemented Yet] Specify tpm limit for a given customer (Tokens per minute)- rpm_limit: Optional[int] - [Not Implemented Yet] Specify rpm limit for a given customer (Requests per minute)- model_max_budget: Optional[dict] - [Not Implemented Yet] Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d"}}- max_parallel_requests: Optional[int] - [Not Implemented Yet] Specify max parallel requests for a given customer.- soft_budget: Optional[float] - [Not Implemented Yet] Get alerts when customer crosses given budget, doesn't block requests.- spend: Optional[float] - Specify initial spend for a given customer.- budget_reset_at: Optional[str] - Specify the date and time when the budget should be reset.- Allow specifying allowed regions - Allow specifying default modelExample curl:```curl --location 'http://0.0.0.0:4000/customer/new'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "user_id" : "ishaan-jaff-3",        "allowed_region": "eu",        "budget_id": "free_tier",        "default_model": "azure/gpt-3.5-turbo-eu" <- all calls from this user, use this model?     }'    # return end-user object```NOTE: This used to be called `/end_user/new`, we will still be maintaining compatibility for /end_user/XXX for these endpoints
 * @summary New End User
 * {@link /customer/new}
 */
export async function newEndUserCustomerNewPost({
	body,
	config = {},
}: {
	body: NewEndUserCustomerNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewEndUserCustomerNewPostMutationResponse,
		ErrorWrapper<NewEndUserCustomerNewPost422>,
		NewEndUserCustomerNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/new`, body, ...requestConfig });
	return data;
}

/**
 * @description Get information about an end-user. An `end_user` is a customer (external user) of the proxy.Parameters:- end_user_id (str, required): The unique identifier for the end-userExample curl:```curl -X GET 'http://localhost:4000/customer/info?end_user_id=test-litellm-user-4'         -H 'Authorization: Bearer sk-1234'```
 * @summary End User Info
 * {@link /customer/info}
 */
export async function endUserInfoCustomerInfoGet({
	queryParams,
	config = {},
}: {
	queryParams: EndUserInfoCustomerInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EndUserInfoCustomerInfoGetQueryResponse,
		ErrorWrapper<EndUserInfoCustomerInfoGet422>,
		null,
		Record<string, string>,
		EndUserInfoCustomerInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/customer/info`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Example curl Parameters:- user_id: str- alias: Optional[str] = None  # human-friendly alias- blocked: bool = False  # allow/disallow requests for this end-user- max_budget: Optional[float] = None- budget_id: Optional[str] = None  # give either a budget_id or max_budget- allowed_model_region: Optional[AllowedModelRegion] = (    None  # require all user requests to use models in this specific region)- default_model: Optional[str] = (    None  # if no equivalent model in allowed region - default all requests to this model)Example curl:```curl --location 'http://0.0.0.0:4000/customer/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "user_id": "test-litellm-user-4",    "budget_id": "paid_tier"}'See below for all params ```
 * @summary Update End User
 * {@link /customer/update}
 */
export async function updateEndUserCustomerUpdatePost({
	body,
	config = {},
}: {
	body: UpdateEndUserCustomerUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateEndUserCustomerUpdatePostMutationResponse,
		ErrorWrapper<UpdateEndUserCustomerUpdatePost422>,
		UpdateEndUserCustomerUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Delete multiple end-users.Parameters:- user_ids (List[str], required): The unique `user_id`s for the users to deleteExample curl:```curl --location 'http://0.0.0.0:4000/customer/delete'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "user_ids" :["ishaan-jaff-5"]}'See below for all params ```
 * @summary Delete End User
 * {@link /customer/delete}
 */
export async function deleteEndUserCustomerDeletePost({
	body,
	config = {},
}: {
	body: DeleteEndUserCustomerDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteEndUserCustomerDeletePostMutationResponse,
		ErrorWrapper<DeleteEndUserCustomerDeletePost422>,
		DeleteEndUserCustomerDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description [Admin-only] List all available customersExample curl:```curl --location --request GET 'http://0.0.0.0:4000/customer/list'         --header 'Authorization: Bearer sk-1234'```
 * @summary List End User
 * {@link /customer/list}
 */
export async function listEndUserCustomerListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListEndUserCustomerListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/customer/list`, ...requestConfig });
	return data;
}

/**
 * @description LiteLLM Enterprise - View Spend Per Request TagExample Request:```curl -X GET "http://0.0.0.0:8000/spend/tags" -H "Authorization: Bearer sk-1234"```Spend with Start Date and End Date```curl -X GET "http://0.0.0.0:8000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"```
 * @summary View Spend Tags
 * {@link /spend/tags}
 */
export async function viewSpendTagsSpendTagsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ViewSpendTagsSpendTagsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ViewSpendTagsSpendTagsGetQueryResponse,
		ErrorWrapper<ViewSpendTagsSpendTagsGet422>,
		null,
		Record<string, string>,
		ViewSpendTagsSpendTagsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/spend/tags`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get Daily Spend per Team, based on specific startTime and endTime. Per team, view usage by each key, model[    {        "group-by-day": "2024-05-10",        "teams": [            {                "team_name": "team-1"                "spend": 10,                "keys": [                    "key": "1213",                    "usage": {                        "model-1": {                                "cost": 12.50,                                "input_tokens": 1000,                                "output_tokens": 5000,                                "requests": 100                            },                            "audio-modelname1": {                            "cost": 25.50,                            "seconds": 25,                            "requests": 50                    },                    }                }        ]    ]}
 * @summary Get Global Spend Report
 * {@link /global/spend/report}
 */
export async function getGlobalSpendReportGlobalSpendReportGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetGlobalSpendReportGlobalSpendReportGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetGlobalSpendReportGlobalSpendReportGetQueryResponse,
		ErrorWrapper<GetGlobalSpendReportGlobalSpendReportGet422>,
		null,
		Record<string, string>,
		GetGlobalSpendReportGlobalSpendReportGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/global/spend/report`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description LiteLLM Enterprise - View Spend Per Request Tag. Used by LiteLLM UIExample Request:```curl -X GET "http://0.0.0.0:4000/spend/tags" -H "Authorization: Bearer sk-1234"```Spend with Start Date and End Date```curl -X GET "http://0.0.0.0:4000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"```
 * @summary Global View Spend Tags
 * {@link /global/spend/tags}
 */
export async function globalViewSpendTagsGlobalSpendTagsGet({
	queryParams,
	config = {},
}: {
	queryParams?: GlobalViewSpendTagsGlobalSpendTagsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GlobalViewSpendTagsGlobalSpendTagsGetQueryResponse,
		ErrorWrapper<GlobalViewSpendTagsGlobalSpendTagsGet422>,
		null,
		Record<string, string>,
		GlobalViewSpendTagsGlobalSpendTagsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/global/spend/tags`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Accepts all the params of completion_cost.Calculate spend **before** making call:Note: If you see a spend of $0.0 you need to set custom_pricing for your model: https://docs.litellm.ai/docs/proxy/custom_pricing```curl --location 'http://localhost:4000/spend/calculate'--header 'Authorization: Bearer sk-1234'--header 'Content-Type: application/json'--data '{    "model": "anthropic.claude-v2",    "messages": [{"role": "user", "content": "Hey, how'''s it going?"}]}'```Calculate spend **after** making call:```curl --location 'http://localhost:4000/spend/calculate'--header 'Authorization: Bearer sk-1234'--header 'Content-Type: application/json'--data '{    "completion_response": {        "id": "chatcmpl-123",        "object": "chat.completion",        "created": 1677652288,        "model": "gpt-3.5-turbo-0125",        "system_fingerprint": "fp_44709d6fcb",        "choices": [{            "index": 0,            "message": {                "role": "assistant",                "content": "Hello there, how may I assist you today?"            },            "logprobs": null,            "finish_reason": "stop"        }]        "usage": {            "prompt_tokens": 9,            "completion_tokens": 12,            "total_tokens": 21        }    }}'```
 * @summary Calculate Spend
 * {@link /spend/calculate}
 */
export async function calculateSpendSpendCalculatePost({
	body,
	config = {},
}: {
	body?: CalculateSpendSpendCalculatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CalculateSpendSpendCalculatePostMutationResponse,
		ErrorWrapper<CalculateSpendSpendCalculatePost422>,
		CalculateSpendSpendCalculatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/spend/calculate`, body, ...requestConfig });
	return data;
}

/**
 * @description View all spend logs, if request_id is provided, only logs for that request_id will be returnedWhen start_date and end_date are provided:- summarize=true (default): Returns aggregated spend data grouped by date (maintains backward compatibility)- summarize=false: Returns filtered individual log entries within the date rangeExample Request for all logs```curl -X GET "http://0.0.0.0:8000/spend/logs" -H "Authorization: Bearer sk-1234"```Example Request for specific request_id```curl -X GET "http://0.0.0.0:8000/spend/logs?request_id=chatcmpl-6dcb2540-d3d7-4e49-bb27-291f863f112e" -H "Authorization: Bearer sk-1234"```Example Request for specific api_key```curl -X GET "http://0.0.0.0:8000/spend/logs?api_key=sk-Fn8Ej39NkBQmUagFEoUWPQ" -H "Authorization: Bearer sk-1234"```Example Request for specific user_id```curl -X GET "http://0.0.0.0:8000/spend/logs?user_id=ishaan@berri.ai" -H "Authorization: Bearer sk-1234"```Example Request for date range with individual logs (unsummarized)```curl -X GET "http://0.0.0.0:8000/spend/logs?start_date=2024-01-01&end_date=2024-01-02&summarize=false" -H "Authorization: Bearer sk-1234"```
 * @summary View Spend Logs
 * {@link /spend/logs}
 */
export async function viewSpendLogsSpendLogsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ViewSpendLogsSpendLogsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ViewSpendLogsSpendLogsGetQueryResponse,
		ErrorWrapper<ViewSpendLogsSpendLogsGet422>,
		null,
		Record<string, string>,
		ViewSpendLogsSpendLogsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/spend/logs`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description ADMIN ONLY / MASTER KEY Only EndpointGlobally reset spend for All API Keys and Teams, maintain LiteLLM_SpendLogs1. LiteLLM_SpendLogs will maintain the logs on spend, no data gets deleted from there2. LiteLLM_VerificationTokens spend will be set = 03. LiteLLM_TeamTable spend will be set = 0
 * @summary Global Spend Reset
 * {@link /global/spend/reset}
 */
export async function globalSpendResetGlobalSpendResetPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GlobalSpendResetGlobalSpendResetPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/global/spend/reset`, ...requestConfig });
	return data;
}

/**
 * @description Provider Budget Routing - Get Budget, Spend Details https://docs.litellm.ai/docs/proxy/provider_budget_routingUse this endpoint to check current budget, spend and budget reset time for a providerExample Request```bashcurl -X GET http://localhost:4000/provider/budgets     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"```Example Response```json{    "providers": {        "openai": {            "budget_limit": 1e-12,            "time_period": "1d",            "spend": 0.0,            "budget_reset_at": null        },        "azure": {            "budget_limit": 100.0,            "time_period": "1d",            "spend": 0.0,            "budget_reset_at": null        },        "anthropic": {            "budget_limit": 100.0,            "time_period": "10d",            "spend": 0.0,            "budget_reset_at": null        },        "vertex_ai": {            "budget_limit": 100.0,            "time_period": "12d",            "spend": 0.0,            "budget_reset_at": null        }    }}```
 * @summary Provider Budgets
 * {@link /provider/budgets}
 */
export async function providerBudgetsProviderBudgetsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ProviderBudgetsProviderBudgetsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/provider/budgets`, ...requestConfig });
	return data;
}

/**
 * @description View current CloudZero settings.Returns the current CloudZero configuration with the API key masked for security.Only the first 4 and last 4 characters of the API key are shown.Only admin users can view CloudZero settings.
 * @summary Get Cloudzero Settings
 * {@link /cloudzero/settings}
 */
export async function getCloudzeroSettingsCloudzeroSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCloudzeroSettingsCloudzeroSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cloudzero/settings`, ...requestConfig });
	return data;
}

/**
 * @description Update existing CloudZero settings.Allows updating individual CloudZero configuration fields without requiring all fields.Only provided fields will be updated; others will remain unchanged.Parameters:- api_key: (Optional) New CloudZero API key for authentication- connection_id: (Optional) New CloudZero connection ID for data submission- timezone: (Optional) New timezone for date handlingOnly admin users can update CloudZero settings.
 * @summary Update Cloudzero Settings
 * {@link /cloudzero/settings}
 */
export async function updateCloudzeroSettingsCloudzeroSettingsPut({
	body,
	config = {},
}: {
	body?: UpdateCloudzeroSettingsCloudzeroSettingsPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateCloudzeroSettingsCloudzeroSettingsPutMutationResponse,
		ErrorWrapper<UpdateCloudzeroSettingsCloudzeroSettingsPut422>,
		UpdateCloudzeroSettingsCloudzeroSettingsPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PUT", url: `/cloudzero/settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Initialize CloudZero settings and store in the database.This endpoint stores the CloudZero API key, connection ID, and timezone configurationin the proxy database for use by the CloudZero logger.Parameters:- api_key: CloudZero API key for authentication- connection_id: CloudZero connection ID for data submission- timezone: Timezone for date handling (default: UTC)Only admin users can configure CloudZero settings.
 * @summary Init Cloudzero Settings
 * {@link /cloudzero/init}
 */
export async function initCloudzeroSettingsCloudzeroInitPost({
	body,
	config = {},
}: {
	body: InitCloudzeroSettingsCloudzeroInitPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InitCloudzeroSettingsCloudzeroInitPostMutationResponse,
		ErrorWrapper<InitCloudzeroSettingsCloudzeroInitPost422>,
		InitCloudzeroSettingsCloudzeroInitPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cloudzero/init`, body, ...requestConfig });
	return data;
}

/**
 * @description Perform a dry run export using the CloudZero logger.This endpoint uses the CloudZero logger to perform a dry run export,which returns the data that would be exported without actually sending it to CloudZero.Parameters:- limit: Optional limit on number of records to process (default: 10000)Returns:- usage_data: Sample of the raw usage data (first 50 records)- cbf_data: CloudZero CBF formatted data ready for export- summary: Statistics including total cost, tokens, and record countsOnly admin users can perform CloudZero exports.
 * @summary Cloudzero Dry Run Export
 * {@link /cloudzero/dry-run}
 */
export async function cloudzeroDryRunExportCloudzeroDryRunPost({
	body,
	config = {},
}: {
	body?: CloudzeroDryRunExportCloudzeroDryRunPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CloudzeroDryRunExportCloudzeroDryRunPostMutationResponse,
		ErrorWrapper<CloudzeroDryRunExportCloudzeroDryRunPost422>,
		CloudzeroDryRunExportCloudzeroDryRunPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cloudzero/dry-run`, body, ...requestConfig });
	return data;
}

/**
 * @description Perform an actual export using the CloudZero logger.This endpoint uses the CloudZero logger to export usage data to CloudZero AnyCost API.Parameters:- limit: Optional limit on number of records to export- operation: CloudZero operation type ("replace_hourly" or "sum", default: "replace_hourly")Only admin users can perform CloudZero exports.
 * @summary Cloudzero Export
 * {@link /cloudzero/export}
 */
export async function cloudzeroExportCloudzeroExportPost({
	body,
	config = {},
}: {
	body?: CloudzeroExportCloudzeroExportPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CloudzeroExportCloudzeroExportPostMutationResponse,
		ErrorWrapper<CloudzeroExportCloudzeroExportPost422>,
		CloudzeroExportCloudzeroExportPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cloudzero/export`, body, ...requestConfig });
	return data;
}

/**
 * @description Endpoint for checking if cache can be pinged
 * @summary Cache Ping
 * {@link /cache/ping}
 */
export async function cachePingCachePingGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CachePingCachePingGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cache/ping`, ...requestConfig });
	return data;
}

/**
 * @description Endpoint for deleting a key from the cache. All responses from litellm proxy have `x-litellm-cache-key` in the headersParameters:- **keys**: *Optional[List[str]]* - A list of keys to delete from the cache. Example {"keys": ["key1", "key2"]}```shellcurl -X POST "http://0.0.0.0:4000/cache/delete"     -H "Authorization: Bearer sk-1234"     -d '{"keys": ["key1", "key2"]}'```
 * @summary Cache Delete
 * {@link /cache/delete}
 */
export async function cacheDeleteCacheDeletePost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CacheDeleteCacheDeletePostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/delete`, ...requestConfig });
	return data;
}

/**
 * @description Endpoint for getting /redis/info
 * @summary Cache Redis Info
 * {@link /cache/redis/info}
 */
export async function cacheRedisInfoCacheRedisInfoGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CacheRedisInfoCacheRedisInfoGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cache/redis/info`, ...requestConfig });
	return data;
}

/**
 * @description A function to flush all items from the cache. (All items will be deleted from the cache with this)Raises HTTPException if the cache is not initialized or if the cache type does not support flushing.Returns a dictionary with the status of the operation.Usage:```curl -X POST http://0.0.0.0:4000/cache/flushall -H "Authorization: Bearer sk-1234"```
 * @summary Cache Flushall
 * {@link /cache/flushall}
 */
export async function cacheFlushallCacheFlushallPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CacheFlushallCacheFlushallPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/flushall`, ...requestConfig });
	return data;
}

/**
 * @description List the guardrails that are available on the proxy server [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/guardrails/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrails": [        {        "guardrail_name": "bedrock-pre-guard",        "guardrail_info": {            "params": [            {                "name": "toxicity_score",                "type": "float",                "description": "Score between 0-1 indicating content toxicity level"            },            {                "name": "pii_detection",                "type": "boolean"            }            ]        }        }    ]}```
 * @summary List Guardrails
 * {@link /guardrails/list}
 */
export async function listGuardrailsGuardrailsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListGuardrailsGuardrailsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/guardrails/list`, ...requestConfig });
	return data;
}

/**
 * @description List the guardrails that are available in the database using GuardrailRegistry [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/v2/guardrails/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrails": [        {            "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",            "guardrail_name": "my-bedrock-guard",            "litellm_params": {                "guardrail": "bedrock",                "mode": "pre_call",                "guardrailIdentifier": "ff6ujrregl1q",                "guardrailVersion": "DRAFT",                "default_on": true            },            "guardrail_info": {                "description": "Bedrock content moderation guardrail"            }        }    ]}```
 * @summary List Guardrails V2
 * {@link /v2/guardrails/list}
 */
export async function listGuardrailsV2V2GuardrailsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListGuardrailsV2V2GuardrailsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v2/guardrails/list`, ...requestConfig });
	return data;
}

/**
 * @description Create a new guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X POST "http://localhost:4000/guardrails" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "guardrail": {            "guardrail_name": "my-bedrock-guard",            "litellm_params": {                "guardrail": "bedrock",                "mode": "pre_call",                "guardrailIdentifier": "ff6ujrregl1q",                "guardrailVersion": "DRAFT",                "default_on": true            },            "guardrail_info": {                "description": "Bedrock content moderation guardrail"            }        }    }'```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "my-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Create Guardrail
 * {@link /guardrails}
 */
export async function createGuardrailGuardrailsPost({
	body,
	config = {},
}: {
	body: CreateGuardrailGuardrailsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateGuardrailGuardrailsPostMutationResponse,
		ErrorWrapper<CreateGuardrailGuardrailsPost422>,
		CreateGuardrailGuardrailsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/guardrails`, body, ...requestConfig });
	return data;
}

/**
 * @description Update an existing guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X PUT "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "guardrail": {            "guardrail_name": "updated-bedrock-guard",            "litellm_params": {                "guardrail": "bedrock",                "mode": "pre_call",                "guardrailIdentifier": "ff6ujrregl1q",                "guardrailVersion": "1.0",                "default_on": true            },            "guardrail_info": {                "description": "Updated Bedrock content moderation guardrail"            }        }    }'```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "updated-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "1.0",        "default_on": true    },    "guardrail_info": {        "description": "Updated Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T13:45:12.345Z"}```
 * @summary Update Guardrail
 * {@link /guardrails/:guardrail_id}
 */
export async function updateGuardrailGuardrailsGuardrailIdPut({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdateGuardrailGuardrailsGuardrailIdPutPathParams;
	body: UpdateGuardrailGuardrailsGuardrailIdPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		UpdateGuardrailGuardrailsGuardrailIdPutMutationResponse,
		ErrorWrapper<UpdateGuardrailGuardrailsGuardrailIdPut422>,
		UpdateGuardrailGuardrailsGuardrailIdPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdateGuardrailGuardrailsGuardrailIdPutPathParams
	>({ method: "PUT", url: `/guardrails/${pathParams["guardrail_id"]}`, body, ...requestConfig });
	return data;
}

/**
 * @description Delete a guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X DELETE "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "message": "Guardrail 123e4567-e89b-12d3-a456-426614174000 deleted successfully"}```
 * @summary Delete Guardrail
 * {@link /guardrails/:guardrail_id}
 */
export async function deleteGuardrailGuardrailsGuardrailIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteGuardrailGuardrailsGuardrailIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		DeleteGuardrailGuardrailsGuardrailIdDeleteMutationResponse,
		ErrorWrapper<DeleteGuardrailGuardrailsGuardrailIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteGuardrailGuardrailsGuardrailIdDeletePathParams
	>({ method: "DELETE", url: `/guardrails/${pathParams["guardrail_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Partially update an existing guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)This endpoint allows updating specific fields of a guardrail without sending the entire object.Only the following fields can be updated:- guardrail_name: The name of the guardrail- default_on: Whether the guardrail is enabled by default- guardrail_info: Additional information about the guardrailExample Request:```bashcurl -X PATCH "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "guardrail_name": "updated-name",        "default_on": true,        "guardrail_info": {            "description": "Updated description"        }    }'```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "updated-name",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Updated description"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T14:22:33.456Z"}```
 * @summary Patch Guardrail
 * {@link /guardrails/:guardrail_id}
 */
export async function patchGuardrailGuardrailsGuardrailIdPatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: PatchGuardrailGuardrailsGuardrailIdPatchPathParams;
	body?: PatchGuardrailGuardrailsGuardrailIdPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		PatchGuardrailGuardrailsGuardrailIdPatchMutationResponse,
		ErrorWrapper<PatchGuardrailGuardrailsGuardrailIdPatch422>,
		PatchGuardrailGuardrailsGuardrailIdPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		PatchGuardrailGuardrailsGuardrailIdPatchPathParams
	>({ method: "PATCH", url: `/guardrails/${pathParams["guardrail_id"]}`, body, ...requestConfig });
	return data;
}

/**
 * @description Get detailed information about a specific guardrail by ID [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "my-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Get Guardrail Info
 * {@link /guardrails/:guardrail_id}
 */
export async function getGuardrailInfoGuardrailsGuardrailIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetGuardrailInfoGuardrailsGuardrailIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		GetGuardrailInfoGuardrailsGuardrailIdGetQueryResponse,
		ErrorWrapper<GetGuardrailInfoGuardrailsGuardrailIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetGuardrailInfoGuardrailsGuardrailIdGetPathParams
	>({ method: "GET", url: `/guardrails/${pathParams["guardrail_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Get detailed information about a specific guardrail by ID [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "my-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Get Guardrail Info
 * {@link /guardrails/:guardrail_id/info}
 */
export async function getGuardrailInfoGuardrailsGuardrailIdInfoGet({
	pathParams,
	config = {},
}: {
	pathParams: GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetQueryResponse,
		ErrorWrapper<GetGuardrailInfoGuardrailsGuardrailIdInfoGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams
	>({ method: "GET", url: `/guardrails/${pathParams["guardrail_id"]}/info`, ...requestConfig });
	return data;
}

/**
 * @description Get the UI settings for the guardrailsReturns:- Supported entities for guardrails- Supported modes for guardrails- PII entity categories for UI organization- Content filter settings (patterns and categories)
 * @summary Get Guardrail Ui Settings
 * {@link /guardrails/ui/add_guardrail_settings}
 */
export async function getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/guardrails/ui/add_guardrail_settings`, ...requestConfig });
	return data;
}

/**
 * @description Validate a blocked_words YAML file content.Args:    request: Dictionary with 'file_content' key containing the YAML stringReturns:    Dictionary with 'valid' boolean and either 'message'/'errors' depending on resultExample Request:```json{    "file_content": "blocked_words:\n  - keyword: \"test\"\n    action: \"BLOCK\""}```Example Success Response:```json{    "valid": true,    "message": "Valid YAML file with 2 blocked words"}```Example Error Response:```json{    "valid": false,    "errors": ["Entry 0: missing 'action' field"]}```
 * @summary Validate Blocked Words File
 * {@link /guardrails/validate_blocked_words_file}
 */
export async function validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost({
	body,
	config = {},
}: {
	body?: ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationResponse,
		ErrorWrapper<ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost422>,
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/guardrails/validate_blocked_words_file`, body, ...requestConfig });
	return data;
}

/**
 * @description Get provider-specific parameters for different guardrail types.Returns a dictionary mapping guardrail providers to their specific parameters,including parameter names, descriptions, and whether they are required.Example Response:```json{    "bedrock": {        "guardrailIdentifier": {            "description": "The ID of your guardrail on Bedrock",            "required": true,            "type": null        },        "guardrailVersion": {            "description": "The version of your Bedrock guardrail (e.g., DRAFT or version number)",            "required": true,            "type": null        }    },    "azure_content_safety_text_moderation": {        "api_key": {            "description": "API key for the Azure Content Safety Text Moderation guardrail",            "required": false,            "type": null        },        "optional_params": {            "description": "Optional parameters for the Azure Content Safety Text Moderation guardrail",            "required": true,            "type": "nested",            "fields": {                "severity_threshold": {                    "description": "Severity threshold for the Azure Content Safety Text Moderation guardrail across all categories",                    "required": false,                    "type": null                },                "categories": {                    "description": "Categories to scan for the Azure Content Safety Text Moderation guardrail",                    "required": false,                    "type": "multiselect",                    "options": ["Hate", "SelfHarm", "Sexual", "Violence"],                    "default_value": None                }            }        }    }}```
 * @summary Get Provider Specific Params
 * {@link /guardrails/ui/provider_specific_params}
 */
export async function getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/guardrails/ui/provider_specific_params`, ...requestConfig });
	return data;
}

/**
 * @description Apply a guardrail to text input and return the processed result.This endpoint allows testing guardrails by applying them to custom text inputs.
 * @summary Apply Guardrail
 * {@link /apply_guardrail}
 */
export async function applyGuardrailApplyGuardrailPost({
	body,
	config = {},
}: {
	body: ApplyGuardrailApplyGuardrailPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ApplyGuardrailApplyGuardrailPostMutationResponse,
		ErrorWrapper<ApplyGuardrailApplyGuardrailPost422>,
		ApplyGuardrailApplyGuardrailPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/apply_guardrail`, body, ...requestConfig });
	return data;
}

/**
 * @description Mask PII from a given text, requires a guardrail to be added to litellm.
 * @summary Apply Guardrail
 * {@link /guardrails/apply_guardrail}
 */
export async function applyGuardrailGuardrailsApplyGuardrailPost({
	body,
	config = {},
}: {
	body: ApplyGuardrailGuardrailsApplyGuardrailPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ApplyGuardrailGuardrailsApplyGuardrailPostMutationResponse,
		ErrorWrapper<ApplyGuardrailGuardrailsApplyGuardrailPost422>,
		ApplyGuardrailGuardrailsApplyGuardrailPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/guardrails/apply_guardrail`, body, ...requestConfig });
	return data;
}

/**
 * @description List all search tools that are available in the database.Example Request:```bashcurl -X GET "http://localhost:4000/search_tools/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "search_tools": [        {            "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",            "search_tool_name": "litellm-search",            "litellm_params": {                "search_provider": "perplexity",                "api_key": "sk-***",                "api_base": "https://api.perplexity.ai"            },            "search_tool_info": {                "description": "Perplexity search tool"            },            "created_at": "2023-11-09T12:34:56.789Z",            "updated_at": "2023-11-09T12:34:56.789Z"        }    ]}```
 * @summary List Search Tools
 * {@link /search_tools/list}
 */
export async function listSearchToolsSearchToolsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListSearchToolsSearchToolsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/search_tools/list`, ...requestConfig });
	return data;
}

/**
 * @description Create a new search tool.Example Request:```bashcurl -X POST "http://localhost:4000/search_tools" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "search_tool": {            "search_tool_name": "litellm-search",            "litellm_params": {                "search_provider": "perplexity",                "api_key": "sk-..."            },            "search_tool_info": {                "description": "Perplexity search tool"            }        }    }'```Example Response:```json{    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",    "search_tool_name": "litellm-search",    "litellm_params": {        "search_provider": "perplexity",        "api_key": "sk-..."    },    "search_tool_info": {        "description": "Perplexity search tool"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Create Search Tool
 * {@link /search_tools}
 */
export async function createSearchToolSearchToolsPost({
	body,
	config = {},
}: {
	body: CreateSearchToolSearchToolsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateSearchToolSearchToolsPostMutationResponse,
		ErrorWrapper<CreateSearchToolSearchToolsPost422>,
		CreateSearchToolSearchToolsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/search_tools`, body, ...requestConfig });
	return data;
}

/**
 * @description Update an existing search tool.Example Request:```bashcurl -X PUT "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "search_tool": {            "search_tool_name": "updated-search",            "litellm_params": {                "search_provider": "perplexity",                "api_key": "sk-new-key"            },            "search_tool_info": {                "description": "Updated search tool"            }        }    }'```Example Response:```json{    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",    "search_tool_name": "updated-search",    "litellm_params": {        "search_provider": "perplexity",        "api_key": "sk-new-key"    },    "search_tool_info": {        "description": "Updated search tool"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T13:45:12.345Z"}```
 * @summary Update Search Tool
 * {@link /search_tools/:search_tool_id}
 */
export async function updateSearchToolSearchToolsSearchToolIdPut({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdateSearchToolSearchToolsSearchToolIdPutPathParams;
	body: UpdateSearchToolSearchToolsSearchToolIdPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_id"]) {
		throw new Error(`Missing required path parameter: search_tool_id`);
	}
	const data = await request<
		UpdateSearchToolSearchToolsSearchToolIdPutMutationResponse,
		ErrorWrapper<UpdateSearchToolSearchToolsSearchToolIdPut422>,
		UpdateSearchToolSearchToolsSearchToolIdPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdateSearchToolSearchToolsSearchToolIdPutPathParams
	>({
		method: "PUT",
		url: `/search_tools/${pathParams["search_tool_id"]}`,
		body,
		...requestConfig,
	});
	return data;
}

/**
 * @description Delete a search tool.Example Request:```bashcurl -X DELETE "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "message": "Search tool 123e4567-e89b-12d3-a456-426614174000 deleted successfully",    "search_tool_name": "litellm-search"}```
 * @summary Delete Search Tool
 * {@link /search_tools/:search_tool_id}
 */
export async function deleteSearchToolSearchToolsSearchToolIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteSearchToolSearchToolsSearchToolIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_id"]) {
		throw new Error(`Missing required path parameter: search_tool_id`);
	}
	const data = await request<
		DeleteSearchToolSearchToolsSearchToolIdDeleteMutationResponse,
		ErrorWrapper<DeleteSearchToolSearchToolsSearchToolIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteSearchToolSearchToolsSearchToolIdDeletePathParams
	>({ method: "DELETE", url: `/search_tools/${pathParams["search_tool_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Get detailed information about a specific search tool by ID.Example Request:```bashcurl -X GET "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",    "search_tool_name": "litellm-search",    "litellm_params": {        "search_provider": "perplexity",        "api_key": "sk-***"    },    "search_tool_info": {        "description": "Perplexity search tool"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Get Search Tool Info
 * {@link /search_tools/:search_tool_id}
 */
export async function getSearchToolInfoSearchToolsSearchToolIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetSearchToolInfoSearchToolsSearchToolIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_id"]) {
		throw new Error(`Missing required path parameter: search_tool_id`);
	}
	const data = await request<
		GetSearchToolInfoSearchToolsSearchToolIdGetQueryResponse,
		ErrorWrapper<GetSearchToolInfoSearchToolsSearchToolIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetSearchToolInfoSearchToolsSearchToolIdGetPathParams
	>({ method: "GET", url: `/search_tools/${pathParams["search_tool_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Test connection to a search provider with the given configuration.Makes a simple test search query to verify the API key and configuration are valid.Example Request:```bashcurl -X POST "http://localhost:4000/search_tools/test_connection" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "litellm_params": {            "search_provider": "perplexity",            "api_key": "sk-..."        }    }'```Example Response (Success):```json{    "status": "success",    "message": "Successfully connected to perplexity search provider",    "test_query": "test",    "results_count": 5}```Example Response (Failure):```json{    "status": "error",    "message": "Authentication failed: Invalid API key",    "error_type": "AuthenticationError"}```
 * @summary Test Search Tool Connection
 * {@link /search_tools/test_connection}
 */
export async function testSearchToolConnectionSearchToolsTestConnectionPost({
	body,
	config = {},
}: {
	body: TestSearchToolConnectionSearchToolsTestConnectionPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestSearchToolConnectionSearchToolsTestConnectionPostMutationResponse,
		ErrorWrapper<TestSearchToolConnectionSearchToolsTestConnectionPost422>,
		TestSearchToolConnectionSearchToolsTestConnectionPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/search_tools/test_connection`, body, ...requestConfig });
	return data;
}

/**
 * @description Get the list of available search providers with their configuration fields.Auto-discovers search providers and their UI-friendly names from transformation configs.Example Request:```bashcurl -X GET "http://localhost:4000/search_tools/ui/available_providers" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "providers": [        {            "provider_name": "perplexity",            "ui_friendly_name": "Perplexity"        },        {            "provider_name": "tavily",            "ui_friendly_name": "Tavily"        }    ]}```
 * @summary Get Available Search Providers
 * {@link /search_tools/ui/available_providers}
 */
export async function getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/search_tools/ui/available_providers`, ...requestConfig });
	return data;
}

/**
 * @description List the prompts that are available on the proxy server [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X GET "http://localhost:4000/prompts/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "prompts": [        {            "prompt_id": "my_prompt_id",            "litellm_params": {                "prompt_id": "my_prompt_id",                "prompt_integration": "dotprompt",                "prompt_directory": "/path/to/prompts"            },            "prompt_info": {                "prompt_type": "config"            },            "created_at": "2023-11-09T12:34:56.789Z",            "updated_at": "2023-11-09T12:34:56.789Z"        }    ]}```
 * @summary List Prompts
 * {@link /prompts/list}
 */
export async function listPromptsPromptsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListPromptsPromptsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/prompts/list`, ...requestConfig });
	return data;
}

/**
 * @description Get detailed information about a specific prompt by ID, including prompt content     [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)    Example Request:    ```bash    curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \        -H "Authorization: Bearer <your_api_key>"    ```    Example Response:    ```json    {        "prompt_id": "my_prompt_id",        "litellm_params": {            "prompt_id": "my_prompt_id",            "prompt_integration": "dotprompt",            "prompt_directory": "/path/to/prompts"        },        "prompt_info": {            "prompt_type": "config"        },        "created_at": "2023-11-09T12:34:56.789Z",        "updated_at": "2023-11-09T12:34:56.789Z",        "content": "System: You are a helpful assistant.User: {{user_message}}"    }    ```
 * @summary Get Prompt Info
 * {@link /prompts/:prompt_id/info}
 */
export async function getPromptInfoPromptsPromptIdInfoGet({
	pathParams,
	config = {},
}: {
	pathParams: GetPromptInfoPromptsPromptIdInfoGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		GetPromptInfoPromptsPromptIdInfoGetQueryResponse,
		ErrorWrapper<GetPromptInfoPromptsPromptIdInfoGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetPromptInfoPromptsPromptIdInfoGetPathParams
	>({ method: "GET", url: `/prompts/${pathParams["prompt_id"]}/info`, ...requestConfig });
	return data;
}

/**
 * @description Get detailed information about a specific prompt by ID, including prompt content     [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)    Example Request:    ```bash    curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \        -H "Authorization: Bearer <your_api_key>"    ```    Example Response:    ```json    {        "prompt_id": "my_prompt_id",        "litellm_params": {            "prompt_id": "my_prompt_id",            "prompt_integration": "dotprompt",            "prompt_directory": "/path/to/prompts"        },        "prompt_info": {            "prompt_type": "config"        },        "created_at": "2023-11-09T12:34:56.789Z",        "updated_at": "2023-11-09T12:34:56.789Z",        "content": "System: You are a helpful assistant.User: {{user_message}}"    }    ```
 * @summary Get Prompt Info
 * {@link /prompts/:prompt_id}
 */
export async function getPromptInfoPromptsPromptIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetPromptInfoPromptsPromptIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		GetPromptInfoPromptsPromptIdGetQueryResponse,
		ErrorWrapper<GetPromptInfoPromptsPromptIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetPromptInfoPromptsPromptIdGetPathParams
	>({ method: "GET", url: `/prompts/${pathParams["prompt_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Update an existing prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X PUT "http://localhost:4000/prompts/my_prompt_id" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "prompt_id": "my_prompt",        "litellm_params": {            "prompt_id": "my_prompt",                "prompt_integration": "dotprompt",                "prompt_directory": "/path/to/prompts"            },            "prompt_info": {                "prompt_type": "config"            }        }    }'```
 * @summary Update Prompt
 * {@link /prompts/:prompt_id}
 */
export async function updatePromptPromptsPromptIdPut({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdatePromptPromptsPromptIdPutPathParams;
	body: UpdatePromptPromptsPromptIdPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		UpdatePromptPromptsPromptIdPutMutationResponse,
		ErrorWrapper<UpdatePromptPromptsPromptIdPut422>,
		UpdatePromptPromptsPromptIdPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdatePromptPromptsPromptIdPutPathParams
	>({ method: "PUT", url: `/prompts/${pathParams["prompt_id"]}`, body, ...requestConfig });
	return data;
}

/**
 * @description Delete a prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X DELETE "http://localhost:4000/prompts/my_prompt_id" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "message": "Prompt my_prompt_id deleted successfully"}```
 * @summary Delete Prompt
 * {@link /prompts/:prompt_id}
 */
export async function deletePromptPromptsPromptIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeletePromptPromptsPromptIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		DeletePromptPromptsPromptIdDeleteMutationResponse,
		ErrorWrapper<DeletePromptPromptsPromptIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeletePromptPromptsPromptIdDeletePathParams
	>({ method: "DELETE", url: `/prompts/${pathParams["prompt_id"]}`, ...requestConfig });
	return data;
}

/**
 * @description Partially update an existing prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)This endpoint allows updating specific fields of a prompt without sending the entire object.Only the following fields can be updated:- litellm_params: LiteLLM parameters for the prompt- prompt_info: Additional information about the promptExample Request:```bashcurl -X PATCH "http://localhost:4000/prompts/my_prompt_id" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "prompt_info": {            "prompt_type": "db"        }    }'```
 * @summary Patch Prompt
 * {@link /prompts/:prompt_id}
 */
export async function patchPromptPromptsPromptIdPatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: PatchPromptPromptsPromptIdPatchPathParams;
	body?: PatchPromptPromptsPromptIdPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		PatchPromptPromptsPromptIdPatchMutationResponse,
		ErrorWrapper<PatchPromptPromptsPromptIdPatch422>,
		PatchPromptPromptsPromptIdPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		PatchPromptPromptsPromptIdPatchPathParams
	>({ method: "PATCH", url: `/prompts/${pathParams["prompt_id"]}`, body, ...requestConfig });
	return data;
}

/**
 * @description Create a new prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X POST "http://localhost:4000/prompts" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "prompt_id": "my_prompt",        "litellm_params": {            "prompt_id": "json_prompt",            "prompt_integration": "dotprompt",            ### EITHER prompt_directory OR prompt_data MUST BE PROVIDED            "prompt_directory": "/path/to/dotprompt/folder",            "prompt_data": {"json_prompt": {"content": "This is a prompt", "metadata": {"model": "gpt-4"}}}        },        "prompt_info": {            "prompt_type": "config"        }    }'```
 * @summary Create Prompt
 * {@link /prompts}
 */
export async function createPromptPromptsPost({
	body,
	config = {},
}: {
	body: CreatePromptPromptsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreatePromptPromptsPostMutationResponse,
		ErrorWrapper<CreatePromptPromptsPost422>,
		CreatePromptPromptsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/prompts`, body, ...requestConfig });
	return data;
}

/**
 * @description Convert a .prompt file to JSON format.This endpoint accepts a .prompt file upload and returns the equivalent JSON representationthat can be stored in a database or used programmatically.Returns the JSON structure with 'content' and 'metadata' fields.
 * @summary Convert Prompt File To Json
 * {@link /utils/dotprompt_json_converter}
 */
export async function convertPromptFileToJsonUtilsDotpromptJsonConverterPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostMutationResponse,
		ErrorWrapper<ConvertPromptFileToJsonUtilsDotpromptJsonConverterPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/utils/dotprompt_json_converter`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description View List of Active Logging Callbacks
 * @summary List Callbacks
 * {@link /callbacks/list}
 */
export async function listCallbacksCallbacksListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListCallbacksCallbacksListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/callbacks/list`, ...requestConfig });
	return data;
}

/**
 * @description Returns:  total_active_tasks: int  by_name: { coroutine_name: count }
 * @summary Get Active Tasks Stats
 * {@link /debug/asyncio-tasks}
 */
export async function getActiveTasksStatsDebugAsyncioTasksGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetActiveTasksStatsDebugAsyncioTasksGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/debug/asyncio-tasks`, ...requestConfig });
	return data;
}

/**
 * @summary Add Allowed Ip
 * {@link /add/allowed_ip}
 */
export async function addAllowedIpAddAllowedIpPost({
	body,
	config = {},
}: {
	body: AddAllowedIpAddAllowedIpPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AddAllowedIpAddAllowedIpPostMutationResponse,
		ErrorWrapper<AddAllowedIpAddAllowedIpPost422>,
		AddAllowedIpAddAllowedIpPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/add/allowed_ip`, body, ...requestConfig });
	return data;
}

/**
 * @summary Delete Allowed Ip
 * {@link /delete/allowed_ip}
 */
export async function deleteAllowedIpDeleteAllowedIpPost({
	body,
	config = {},
}: {
	body: DeleteAllowedIpDeleteAllowedIpPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteAllowedIpDeleteAllowedIpPostMutationResponse,
		ErrorWrapper<DeleteAllowedIpDeleteAllowedIpPost422>,
		DeleteAllowedIpDeleteAllowedIpPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/delete/allowed_ip`, body, ...requestConfig });
	return data;
}

/**
 * @description Get all SSO settings from the litellm_settings configuration.Returns a structured object with values and descriptions for UI display.
 * @summary Get Internal User Settings
 * {@link /get/internal_user_settings}
 */
export async function getInternalUserSettingsGetInternalUserSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetInternalUserSettingsGetInternalUserSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/internal_user_settings`, ...requestConfig });
	return data;
}

/**
 * @description Get all SSO settings from the litellm_settings configuration.Returns a structured object with values and descriptions for UI display.
 * @summary Get Default Team Settings
 * {@link /get/default_team_settings}
 */
export async function getDefaultTeamSettingsGetDefaultTeamSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetDefaultTeamSettingsGetDefaultTeamSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/default_team_settings`, ...requestConfig });
	return data;
}

/**
 * @description Update the default internal user parameters for SSO users.These settings will be applied to new users who sign in via SSO.
 * @summary Update Internal User Settings
 * {@link /update/internal_user_settings}
 */
export async function updateInternalUserSettingsUpdateInternalUserSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationResponse,
		ErrorWrapper<UpdateInternalUserSettingsUpdateInternalUserSettingsPatch422>,
		UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/internal_user_settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Update the default team parameters for SSO users.These settings will be applied to new teams created from SSO.
 * @summary Update Default Team Settings
 * {@link /update/default_team_settings}
 */
export async function updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationResponse,
		ErrorWrapper<UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch422>,
		UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/default_team_settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Get all SSO configuration settings from the dedicated SSO table.Returns a structured object with values and descriptions for UI display.
 * @summary Get Sso Settings
 * {@link /get/sso_settings}
 */
export async function getSsoSettingsGetSsoSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetSsoSettingsGetSsoSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/sso_settings`, ...requestConfig });
	return data;
}

/**
 * @description Update SSO configuration by saving to the dedicated SSO table.
 * @summary Update Sso Settings
 * {@link /update/sso_settings}
 */
export async function updateSsoSettingsUpdateSsoSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateSsoSettingsUpdateSsoSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateSsoSettingsUpdateSsoSettingsPatchMutationResponse,
		ErrorWrapper<UpdateSsoSettingsUpdateSsoSettingsPatch422>,
		UpdateSsoSettingsUpdateSsoSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/sso_settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Get UI theme configuration from the litellm_settings.Returns current logo settings for UI customization.Note: This endpoint is public (no authentication required) so all users can see custom branding.Only the /update/ui_theme_settings endpoint requires authentication for admins to change settings.
 * @summary Get Ui Theme Settings
 * {@link /get/ui_theme_settings}
 */
export async function getUiThemeSettingsGetUiThemeSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUiThemeSettingsGetUiThemeSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/ui_theme_settings`, ...requestConfig });
	return data;
}

/**
 * @description Update UI theme configuration.Updates logo settings for the admin UI.
 * @summary Update Ui Theme Settings
 * {@link /update/ui_theme_settings}
 */
export async function updateUiThemeSettingsUpdateUiThemeSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationResponse,
		ErrorWrapper<UpdateUiThemeSettingsUpdateUiThemeSettingsPatch422>,
		UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/ui_theme_settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Upload a custom logo for the admin UI.Accepts image files (PNG, JPG, JPEG, SVG) and stores them for use in the UI.
 * @summary Upload Logo
 * {@link /upload/logo}
 */
export async function uploadLogoUploadLogoPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		UploadLogoUploadLogoPostMutationResponse,
		ErrorWrapper<UploadLogoUploadLogoPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/upload/logo`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Upload a file that can be used across - Assistants API, Batch API This is the equivalent of POST https://api.openai.com/v1/filesSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/createExample Curl```curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"```
 * @summary Create File
 * {@link /files}
 */
export async function createFileFilesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateFileFilesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		CreateFileFilesPostMutationResponse,
		ErrorWrapper<CreateFileFilesPost422>,
		null,
		Record<string, string>,
		CreateFileFilesPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/files`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/listExample Curl```curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"```
 * @summary List Files
 * {@link /files}
 */
export async function listFilesFilesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFilesFilesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFilesFilesGetQueryResponse,
		ErrorWrapper<ListFilesFilesGet422>,
		null,
		Record<string, string>,
		ListFilesFilesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/files`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Upload a file that can be used across - Assistants API, Batch API This is the equivalent of POST https://api.openai.com/v1/filesSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/createExample Curl```curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"```
 * @summary Create File
 * {@link /v1/files}
 */
export async function createFileV1FilesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateFileV1FilesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		CreateFileV1FilesPostMutationResponse,
		ErrorWrapper<CreateFileV1FilesPost422>,
		null,
		Record<string, string>,
		CreateFileV1FilesPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/files`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/listExample Curl```curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"```
 * @summary List Files
 * {@link /v1/files}
 */
export async function listFilesV1FilesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFilesV1FilesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFilesV1FilesGetQueryResponse,
		ErrorWrapper<ListFilesV1FilesGet422>,
		null,
		Record<string, string>,
		ListFilesV1FilesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/files`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Upload a file that can be used across - Assistants API, Batch API This is the equivalent of POST https://api.openai.com/v1/filesSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/createExample Curl```curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"```
 * @summary Create File
 * {@link /:provider/v1/files}
 */
export async function createFileProviderV1FilesPost({
	pathParams,
	config = {},
}: {
	pathParams: CreateFileProviderV1FilesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		CreateFileProviderV1FilesPostMutationResponse,
		ErrorWrapper<CreateFileProviderV1FilesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CreateFileProviderV1FilesPostPathParams
	>({
		method: "POST",
		url: `/${pathParams["provider"]}/v1/files`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/listExample Curl```curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"```
 * @summary List Files
 * {@link /:provider/v1/files}
 */
export async function listFilesProviderV1FilesGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: ListFilesProviderV1FilesGetPathParams;
	queryParams?: ListFilesProviderV1FilesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		ListFilesProviderV1FilesGetQueryResponse,
		ErrorWrapper<ListFilesProviderV1FilesGet422>,
		null,
		Record<string, string>,
		ListFilesProviderV1FilesGetQueryParams,
		ListFilesProviderV1FilesGetPathParams
	>({ method: "GET", url: `/${pathParams["provider"]}/v1/files`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/contentSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contentsExample Curl```curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"```
 * @summary Get File Content
 * {@link /files/:file_id/content}
 */
export async function getFileContentFilesFileIdContentGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileContentFilesFileIdContentGetPathParams;
	queryParams?: GetFileContentFilesFileIdContentGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileContentFilesFileIdContentGetQueryResponse,
		ErrorWrapper<GetFileContentFilesFileIdContentGet422>,
		null,
		Record<string, string>,
		GetFileContentFilesFileIdContentGetQueryParams,
		GetFileContentFilesFileIdContentGetPathParams
	>({
		method: "GET",
		url: `/files/${pathParams["file_id"]}/content`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/contentSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contentsExample Curl```curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"```
 * @summary Get File Content
 * {@link /v1/files/:file_id/content}
 */
export async function getFileContentV1FilesFileIdContentGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileContentV1FilesFileIdContentGetPathParams;
	queryParams?: GetFileContentV1FilesFileIdContentGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileContentV1FilesFileIdContentGetQueryResponse,
		ErrorWrapper<GetFileContentV1FilesFileIdContentGet422>,
		null,
		Record<string, string>,
		GetFileContentV1FilesFileIdContentGetQueryParams,
		GetFileContentV1FilesFileIdContentGetPathParams
	>({
		method: "GET",
		url: `/v1/files/${pathParams["file_id"]}/content`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/contentSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contentsExample Curl```curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"```
 * @summary Get File Content
 * {@link /:provider/v1/files/:file_id/content}
 */
export async function getFileContentProviderV1FilesFileIdContentGet({
	pathParams,
	config = {},
}: {
	pathParams: GetFileContentProviderV1FilesFileIdContentGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		GetFileContentProviderV1FilesFileIdContentGetQueryResponse,
		ErrorWrapper<GetFileContentProviderV1FilesFileIdContentGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetFileContentProviderV1FilesFileIdContentGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["provider"]}/v1/files/${pathParams["file_id"]}/content`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieveExample Curl```curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"```
 * @summary Get File
 * {@link /files/:file_id}
 */
export async function getFileFilesFileIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileFilesFileIdGetPathParams;
	queryParams?: GetFileFilesFileIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileFilesFileIdGetQueryResponse,
		ErrorWrapper<GetFileFilesFileIdGet422>,
		null,
		Record<string, string>,
		GetFileFilesFileIdGetQueryParams,
		GetFileFilesFileIdGetPathParams
	>({ method: "GET", url: `/files/${pathParams["file_id"]}`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Deletes a specified file. that can be used across - Assistants API, Batch API This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/deleteExample Curl```curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"```
 * @summary Delete File
 * {@link /files/:file_id}
 */
export async function deleteFileFilesFileIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteFileFilesFileIdDeletePathParams;
	queryParams?: DeleteFileFilesFileIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		DeleteFileFilesFileIdDeleteMutationResponse,
		ErrorWrapper<DeleteFileFilesFileIdDelete422>,
		null,
		Record<string, string>,
		DeleteFileFilesFileIdDeleteQueryParams,
		DeleteFileFilesFileIdDeletePathParams
	>({ method: "DELETE", url: `/files/${pathParams["file_id"]}`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieveExample Curl```curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"```
 * @summary Get File
 * {@link /v1/files/:file_id}
 */
export async function getFileV1FilesFileIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileV1FilesFileIdGetPathParams;
	queryParams?: GetFileV1FilesFileIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileV1FilesFileIdGetQueryResponse,
		ErrorWrapper<GetFileV1FilesFileIdGet422>,
		null,
		Record<string, string>,
		GetFileV1FilesFileIdGetQueryParams,
		GetFileV1FilesFileIdGetPathParams
	>({ method: "GET", url: `/v1/files/${pathParams["file_id"]}`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Deletes a specified file. that can be used across - Assistants API, Batch API This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/deleteExample Curl```curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"```
 * @summary Delete File
 * {@link /v1/files/:file_id}
 */
export async function deleteFileV1FilesFileIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteFileV1FilesFileIdDeletePathParams;
	queryParams?: DeleteFileV1FilesFileIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		DeleteFileV1FilesFileIdDeleteMutationResponse,
		ErrorWrapper<DeleteFileV1FilesFileIdDelete422>,
		null,
		Record<string, string>,
		DeleteFileV1FilesFileIdDeleteQueryParams,
		DeleteFileV1FilesFileIdDeletePathParams
	>({ method: "DELETE", url: `/v1/files/${pathParams["file_id"]}`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieveExample Curl```curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"```
 * @summary Get File
 * {@link /:provider/v1/files/:file_id}
 */
export async function getFileProviderV1FilesFileIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetFileProviderV1FilesFileIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		GetFileProviderV1FilesFileIdGetQueryResponse,
		ErrorWrapper<GetFileProviderV1FilesFileIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetFileProviderV1FilesFileIdGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["provider"]}/v1/files/${pathParams["file_id"]}`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Deletes a specified file. that can be used across - Assistants API, Batch API This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/deleteExample Curl```curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"```
 * @summary Delete File
 * {@link /:provider/v1/files/:file_id}
 */
export async function deleteFileProviderV1FilesFileIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteFileProviderV1FilesFileIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		DeleteFileProviderV1FilesFileIdDeleteMutationResponse,
		ErrorWrapper<DeleteFileProviderV1FilesFileIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteFileProviderV1FilesFileIdDeletePathParams
	>({
		method: "DELETE",
		url: `/${pathParams["provider"]}/v1/files/${pathParams["file_id"]}`,
		...requestConfig,
	});
	return data;
}

/**
 * @description Add a success/failure callback to a teamUse this if if you want different teams to have different success/failure callbacksParameters:- callback_name (Literal["langfuse", "langsmith", "gcs"], required): The name of the callback to add- callback_type (Literal["success", "failure", "success_and_failure"], required): The type of callback to add. One of:    - "success": Callback for successful LLM calls    - "failure": Callback for failed LLM calls    - "success_and_failure": Callback for both successful and failed LLM calls- callback_vars (StandardCallbackDynamicParams, required): A dictionary of variables to pass to the callback    - langfuse_public_key: The public key for the Langfuse callback    - langfuse_secret_key: The secret key for the Langfuse callback    - langfuse_secret: The secret for the Langfuse callback    - langfuse_host: The host for the Langfuse callback    - gcs_bucket_name: The name of the GCS bucket    - gcs_path_service_account: The path to the GCS service account    - langsmith_api_key: The API key for the Langsmith callback    - langsmith_project: The project for the Langsmith callback    - langsmith_base_url: The base URL for the Langsmith callbackExample curl:```curl -X POST 'http:/localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -d '{    "callback_name": "langfuse",    "callback_type": "success",    "callback_vars": {"langfuse_public_key": "pk-lf-xxxx1", "langfuse_secret_key": "sk-xxxxx"}    }'```This means for the team where team_id = dbe2f686-a686-4896-864a-4c3924458709, all LLM calls will be logged to langfuse using the public key pk-lf-xxxx1 and the secret key sk-xxxxx
 * @summary Add Team Callbacks
 * {@link /team/:team_id/callback}
 */
export async function addTeamCallbacksTeamTeamIdCallbackPost({
	pathParams,
	body,
	headers,
	config = {},
}: {
	pathParams: AddTeamCallbacksTeamTeamIdCallbackPostPathParams;
	body: AddTeamCallbacksTeamTeamIdCallbackPostMutationRequest;
	headers?: AddTeamCallbacksTeamTeamIdCallbackPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		AddTeamCallbacksTeamTeamIdCallbackPostMutationResponse,
		ErrorWrapper<AddTeamCallbacksTeamTeamIdCallbackPost422>,
		AddTeamCallbacksTeamTeamIdCallbackPostMutationRequest,
		AddTeamCallbacksTeamTeamIdCallbackPostHeaderParams,
		Record<string, string>,
		AddTeamCallbacksTeamTeamIdCallbackPostPathParams
	>({
		method: "POST",
		url: `/team/${pathParams["team_id"]}/callback`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Get the success/failure callbacks and variables for a teamParameters:- team_id (str, required): The unique identifier for the teamExample curl:```curl -X GET 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Authorization: Bearer sk-1234'```This will return the callback settings for the team with id dbe2f686-a686-4896-864a-4c3924458709Returns {        "status": "success",        "data": {            "team_id": team_id,            "success_callbacks": team_callback_settings_obj.success_callback,            "failure_callbacks": team_callback_settings_obj.failure_callback,            "callback_vars": team_callback_settings_obj.callback_vars,        },    }
 * @summary Get Team Callbacks
 * {@link /team/:team_id/callback}
 */
export async function getTeamCallbacksTeamTeamIdCallbackGet({
	pathParams,
	config = {},
}: {
	pathParams: GetTeamCallbacksTeamTeamIdCallbackGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		GetTeamCallbacksTeamTeamIdCallbackGetQueryResponse,
		ErrorWrapper<GetTeamCallbacksTeamTeamIdCallbackGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetTeamCallbacksTeamTeamIdCallbackGetPathParams
	>({ method: "GET", url: `/team/${pathParams["team_id"]}/callback`, ...requestConfig });
	return data;
}

/**
 * @description Disable all logging callbacks for a teamParameters:- team_id (str, required): The unique identifier for the teamExample curl:```curl -X POST 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/disable_logging'         -H 'Authorization: Bearer sk-1234'```
 * @summary Disable Team Logging
 * {@link /team/:team_id/disable_logging}
 */
export async function disableTeamLoggingTeamTeamIdDisableLoggingPost({
	pathParams,
	config = {},
}: {
	pathParams: DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		DisableTeamLoggingTeamTeamIdDisableLoggingPostMutationResponse,
		ErrorWrapper<DisableTeamLoggingTeamTeamIdDisableLoggingPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams
	>({ method: "POST", url: `/team/${pathParams["team_id"]}/disable_logging`, ...requestConfig });
	return data;
}

/**
 * @description Create a new budget object. Can apply this to teams, orgs, end-users, keys.Parameters:- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)- budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.- max_budget: Optional[float] - The max budget for the budget.- soft_budget: Optional[float] - The soft budget for the budget.- max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.- tpm_limit: Optional[int] - The tokens per minute limit for the budget.- rpm_limit: Optional[int] - The requests per minute limit for the budget.- model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}- budget_reset_at: Optional[datetime] - Datetime when the initial budget is reset. Default is now.
 * @summary New Budget
 * {@link /budget/new}
 */
export async function newBudgetBudgetNewPost({
	body,
	config = {},
}: {
	body?: NewBudgetBudgetNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewBudgetBudgetNewPostMutationResponse,
		ErrorWrapper<NewBudgetBudgetNewPost422>,
		NewBudgetBudgetNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/new`, body, ...requestConfig });
	return data;
}

/**
 * @description Update an existing budget object.Parameters:- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)- budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.- max_budget: Optional[float] - The max budget for the budget.- soft_budget: Optional[float] - The soft budget for the budget.- max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.- tpm_limit: Optional[int] - The tokens per minute limit for the budget.- rpm_limit: Optional[int] - The requests per minute limit for the budget.- model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}- budget_reset_at: Optional[datetime] - Update the Datetime when the budget was last reset.
 * @summary Update Budget
 * {@link /budget/update}
 */
export async function updateBudgetBudgetUpdatePost({
	body,
	config = {},
}: {
	body?: UpdateBudgetBudgetUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateBudgetBudgetUpdatePostMutationResponse,
		ErrorWrapper<UpdateBudgetBudgetUpdatePost422>,
		UpdateBudgetBudgetUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Get the budget id specific informationParameters:- budgets: List[str] - The list of budget ids to get information for
 * @summary Info Budget
 * {@link /budget/info}
 */
export async function infoBudgetBudgetInfoPost({
	body,
	config = {},
}: {
	body: InfoBudgetBudgetInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoBudgetBudgetInfoPostMutationResponse,
		ErrorWrapper<InfoBudgetBudgetInfoPost422>,
		InfoBudgetBudgetInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/info`, body, ...requestConfig });
	return data;
}

/**
 * @description Get list of configurable params + current value for a budget item + description of each fieldUsed on Admin UI.Query Parameters:- budget_id: str - The budget id to get information for
 * @summary Budget Settings
 * {@link /budget/settings}
 */
export async function budgetSettingsBudgetSettingsGet({
	queryParams,
	config = {},
}: {
	queryParams: BudgetSettingsBudgetSettingsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BudgetSettingsBudgetSettingsGetQueryResponse,
		ErrorWrapper<BudgetSettingsBudgetSettingsGet422>,
		null,
		Record<string, string>,
		BudgetSettingsBudgetSettingsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/budget/settings`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description List all the created budgets in proxy db. Used on Admin UI.
 * @summary List Budget
 * {@link /budget/list}
 */
export async function listBudgetBudgetListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListBudgetBudgetListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/budget/list`, ...requestConfig });
	return data;
}

/**
 * @description Delete budgetParameters:- id: str - The budget id to delete
 * @summary Delete Budget
 * {@link /budget/delete}
 */
export async function deleteBudgetBudgetDeletePost({
	body,
	config = {},
}: {
	body: DeleteBudgetBudgetDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteBudgetBudgetDeletePostMutationResponse,
		ErrorWrapper<DeleteBudgetBudgetDeletePost422>,
		DeleteBudgetBudgetDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description PATCH Endpoint for partial model updates.Only updates the fields specified in the request while preserving other existing values.Follows proper PATCH semantics by only modifying provided fields.Args:    model_id: The ID of the model to update    patch_data: The fields to update and their new values    user_api_key_dict: User authentication informationReturns:    Updated model informationRaises:    ProxyException: For various error conditions including authentication and database errors
 * @summary Patch Model
 * {@link /model/:model_id/update}
 */
export async function patchModelModelModelIdUpdatePatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: PatchModelModelModelIdUpdatePatchPathParams;
	body?: PatchModelModelModelIdUpdatePatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		PatchModelModelModelIdUpdatePatchMutationResponse,
		ErrorWrapper<PatchModelModelModelIdUpdatePatch422>,
		PatchModelModelModelIdUpdatePatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		PatchModelModelModelIdUpdatePatchPathParams
	>({ method: "PATCH", url: `/model/${pathParams["model_id"]}/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Allows deleting models in the model list in the config.yaml
 * @summary Delete Model
 * {@link /model/delete}
 */
export async function deleteModelModelDeletePost({
	body,
	config = {},
}: {
	body: DeleteModelModelDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteModelModelDeletePostMutationResponse,
		ErrorWrapper<DeleteModelModelDeletePost422>,
		DeleteModelModelDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description Allows adding new models to the model list in the config.yaml
 * @summary Add New Model
 * {@link /model/new}
 */
export async function addNewModelModelNewPost({
	body,
	config = {},
}: {
	body: AddNewModelModelNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AddNewModelModelNewPostMutationResponse,
		ErrorWrapper<AddNewModelModelNewPost422>,
		AddNewModelModelNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model/new`, body, ...requestConfig });
	return data;
}

/**
 * @description Edit existing model params
 * @summary Update Model
 * {@link /model/update}
 */
export async function updateModelModelUpdatePost({
	body,
	config = {},
}: {
	body?: UpdateModelModelUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateModelModelUpdatePostMutationResponse,
		ErrorWrapper<UpdateModelModelUpdatePost422>,
		UpdateModelModelUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Update which model groups are public
 * @summary Update Public Model Groups
 * {@link /model_group/make_public}
 */
export async function updatePublicModelGroupsModelGroupMakePublicPost({
	body,
	config = {},
}: {
	body: UpdatePublicModelGroupsModelGroupMakePublicPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdatePublicModelGroupsModelGroupMakePublicPostMutationResponse,
		ErrorWrapper<UpdatePublicModelGroupsModelGroupMakePublicPost422>,
		UpdatePublicModelGroupsModelGroupMakePublicPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model_group/make_public`, body, ...requestConfig });
	return data;
}

/**
 * @description Update useful links
 * @summary Update Useful Links
 * {@link /model_hub/update_useful_links}
 */
export async function updateUsefulLinksModelHubUpdateUsefulLinksPost({
	body,
	config = {},
}: {
	body: UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationResponse,
		ErrorWrapper<UpdateUsefulLinksModelHubUpdateUsefulLinksPost422>,
		UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model_hub/update_useful_links`, body, ...requestConfig });
	return data;
}

/**
 * @description Create a new tag.Parameters:- name: str - The name of the tag- description: Optional[str] - Description of what this tag represents- models: List[str] - List of either 'model_id' or 'model_name' allowed for this tag- budget_id: Optional[str] - The id for a budget (tpm/rpm/max budget) for the tag### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###- max_budget: Optional[float] - Max budget for tag- tpm_limit: Optional[int] - Max tpm limit for tag- rpm_limit: Optional[int] - Max rpm limit for tag- max_parallel_requests: Optional[int] - Max parallel requests for tag- soft_budget: Optional[float] - Get a slack alert when this soft budget is reached- model_max_budget: Optional[dict] - Max budget for a specific model- budget_duration: Optional[str] - Frequency of resetting tag budget
 * @summary New Tag
 * {@link /tag/new}
 */
export async function newTagTagNewPost({
	body,
	config = {},
}: {
	body: NewTagTagNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewTagTagNewPostMutationResponse,
		ErrorWrapper<NewTagTagNewPost422>,
		NewTagTagNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/new`, body, ...requestConfig });
	return data;
}

/**
 * @description Update an existing tag.Parameters:- name: str - The name of the tag to update- description: Optional[str] - Updated description- models: List[str] - Updated list of allowed LLM models- budget_id: Optional[str] - The id for a budget to associate with the tag### BUDGET UPDATE PARAMS ###- max_budget: Optional[float] - Max budget for tag- tpm_limit: Optional[int] - Max tpm limit for tag- rpm_limit: Optional[int] - Max rpm limit for tag- max_parallel_requests: Optional[int] - Max parallel requests for tag- soft_budget: Optional[float] - Get a slack alert when this soft budget is reached- model_max_budget: Optional[dict] - Max budget for a specific model- budget_duration: Optional[str] - Frequency of resetting tag budget
 * @summary Update Tag
 * {@link /tag/update}
 */
export async function updateTagTagUpdatePost({
	body,
	config = {},
}: {
	body: UpdateTagTagUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateTagTagUpdatePostMutationResponse,
		ErrorWrapper<UpdateTagTagUpdatePost422>,
		UpdateTagTagUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Get information about specific tags.Parameters:- names: List[str] - List of tag names to get information for
 * @summary Info Tag
 * {@link /tag/info}
 */
export async function infoTagTagInfoPost({
	body,
	config = {},
}: {
	body: InfoTagTagInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoTagTagInfoPostMutationResponse,
		ErrorWrapper<InfoTagTagInfoPost422>,
		InfoTagTagInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/info`, body, ...requestConfig });
	return data;
}

/**
 * @description List all available tags with their budget information.
 * @summary List Tags
 * {@link /tag/list}
 */
export async function listTagsTagListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListTagsTagListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/tag/list`, ...requestConfig });
	return data;
}

/**
 * @description Delete a tag.Parameters:- name: str - The name of the tag to delete
 * @summary Delete Tag
 * {@link /tag/delete}
 */
export async function deleteTagTagDeletePost({
	body,
	config = {},
}: {
	body: DeleteTagTagDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteTagTagDeletePostMutationResponse,
		ErrorWrapper<DeleteTagTagDeletePost422>,
		DeleteTagTagDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description Get daily activity for specific tags or all tags.Args:    tags (Optional[str]): Comma-separated list of tags to filter by. If not provided, returns data for all tags.    start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).    end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).    model (Optional[str]): Filter by model name.    api_key (Optional[str]): Filter by API key.    page (int): Page number for pagination.    page_size (int): Number of items per page.Returns:    SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 * @summary Get Tag Daily Activity
 * {@link /tag/daily/activity}
 */
export async function getTagDailyActivityTagDailyActivityGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetTagDailyActivityTagDailyActivityGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetTagDailyActivityTagDailyActivityGetQueryResponse,
		ErrorWrapper<GetTagDailyActivityTagDailyActivityGet422>,
		null,
		Record<string, string>,
		GetTagDailyActivityTagDailyActivityGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/daily/activity`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get current cost discount configuration.Returns the cost_discount_config from litellm_settings.
 * @summary Get Cost Discount Config
 * {@link /config/cost_discount_config}
 */
export async function getCostDiscountConfigConfigCostDiscountConfigGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCostDiscountConfigConfigCostDiscountConfigGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/config/cost_discount_config`, ...requestConfig });
	return data;
}

/**
 * @description Update cost discount configuration.Updates the cost_discount_config in litellm_settings.Discounts should be between 0 and 1 (e.g., 0.05 = 5% discount).Example:```json{    "vertex_ai": 0.05,    "gemini": 0.05,    "openai": 0.01}```
 * @summary Update Cost Discount Config
 * {@link /config/cost_discount_config}
 */
export async function updateCostDiscountConfigConfigCostDiscountConfigPatch({
	body,
	config = {},
}: {
	body?: UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationResponse,
		ErrorWrapper<UpdateCostDiscountConfigConfigCostDiscountConfigPatch422>,
		UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/config/cost_discount_config`, body, ...requestConfig });
	return data;
}

/**
 * @description Get router configuration and available settings.Returns:- fields: List of all configurable router settings with their metadata (type, description, default, options)          The routing_strategy field includes available options extracted from the Router class- current_values: Current values of router settings from config
 * @summary Get Router Settings
 * {@link /router/settings}
 */
export async function getRouterSettingsRouterSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetRouterSettingsRouterSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/router/settings`, ...requestConfig });
	return data;
}

/**
 * @description Get cache configuration and available settings.Returns:- fields: List of all configurable cache settings with their metadata (type, description, default, options)- current_values: Current values of cache settings from database
 * @summary Get Cache Settings
 * {@link /cache/settings}
 */
export async function getCacheSettingsCacheSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCacheSettingsCacheSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cache/settings`, ...requestConfig });
	return data;
}

/**
 * @description Save cache settings to database and initialize cache.This endpoint:1. Encrypts sensitive fields (passwords, etc.)2. Saves to LiteLLM_CacheConfig table3. Reinitializes cache with new settings
 * @summary Update Cache Settings
 * {@link /cache/settings}
 */
export async function updateCacheSettingsCacheSettingsPost({
	body,
	config = {},
}: {
	body: UpdateCacheSettingsCacheSettingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateCacheSettingsCacheSettingsPostMutationResponse,
		ErrorWrapper<UpdateCacheSettingsCacheSettingsPost422>,
		UpdateCacheSettingsCacheSettingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Test cache connection with provided credentials.Creates a temporary cache instance and uses its test_connection methodto verify the credentials work without affecting global state.
 * @summary Test Cache Connection
 * {@link /cache/settings/test}
 */
export async function testCacheConnectionCacheSettingsTestPost({
	body,
	config = {},
}: {
	body: TestCacheConnectionCacheSettingsTestPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestCacheConnectionCacheSettingsTestPostMutationResponse,
		ErrorWrapper<TestCacheConnectionCacheSettingsTestPost422>,
		TestCacheConnectionCacheSettingsTestPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/settings/test`, body, ...requestConfig });
	return data;
}

/**
 * @description Get all distinct user agent tags up to a maximum of {MAX_TAGS} tags.This endpoint returns all unique user agent tags found in the database,sorted by frequency of usage.Returns:    DistinctTagsResponse: List of distinct user agent tags
 * @summary Get Distinct User Agent Tags
 * {@link /tag/distinct}
 */
export async function getDistinctUserAgentTagsTagDistinctGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetDistinctUserAgentTagsTagDistinctGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/tag/distinct`, ...requestConfig });
	return data;
}

/**
 * @description Get Daily Active Users (DAU) by tags for the last {MAX_DAYS} days ending on UTC today + 1 day.This endpoint efficiently calculates unique users per tag for each of the last {MAX_DAYS} daysusing a single optimized SQL query, perfect for dashboard time series visualization.Args:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    ActiveUsersAnalyticsResponse: DAU data by tag for each of the last {MAX_DAYS} days
 * @summary Get Daily Active Users
 * {@link /tag/dau}
 */
export async function getDailyActiveUsersTagDauGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetDailyActiveUsersTagDauGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetDailyActiveUsersTagDauGetQueryResponse,
		ErrorWrapper<GetDailyActiveUsersTagDauGet422>,
		null,
		Record<string, string>,
		GetDailyActiveUsersTagDauGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/dau`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get Weekly Active Users (WAU) by tags for the last {MAX_WEEKS} weeks ending on UTC today + 1 day.Shows week-by-week breakdown:- Week 1 (Jan 1): Earliest week (7 weeks ago)- Week 2 (Jan 8): Next week (6 weeks ago)- Week 3 (Jan 15): Next week (5 weeks ago)- ... and so on for {MAX_WEEKS} weeks total- Week 7: Most recent week ending on UTC today + 1 dayArgs:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    ActiveUsersAnalyticsResponse: WAU data by tag for each of the last {MAX_WEEKS} weeks with descriptive week labels (e.g., "Week 1 (Jan 1)")
 * @summary Get Weekly Active Users
 * {@link /tag/wau}
 */
export async function getWeeklyActiveUsersTagWauGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetWeeklyActiveUsersTagWauGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetWeeklyActiveUsersTagWauGetQueryResponse,
		ErrorWrapper<GetWeeklyActiveUsersTagWauGet422>,
		null,
		Record<string, string>,
		GetWeeklyActiveUsersTagWauGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/wau`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get Monthly Active Users (MAU) by tags for the last {MAX_MONTHS} months ending on UTC today + 1 day.Shows month-by-month breakdown:- Month 1 (Nov): Earliest month (7 months ago, 30-day period)- Month 2 (Dec): Next month (6 months ago)- Month 3 (Jan): Next month (5 months ago)- ... and so on for {MAX_MONTHS} months total- Month 7: Most recent month ending on UTC today + 1 dayArgs:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    ActiveUsersAnalyticsResponse: MAU data by tag for each of the last {MAX_MONTHS} months with descriptive month labels (e.g., "Month 1 (Nov)")
 * @summary Get Monthly Active Users
 * {@link /tag/mau}
 */
export async function getMonthlyActiveUsersTagMauGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetMonthlyActiveUsersTagMauGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetMonthlyActiveUsersTagMauGetQueryResponse,
		ErrorWrapper<GetMonthlyActiveUsersTagMauGet422>,
		null,
		Record<string, string>,
		GetMonthlyActiveUsersTagMauGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/mau`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get summary analytics for tags including unique users, requests, tokens, and spend.Args:    start_date: Start date for the analytics period (YYYY-MM-DD)    end_date: End date for the analytics period (YYYY-MM-DD)    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    TagSummaryResponse: Summary analytics data by tag
 * @summary Get Tag Summary
 * {@link /tag/summary}
 */
export async function getTagSummaryTagSummaryGet({
	queryParams,
	config = {},
}: {
	queryParams: GetTagSummaryTagSummaryGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetTagSummaryTagSummaryGetQueryResponse,
		ErrorWrapper<GetTagSummaryTagSummaryGet422>,
		null,
		Record<string, string>,
		GetTagSummaryTagSummaryGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/summary`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get per-user analytics including successful requests, tokens, and spend by individual users.This endpoint provides usage metrics broken down by individual users based on theirtag activity during the last 30 days ending on UTC today + 1 day.Args:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    page: Page number for pagination    page_size: Number of items per page    Returns:    PerUserAnalyticsResponse: Analytics data broken down by individual users for the last 30 days
 * @summary Get Per User Analytics
 * {@link /tag/user-agent/per-user-analytics}
 */
export async function getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryResponse,
		ErrorWrapper<GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGet422>,
		null,
		Record<string, string>,
		GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/user-agent/per-user-analytics`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Create a new vector store.Parameters:- vector_store_id: str - Unique identifier for the vector store- custom_llm_provider: str - Provider of the vector store- vector_store_name: Optional[str] - Name of the vector store- vector_store_description: Optional[str] - Description of the vector store- vector_store_metadata: Optional[Dict] - Additional metadata for the vector store
 * @summary New Vector Store
 * {@link /vector_store/new}
 */
export async function newVectorStoreVectorStoreNewPost({
	body,
	config = {},
}: {
	body?: NewVectorStoreVectorStoreNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewVectorStoreVectorStoreNewPostMutationResponse,
		ErrorWrapper<NewVectorStoreVectorStoreNewPost422>,
		NewVectorStoreVectorStoreNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/new`, body, ...requestConfig });
	return data;
}

/**
 * @description List all available vector stores with optional filtering and pagination.Combines both in-memory vector stores and those stored in the database.Parameters:- page: int - Page number for pagination (default: 1)- page_size: int - Number of items per page (default: 100)
 * @summary List Vector Stores
 * {@link /vector_store/list}
 */
export async function listVectorStoresVectorStoreListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListVectorStoresVectorStoreListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListVectorStoresVectorStoreListGetQueryResponse,
		ErrorWrapper<ListVectorStoresVectorStoreListGet422>,
		null,
		Record<string, string>,
		ListVectorStoresVectorStoreListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/vector_store/list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Delete a vector store.Parameters:- vector_store_id: str - ID of the vector store to delete
 * @summary Delete Vector Store
 * {@link /vector_store/delete}
 */
export async function deleteVectorStoreVectorStoreDeletePost({
	body,
	config = {},
}: {
	body: DeleteVectorStoreVectorStoreDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteVectorStoreVectorStoreDeletePostMutationResponse,
		ErrorWrapper<DeleteVectorStoreVectorStoreDeletePost422>,
		DeleteVectorStoreVectorStoreDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/delete`, body, ...requestConfig });
	return data;
}

/**
 * @description Return a single vector store's details
 * @summary Get Vector Store Info
 * {@link /vector_store/info}
 */
export async function getVectorStoreInfoVectorStoreInfoPost({
	body,
	config = {},
}: {
	body: GetVectorStoreInfoVectorStoreInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetVectorStoreInfoVectorStoreInfoPostMutationResponse,
		ErrorWrapper<GetVectorStoreInfoVectorStoreInfoPost422>,
		GetVectorStoreInfoVectorStoreInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/info`, body, ...requestConfig });
	return data;
}

/**
 * @description Update vector store details
 * @summary Update Vector Store
 * {@link /vector_store/update}
 */
export async function updateVectorStoreVectorStoreUpdatePost({
	body,
	config = {},
}: {
	body: UpdateVectorStoreVectorStoreUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateVectorStoreVectorStoreUpdatePostMutationResponse,
		ErrorWrapper<UpdateVectorStoreVectorStoreUpdatePost422>,
		UpdateVectorStoreVectorStoreUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/update`, body, ...requestConfig });
	return data;
}

/**
 * @description Get all email event settings
 * @summary Get Email Event Settings
 * {@link /email/event_settings}
 */
export async function getEmailEventSettingsEmailEventSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetEmailEventSettingsEmailEventSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/email/event_settings`, ...requestConfig });
	return data;
}

/**
 * @description Update the settings for email events
 * @summary Update Event Settings
 * {@link /email/event_settings}
 */
export async function updateEventSettingsEmailEventSettingsPatch({
	body,
	config = {},
}: {
	body: UpdateEventSettingsEmailEventSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateEventSettingsEmailEventSettingsPatchMutationResponse,
		ErrorWrapper<UpdateEventSettingsEmailEventSettingsPatch422>,
		UpdateEventSettingsEmailEventSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/email/event_settings`, body, ...requestConfig });
	return data;
}

/**
 * @description Reset all email event settings to default (new user invitations on, virtual key creation off)
 * @summary Reset Event Settings
 * {@link /email/event_settings/reset}
 */
export async function resetEventSettingsEmailEventSettingsResetPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResetEventSettingsEmailEventSettingsResetPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/email/event_settings/reset`, ...requestConfig });
	return data;
}

/**
 * @description Get all audit logs with filtering and pagination.Returns a paginated response of audit logs matching the specified filters.
 * @summary Get Audit Logs
 * {@link /audit}
 */
export async function getAuditLogsAuditGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetAuditLogsAuditGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAuditLogsAuditGetQueryResponse,
		ErrorWrapper<GetAuditLogsAuditGet422>,
		null,
		Record<string, string>,
		GetAuditLogsAuditGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/audit`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description Get detailed information about a specific audit log entry by its ID.Args:    id (str): The unique identifier of the audit log entryReturns:    AuditLogResponse: Detailed information about the audit log entryRaises:    HTTPException: If the audit log is not found or if there's a database connection error
 * @summary Get Audit Log By Id
 * {@link /audit/:id}
 */
export async function getAuditLogByIdAuditIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetAuditLogByIdAuditIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["id"]) {
		throw new Error(`Missing required path parameter: id`);
	}
	const data = await request<
		GetAuditLogByIdAuditIdGetQueryResponse,
		ErrorWrapper<
			GetAuditLogByIdAuditIdGet404 | GetAuditLogByIdAuditIdGet422 | GetAuditLogByIdAuditIdGet500
		>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetAuditLogByIdAuditIdGetPathParams
	>({ method: "GET", url: `/audit/${pathParams["id"]}`, ...requestConfig });
	return data;
}

/**
 * @description For keys with `max_users` set, return the list of users that are allowed to use the key.
 * @summary Available Enterprise Users
 * {@link /user/available_users}
 */
export async function availableEnterpriseUsersUserAvailableUsersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AvailableEnterpriseUsersUserAvailableUsersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/user/available_users`, ...requestConfig });
	return data;
}

/**
 * @description Block all web crawlers from indexing the proxy server endpointsThis is useful for ensuring that the API endpoints aren't indexed by search engines
 * @summary Get Robots
 * {@link /robots.txt}
 */
export async function getRobotsRobotsTxtGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetRobotsRobotsTxtGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/robots.txt`, ...requestConfig });
	return data;
}

/**
 * @summary Get Ui Config
 * {@link /litellm/.well-known/litellm-ui-config}
 */
export async function getUiConfigLitellmWellKnownLitellmUiConfigGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUiConfigLitellmWellKnownLitellmUiConfigGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/litellm/.well-known/litellm-ui-config`, ...requestConfig });
	return data;
}

/**
 * @summary Get Ui Config
 * {@link /.well-known/litellm-ui-config}
 */
export async function getUiConfigWellKnownLitellmUiConfigGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUiConfigWellKnownLitellmUiConfigGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/.well-known/litellm-ui-config`, ...requestConfig });
	return data;
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch4({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch4PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch4MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch4422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch4PathParams
	>({ method: "PATCH", url: `/${pathParams["mcp_server_name"]}/mcp`, ...requestConfig });
	return data;
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch2({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch2PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch2MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch2422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch2PathParams
	>({ method: "POST", url: `/${pathParams["mcp_server_name"]}/mcp`, ...requestConfig });
	return data;
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatchPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatchMutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatchPathParams
	>({ method: "OPTIONS", url: `/${pathParams["mcp_server_name"]}/mcp`, ...requestConfig });
	return data;
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch3({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch3PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch3MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch3422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch3PathParams
	>({ method: "PUT", url: `/${pathParams["mcp_server_name"]}/mcp`, ...requestConfig });
	return data;
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch5({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch5PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch5MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch5422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch5PathParams
	>({ method: "DELETE", url: `/${pathParams["mcp_server_name"]}/mcp`, ...requestConfig });
	return data;
}

/**
 * @description List all available tools with information about the server they belong to.Example response:{    "tools": [        {            "name": "create_zap",            "description": "Create a new zap",            "inputSchema": "tool_input_schema",            "mcp_info": {                "server_name": "zapier",                "logo_url": "https://www.zapier.com/logo.png",            }        }    ],    "error": null,    "message": "Successfully retrieved tools"}
 * @summary List Tool Rest Api
 * {@link /mcp-rest/tools/list}
 */
export async function listToolRestApiMcpRestToolsListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListToolRestApiMcpRestToolsListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListToolRestApiMcpRestToolsListGetQueryResponse,
		ErrorWrapper<ListToolRestApiMcpRestToolsListGet422>,
		null,
		Record<string, string>,
		ListToolRestApiMcpRestToolsListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/mcp-rest/tools/list`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description REST API to call a specific MCP tool with the provided arguments
 * @summary Call Tool Rest Api
 * {@link /mcp-rest/tools/call}
 */
export async function callToolRestApiMcpRestToolsCallPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CallToolRestApiMcpRestToolsCallPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/mcp-rest/tools/call`, ...requestConfig });
	return data;
}

/**
 * @description Test if we can connect to the provided MCP server before adding it
 * @summary Test Connection
 * {@link /mcp-rest/test/connection}
 */
export async function testConnectionMcpRestTestConnectionPost({
	body,
	config = {},
}: {
	body?: TestConnectionMcpRestTestConnectionPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestConnectionMcpRestTestConnectionPostMutationResponse,
		ErrorWrapper<TestConnectionMcpRestTestConnectionPost422>,
		TestConnectionMcpRestTestConnectionPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/mcp-rest/test/connection`, body, ...requestConfig });
	return data;
}

/**
 * @description Preview tools available from MCP server before adding it
 * @summary Test Tools List
 * {@link /mcp-rest/test/tools/list}
 */
export async function testToolsListMcpRestTestToolsListPost({
	body,
	config = {},
}: {
	body?: TestToolsListMcpRestTestToolsListPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestToolsListMcpRestTestToolsListPostMutationResponse,
		ErrorWrapper<TestToolsListMcpRestTestToolsListPost422>,
		TestToolsListMcpRestTestToolsListPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/mcp-rest/test/tools/list`, body, ...requestConfig });
	return data;
}

/**
 * @summary Authorize
 * {@link /authorize}
 */
export async function authorizeAuthorizeGet({
	queryParams,
	config = {},
}: {
	queryParams: AuthorizeAuthorizeGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AuthorizeAuthorizeGetQueryResponse,
		ErrorWrapper<AuthorizeAuthorizeGet422>,
		null,
		Record<string, string>,
		AuthorizeAuthorizeGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/authorize`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Authorize
 * {@link /:mcp_server_name/authorize}
 */
export async function authorizeMcpServerNameAuthorizeGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: AuthorizeMcpServerNameAuthorizeGetPathParams;
	queryParams: AuthorizeMcpServerNameAuthorizeGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		AuthorizeMcpServerNameAuthorizeGetQueryResponse,
		ErrorWrapper<AuthorizeMcpServerNameAuthorizeGet422>,
		null,
		Record<string, string>,
		AuthorizeMcpServerNameAuthorizeGetQueryParams,
		AuthorizeMcpServerNameAuthorizeGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["mcp_server_name"]}/authorize`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @description Accept the authorization code from client and exchange it for OAuth token.Supports PKCE flow by forwarding code_verifier to upstream provider.1. Call the token endpoint with PKCE parameters2. Store the user's token in the db - and generate a LiteLLM virtual key3. Return the token4. Return a virtual key in this response
 * @summary Token Endpoint
 * {@link /token}
 */
export async function tokenEndpointTokenPost({
	queryParams,
	config = {},
}: {
	queryParams?: TokenEndpointTokenPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TokenEndpointTokenPostMutationResponse,
		ErrorWrapper<TokenEndpointTokenPost422>,
		null,
		Record<string, string>,
		TokenEndpointTokenPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/token`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "application/x-www-form-urlencoded", ...requestConfig.headers },
	});
	return data;
}

/**
 * @description Accept the authorization code from client and exchange it for OAuth token.Supports PKCE flow by forwarding code_verifier to upstream provider.1. Call the token endpoint with PKCE parameters2. Store the user's token in the db - and generate a LiteLLM virtual key3. Return the token4. Return a virtual key in this response
 * @summary Token Endpoint
 * {@link /:mcp_server_name/token}
 */
export async function tokenEndpointMcpServerNameTokenPost({
	pathParams,
	config = {},
}: {
	pathParams: TokenEndpointMcpServerNameTokenPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		TokenEndpointMcpServerNameTokenPostMutationResponse,
		ErrorWrapper<TokenEndpointMcpServerNameTokenPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		TokenEndpointMcpServerNameTokenPostPathParams
	>({
		method: "POST",
		url: `/${pathParams["mcp_server_name"]}/token`,
		...requestConfig,
		headers: { "Content-Type": "application/x-www-form-urlencoded", ...requestConfig.headers },
	});
	return data;
}

/**
 * @summary Callback
 * {@link /callback}
 */
export async function callbackCallbackGet({
	queryParams,
	config = {},
}: {
	queryParams: CallbackCallbackGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CallbackCallbackGetQueryResponse,
		ErrorWrapper<CallbackCallbackGet422>,
		null,
		Record<string, string>,
		CallbackCallbackGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/callback`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Oauth Protected Resource Mcp
 * {@link /.well-known/oauth-protected-resource}
 */
export async function oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet({
	queryParams,
	config = {},
}: {
	queryParams?: OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryResponse,
		ErrorWrapper<OauthProtectedResourceMcpWellKnownOauthProtectedResourceGet422>,
		null,
		Record<string, string>,
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/.well-known/oauth-protected-resource`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Oauth Protected Resource Mcp
 * {@link /.well-known/oauth-protected-resource/:mcp_server_name/mcp}
 */
export async function oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet({
	pathParams,
	config = {},
}: {
	pathParams: OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetQueryResponse,
		ErrorWrapper<OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams
	>({
		method: "GET",
		url: `/.well-known/oauth-protected-resource/${pathParams["mcp_server_name"]}/mcp`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Oauth Authorization Server Root
 * {@link /.well-known/oauth-authorization-server}
 */
export async function oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet({
	queryParams,
	config = {},
}: {
	queryParams?: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryResponse,
		ErrorWrapper<OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet422>,
		null,
		Record<string, string>,
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams,
		Record<string, string>
	>({
		method: "GET",
		url: `/.well-known/oauth-authorization-server`,
		queryParams,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Oauth Authorization Server Mcp
 * {@link /.well-known/oauth-authorization-server/:mcp_server_name}
 */
export async function oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet({
	pathParams,
	config = {},
}: {
	pathParams: OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetQueryResponse,
		ErrorWrapper<OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams
	>({
		method: "GET",
		url: `/.well-known/oauth-authorization-server/${pathParams["mcp_server_name"]}`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Openid Configuration
 * {@link /.well-known/openid-configuration}
 */
export async function openidConfigurationWellKnownOpenidConfigurationGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OpenidConfigurationWellKnownOpenidConfigurationGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/.well-known/openid-configuration`, ...requestConfig });
	return data;
}

/**
 * @summary Oauth Authorization Server Root
 * {@link /.well-known/oauth-authorization-server/:mcp_server_name/mcp}
 */
export async function oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet({
	pathParams,
	config = {},
}: {
	pathParams: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetQueryResponse,
		ErrorWrapper<OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams
	>({
		method: "GET",
		url: `/.well-known/oauth-authorization-server/${pathParams["mcp_server_name"]}/mcp`,
		...requestConfig,
	});
	return data;
}

/**
 * @summary Register Client
 * {@link /register}
 */
export async function registerClientRegisterPost({
	queryParams,
	config = {},
}: {
	queryParams?: RegisterClientRegisterPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RegisterClientRegisterPostMutationResponse,
		ErrorWrapper<RegisterClientRegisterPost422>,
		null,
		Record<string, string>,
		RegisterClientRegisterPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/register`, queryParams, ...requestConfig });
	return data;
}

/**
 * @summary Register Client
 * {@link /:mcp_server_name/register}
 */
export async function registerClientMcpServerNameRegisterPost({
	pathParams,
	config = {},
}: {
	pathParams: RegisterClientMcpServerNameRegisterPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		RegisterClientMcpServerNameRegisterPostMutationResponse,
		ErrorWrapper<RegisterClientMcpServerNameRegisterPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RegisterClientMcpServerNameRegisterPostPathParams
	>({ method: "POST", url: `/${pathParams["mcp_server_name"]}/register`, ...requestConfig });
	return data;
}

/**
 * @description WebSocket connection endpoint
 * @summary WebSocket: vertex_ai_live_passthrough_endpoint
 * {@link /vertex_ai/live}
 */
export async function websocketVertexAiLivePassthroughEndpoint({
	queryParams,
	config = {},
}: {
	queryParams?: WebsocketVertexAiLivePassthroughEndpointQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		WebsocketVertexAiLivePassthroughEndpointQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		WebsocketVertexAiLivePassthroughEndpointQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/vertex_ai/live`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description WebSocket connection endpoint
 * @summary WebSocket: websocket_endpoint
 * {@link /realtime}
 */
export async function websocketWebsocketEndpoint({
	queryParams,
	config = {},
}: {
	queryParams: WebsocketWebsocketEndpointQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		WebsocketWebsocketEndpointQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		WebsocketWebsocketEndpointQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/realtime`, queryParams, ...requestConfig });
	return data;
}

/**
 * @description WebSocket connection endpoint
 * @summary WebSocket: websocket_endpoint
 * {@link /v1/realtime}
 */
export async function websocketWebsocketEndpoint2({
	queryParams,
	config = {},
}: {
	queryParams: WebsocketWebsocketEndpoint2QueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}) {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		WebsocketWebsocketEndpoint2QueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		WebsocketWebsocketEndpoint2QueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/realtime`, queryParams, ...requestConfig });
	return data;
}

export const operationsByPath = {
	"GET /models": modelListModelsGet,
	"GET /v1/models": modelListV1ModelsGet,
	"GET /models/{model_id}": modelInfoModelsModelIdGet,
	"GET /v1/models/{model_id}": modelInfoV1ModelsModelIdGet,
	"POST /openai/deployments/{model}/chat/completions":
		chatCompletionOpenaiDeploymentsModelChatCompletionsPost,
	"POST /engines/{model}/chat/completions": chatCompletionEnginesModelChatCompletionsPost,
	"POST /chat/completions": chatCompletionChatCompletionsPost,
	"POST /v1/chat/completions": chatCompletionV1ChatCompletionsPost,
	"POST /openai/deployments/{model}/completions": completionOpenaiDeploymentsModelCompletionsPost,
	"POST /engines/{model}/completions": completionEnginesModelCompletionsPost,
	"POST /completions": completionCompletionsPost,
	"POST /v1/completions": completionV1CompletionsPost,
	"POST /openai/deployments/{model}/embeddings": embeddingsOpenaiDeploymentsModelEmbeddingsPost,
	"POST /engines/{model}/embeddings": embeddingsEnginesModelEmbeddingsPost,
	"POST /embeddings": embeddingsEmbeddingsPost,
	"POST /v1/embeddings": embeddingsV1EmbeddingsPost,
	"POST /moderations": moderationsModerationsPost,
	"POST /v1/moderations": moderationsV1ModerationsPost,
	"POST /audio/speech": audioSpeechAudioSpeechPost,
	"POST /v1/audio/speech": audioSpeechV1AudioSpeechPost,
	"POST /audio/transcriptions": audioTranscriptionsAudioTranscriptionsPost,
	"POST /v1/audio/transcriptions": audioTranscriptionsV1AudioTranscriptionsPost,
	"GET /assistants": getAssistantsAssistantsGet,
	"POST /assistants": createAssistantAssistantsPost,
	"GET /v1/assistants": getAssistantsV1AssistantsGet,
	"POST /v1/assistants": createAssistantV1AssistantsPost,
	"DELETE /assistants/{assistant_id}": deleteAssistantAssistantsAssistantIdDelete,
	"DELETE /v1/assistants/{assistant_id}": deleteAssistantV1AssistantsAssistantIdDelete,
	"POST /threads": createThreadsThreadsPost,
	"POST /v1/threads": createThreadsV1ThreadsPost,
	"GET /threads/{thread_id}": getThreadThreadsThreadIdGet,
	"GET /v1/threads/{thread_id}": getThreadV1ThreadsThreadIdGet,
	"POST /threads/{thread_id}/messages": addMessagesThreadsThreadIdMessagesPost,
	"GET /threads/{thread_id}/messages": getMessagesThreadsThreadIdMessagesGet,
	"POST /v1/threads/{thread_id}/messages": addMessagesV1ThreadsThreadIdMessagesPost,
	"GET /v1/threads/{thread_id}/messages": getMessagesV1ThreadsThreadIdMessagesGet,
	"POST /threads/{thread_id}/runs": runThreadThreadsThreadIdRunsPost,
	"POST /v1/threads/{thread_id}/runs": runThreadV1ThreadsThreadIdRunsPost,
	"POST /utils/token_counter": tokenCounterUtilsTokenCounterPost,
	"GET /utils/supported_openai_params": supportedOpenaiParamsUtilsSupportedOpenaiParamsGet,
	"POST /utils/transform_request": transformRequestUtilsTransformRequestPost,
	"GET /v1/model/info": modelInfoV1V1ModelInfoGet,
	"GET /model/info": modelInfoV1ModelInfoGet,
	"GET /model_group/info": modelGroupInfoModelGroupInfoGet,
	"GET /": homeGet,
	"GET /routes": getRoutesRoutesGet,
	"POST /openai/v1/responses": responsesApiOpenaiV1ResponsesPost,
	"POST /responses": responsesApiResponsesPost,
	"POST /v1/responses": responsesApiV1ResponsesPost,
	"GET /openai/v1/responses/{response_id}": getResponseOpenaiV1ResponsesResponseIdGet,
	"DELETE /openai/v1/responses/{response_id}": deleteResponseOpenaiV1ResponsesResponseIdDelete,
	"GET /responses/{response_id}": getResponseResponsesResponseIdGet,
	"DELETE /responses/{response_id}": deleteResponseResponsesResponseIdDelete,
	"GET /v1/responses/{response_id}": getResponseV1ResponsesResponseIdGet,
	"DELETE /v1/responses/{response_id}": deleteResponseV1ResponsesResponseIdDelete,
	"GET /openai/v1/responses/{response_id}/input_items":
		getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet,
	"GET /responses/{response_id}/input_items": getResponseInputItemsResponsesResponseIdInputItemsGet,
	"GET /v1/responses/{response_id}/input_items":
		getResponseInputItemsV1ResponsesResponseIdInputItemsGet,
	"POST /openai/v1/responses/{response_id}/cancel":
		cancelResponseOpenaiV1ResponsesResponseIdCancelPost,
	"POST /responses/{response_id}/cancel": cancelResponseResponsesResponseIdCancelPost,
	"POST /v1/responses/{response_id}/cancel": cancelResponseV1ResponsesResponseIdCancelPost,
	"POST /batches": createBatchBatchesPost,
	"GET /batches": listBatchesBatchesGet,
	"POST /v1/batches": createBatchV1BatchesPost,
	"GET /v1/batches": listBatchesV1BatchesGet,
	"POST /{provider}/v1/batches": createBatchProviderV1BatchesPost,
	"GET /{provider}/v1/batches": listBatchesProviderV1BatchesGet,
	"GET /batches/{batch_id}": retrieveBatchBatchesBatchIdGet,
	"GET /v1/batches/{batch_id}": retrieveBatchV1BatchesBatchIdGet,
	"GET /{provider}/v1/batches/{batch_id}": retrieveBatchProviderV1BatchesBatchIdGet,
	"POST /batches/{batch_id}/cancel": cancelBatchBatchesBatchIdCancelPost,
	"POST /v1/batches/{batch_id}/cancel": cancelBatchV1BatchesBatchIdCancelPost,
	"POST /{provider}/v1/batches/{batch_id}/cancel": cancelBatchProviderV1BatchesBatchIdCancelPost,
	"GET /public/model_hub": publicModelHubPublicModelHubGet,
	"GET /public/model_hub/info": publicModelHubInfoPublicModelHubInfoGet,
	"POST /rerank": rerankRerankPost,
	"POST /v1/rerank": rerankV1RerankPost,
	"POST /v2/rerank": rerankV2RerankPost,
	"POST /ocr": ocrOcrPost,
	"POST /v1/ocr": ocrV1OcrPost,
	"GET /videos": videoListVideosGet,
	"POST /videos": videoGenerationVideosPost,
	"GET /v1/videos": videoListV1VideosGet,
	"POST /v1/videos": videoGenerationV1VideosPost,
	"GET /videos/{video_id}": videoStatusVideosVideoIdGet,
	"GET /v1/videos/{video_id}": videoStatusV1VideosVideoIdGet,
	"GET /videos/{video_id}/content": videoContentVideosVideoIdContentGet,
	"GET /v1/videos/{video_id}/content": videoContentV1VideosVideoIdContentGet,
	"POST /videos/{video_id}/remix": videoRemixVideosVideoIdRemixPost,
	"POST /v1/videos/{video_id}/remix": videoRemixV1VideosVideoIdRemixPost,
	"GET /containers": listContainersContainersGet,
	"POST /containers": createContainerContainersPost,
	"GET /v1/containers": listContainersV1ContainersGet,
	"POST /v1/containers": createContainerV1ContainersPost,
	"GET /containers/{container_id}": retrieveContainerContainersContainerIdGet,
	"DELETE /containers/{container_id}": deleteContainerContainersContainerIdDelete,
	"GET /v1/containers/{container_id}": retrieveContainerV1ContainersContainerIdGet,
	"DELETE /v1/containers/{container_id}": deleteContainerV1ContainersContainerIdDelete,
	"POST /search": searchSearchPost,
	"POST /v1/search": searchV1SearchPost,
	"POST /search/{search_tool_name}": searchSearchSearchToolNamePost,
	"POST /v1/search/{search_tool_name}": searchV1SearchSearchToolNamePost,
	"POST /openai/deployments/{model}/images/generations":
		imageGenerationOpenaiDeploymentsModelImagesGenerationsPost,
	"POST /images/generations": imageGenerationImagesGenerationsPost,
	"POST /v1/images/generations": imageGenerationV1ImagesGenerationsPost,
	"POST /openai/deployments/{model}/images/edits":
		imageEditApiOpenaiDeploymentsModelImagesEditsPost,
	"POST /images/edits": imageEditApiImagesEditsPost,
	"POST /v1/images/edits": imageEditApiV1ImagesEditsPost,
	"POST /fine_tuning/jobs": createFineTuningJobFineTuningJobsPost,
	"GET /fine_tuning/jobs": listFineTuningJobsFineTuningJobsGet,
	"POST /v1/fine_tuning/jobs": createFineTuningJobV1FineTuningJobsPost,
	"GET /v1/fine_tuning/jobs": listFineTuningJobsV1FineTuningJobsGet,
	"GET /fine_tuning/jobs/{fine_tuning_job_id}":
		retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet,
	"GET /v1/fine_tuning/jobs/{fine_tuning_job_id}":
		retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet,
	"POST /fine_tuning/jobs/{fine_tuning_job_id}/cancel":
		cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost,
	"POST /v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel":
		cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost,
	"POST /vector_stores/{vector_store_id}/search":
		vectorStoreSearchVectorStoresVectorStoreIdSearchPost,
	"POST /v1/vector_stores/{vector_store_id}/search":
		vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost,
	"POST /vector_stores": vectorStoreCreateVectorStoresPost,
	"POST /v1/vector_stores": vectorStoreCreateV1VectorStoresPost,
	"POST /v1/indexes": indexCreateV1IndexesPost,
	"GET /credentials": getCredentialsCredentialsGet,
	"POST /credentials": createCredentialCredentialsPost,
	"GET /credentials/by_model/{model_id}": getCredentialCredentialsByModelModelIdGet,
	"GET /credentials/by_name/{credential_name}": getCredentialCredentialsByNameCredentialNameGet,
	"DELETE /credentials/{credential_name}": deleteCredentialCredentialsCredentialNameDelete,
	"PATCH /credentials/{credential_name}": updateCredentialCredentialsCredentialNamePatch,
	"GET /v1/mcp/tools": getMcpToolsV1McpToolsGet,
	"GET /v1/mcp/access_groups": getMcpAccessGroupsV1McpAccessGroupsGet,
	"GET /v1/mcp/server/{server_id}/health": healthCheckMcpServerV1McpServerServerIdHealthGet,
	"GET /v1/mcp/server/health": healthCheckAllMcpServersV1McpServerHealthGet,
	"GET /v1/mcp/server": fetchAllMcpServersV1McpServerGet,
	"POST /v1/mcp/server": addMcpServerV1McpServerPost,
	"PUT /v1/mcp/server": editMcpServerV1McpServerPut,
	"GET /v1/mcp/server/{server_id}": fetchMcpServerV1McpServerServerIdGet,
	"DELETE /v1/mcp/server/{server_id}": removeMcpServerV1McpServerServerIdDelete,
	"POST /v1/messages": anthropicResponseV1MessagesPost,
	"POST /v1/messages/count_tokens": countTokensV1MessagesCountTokensPost,
	"POST /models/{model_name}:generateContent":
		googleGenerateContentModelsModelNameGenerateContentPost,
	"POST /v1beta/models/{model_name}:generateContent":
		googleGenerateContentV1betaModelsModelNameGenerateContentPost,
	"POST /models/{model_name}:streamGenerateContent":
		googleStreamGenerateContentModelsModelNameStreamGenerateContentPost,
	"POST /v1beta/models/{model_name}:streamGenerateContent":
		googleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPost,
	"POST /models/{model_name}:countTokens": googleCountTokensModelsModelNameCountTokensPost,
	"POST /v1beta/models/{model_name}:countTokens":
		googleCountTokensV1betaModelsModelNameCountTokensPost,
	"GET /config/pass_through_endpoint/team/{team_id}":
		getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet,
	"GET /config/pass_through_endpoint": getPassThroughEndpointsConfigPassThroughEndpointGet,
	"POST /config/pass_through_endpoint": createPassThroughEndpointsConfigPassThroughEndpointPost,
	"DELETE /config/pass_through_endpoint": deletePassThroughEndpointsConfigPassThroughEndpointDelete,
	"POST /config/pass_through_endpoint/{endpoint_id}":
		updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost,
	"GET /test": testEndpointTestGet,
	"GET /health/services": healthServicesEndpointHealthServicesGet,
	"GET /health": healthEndpointHealthGet,
	"GET /health/history": healthCheckHistoryEndpointHealthHistoryGet,
	"GET /health/latest": latestHealthChecksEndpointHealthLatestGet,
	"GET /health/shared-status": sharedHealthCheckStatusEndpointHealthSharedStatusGet,
	"GET /active/callbacks": activeCallbacksActiveCallbacksGet,
	"GET /settings": activeCallbacksSettingsGet,
	"GET /health/readiness": healthReadinessHealthReadinessGet,
	"GET /health/liveness": healthLivelinessHealthLivenessGet,
	"GET /health/liveliness": healthLivelinessHealthLivelinessGet,
	"POST /health/test_connection": testModelConnectionHealthTestConnectionPost,
	"POST /key/generate": generateKeyFnKeyGeneratePost,
	"POST /key/service-account/generate": generateServiceAccountKeyFnKeyServiceAccountGeneratePost,
	"POST /key/update": updateKeyFnKeyUpdatePost,
	"POST /key/delete": deleteKeyFnKeyDeletePost,
	"GET /key/info": infoKeyFnKeyInfoGet,
	"POST /key/regenerate": regenerateKeyFnKeyRegeneratePost,
	"POST /key/{key}/regenerate": regenerateKeyFnKeyKeyRegeneratePost,
	"GET /key/list": listKeysKeyListGet,
	"GET /key/aliases": keyAliasesKeyAliasesGet,
	"POST /key/block": blockKeyKeyBlockPost,
	"POST /key/unblock": unblockKeyKeyUnblockPost,
	"POST /key/health": keyHealthKeyHealthPost,
	"POST /user/new": newUserUserNewPost,
	"GET /user/info": userInfoUserInfoGet,
	"POST /user/update": userUpdateUserUpdatePost,
	"POST /user/bulk_update": bulkUserUpdateUserBulkUpdatePost,
	"GET /user/list": getUsersUserListGet,
	"POST /user/delete": deleteUserUserDeletePost,
	"GET /user/daily/activity": getUserDailyActivityUserDailyActivityGet,
	"GET /user/daily/activity/aggregated":
		getUserDailyActivityAggregatedUserDailyActivityAggregatedGet,
	"POST /team/new": newTeamTeamNewPost,
	"POST /team/update": updateTeamTeamUpdatePost,
	"POST /team/member_add": teamMemberAddTeamMemberAddPost,
	"POST /team/member_delete": teamMemberDeleteTeamMemberDeletePost,
	"POST /team/member_update": teamMemberUpdateTeamMemberUpdatePost,
	"POST /team/bulk_member_add": bulkTeamMemberAddTeamBulkMemberAddPost,
	"POST /team/delete": deleteTeamTeamDeletePost,
	"GET /team/info": teamInfoTeamInfoGet,
	"POST /team/block": blockTeamTeamBlockPost,
	"POST /team/unblock": unblockTeamTeamUnblockPost,
	"GET /team/available": listAvailableTeamsTeamAvailableGet,
	"GET /v2/team/list": listTeamV2V2TeamListGet,
	"GET /team/list": listTeamTeamListGet,
	"POST /team/model/add": teamModelAddTeamModelAddPost,
	"POST /team/model/delete": teamModelDeleteTeamModelDeletePost,
	"GET /team/permissions_list": teamMemberPermissionsTeamPermissionsListGet,
	"POST /team/permissions_update": updateTeamMemberPermissionsTeamPermissionsUpdatePost,
	"GET /team/daily/activity": getTeamDailyActivityTeamDailyActivityGet,
	"GET /scim/v2/ServiceProviderConfig": getServiceProviderConfigScimV2ServiceProviderConfigGet,
	"GET /scim/v2/Users": getUsersScimV2UsersGet,
	"POST /scim/v2/Users": createUserScimV2UsersPost,
	"GET /scim/v2/Users/{user_id}": getUserScimV2UsersUserIdGet,
	"PUT /scim/v2/Users/{user_id}": updateUserScimV2UsersUserIdPut,
	"DELETE /scim/v2/Users/{user_id}": deleteUserScimV2UsersUserIdDelete,
	"PATCH /scim/v2/Users/{user_id}": patchUserScimV2UsersUserIdPatch,
	"GET /scim/v2/Groups": getGroupsScimV2GroupsGet,
	"POST /scim/v2/Groups": createGroupScimV2GroupsPost,
	"GET /scim/v2/Groups/{group_id}": getGroupScimV2GroupsGroupIdGet,
	"PUT /scim/v2/Groups/{group_id}": updateGroupScimV2GroupsGroupIdPut,
	"DELETE /scim/v2/Groups/{group_id}": deleteGroupScimV2GroupsGroupIdDelete,
	"PATCH /scim/v2/Groups/{group_id}": patchGroupScimV2GroupsGroupIdPatch,
	"POST /organization/new": newOrganizationOrganizationNewPost,
	"PATCH /organization/update": updateOrganizationOrganizationUpdatePatch,
	"DELETE /organization/delete": deleteOrganizationOrganizationDeleteDelete,
	"GET /organization/list": listOrganizationOrganizationListGet,
	"GET /organization/info": infoOrganizationOrganizationInfoGet,
	"POST /organization/info": deprecatedInfoOrganizationOrganizationInfoPost,
	"POST /organization/member_add": organizationMemberAddOrganizationMemberAddPost,
	"PATCH /organization/member_update": organizationMemberUpdateOrganizationMemberUpdatePatch,
	"DELETE /organization/member_delete": organizationMemberDeleteOrganizationMemberDeleteDelete,
	"POST /customer/block": blockUserCustomerBlockPost,
	"POST /customer/unblock": unblockUserCustomerUnblockPost,
	"POST /customer/new": newEndUserCustomerNewPost,
	"GET /customer/info": endUserInfoCustomerInfoGet,
	"POST /customer/update": updateEndUserCustomerUpdatePost,
	"POST /customer/delete": deleteEndUserCustomerDeletePost,
	"GET /customer/list": listEndUserCustomerListGet,
	"GET /spend/tags": viewSpendTagsSpendTagsGet,
	"GET /global/spend/report": getGlobalSpendReportGlobalSpendReportGet,
	"GET /global/spend/tags": globalViewSpendTagsGlobalSpendTagsGet,
	"POST /spend/calculate": calculateSpendSpendCalculatePost,
	"GET /spend/logs": viewSpendLogsSpendLogsGet,
	"POST /global/spend/reset": globalSpendResetGlobalSpendResetPost,
	"GET /provider/budgets": providerBudgetsProviderBudgetsGet,
	"GET /cloudzero/settings": getCloudzeroSettingsCloudzeroSettingsGet,
	"PUT /cloudzero/settings": updateCloudzeroSettingsCloudzeroSettingsPut,
	"POST /cloudzero/init": initCloudzeroSettingsCloudzeroInitPost,
	"POST /cloudzero/dry-run": cloudzeroDryRunExportCloudzeroDryRunPost,
	"POST /cloudzero/export": cloudzeroExportCloudzeroExportPost,
	"GET /cache/ping": cachePingCachePingGet,
	"POST /cache/delete": cacheDeleteCacheDeletePost,
	"GET /cache/redis/info": cacheRedisInfoCacheRedisInfoGet,
	"POST /cache/flushall": cacheFlushallCacheFlushallPost,
	"GET /guardrails/list": listGuardrailsGuardrailsListGet,
	"GET /v2/guardrails/list": listGuardrailsV2V2GuardrailsListGet,
	"POST /guardrails": createGuardrailGuardrailsPost,
	"PUT /guardrails/{guardrail_id}": updateGuardrailGuardrailsGuardrailIdPut,
	"DELETE /guardrails/{guardrail_id}": deleteGuardrailGuardrailsGuardrailIdDelete,
	"PATCH /guardrails/{guardrail_id}": patchGuardrailGuardrailsGuardrailIdPatch,
	"GET /guardrails/{guardrail_id}": getGuardrailInfoGuardrailsGuardrailIdGet,
	"GET /guardrails/{guardrail_id}/info": getGuardrailInfoGuardrailsGuardrailIdInfoGet,
	"GET /guardrails/ui/add_guardrail_settings":
		getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet,
	"POST /guardrails/validate_blocked_words_file":
		validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost,
	"GET /guardrails/ui/provider_specific_params":
		getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet,
	"POST /apply_guardrail": applyGuardrailApplyGuardrailPost,
	"POST /guardrails/apply_guardrail": applyGuardrailGuardrailsApplyGuardrailPost,
	"GET /search_tools/list": listSearchToolsSearchToolsListGet,
	"POST /search_tools": createSearchToolSearchToolsPost,
	"PUT /search_tools/{search_tool_id}": updateSearchToolSearchToolsSearchToolIdPut,
	"DELETE /search_tools/{search_tool_id}": deleteSearchToolSearchToolsSearchToolIdDelete,
	"GET /search_tools/{search_tool_id}": getSearchToolInfoSearchToolsSearchToolIdGet,
	"POST /search_tools/test_connection": testSearchToolConnectionSearchToolsTestConnectionPost,
	"GET /search_tools/ui/available_providers":
		getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet,
	"GET /prompts/list": listPromptsPromptsListGet,
	"GET /prompts/{prompt_id}/info": getPromptInfoPromptsPromptIdInfoGet,
	"GET /prompts/{prompt_id}": getPromptInfoPromptsPromptIdGet,
	"PUT /prompts/{prompt_id}": updatePromptPromptsPromptIdPut,
	"DELETE /prompts/{prompt_id}": deletePromptPromptsPromptIdDelete,
	"PATCH /prompts/{prompt_id}": patchPromptPromptsPromptIdPatch,
	"POST /prompts": createPromptPromptsPost,
	"POST /utils/dotprompt_json_converter": convertPromptFileToJsonUtilsDotpromptJsonConverterPost,
	"GET /callbacks/list": listCallbacksCallbacksListGet,
	"GET /debug/asyncio-tasks": getActiveTasksStatsDebugAsyncioTasksGet,
	"POST /add/allowed_ip": addAllowedIpAddAllowedIpPost,
	"POST /delete/allowed_ip": deleteAllowedIpDeleteAllowedIpPost,
	"GET /get/internal_user_settings": getInternalUserSettingsGetInternalUserSettingsGet,
	"GET /get/default_team_settings": getDefaultTeamSettingsGetDefaultTeamSettingsGet,
	"PATCH /update/internal_user_settings": updateInternalUserSettingsUpdateInternalUserSettingsPatch,
	"PATCH /update/default_team_settings": updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch,
	"GET /get/sso_settings": getSsoSettingsGetSsoSettingsGet,
	"PATCH /update/sso_settings": updateSsoSettingsUpdateSsoSettingsPatch,
	"GET /get/ui_theme_settings": getUiThemeSettingsGetUiThemeSettingsGet,
	"PATCH /update/ui_theme_settings": updateUiThemeSettingsUpdateUiThemeSettingsPatch,
	"POST /upload/logo": uploadLogoUploadLogoPost,
	"POST /files": createFileFilesPost,
	"GET /files": listFilesFilesGet,
	"POST /v1/files": createFileV1FilesPost,
	"GET /v1/files": listFilesV1FilesGet,
	"POST /{provider}/v1/files": createFileProviderV1FilesPost,
	"GET /{provider}/v1/files": listFilesProviderV1FilesGet,
	"GET /files/{file_id}/content": getFileContentFilesFileIdContentGet,
	"GET /v1/files/{file_id}/content": getFileContentV1FilesFileIdContentGet,
	"GET /{provider}/v1/files/{file_id}/content": getFileContentProviderV1FilesFileIdContentGet,
	"GET /files/{file_id}": getFileFilesFileIdGet,
	"DELETE /files/{file_id}": deleteFileFilesFileIdDelete,
	"GET /v1/files/{file_id}": getFileV1FilesFileIdGet,
	"DELETE /v1/files/{file_id}": deleteFileV1FilesFileIdDelete,
	"GET /{provider}/v1/files/{file_id}": getFileProviderV1FilesFileIdGet,
	"DELETE /{provider}/v1/files/{file_id}": deleteFileProviderV1FilesFileIdDelete,
	"POST /team/{team_id}/callback": addTeamCallbacksTeamTeamIdCallbackPost,
	"GET /team/{team_id}/callback": getTeamCallbacksTeamTeamIdCallbackGet,
	"POST /team/{team_id}/disable_logging": disableTeamLoggingTeamTeamIdDisableLoggingPost,
	"POST /budget/new": newBudgetBudgetNewPost,
	"POST /budget/update": updateBudgetBudgetUpdatePost,
	"POST /budget/info": infoBudgetBudgetInfoPost,
	"GET /budget/settings": budgetSettingsBudgetSettingsGet,
	"GET /budget/list": listBudgetBudgetListGet,
	"POST /budget/delete": deleteBudgetBudgetDeletePost,
	"PATCH /model/{model_id}/update": patchModelModelModelIdUpdatePatch,
	"POST /model/delete": deleteModelModelDeletePost,
	"POST /model/new": addNewModelModelNewPost,
	"POST /model/update": updateModelModelUpdatePost,
	"POST /model_group/make_public": updatePublicModelGroupsModelGroupMakePublicPost,
	"POST /model_hub/update_useful_links": updateUsefulLinksModelHubUpdateUsefulLinksPost,
	"POST /tag/new": newTagTagNewPost,
	"POST /tag/update": updateTagTagUpdatePost,
	"POST /tag/info": infoTagTagInfoPost,
	"GET /tag/list": listTagsTagListGet,
	"POST /tag/delete": deleteTagTagDeletePost,
	"GET /tag/daily/activity": getTagDailyActivityTagDailyActivityGet,
	"GET /config/cost_discount_config": getCostDiscountConfigConfigCostDiscountConfigGet,
	"PATCH /config/cost_discount_config": updateCostDiscountConfigConfigCostDiscountConfigPatch,
	"GET /router/settings": getRouterSettingsRouterSettingsGet,
	"GET /cache/settings": getCacheSettingsCacheSettingsGet,
	"POST /cache/settings": updateCacheSettingsCacheSettingsPost,
	"POST /cache/settings/test": testCacheConnectionCacheSettingsTestPost,
	"GET /tag/distinct": getDistinctUserAgentTagsTagDistinctGet,
	"GET /tag/dau": getDailyActiveUsersTagDauGet,
	"GET /tag/wau": getWeeklyActiveUsersTagWauGet,
	"GET /tag/mau": getMonthlyActiveUsersTagMauGet,
	"GET /tag/summary": getTagSummaryTagSummaryGet,
	"GET /tag/user-agent/per-user-analytics": getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet,
	"POST /vector_store/new": newVectorStoreVectorStoreNewPost,
	"GET /vector_store/list": listVectorStoresVectorStoreListGet,
	"POST /vector_store/delete": deleteVectorStoreVectorStoreDeletePost,
	"POST /vector_store/info": getVectorStoreInfoVectorStoreInfoPost,
	"POST /vector_store/update": updateVectorStoreVectorStoreUpdatePost,
	"GET /email/event_settings": getEmailEventSettingsEmailEventSettingsGet,
	"PATCH /email/event_settings": updateEventSettingsEmailEventSettingsPatch,
	"POST /email/event_settings/reset": resetEventSettingsEmailEventSettingsResetPost,
	"GET /audit": getAuditLogsAuditGet,
	"GET /audit/{id}": getAuditLogByIdAuditIdGet,
	"GET /user/available_users": availableEnterpriseUsersUserAvailableUsersGet,
	"GET /robots.txt": getRobotsRobotsTxtGet,
	"GET /litellm/.well-known/litellm-ui-config": getUiConfigLitellmWellKnownLitellmUiConfigGet,
	"GET /.well-known/litellm-ui-config": getUiConfigWellKnownLitellmUiConfigGet,
	"PATCH /{mcp_server_name}/mcp": dynamicMcpRouteMcpServerNameMcpPatch4,
	"POST /{mcp_server_name}/mcp": dynamicMcpRouteMcpServerNameMcpPatch2,
	"PUT /{mcp_server_name}/mcp": dynamicMcpRouteMcpServerNameMcpPatch3,
	"GET /{mcp_server_name}/mcp": dynamicMcpRouteMcpServerNameMcpPatch,
	"DELETE /{mcp_server_name}/mcp": dynamicMcpRouteMcpServerNameMcpPatch5,
	"GET /mcp-rest/tools/list": listToolRestApiMcpRestToolsListGet,
	"POST /mcp-rest/tools/call": callToolRestApiMcpRestToolsCallPost,
	"POST /mcp-rest/test/connection": testConnectionMcpRestTestConnectionPost,
	"POST /mcp-rest/test/tools/list": testToolsListMcpRestTestToolsListPost,
	"GET /authorize": authorizeAuthorizeGet,
	"GET /{mcp_server_name}/authorize": authorizeMcpServerNameAuthorizeGet,
	"POST /token": tokenEndpointTokenPost,
	"POST /{mcp_server_name}/token": tokenEndpointMcpServerNameTokenPost,
	"GET /callback": callbackCallbackGet,
	"GET /.well-known/oauth-protected-resource":
		oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet,
	"GET /.well-known/oauth-protected-resource/{mcp_server_name}/mcp":
		oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet,
	"GET /.well-known/oauth-authorization-server":
		oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet,
	"GET /.well-known/oauth-authorization-server/{mcp_server_name}":
		oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet,
	"GET /.well-known/openid-configuration": openidConfigurationWellKnownOpenidConfigurationGet,
	"GET /.well-known/oauth-authorization-server/{mcp_server_name}/mcp":
		oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet,
	"POST /register": registerClientRegisterPost,
	"POST /{mcp_server_name}/register": registerClientMcpServerNameRegisterPost,
	"GET /vertex_ai/live": websocketVertexAiLivePassthroughEndpoint,
	"GET /realtime": websocketWebsocketEndpoint,
	"GET /v1/realtime": websocketWebsocketEndpoint2,
};

export const operationsByTag = {
	modelManagement: {
		modelListModelsGet,
		modelListV1ModelsGet,
		modelInfoModelsModelIdGet,
		modelInfoV1ModelsModelIdGet,
		modelInfoV1V1ModelInfoGet,
		modelInfoV1ModelInfoGet,
		modelGroupInfoModelGroupInfoGet,
		publicModelHubPublicModelHubGet,
		publicModelHubInfoPublicModelHubInfoGet,
		patchModelModelModelIdUpdatePatch,
		deleteModelModelDeletePost,
		addNewModelModelNewPost,
		updateModelModelUpdatePost,
		updatePublicModelGroupsModelGroupMakePublicPost,
		updateUsefulLinksModelHubUpdateUsefulLinksPost,
	},
	chatCompletions: {
		chatCompletionOpenaiDeploymentsModelChatCompletionsPost,
		chatCompletionEnginesModelChatCompletionsPost,
		chatCompletionChatCompletionsPost,
		chatCompletionV1ChatCompletionsPost,
	},
	completions: {
		completionOpenaiDeploymentsModelCompletionsPost,
		completionEnginesModelCompletionsPost,
		completionCompletionsPost,
		completionV1CompletionsPost,
	},
	embeddings: {
		embeddingsOpenaiDeploymentsModelEmbeddingsPost,
		embeddingsEnginesModelEmbeddingsPost,
		embeddingsEmbeddingsPost,
		embeddingsV1EmbeddingsPost,
	},
	moderations: {
		moderationsModerationsPost,
		moderationsV1ModerationsPost,
	},
	audio: {
		audioSpeechAudioSpeechPost,
		audioSpeechV1AudioSpeechPost,
		audioTranscriptionsAudioTranscriptionsPost,
		audioTranscriptionsV1AudioTranscriptionsPost,
	},
	assistants: {
		getAssistantsAssistantsGet,
		createAssistantAssistantsPost,
		getAssistantsV1AssistantsGet,
		createAssistantV1AssistantsPost,
		deleteAssistantAssistantsAssistantIdDelete,
		deleteAssistantV1AssistantsAssistantIdDelete,
		createThreadsThreadsPost,
		createThreadsV1ThreadsPost,
		getThreadThreadsThreadIdGet,
		getThreadV1ThreadsThreadIdGet,
		addMessagesThreadsThreadIdMessagesPost,
		getMessagesThreadsThreadIdMessagesGet,
		addMessagesV1ThreadsThreadIdMessagesPost,
		getMessagesV1ThreadsThreadIdMessagesGet,
		runThreadThreadsThreadIdRunsPost,
		runThreadV1ThreadsThreadIdRunsPost,
	},
	llmUtils: {
		tokenCounterUtilsTokenCounterPost,
		supportedOpenaiParamsUtilsSupportedOpenaiParamsGet,
		transformRequestUtilsTransformRequestPost,
	},
	responses: {
		responsesApiOpenaiV1ResponsesPost,
		responsesApiResponsesPost,
		responsesApiV1ResponsesPost,
		getResponseOpenaiV1ResponsesResponseIdGet,
		deleteResponseOpenaiV1ResponsesResponseIdDelete,
		getResponseResponsesResponseIdGet,
		deleteResponseResponsesResponseIdDelete,
		getResponseV1ResponsesResponseIdGet,
		deleteResponseV1ResponsesResponseIdDelete,
		getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet,
		getResponseInputItemsResponsesResponseIdInputItemsGet,
		getResponseInputItemsV1ResponsesResponseIdInputItemsGet,
		cancelResponseOpenaiV1ResponsesResponseIdCancelPost,
		cancelResponseResponsesResponseIdCancelPost,
		cancelResponseV1ResponsesResponseIdCancelPost,
	},
	batch: {
		createBatchBatchesPost,
		listBatchesBatchesGet,
		createBatchV1BatchesPost,
		listBatchesV1BatchesGet,
		createBatchProviderV1BatchesPost,
		listBatchesProviderV1BatchesGet,
		retrieveBatchBatchesBatchIdGet,
		retrieveBatchV1BatchesBatchIdGet,
		retrieveBatchProviderV1BatchesBatchIdGet,
		cancelBatchBatchesBatchIdCancelPost,
		cancelBatchV1BatchesBatchIdCancelPost,
		cancelBatchProviderV1BatchesBatchIdCancelPost,
	},
	public: {
		publicModelHubPublicModelHubGet,
		publicModelHubInfoPublicModelHubInfoGet,
	},
	rerank: {
		rerankRerankPost,
		rerankV1RerankPost,
		rerankV2RerankPost,
	},
	ocr: {
		ocrOcrPost,
		ocrV1OcrPost,
	},
	videos: {
		videoListVideosGet,
		videoGenerationVideosPost,
		videoListV1VideosGet,
		videoGenerationV1VideosPost,
		videoStatusVideosVideoIdGet,
		videoStatusV1VideosVideoIdGet,
		videoContentVideosVideoIdContentGet,
		videoContentV1VideosVideoIdContentGet,
		videoRemixVideosVideoIdRemixPost,
		videoRemixV1VideosVideoIdRemixPost,
	},
	containers: {
		listContainersContainersGet,
		createContainerContainersPost,
		listContainersV1ContainersGet,
		createContainerV1ContainersPost,
		retrieveContainerContainersContainerIdGet,
		deleteContainerContainersContainerIdDelete,
		retrieveContainerV1ContainersContainerIdGet,
		deleteContainerV1ContainersContainerIdDelete,
	},
	search: {
		searchSearchPost,
		searchV1SearchPost,
		searchSearchSearchToolNamePost,
		searchV1SearchSearchToolNamePost,
	},
	images: {
		imageGenerationOpenaiDeploymentsModelImagesGenerationsPost,
		imageGenerationImagesGenerationsPost,
		imageGenerationV1ImagesGenerationsPost,
		imageEditApiOpenaiDeploymentsModelImagesEditsPost,
		imageEditApiImagesEditsPost,
		imageEditApiV1ImagesEditsPost,
	},
	fineTuning: {
		createFineTuningJobFineTuningJobsPost,
		listFineTuningJobsFineTuningJobsGet,
		createFineTuningJobV1FineTuningJobsPost,
		listFineTuningJobsV1FineTuningJobsGet,
		retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet,
		retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet,
		cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost,
		cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost,
	},
	credentialManagement: {
		getCredentialsCredentialsGet,
		createCredentialCredentialsPost,
		getCredentialCredentialsByModelModelIdGet,
		getCredentialCredentialsByNameCredentialNameGet,
		deleteCredentialCredentialsCredentialNameDelete,
		updateCredentialCredentialsCredentialNamePatch,
	},
	mcp: {
		getMcpToolsV1McpToolsGet,
		getMcpAccessGroupsV1McpAccessGroupsGet,
		healthCheckMcpServerV1McpServerServerIdHealthGet,
		healthCheckAllMcpServersV1McpServerHealthGet,
		fetchAllMcpServersV1McpServerGet,
		addMcpServerV1McpServerPost,
		editMcpServerV1McpServerPut,
		fetchMcpServerV1McpServerServerIdGet,
		removeMcpServerV1McpServerServerIdDelete,
		listToolRestApiMcpRestToolsListGet,
		callToolRestApiMcpRestToolsCallPost,
		testConnectionMcpRestTestConnectionPost,
		testToolsListMcpRestTestToolsListPost,
		authorizeAuthorizeGet,
		authorizeMcpServerNameAuthorizeGet,
		tokenEndpointTokenPost,
		tokenEndpointMcpServerNameTokenPost,
		callbackCallbackGet,
		oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet,
		oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet,
		oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet,
		oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet,
		openidConfigurationWellKnownOpenidConfigurationGet,
		oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet,
		registerClientRegisterPost,
		registerClientMcpServerNameRegisterPost,
	},
	betaAnthropicV1Messages: {
		anthropicResponseV1MessagesPost,
	},
	betaAnthropicMessagesTokenCounting: {
		countTokensV1MessagesCountTokensPost,
	},
	googleGenaiEndpoints: {
		googleGenerateContentModelsModelNameGenerateContentPost,
		googleGenerateContentV1betaModelsModelNameGenerateContentPost,
		googleStreamGenerateContentModelsModelNameStreamGenerateContentPost,
		googleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPost,
		googleCountTokensModelsModelNameCountTokensPost,
		googleCountTokensV1betaModelsModelNameCountTokensPost,
	},
	health: {
		testEndpointTestGet,
		healthServicesEndpointHealthServicesGet,
		healthEndpointHealthGet,
		healthCheckHistoryEndpointHealthHistoryGet,
		latestHealthChecksEndpointHealthLatestGet,
		sharedHealthCheckStatusEndpointHealthSharedStatusGet,
		activeCallbacksActiveCallbacksGet,
		activeCallbacksSettingsGet,
		healthReadinessHealthReadinessGet,
		health_readiness_options_health_readiness_options,
		healthLivelinessHealthLivenessGet,
		health_liveliness_options_health_liveness_options,
		healthLivelinessHealthLivelinessGet,
		health_liveliness_options_health_liveliness_options,
		testModelConnectionHealthTestConnectionPost,
	},
	keyManagement: {
		generateKeyFnKeyGeneratePost,
		generateServiceAccountKeyFnKeyServiceAccountGeneratePost,
		updateKeyFnKeyUpdatePost,
		deleteKeyFnKeyDeletePost,
		infoKeyFnKeyInfoGet,
		regenerateKeyFnKeyRegeneratePost,
		regenerateKeyFnKeyKeyRegeneratePost,
		listKeysKeyListGet,
		keyAliasesKeyAliasesGet,
		blockKeyKeyBlockPost,
		unblockKeyKeyUnblockPost,
		keyHealthKeyHealthPost,
	},
	internalUserManagement: {
		newUserUserNewPost,
		userInfoUserInfoGet,
		userUpdateUserUpdatePost,
		bulkUserUpdateUserBulkUpdatePost,
		getUsersUserListGet,
		deleteUserUserDeletePost,
		getUserDailyActivityUserDailyActivityGet,
		getUserDailyActivityAggregatedUserDailyActivityAggregatedGet,
		availableEnterpriseUsersUserAvailableUsersGet,
	},
	budgetSpendTracking: {
		getUserDailyActivityUserDailyActivityGet,
		getUserDailyActivityAggregatedUserDailyActivityAggregatedGet,
		viewSpendTagsSpendTagsGet,
		getGlobalSpendReportGlobalSpendReportGet,
		globalViewSpendTagsGlobalSpendTagsGet,
		calculateSpendSpendCalculatePost,
		viewSpendLogsSpendLogsGet,
		globalSpendResetGlobalSpendResetPost,
		addAllowedIpAddAllowedIpPost,
		deleteAllowedIpDeleteAllowedIpPost,
	},
	teamManagement: {
		newTeamTeamNewPost,
		updateTeamTeamUpdatePost,
		teamMemberAddTeamMemberAddPost,
		teamMemberDeleteTeamMemberDeletePost,
		teamMemberUpdateTeamMemberUpdatePost,
		bulkTeamMemberAddTeamBulkMemberAddPost,
		deleteTeamTeamDeletePost,
		teamInfoTeamInfoGet,
		blockTeamTeamBlockPost,
		unblockTeamTeamUnblockPost,
		listTeamV2V2TeamListGet,
		listTeamTeamListGet,
		teamModelAddTeamModelAddPost,
		teamModelDeleteTeamModelDeletePost,
		teamMemberPermissionsTeamPermissionsListGet,
		updateTeamMemberPermissionsTeamPermissionsUpdatePost,
		getTeamDailyActivityTeamDailyActivityGet,
		addTeamCallbacksTeamTeamIdCallbackPost,
		getTeamCallbacksTeamTeamIdCallbackGet,
		disableTeamLoggingTeamTeamIdDisableLoggingPost,
	},
	"ScimV2EnterpriseOnly": {
		getServiceProviderConfigScimV2ServiceProviderConfigGet,
		getUsersScimV2UsersGet,
		createUserScimV2UsersPost,
		getUserScimV2UsersUserIdGet,
		updateUserScimV2UsersUserIdPut,
		deleteUserScimV2UsersUserIdDelete,
		patchUserScimV2UsersUserIdPatch,
		getGroupsScimV2GroupsGet,
		createGroupScimV2GroupsPost,
		getGroupScimV2GroupsGroupIdGet,
		updateGroupScimV2GroupsGroupIdPut,
		deleteGroupScimV2GroupsGroupIdDelete,
		patchGroupScimV2GroupsGroupIdPatch,
	},
	organizationManagement: {
		newOrganizationOrganizationNewPost,
		updateOrganizationOrganizationUpdatePatch,
		deleteOrganizationOrganizationDeleteDelete,
		listOrganizationOrganizationListGet,
		infoOrganizationOrganizationInfoGet,
		deprecatedInfoOrganizationOrganizationInfoPost,
		organizationMemberAddOrganizationMemberAddPost,
		organizationMemberUpdateOrganizationMemberUpdatePatch,
		organizationMemberDeleteOrganizationMemberDeleteDelete,
	},
	customerManagement: {
		blockUserCustomerBlockPost,
		unblockUserCustomerUnblockPost,
		newEndUserCustomerNewPost,
		endUserInfoCustomerInfoGet,
		updateEndUserCustomerUpdatePost,
		deleteEndUserCustomerDeletePost,
		listEndUserCustomerListGet,
	},
	cloudzero: {
		getCloudzeroSettingsCloudzeroSettingsGet,
		updateCloudzeroSettingsCloudzeroSettingsPut,
		initCloudzeroSettingsCloudzeroInitPost,
		cloudzeroDryRunExportCloudzeroDryRunPost,
		cloudzeroExportCloudzeroExportPost,
	},
	caching: {
		cachePingCachePingGet,
		cacheDeleteCacheDeletePost,
		cacheRedisInfoCacheRedisInfoGet,
		cacheFlushallCacheFlushallPost,
	},
	guardrails: {
		applyGuardrailGuardrailsApplyGuardrailPost,
	},
	searchTools: {
		listSearchToolsSearchToolsListGet,
		createSearchToolSearchToolsPost,
		updateSearchToolSearchToolsSearchToolIdPut,
		deleteSearchToolSearchToolsSearchToolIdDelete,
		getSearchToolInfoSearchToolsSearchToolIdGet,
		testSearchToolConnectionSearchToolsTestConnectionPost,
		getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet,
	},
	promptManagement: {
		listPromptsPromptsListGet,
		getPromptInfoPromptsPromptIdInfoGet,
		getPromptInfoPromptsPromptIdGet,
		updatePromptPromptsPromptIdPut,
		deletePromptPromptsPromptIdDelete,
		patchPromptPromptsPromptIdPatch,
		createPromptPromptsPost,
	},
	prompts: {
		convertPromptFileToJsonUtilsDotpromptJsonConverterPost,
	},
	utils: {
		convertPromptFileToJsonUtilsDotpromptJsonConverterPost,
	},
	loggingCallbacks: {
		listCallbacksCallbacksListGet,
	},
	ssoSettings: {
		getInternalUserSettingsGetInternalUserSettingsGet,
		getDefaultTeamSettingsGetDefaultTeamSettingsGet,
		updateInternalUserSettingsUpdateInternalUserSettingsPatch,
		updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch,
		getSsoSettingsGetSsoSettingsGet,
		updateSsoSettingsUpdateSsoSettingsPatch,
	},
	uiThemeSettings: {
		getUiThemeSettingsGetUiThemeSettingsGet,
		updateUiThemeSettingsUpdateUiThemeSettingsPatch,
		uploadLogoUploadLogoPost,
	},
	files: {
		createFileFilesPost,
		listFilesFilesGet,
		createFileV1FilesPost,
		listFilesV1FilesGet,
		createFileProviderV1FilesPost,
		listFilesProviderV1FilesGet,
		getFileContentFilesFileIdContentGet,
		getFileContentV1FilesFileIdContentGet,
		getFileContentProviderV1FilesFileIdContentGet,
		getFileFilesFileIdGet,
		deleteFileFilesFileIdDelete,
		getFileV1FilesFileIdGet,
		deleteFileV1FilesFileIdDelete,
		getFileProviderV1FilesFileIdGet,
		deleteFileProviderV1FilesFileIdDelete,
	},
	budgetManagement: {
		newBudgetBudgetNewPost,
		updateBudgetBudgetUpdatePost,
		infoBudgetBudgetInfoPost,
		budgetSettingsBudgetSettingsGet,
		listBudgetBudgetListGet,
		deleteBudgetBudgetDeletePost,
	},
	tagManagement: {
		newTagTagNewPost,
		updateTagTagUpdatePost,
		infoTagTagInfoPost,
		listTagsTagListGet,
		deleteTagTagDeletePost,
		getTagDailyActivityTagDailyActivityGet,
		getDistinctUserAgentTagsTagDistinctGet,
		getDailyActiveUsersTagDauGet,
		getWeeklyActiveUsersTagWauGet,
		getMonthlyActiveUsersTagMauGet,
		getTagSummaryTagSummaryGet,
		getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet,
	},
	costTracking: {
		getCostDiscountConfigConfigCostDiscountConfigGet,
		updateCostDiscountConfigConfigCostDiscountConfigPatch,
	},
	routerSettings: {
		getRouterSettingsRouterSettingsGet,
	},
	cacheSettings: {
		getCacheSettingsCacheSettingsGet,
		updateCacheSettingsCacheSettingsPost,
		testCacheConnectionCacheSettingsTestPost,
	},
	userAgentAnalytics: {
		getDistinctUserAgentTagsTagDistinctGet,
		getDailyActiveUsersTagDauGet,
		getWeeklyActiveUsersTagWauGet,
		getMonthlyActiveUsersTagMauGet,
		getTagSummaryTagSummaryGet,
		getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet,
	},
	vectorStoreManagement: {
		newVectorStoreVectorStoreNewPost,
		listVectorStoresVectorStoreListGet,
		deleteVectorStoreVectorStoreDeletePost,
		getVectorStoreInfoVectorStoreInfoPost,
		updateVectorStoreVectorStoreUpdatePost,
	},
	emailManagement: {
		getEmailEventSettingsEmailEventSettingsGet,
		updateEventSettingsEmailEventSettingsPatch,
		resetEventSettingsEmailEventSettingsResetPost,
	},
	auditLogging: {
		getAuditLogsAuditGet,
		getAuditLogByIdAuditIdGet,
	},
	websocket: {
		websocketVertexAiLivePassthroughEndpoint,
		websocketWebsocketEndpoint,
		websocketWebsocketEndpoint2,
	},
};

export const tagDictionary = {
	modelManagement: {
		GET: [
			"modelListModelsGet",
			"modelListV1ModelsGet",
			"modelInfoModelsModelIdGet",
			"modelInfoV1ModelsModelIdGet",
			"modelInfoV1V1ModelInfoGet",
			"modelInfoV1ModelInfoGet",
			"modelGroupInfoModelGroupInfoGet",
			"publicModelHubPublicModelHubGet",
			"publicModelHubInfoPublicModelHubInfoGet",
		],
		PATCH: ["patchModelModelModelIdUpdatePatch"],
		POST: [
			"deleteModelModelDeletePost",
			"addNewModelModelNewPost",
			"updateModelModelUpdatePost",
			"updatePublicModelGroupsModelGroupMakePublicPost",
			"updateUsefulLinksModelHubUpdateUsefulLinksPost",
		],
	},
	chatCompletions: {
		POST: [
			"chatCompletionOpenaiDeploymentsModelChatCompletionsPost",
			"chatCompletionEnginesModelChatCompletionsPost",
			"chatCompletionChatCompletionsPost",
			"chatCompletionV1ChatCompletionsPost",
		],
	},
	completions: {
		POST: [
			"completionOpenaiDeploymentsModelCompletionsPost",
			"completionEnginesModelCompletionsPost",
			"completionCompletionsPost",
			"completionV1CompletionsPost",
		],
	},
	embeddings: {
		POST: [
			"embeddingsOpenaiDeploymentsModelEmbeddingsPost",
			"embeddingsEnginesModelEmbeddingsPost",
			"embeddingsEmbeddingsPost",
			"embeddingsV1EmbeddingsPost",
		],
	},
	moderations: {
		POST: ["moderationsModerationsPost", "moderationsV1ModerationsPost"],
	},
	audio: {
		POST: [
			"audioSpeechAudioSpeechPost",
			"audioSpeechV1AudioSpeechPost",
			"audioTranscriptionsAudioTranscriptionsPost",
			"audioTranscriptionsV1AudioTranscriptionsPost",
		],
	},
	assistants: {
		GET: [
			"getAssistantsAssistantsGet",
			"getAssistantsV1AssistantsGet",
			"getThreadThreadsThreadIdGet",
			"getThreadV1ThreadsThreadIdGet",
			"getMessagesThreadsThreadIdMessagesGet",
			"getMessagesV1ThreadsThreadIdMessagesGet",
		],
		POST: [
			"createAssistantAssistantsPost",
			"createAssistantV1AssistantsPost",
			"createThreadsThreadsPost",
			"createThreadsV1ThreadsPost",
			"addMessagesThreadsThreadIdMessagesPost",
			"addMessagesV1ThreadsThreadIdMessagesPost",
			"runThreadThreadsThreadIdRunsPost",
			"runThreadV1ThreadsThreadIdRunsPost",
		],
		DELETE: [
			"deleteAssistantAssistantsAssistantIdDelete",
			"deleteAssistantV1AssistantsAssistantIdDelete",
		],
	},
	llmUtils: {
		POST: ["tokenCounterUtilsTokenCounterPost", "transformRequestUtilsTransformRequestPost"],
		GET: ["supportedOpenaiParamsUtilsSupportedOpenaiParamsGet"],
	},
	responses: {
		POST: [
			"responsesApiOpenaiV1ResponsesPost",
			"responsesApiResponsesPost",
			"responsesApiV1ResponsesPost",
			"cancelResponseOpenaiV1ResponsesResponseIdCancelPost",
			"cancelResponseResponsesResponseIdCancelPost",
			"cancelResponseV1ResponsesResponseIdCancelPost",
		],
		GET: [
			"getResponseOpenaiV1ResponsesResponseIdGet",
			"getResponseResponsesResponseIdGet",
			"getResponseV1ResponsesResponseIdGet",
			"getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet",
			"getResponseInputItemsResponsesResponseIdInputItemsGet",
			"getResponseInputItemsV1ResponsesResponseIdInputItemsGet",
		],
		DELETE: [
			"deleteResponseOpenaiV1ResponsesResponseIdDelete",
			"deleteResponseResponsesResponseIdDelete",
			"deleteResponseV1ResponsesResponseIdDelete",
		],
	},
	batch: {
		POST: [
			"createBatchBatchesPost",
			"createBatchV1BatchesPost",
			"createBatchProviderV1BatchesPost",
			"cancelBatchBatchesBatchIdCancelPost",
			"cancelBatchV1BatchesBatchIdCancelPost",
			"cancelBatchProviderV1BatchesBatchIdCancelPost",
		],
		GET: [
			"listBatchesBatchesGet",
			"listBatchesV1BatchesGet",
			"listBatchesProviderV1BatchesGet",
			"retrieveBatchBatchesBatchIdGet",
			"retrieveBatchV1BatchesBatchIdGet",
			"retrieveBatchProviderV1BatchesBatchIdGet",
		],
	},
	public: {
		GET: ["publicModelHubPublicModelHubGet", "publicModelHubInfoPublicModelHubInfoGet"],
	},
	rerank: {
		POST: ["rerankRerankPost", "rerankV1RerankPost", "rerankV2RerankPost"],
	},
	ocr: {
		POST: ["ocrOcrPost", "ocrV1OcrPost"],
	},
	videos: {
		GET: [
			"videoListVideosGet",
			"videoListV1VideosGet",
			"videoStatusVideosVideoIdGet",
			"videoStatusV1VideosVideoIdGet",
			"videoContentVideosVideoIdContentGet",
			"videoContentV1VideosVideoIdContentGet",
		],
		POST: [
			"videoGenerationVideosPost",
			"videoGenerationV1VideosPost",
			"videoRemixVideosVideoIdRemixPost",
			"videoRemixV1VideosVideoIdRemixPost",
		],
	},
	containers: {
		GET: [
			"listContainersContainersGet",
			"listContainersV1ContainersGet",
			"retrieveContainerContainersContainerIdGet",
			"retrieveContainerV1ContainersContainerIdGet",
		],
		POST: ["createContainerContainersPost", "createContainerV1ContainersPost"],
		DELETE: [
			"deleteContainerContainersContainerIdDelete",
			"deleteContainerV1ContainersContainerIdDelete",
		],
	},
	search: {
		POST: [
			"searchSearchPost",
			"searchV1SearchPost",
			"searchSearchSearchToolNamePost",
			"searchV1SearchSearchToolNamePost",
		],
	},
	images: {
		POST: [
			"imageGenerationOpenaiDeploymentsModelImagesGenerationsPost",
			"imageGenerationImagesGenerationsPost",
			"imageGenerationV1ImagesGenerationsPost",
			"imageEditApiOpenaiDeploymentsModelImagesEditsPost",
			"imageEditApiImagesEditsPost",
			"imageEditApiV1ImagesEditsPost",
		],
	},
	fineTuning: {
		POST: [
			"createFineTuningJobFineTuningJobsPost",
			"createFineTuningJobV1FineTuningJobsPost",
			"cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost",
			"cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost",
		],
		GET: [
			"listFineTuningJobsFineTuningJobsGet",
			"listFineTuningJobsV1FineTuningJobsGet",
			"retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet",
			"retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet",
		],
	},
	credentialManagement: {
		GET: [
			"getCredentialsCredentialsGet",
			"getCredentialCredentialsByModelModelIdGet",
			"getCredentialCredentialsByNameCredentialNameGet",
		],
		POST: ["createCredentialCredentialsPost"],
		DELETE: ["deleteCredentialCredentialsCredentialNameDelete"],
		PATCH: ["updateCredentialCredentialsCredentialNamePatch"],
	},
	mcp: {
		GET: [
			"getMcpToolsV1McpToolsGet",
			"getMcpAccessGroupsV1McpAccessGroupsGet",
			"healthCheckMcpServerV1McpServerServerIdHealthGet",
			"healthCheckAllMcpServersV1McpServerHealthGet",
			"fetchAllMcpServersV1McpServerGet",
			"fetchMcpServerV1McpServerServerIdGet",
			"listToolRestApiMcpRestToolsListGet",
			"authorizeAuthorizeGet",
			"authorizeMcpServerNameAuthorizeGet",
			"callbackCallbackGet",
			"oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet",
			"oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet",
			"oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet",
			"oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet",
			"openidConfigurationWellKnownOpenidConfigurationGet",
			"oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet",
		],
		POST: [
			"addMcpServerV1McpServerPost",
			"callToolRestApiMcpRestToolsCallPost",
			"testConnectionMcpRestTestConnectionPost",
			"testToolsListMcpRestTestToolsListPost",
			"tokenEndpointTokenPost",
			"tokenEndpointMcpServerNameTokenPost",
			"registerClientRegisterPost",
			"registerClientMcpServerNameRegisterPost",
		],
		PUT: ["editMcpServerV1McpServerPut"],
		DELETE: ["removeMcpServerV1McpServerServerIdDelete"],
	},
	betaAnthropicV1Messages: {
		POST: ["anthropicResponseV1MessagesPost"],
	},
	betaAnthropicMessagesTokenCounting: {
		POST: ["countTokensV1MessagesCountTokensPost"],
	},
	googleGenaiEndpoints: {
		POST: [
			"googleGenerateContentModelsModelNameGenerateContentPost",
			"googleGenerateContentV1betaModelsModelNameGenerateContentPost",
			"googleStreamGenerateContentModelsModelNameStreamGenerateContentPost",
			"googleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPost",
			"googleCountTokensModelsModelNameCountTokensPost",
			"googleCountTokensV1betaModelsModelNameCountTokensPost",
		],
	},
	health: {
		GET: [
			"testEndpointTestGet",
			"healthServicesEndpointHealthServicesGet",
			"healthEndpointHealthGet",
			"healthCheckHistoryEndpointHealthHistoryGet",
			"latestHealthChecksEndpointHealthLatestGet",
			"sharedHealthCheckStatusEndpointHealthSharedStatusGet",
			"activeCallbacksActiveCallbacksGet",
			"activeCallbacksSettingsGet",
			"healthReadinessHealthReadinessGet",
			"healthLivelinessHealthLivenessGet",
			"healthLivelinessHealthLivelinessGet",
		],
		POST: ["testModelConnectionHealthTestConnectionPost"],
	},
	keyManagement: {
		POST: [
			"generateKeyFnKeyGeneratePost",
			"generateServiceAccountKeyFnKeyServiceAccountGeneratePost",
			"updateKeyFnKeyUpdatePost",
			"deleteKeyFnKeyDeletePost",
			"regenerateKeyFnKeyRegeneratePost",
			"regenerateKeyFnKeyKeyRegeneratePost",
			"blockKeyKeyBlockPost",
			"unblockKeyKeyUnblockPost",
			"keyHealthKeyHealthPost",
		],
		GET: ["infoKeyFnKeyInfoGet", "listKeysKeyListGet", "keyAliasesKeyAliasesGet"],
	},
	internalUserManagement: {
		POST: [
			"newUserUserNewPost",
			"userUpdateUserUpdatePost",
			"bulkUserUpdateUserBulkUpdatePost",
			"deleteUserUserDeletePost",
		],
		GET: [
			"userInfoUserInfoGet",
			"getUsersUserListGet",
			"getUserDailyActivityUserDailyActivityGet",
			"getUserDailyActivityAggregatedUserDailyActivityAggregatedGet",
			"availableEnterpriseUsersUserAvailableUsersGet",
		],
	},
	budgetSpendTracking: {
		GET: [
			"getUserDailyActivityUserDailyActivityGet",
			"getUserDailyActivityAggregatedUserDailyActivityAggregatedGet",
			"viewSpendTagsSpendTagsGet",
			"getGlobalSpendReportGlobalSpendReportGet",
			"globalViewSpendTagsGlobalSpendTagsGet",
			"viewSpendLogsSpendLogsGet",
		],
		POST: [
			"calculateSpendSpendCalculatePost",
			"globalSpendResetGlobalSpendResetPost",
			"addAllowedIpAddAllowedIpPost",
			"deleteAllowedIpDeleteAllowedIpPost",
		],
	},
	teamManagement: {
		POST: [
			"newTeamTeamNewPost",
			"updateTeamTeamUpdatePost",
			"teamMemberAddTeamMemberAddPost",
			"teamMemberDeleteTeamMemberDeletePost",
			"teamMemberUpdateTeamMemberUpdatePost",
			"bulkTeamMemberAddTeamBulkMemberAddPost",
			"deleteTeamTeamDeletePost",
			"blockTeamTeamBlockPost",
			"unblockTeamTeamUnblockPost",
			"teamModelAddTeamModelAddPost",
			"teamModelDeleteTeamModelDeletePost",
			"updateTeamMemberPermissionsTeamPermissionsUpdatePost",
			"addTeamCallbacksTeamTeamIdCallbackPost",
			"disableTeamLoggingTeamTeamIdDisableLoggingPost",
		],
		GET: [
			"teamInfoTeamInfoGet",
			"listTeamV2V2TeamListGet",
			"listTeamTeamListGet",
			"teamMemberPermissionsTeamPermissionsListGet",
			"getTeamDailyActivityTeamDailyActivityGet",
			"getTeamCallbacksTeamTeamIdCallbackGet",
		],
	},
	"ScimV2EnterpriseOnly": {
		GET: [
			"getServiceProviderConfigScimV2ServiceProviderConfigGet",
			"getUsersScimV2UsersGet",
			"getUserScimV2UsersUserIdGet",
			"getGroupsScimV2GroupsGet",
			"getGroupScimV2GroupsGroupIdGet",
		],
		POST: ["createUserScimV2UsersPost", "createGroupScimV2GroupsPost"],
		PUT: ["updateUserScimV2UsersUserIdPut", "updateGroupScimV2GroupsGroupIdPut"],
		DELETE: ["deleteUserScimV2UsersUserIdDelete", "deleteGroupScimV2GroupsGroupIdDelete"],
		PATCH: ["patchUserScimV2UsersUserIdPatch", "patchGroupScimV2GroupsGroupIdPatch"],
	},
	organizationManagement: {
		POST: [
			"newOrganizationOrganizationNewPost",
			"deprecatedInfoOrganizationOrganizationInfoPost",
			"organizationMemberAddOrganizationMemberAddPost",
		],
		PATCH: [
			"updateOrganizationOrganizationUpdatePatch",
			"organizationMemberUpdateOrganizationMemberUpdatePatch",
		],
		DELETE: [
			"deleteOrganizationOrganizationDeleteDelete",
			"organizationMemberDeleteOrganizationMemberDeleteDelete",
		],
		GET: ["listOrganizationOrganizationListGet", "infoOrganizationOrganizationInfoGet"],
	},
	customerManagement: {
		POST: [
			"blockUserCustomerBlockPost",
			"unblockUserCustomerUnblockPost",
			"newEndUserCustomerNewPost",
			"updateEndUserCustomerUpdatePost",
			"deleteEndUserCustomerDeletePost",
		],
		GET: ["endUserInfoCustomerInfoGet", "listEndUserCustomerListGet"],
	},
	cloudzero: {
		GET: ["getCloudzeroSettingsCloudzeroSettingsGet"],
		PUT: ["updateCloudzeroSettingsCloudzeroSettingsPut"],
		POST: [
			"initCloudzeroSettingsCloudzeroInitPost",
			"cloudzeroDryRunExportCloudzeroDryRunPost",
			"cloudzeroExportCloudzeroExportPost",
		],
	},
	caching: {
		GET: ["cachePingCachePingGet", "cacheRedisInfoCacheRedisInfoGet"],
		POST: ["cacheDeleteCacheDeletePost", "cacheFlushallCacheFlushallPost"],
	},
	guardrails: {
		POST: ["applyGuardrailGuardrailsApplyGuardrailPost"],
	},
	searchTools: {
		GET: [
			"listSearchToolsSearchToolsListGet",
			"getSearchToolInfoSearchToolsSearchToolIdGet",
			"getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet",
		],
		POST: [
			"createSearchToolSearchToolsPost",
			"testSearchToolConnectionSearchToolsTestConnectionPost",
		],
		PUT: ["updateSearchToolSearchToolsSearchToolIdPut"],
		DELETE: ["deleteSearchToolSearchToolsSearchToolIdDelete"],
	},
	promptManagement: {
		GET: [
			"listPromptsPromptsListGet",
			"getPromptInfoPromptsPromptIdInfoGet",
			"getPromptInfoPromptsPromptIdGet",
		],
		PUT: ["updatePromptPromptsPromptIdPut"],
		DELETE: ["deletePromptPromptsPromptIdDelete"],
		PATCH: ["patchPromptPromptsPromptIdPatch"],
		POST: ["createPromptPromptsPost"],
	},
	prompts: {
		POST: ["convertPromptFileToJsonUtilsDotpromptJsonConverterPost"],
	},
	utils: {
		POST: ["convertPromptFileToJsonUtilsDotpromptJsonConverterPost"],
	},
	loggingCallbacks: {
		GET: ["listCallbacksCallbacksListGet"],
	},
	ssoSettings: {
		GET: [
			"getInternalUserSettingsGetInternalUserSettingsGet",
			"getDefaultTeamSettingsGetDefaultTeamSettingsGet",
			"getSsoSettingsGetSsoSettingsGet",
		],
		PATCH: [
			"updateInternalUserSettingsUpdateInternalUserSettingsPatch",
			"updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch",
			"updateSsoSettingsUpdateSsoSettingsPatch",
		],
	},
	uiThemeSettings: {
		GET: ["getUiThemeSettingsGetUiThemeSettingsGet"],
		PATCH: ["updateUiThemeSettingsUpdateUiThemeSettingsPatch"],
		POST: ["uploadLogoUploadLogoPost"],
	},
	files: {
		POST: ["createFileFilesPost", "createFileV1FilesPost", "createFileProviderV1FilesPost"],
		GET: [
			"listFilesFilesGet",
			"listFilesV1FilesGet",
			"listFilesProviderV1FilesGet",
			"getFileContentFilesFileIdContentGet",
			"getFileContentV1FilesFileIdContentGet",
			"getFileContentProviderV1FilesFileIdContentGet",
			"getFileFilesFileIdGet",
			"getFileV1FilesFileIdGet",
			"getFileProviderV1FilesFileIdGet",
		],
		DELETE: [
			"deleteFileFilesFileIdDelete",
			"deleteFileV1FilesFileIdDelete",
			"deleteFileProviderV1FilesFileIdDelete",
		],
	},
	budgetManagement: {
		POST: [
			"newBudgetBudgetNewPost",
			"updateBudgetBudgetUpdatePost",
			"infoBudgetBudgetInfoPost",
			"deleteBudgetBudgetDeletePost",
		],
		GET: ["budgetSettingsBudgetSettingsGet", "listBudgetBudgetListGet"],
	},
	tagManagement: {
		POST: [
			"newTagTagNewPost",
			"updateTagTagUpdatePost",
			"infoTagTagInfoPost",
			"deleteTagTagDeletePost",
		],
		GET: [
			"listTagsTagListGet",
			"getTagDailyActivityTagDailyActivityGet",
			"getDistinctUserAgentTagsTagDistinctGet",
			"getDailyActiveUsersTagDauGet",
			"getWeeklyActiveUsersTagWauGet",
			"getMonthlyActiveUsersTagMauGet",
			"getTagSummaryTagSummaryGet",
			"getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet",
		],
	},
	costTracking: {
		GET: ["getCostDiscountConfigConfigCostDiscountConfigGet"],
		PATCH: ["updateCostDiscountConfigConfigCostDiscountConfigPatch"],
	},
	routerSettings: {
		GET: ["getRouterSettingsRouterSettingsGet"],
	},
	cacheSettings: {
		GET: ["getCacheSettingsCacheSettingsGet"],
		POST: ["updateCacheSettingsCacheSettingsPost", "testCacheConnectionCacheSettingsTestPost"],
	},
	userAgentAnalytics: {
		GET: [
			"getDistinctUserAgentTagsTagDistinctGet",
			"getDailyActiveUsersTagDauGet",
			"getWeeklyActiveUsersTagWauGet",
			"getMonthlyActiveUsersTagMauGet",
			"getTagSummaryTagSummaryGet",
			"getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet",
		],
	},
	vectorStoreManagement: {
		POST: [
			"newVectorStoreVectorStoreNewPost",
			"deleteVectorStoreVectorStoreDeletePost",
			"getVectorStoreInfoVectorStoreInfoPost",
			"updateVectorStoreVectorStoreUpdatePost",
		],
		GET: ["listVectorStoresVectorStoreListGet"],
	},
	emailManagement: {
		GET: ["getEmailEventSettingsEmailEventSettingsGet"],
		PATCH: ["updateEventSettingsEmailEventSettingsPatch"],
		POST: ["resetEventSettingsEmailEventSettingsResetPost"],
	},
	auditLogging: {
		GET: ["getAuditLogsAuditGet", "getAuditLogByIdAuditIdGet"],
	},
	websocket: {
		GET: [
			"websocketVertexAiLivePassthroughEndpoint",
			"websocketWebsocketEndpoint",
			"websocketWebsocketEndpoint2",
		],
	},
} as const;
