/**
 * Generated by Kubb (https://kubb.dev/).
 * Do not edit manually.
 */

import type { ErrorWrapper, FetcherConfig } from "../utils/fetcher";
import client from "../utils/fetcher";
import type { CallToolResult } from "../utils/mcp";
import {
	addAllowedIpAddAllowedIpPostMutationRequestSchema,
	addMcpServerV1McpServerPostHeaderParamsSchema,
	addMcpServerV1McpServerPostMutationRequestSchema,
	addMessagesThreadsThreadIdMessagesPostPathParamsSchema,
	addMessagesV1ThreadsThreadIdMessagesPostPathParamsSchema,
	addNewModelModelNewPostMutationRequestSchema,
	addTeamCallbacksTeamTeamIdCallbackPostHeaderParamsSchema,
	addTeamCallbacksTeamTeamIdCallbackPostMutationRequestSchema,
	addTeamCallbacksTeamTeamIdCallbackPostPathParamsSchema,
	applyGuardrailApplyGuardrailPostMutationRequestSchema,
	applyGuardrailGuardrailsApplyGuardrailPostMutationRequestSchema,
	authorizeAuthorizeGetQueryParamsSchema,
	authorizeMcpServerNameAuthorizeGetPathParamsSchema,
	authorizeMcpServerNameAuthorizeGetQueryParamsSchema,
	blockKeyKeyBlockPostHeaderParamsSchema,
	blockKeyKeyBlockPostMutationRequestSchema,
	blockTeamTeamBlockPostMutationRequestSchema,
	blockUserCustomerBlockPostMutationRequestSchema,
	budgetSettingsBudgetSettingsGetQueryParamsSchema,
	bulkTeamMemberAddTeamBulkMemberAddPostMutationRequestSchema,
	bulkUserUpdateUserBulkUpdatePostHeaderParamsSchema,
	bulkUserUpdateUserBulkUpdatePostMutationRequestSchema,
	calculateSpendSpendCalculatePostMutationRequestSchema,
	callbackCallbackGetQueryParamsSchema,
	cancelBatchBatchesBatchIdCancelPostPathParamsSchema,
	cancelBatchBatchesBatchIdCancelPostQueryParamsSchema,
	cancelBatchProviderV1BatchesBatchIdCancelPostPathParamsSchema,
	cancelBatchV1BatchesBatchIdCancelPostPathParamsSchema,
	cancelBatchV1BatchesBatchIdCancelPostQueryParamsSchema,
	cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParamsSchema,
	cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParamsSchema,
	cancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParamsSchema,
	cancelResponseResponsesResponseIdCancelPostPathParamsSchema,
	cancelResponseV1ResponsesResponseIdCancelPostPathParamsSchema,
	chatCompletionChatCompletionsPostMutationRequestSchema,
	chatCompletionEnginesModelChatCompletionsPostMutationRequestSchema,
	chatCompletionEnginesModelChatCompletionsPostPathParamsSchema,
	chatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequestSchema,
	chatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParamsSchema,
	chatCompletionV1ChatCompletionsPostMutationRequestSchema,
	cloudzeroDryRunExportCloudzeroDryRunPostMutationRequestSchema,
	cloudzeroExportCloudzeroExportPostMutationRequestSchema,
	completionCompletionsPostQueryParamsSchema,
	completionEnginesModelCompletionsPostPathParamsSchema,
	completionOpenaiDeploymentsModelCompletionsPostPathParamsSchema,
	completionV1CompletionsPostQueryParamsSchema,
	createBatchBatchesPostQueryParamsSchema,
	createBatchProviderV1BatchesPostPathParamsSchema,
	createBatchV1BatchesPostQueryParamsSchema,
	createCredentialCredentialsPostMutationRequestSchema,
	createFileFilesPostQueryParamsSchema,
	createFileProviderV1FilesPostPathParamsSchema,
	createFileV1FilesPostQueryParamsSchema,
	createFineTuningJobFineTuningJobsPostMutationRequestSchema,
	createFineTuningJobV1FineTuningJobsPostMutationRequestSchema,
	createGroupScimV2GroupsPostMutationRequestSchema,
	createGroupScimV2GroupsPostQueryParamsSchema,
	createGuardrailGuardrailsPostMutationRequestSchema,
	createPassThroughEndpointsConfigPassThroughEndpointPostMutationRequestSchema,
	createPromptPromptsPostMutationRequestSchema,
	createSearchToolSearchToolsPostMutationRequestSchema,
	createUserScimV2UsersPostMutationRequestSchema,
	createUserScimV2UsersPostQueryParamsSchema,
	deleteAllowedIpDeleteAllowedIpPostMutationRequestSchema,
	deleteAssistantAssistantsAssistantIdDeletePathParamsSchema,
	deleteAssistantV1AssistantsAssistantIdDeletePathParamsSchema,
	deleteBudgetBudgetDeletePostMutationRequestSchema,
	deleteContainerContainersContainerIdDeletePathParamsSchema,
	deleteContainerV1ContainersContainerIdDeletePathParamsSchema,
	deleteCredentialCredentialsCredentialNameDeletePathParamsSchema,
	deleteEndUserCustomerDeletePostMutationRequestSchema,
	deleteFileFilesFileIdDeletePathParamsSchema,
	deleteFileFilesFileIdDeleteQueryParamsSchema,
	deleteFileProviderV1FilesFileIdDeletePathParamsSchema,
	deleteFileV1FilesFileIdDeletePathParamsSchema,
	deleteFileV1FilesFileIdDeleteQueryParamsSchema,
	deleteGroupScimV2GroupsGroupIdDeletePathParamsSchema,
	deleteGroupScimV2GroupsGroupIdDeleteQueryParamsSchema,
	deleteGuardrailGuardrailsGuardrailIdDeletePathParamsSchema,
	deleteKeyFnKeyDeletePostHeaderParamsSchema,
	deleteKeyFnKeyDeletePostMutationRequestSchema,
	deleteModelModelDeletePostMutationRequestSchema,
	deleteOrganizationOrganizationDeleteDeleteMutationRequestSchema,
	deletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParamsSchema,
	deletePromptPromptsPromptIdDeletePathParamsSchema,
	deleteResponseOpenaiV1ResponsesResponseIdDeletePathParamsSchema,
	deleteResponseResponsesResponseIdDeletePathParamsSchema,
	deleteResponseV1ResponsesResponseIdDeletePathParamsSchema,
	deleteSearchToolSearchToolsSearchToolIdDeletePathParamsSchema,
	deleteTagTagDeletePostMutationRequestSchema,
	deleteTeamTeamDeletePostHeaderParamsSchema,
	deleteTeamTeamDeletePostMutationRequestSchema,
	deleteUserScimV2UsersUserIdDeletePathParamsSchema,
	deleteUserScimV2UsersUserIdDeleteQueryParamsSchema,
	deleteUserUserDeletePostHeaderParamsSchema,
	deleteUserUserDeletePostMutationRequestSchema,
	deleteVectorStoreVectorStoreDeletePostMutationRequestSchema,
	deprecatedInfoOrganizationOrganizationInfoPostMutationRequestSchema,
	disableTeamLoggingTeamTeamIdDisableLoggingPostPathParamsSchema,
	dynamicMcpRouteMcpServerNameMcpPatch2PathParamsSchema,
	dynamicMcpRouteMcpServerNameMcpPatch3PathParamsSchema,
	dynamicMcpRouteMcpServerNameMcpPatch4PathParamsSchema,
	dynamicMcpRouteMcpServerNameMcpPatch5PathParamsSchema,
	dynamicMcpRouteMcpServerNameMcpPatchPathParamsSchema,
	editMcpServerV1McpServerPutHeaderParamsSchema,
	editMcpServerV1McpServerPutMutationRequestSchema,
	embeddingsEmbeddingsPostMutationRequestSchema,
	embeddingsEnginesModelEmbeddingsPostMutationRequestSchema,
	embeddingsEnginesModelEmbeddingsPostPathParamsSchema,
	embeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequestSchema,
	embeddingsOpenaiDeploymentsModelEmbeddingsPostPathParamsSchema,
	embeddingsV1EmbeddingsPostMutationRequestSchema,
	endUserInfoCustomerInfoGetQueryParamsSchema,
	fetchMcpServerV1McpServerServerIdGetPathParamsSchema,
	generateKeyFnKeyGeneratePostHeaderParamsSchema,
	generateKeyFnKeyGeneratePostMutationRequestSchema,
	generateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParamsSchema,
	generateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequestSchema,
	getAuditLogByIdAuditIdGetPathParamsSchema,
	getAuditLogsAuditGetQueryParamsSchema,
	getCredentialCredentialsByModelModelIdGetPathParamsSchema,
	getCredentialCredentialsByNameCredentialNameGetPathParamsSchema,
	getCredentialCredentialsByNameCredentialNameGetQueryParamsSchema,
	getDailyActiveUsersTagDauGetQueryParamsSchema,
	getFileContentFilesFileIdContentGetPathParamsSchema,
	getFileContentFilesFileIdContentGetQueryParamsSchema,
	getFileContentProviderV1FilesFileIdContentGetPathParamsSchema,
	getFileContentV1FilesFileIdContentGetPathParamsSchema,
	getFileContentV1FilesFileIdContentGetQueryParamsSchema,
	getFileFilesFileIdGetPathParamsSchema,
	getFileFilesFileIdGetQueryParamsSchema,
	getFileProviderV1FilesFileIdGetPathParamsSchema,
	getFileV1FilesFileIdGetPathParamsSchema,
	getFileV1FilesFileIdGetQueryParamsSchema,
	getGlobalSpendReportGlobalSpendReportGetQueryParamsSchema,
	getGroupScimV2GroupsGroupIdGetPathParamsSchema,
	getGroupScimV2GroupsGroupIdGetQueryParamsSchema,
	getGroupsScimV2GroupsGetQueryParamsSchema,
	getGuardrailInfoGuardrailsGuardrailIdGetPathParamsSchema,
	getGuardrailInfoGuardrailsGuardrailIdInfoGetPathParamsSchema,
	getMessagesThreadsThreadIdMessagesGetPathParamsSchema,
	getMessagesV1ThreadsThreadIdMessagesGetPathParamsSchema,
	getMonthlyActiveUsersTagMauGetQueryParamsSchema,
	getPassThroughEndpointsConfigPassThroughEndpointGetQueryParamsSchema,
	getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParamsSchema,
	getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParamsSchema,
	getPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParamsSchema,
	getPromptInfoPromptsPromptIdGetPathParamsSchema,
	getPromptInfoPromptsPromptIdInfoGetPathParamsSchema,
	getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParamsSchema,
	getResponseInputItemsResponsesResponseIdInputItemsGetPathParamsSchema,
	getResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParamsSchema,
	getResponseOpenaiV1ResponsesResponseIdGetPathParamsSchema,
	getResponseResponsesResponseIdGetPathParamsSchema,
	getResponseV1ResponsesResponseIdGetPathParamsSchema,
	getSearchToolInfoSearchToolsSearchToolIdGetPathParamsSchema,
	getServiceProviderConfigScimV2ServiceProviderConfigGetQueryParamsSchema,
	getTagDailyActivityTagDailyActivityGetQueryParamsSchema,
	getTagSummaryTagSummaryGetQueryParamsSchema,
	getTeamCallbacksTeamTeamIdCallbackGetPathParamsSchema,
	getTeamDailyActivityTeamDailyActivityGetQueryParamsSchema,
	getThreadThreadsThreadIdGetPathParamsSchema,
	getThreadV1ThreadsThreadIdGetPathParamsSchema,
	getUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParamsSchema,
	getUserDailyActivityUserDailyActivityGetQueryParamsSchema,
	getUserScimV2UsersUserIdGetPathParamsSchema,
	getUserScimV2UsersUserIdGetQueryParamsSchema,
	getUsersScimV2UsersGetQueryParamsSchema,
	getUsersUserListGetQueryParamsSchema,
	getVectorStoreInfoVectorStoreInfoPostMutationRequestSchema,
	getWeeklyActiveUsersTagWauGetQueryParamsSchema,
	globalViewSpendTagsGlobalSpendTagsGetQueryParamsSchema,
	googleCountTokensModelsModelNameCountTokensPostPathParamsSchema,
	googleCountTokensV1BetaModelsModelNameCountTokensPostPathParamsSchema,
	googleGenerateContentModelsModelNameGenerateContentPostPathParamsSchema,
	googleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParamsSchema,
	googleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParamsSchema,
	googleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParamsSchema,
	healthCheckHistoryEndpointHealthHistoryGetQueryParamsSchema,
	healthCheckMcpServerV1McpServerServerIdHealthGetPathParamsSchema,
	healthEndpointHealthGetQueryParamsSchema,
	healthServicesEndpointHealthServicesGetQueryParamsSchema,
	imageEditApiImagesEditsPostQueryParamsSchema,
	imageEditApiOpenaiDeploymentsModelImagesEditsPostPathParamsSchema,
	imageEditApiV1ImagesEditsPostQueryParamsSchema,
	imageGenerationImagesGenerationsPostQueryParamsSchema,
	imageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParamsSchema,
	imageGenerationV1ImagesGenerationsPostQueryParamsSchema,
	indexCreateV1IndexesPostMutationRequestSchema,
	infoBudgetBudgetInfoPostMutationRequestSchema,
	infoKeyFnKeyInfoGetQueryParamsSchema,
	infoOrganizationOrganizationInfoGetQueryParamsSchema,
	infoTagTagInfoPostMutationRequestSchema,
	initCloudzeroSettingsCloudzeroInitPostMutationRequestSchema,
	listAvailableTeamsTeamAvailableGetQueryParamsSchema,
	listBatchesBatchesGetQueryParamsSchema,
	listBatchesProviderV1BatchesGetPathParamsSchema,
	listBatchesProviderV1BatchesGetQueryParamsSchema,
	listBatchesV1BatchesGetQueryParamsSchema,
	listFilesFilesGetQueryParamsSchema,
	listFilesProviderV1FilesGetPathParamsSchema,
	listFilesProviderV1FilesGetQueryParamsSchema,
	listFilesV1FilesGetQueryParamsSchema,
	listFineTuningJobsFineTuningJobsGetQueryParamsSchema,
	listFineTuningJobsV1FineTuningJobsGetQueryParamsSchema,
	listKeysKeyListGetQueryParamsSchema,
	listTeamTeamListGetQueryParamsSchema,
	listTeamV2V2TeamListGetQueryParamsSchema,
	listToolRestApiMcpRestToolsListGetQueryParamsSchema,
	listVectorStoresVectorStoreListGetQueryParamsSchema,
	modelGroupInfoModelGroupInfoGetQueryParamsSchema,
	modelInfoModelsModelIdGetPathParamsSchema,
	modelInfoV1ModelInfoGetQueryParamsSchema,
	modelInfoV1ModelsModelIdGetPathParamsSchema,
	modelInfoV1V1ModelInfoGetQueryParamsSchema,
	modelListModelsGetQueryParamsSchema,
	modelListV1ModelsGetQueryParamsSchema,
	newBudgetBudgetNewPostMutationRequestSchema,
	newEndUserCustomerNewPostMutationRequestSchema,
	newOrganizationOrganizationNewPostMutationRequestSchema,
	newTagTagNewPostMutationRequestSchema,
	newTeamTeamNewPostHeaderParamsSchema,
	newTeamTeamNewPostMutationRequestSchema,
	newUserUserNewPostMutationRequestSchema,
	newVectorStoreVectorStoreNewPostMutationRequestSchema,
	oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParamsSchema,
	oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParamsSchema,
	oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParamsSchema,
	oauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParamsSchema,
	oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParamsSchema,
	organizationMemberAddOrganizationMemberAddPostMutationRequestSchema,
	organizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequestSchema,
	organizationMemberUpdateOrganizationMemberUpdatePatchMutationRequestSchema,
	patchGroupScimV2GroupsGroupIdPatchMutationRequestSchema,
	patchGroupScimV2GroupsGroupIdPatchPathParamsSchema,
	patchGroupScimV2GroupsGroupIdPatchQueryParamsSchema,
	patchGuardrailGuardrailsGuardrailIdPatchMutationRequestSchema,
	patchGuardrailGuardrailsGuardrailIdPatchPathParamsSchema,
	patchModelModelModelIdUpdatePatchMutationRequestSchema,
	patchModelModelModelIdUpdatePatchPathParamsSchema,
	patchPromptPromptsPromptIdPatchMutationRequestSchema,
	patchPromptPromptsPromptIdPatchPathParamsSchema,
	patchUserScimV2UsersUserIdPatchMutationRequestSchema,
	patchUserScimV2UsersUserIdPatchPathParamsSchema,
	patchUserScimV2UsersUserIdPatchQueryParamsSchema,
	regenerateKeyFnKeyKeyRegeneratePostHeaderParamsSchema,
	regenerateKeyFnKeyKeyRegeneratePostMutationRequestSchema,
	regenerateKeyFnKeyKeyRegeneratePostPathParamsSchema,
	regenerateKeyFnKeyRegeneratePostHeaderParamsSchema,
	regenerateKeyFnKeyRegeneratePostMutationRequestSchema,
	regenerateKeyFnKeyRegeneratePostQueryParamsSchema,
	registerClientMcpServerNameRegisterPostPathParamsSchema,
	registerClientRegisterPostQueryParamsSchema,
	removeMcpServerV1McpServerServerIdDeleteHeaderParamsSchema,
	removeMcpServerV1McpServerServerIdDeletePathParamsSchema,
	retrieveBatchBatchesBatchIdGetPathParamsSchema,
	retrieveBatchBatchesBatchIdGetQueryParamsSchema,
	retrieveBatchProviderV1BatchesBatchIdGetPathParamsSchema,
	retrieveBatchV1BatchesBatchIdGetPathParamsSchema,
	retrieveBatchV1BatchesBatchIdGetQueryParamsSchema,
	retrieveContainerContainersContainerIdGetPathParamsSchema,
	retrieveContainerV1ContainersContainerIdGetPathParamsSchema,
	retrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParamsSchema,
	retrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParamsSchema,
	retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParamsSchema,
	retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParamsSchema,
	runThreadThreadsThreadIdRunsPostPathParamsSchema,
	runThreadV1ThreadsThreadIdRunsPostPathParamsSchema,
	searchSearchPostQueryParamsSchema,
	searchSearchSearchToolNamePostPathParamsSchema,
	searchV1SearchPostQueryParamsSchema,
	searchV1SearchSearchToolNamePostPathParamsSchema,
	supportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParamsSchema,
	teamInfoTeamInfoGetQueryParamsSchema,
	teamMemberAddTeamMemberAddPostMutationRequestSchema,
	teamMemberDeleteTeamMemberDeletePostMutationRequestSchema,
	teamMemberPermissionsTeamPermissionsListGetQueryParamsSchema,
	teamMemberUpdateTeamMemberUpdatePostMutationRequestSchema,
	teamModelAddTeamModelAddPostMutationRequestSchema,
	teamModelDeleteTeamModelDeletePostMutationRequestSchema,
	testCacheConnectionCacheSettingsTestPostMutationRequestSchema,
	testConnectionMcpRestTestConnectionPostMutationRequestSchema,
	testModelConnectionHealthTestConnectionPostMutationRequestSchema,
	testSearchToolConnectionSearchToolsTestConnectionPostMutationRequestSchema,
	testToolsListMcpRestTestToolsListPostMutationRequestSchema,
	tokenCounterUtilsTokenCounterPostMutationRequestSchema,
	tokenCounterUtilsTokenCounterPostQueryParamsSchema,
	tokenEndpointMcpServerNameTokenPostPathParamsSchema,
	tokenEndpointTokenPostQueryParamsSchema,
	transformRequestUtilsTransformRequestPostMutationRequestSchema,
	unblockKeyKeyUnblockPostHeaderParamsSchema,
	unblockKeyKeyUnblockPostMutationRequestSchema,
	unblockTeamTeamUnblockPostMutationRequestSchema,
	unblockUserCustomerUnblockPostMutationRequestSchema,
	updateBudgetBudgetUpdatePostMutationRequestSchema,
	updateCacheSettingsCacheSettingsPostMutationRequestSchema,
	updateCloudzeroSettingsCloudzeroSettingsPutMutationRequestSchema,
	updateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequestSchema,
	updateCredentialCredentialsCredentialNamePatchMutationRequestSchema,
	updateCredentialCredentialsCredentialNamePatchPathParamsSchema,
	updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequestSchema,
	updateEndUserCustomerUpdatePostMutationRequestSchema,
	updateEventSettingsEmailEventSettingsPatchMutationRequestSchema,
	updateGroupScimV2GroupsGroupIdPutMutationRequestSchema,
	updateGroupScimV2GroupsGroupIdPutPathParamsSchema,
	updateGroupScimV2GroupsGroupIdPutQueryParamsSchema,
	updateGuardrailGuardrailsGuardrailIdPutMutationRequestSchema,
	updateGuardrailGuardrailsGuardrailIdPutPathParamsSchema,
	updateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequestSchema,
	updateKeyFnKeyUpdatePostHeaderParamsSchema,
	updateKeyFnKeyUpdatePostMutationRequestSchema,
	updateModelModelUpdatePostMutationRequestSchema,
	updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequestSchema,
	updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParamsSchema,
	updatePromptPromptsPromptIdPutMutationRequestSchema,
	updatePromptPromptsPromptIdPutPathParamsSchema,
	updatePublicModelGroupsModelGroupMakePublicPostMutationRequestSchema,
	updateSearchToolSearchToolsSearchToolIdPutMutationRequestSchema,
	updateSearchToolSearchToolsSearchToolIdPutPathParamsSchema,
	updateSsoSettingsUpdateSsoSettingsPatchMutationRequestSchema,
	updateTagTagUpdatePostMutationRequestSchema,
	updateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequestSchema,
	updateTeamTeamUpdatePostHeaderParamsSchema,
	updateTeamTeamUpdatePostMutationRequestSchema,
	updateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequestSchema,
	updateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequestSchema,
	updateUserScimV2UsersUserIdPutMutationRequestSchema,
	updateUserScimV2UsersUserIdPutPathParamsSchema,
	updateUserScimV2UsersUserIdPutQueryParamsSchema,
	updateVectorStoreVectorStoreUpdatePostMutationRequestSchema,
	userInfoUserInfoGetQueryParamsSchema,
	userUpdateUserUpdatePostMutationRequestSchema,
	validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequestSchema,
	vectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParamsSchema,
	vectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParamsSchema,
	videoContentV1VideosVideoIdContentGetPathParamsSchema,
	videoContentVideosVideoIdContentGetPathParamsSchema,
	videoRemixV1VideosVideoIdRemixPostPathParamsSchema,
	videoRemixVideosVideoIdRemixPostPathParamsSchema,
	videoStatusV1VideosVideoIdGetPathParamsSchema,
	videoStatusVideosVideoIdGetPathParamsSchema,
	viewSpendLogsSpendLogsGetQueryParamsSchema,
	viewSpendTagsSpendTagsGetQueryParamsSchema,
	websocketVertexAiLivePassthroughEndpointQueryParamsSchema,
	websocketWebsocketEndpoint2QueryParamsSchema,
	websocketWebsocketEndpointQueryParamsSchema,
} from "./schemas";
import type {
	ActiveCallbacksActiveCallbacksGetQueryResponse,
	ActiveCallbacksSettingsGetQueryResponse,
	AddAllowedIpAddAllowedIpPost422,
	AddAllowedIpAddAllowedIpPostMutationRequest,
	AddAllowedIpAddAllowedIpPostMutationResponse,
	AddMcpServerV1McpServerPost422,
	AddMcpServerV1McpServerPostHeaderParams,
	AddMcpServerV1McpServerPostMutationRequest,
	AddMcpServerV1McpServerPostMutationResponse,
	AddMessagesThreadsThreadIdMessagesPost422,
	AddMessagesThreadsThreadIdMessagesPostMutationResponse,
	AddMessagesThreadsThreadIdMessagesPostPathParams,
	AddMessagesV1ThreadsThreadIdMessagesPost422,
	AddMessagesV1ThreadsThreadIdMessagesPostMutationResponse,
	AddMessagesV1ThreadsThreadIdMessagesPostPathParams,
	AddNewModelModelNewPost422,
	AddNewModelModelNewPostMutationRequest,
	AddNewModelModelNewPostMutationResponse,
	AddTeamCallbacksTeamTeamIdCallbackPost422,
	AddTeamCallbacksTeamTeamIdCallbackPostHeaderParams,
	AddTeamCallbacksTeamTeamIdCallbackPostMutationRequest,
	AddTeamCallbacksTeamTeamIdCallbackPostMutationResponse,
	AddTeamCallbacksTeamTeamIdCallbackPostPathParams,
	AnthropicResponseV1MessagesPostMutationResponse,
	ApplyGuardrailApplyGuardrailPost422,
	ApplyGuardrailApplyGuardrailPostMutationRequest,
	ApplyGuardrailApplyGuardrailPostMutationResponse,
	ApplyGuardrailGuardrailsApplyGuardrailPost422,
	ApplyGuardrailGuardrailsApplyGuardrailPostMutationRequest,
	ApplyGuardrailGuardrailsApplyGuardrailPostMutationResponse,
	AudioSpeechAudioSpeechPostMutationResponse,
	AudioSpeechV1AudioSpeechPostMutationResponse,
	AudioTranscriptionsAudioTranscriptionsPost422,
	AudioTranscriptionsAudioTranscriptionsPostMutationResponse,
	AudioTranscriptionsV1AudioTranscriptionsPost422,
	AudioTranscriptionsV1AudioTranscriptionsPostMutationResponse,
	AuthorizeAuthorizeGet422,
	AuthorizeAuthorizeGetQueryParams,
	AuthorizeAuthorizeGetQueryResponse,
	AuthorizeMcpServerNameAuthorizeGet422,
	AuthorizeMcpServerNameAuthorizeGetPathParams,
	AuthorizeMcpServerNameAuthorizeGetQueryParams,
	AuthorizeMcpServerNameAuthorizeGetQueryResponse,
	AvailableEnterpriseUsersUserAvailableUsersGetQueryResponse,
	BlockKeyKeyBlockPost422,
	BlockKeyKeyBlockPostHeaderParams,
	BlockKeyKeyBlockPostMutationRequest,
	BlockKeyKeyBlockPostMutationResponse,
	BlockTeamTeamBlockPost422,
	BlockTeamTeamBlockPostMutationRequest,
	BlockTeamTeamBlockPostMutationResponse,
	BlockUserCustomerBlockPost422,
	BlockUserCustomerBlockPostMutationRequest,
	BlockUserCustomerBlockPostMutationResponse,
	BudgetSettingsBudgetSettingsGet422,
	BudgetSettingsBudgetSettingsGetQueryParams,
	BudgetSettingsBudgetSettingsGetQueryResponse,
	BulkTeamMemberAddTeamBulkMemberAddPost422,
	BulkTeamMemberAddTeamBulkMemberAddPostMutationRequest,
	BulkTeamMemberAddTeamBulkMemberAddPostMutationResponse,
	BulkUserUpdateUserBulkUpdatePost422,
	BulkUserUpdateUserBulkUpdatePostHeaderParams,
	BulkUserUpdateUserBulkUpdatePostMutationRequest,
	BulkUserUpdateUserBulkUpdatePostMutationResponse,
	CacheDeleteCacheDeletePostMutationResponse,
	CacheFlushallCacheFlushallPostMutationResponse,
	CachePingCachePingGetQueryResponse,
	CacheRedisInfoCacheRedisInfoGetQueryResponse,
	CalculateSpendSpendCalculatePost422,
	CalculateSpendSpendCalculatePostMutationRequest,
	CalculateSpendSpendCalculatePostMutationResponse,
	CallbackCallbackGet422,
	CallbackCallbackGetQueryParams,
	CallbackCallbackGetQueryResponse,
	CallToolRestApiMcpRestToolsCallPostMutationResponse,
	CancelBatchBatchesBatchIdCancelPost422,
	CancelBatchBatchesBatchIdCancelPostMutationResponse,
	CancelBatchBatchesBatchIdCancelPostPathParams,
	CancelBatchBatchesBatchIdCancelPostQueryParams,
	CancelBatchProviderV1BatchesBatchIdCancelPost422,
	CancelBatchProviderV1BatchesBatchIdCancelPostMutationResponse,
	CancelBatchProviderV1BatchesBatchIdCancelPostPathParams,
	CancelBatchV1BatchesBatchIdCancelPost422,
	CancelBatchV1BatchesBatchIdCancelPostMutationResponse,
	CancelBatchV1BatchesBatchIdCancelPostPathParams,
	CancelBatchV1BatchesBatchIdCancelPostQueryParams,
	CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost422,
	CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostMutationResponse,
	CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams,
	CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost422,
	CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostMutationResponse,
	CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams,
	CancelResponseOpenaiV1ResponsesResponseIdCancelPost422,
	CancelResponseOpenaiV1ResponsesResponseIdCancelPostMutationResponse,
	CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams,
	CancelResponseResponsesResponseIdCancelPost422,
	CancelResponseResponsesResponseIdCancelPostMutationResponse,
	CancelResponseResponsesResponseIdCancelPostPathParams,
	CancelResponseV1ResponsesResponseIdCancelPost422,
	CancelResponseV1ResponsesResponseIdCancelPostMutationResponse,
	CancelResponseV1ResponsesResponseIdCancelPostPathParams,
	ChatCompletionChatCompletionsPost422,
	ChatCompletionChatCompletionsPostMutationRequest,
	ChatCompletionChatCompletionsPostMutationResponse,
	ChatCompletionEnginesModelChatCompletionsPost422,
	ChatCompletionEnginesModelChatCompletionsPostMutationRequest,
	ChatCompletionEnginesModelChatCompletionsPostMutationResponse,
	ChatCompletionEnginesModelChatCompletionsPostPathParams,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost400,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost401,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost403,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost404,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost408,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost422,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost429,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost500,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPost503,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequest,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationResponse,
	ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams,
	ChatCompletionV1ChatCompletionsPost422,
	ChatCompletionV1ChatCompletionsPostMutationRequest,
	ChatCompletionV1ChatCompletionsPostMutationResponse,
	CloudzeroDryRunExportCloudzeroDryRunPost422,
	CloudzeroDryRunExportCloudzeroDryRunPostMutationRequest,
	CloudzeroDryRunExportCloudzeroDryRunPostMutationResponse,
	CloudzeroExportCloudzeroExportPost422,
	CloudzeroExportCloudzeroExportPostMutationRequest,
	CloudzeroExportCloudzeroExportPostMutationResponse,
	CompletionCompletionsPost422,
	CompletionCompletionsPostMutationResponse,
	CompletionCompletionsPostQueryParams,
	CompletionEnginesModelCompletionsPost422,
	CompletionEnginesModelCompletionsPostMutationResponse,
	CompletionEnginesModelCompletionsPostPathParams,
	CompletionOpenaiDeploymentsModelCompletionsPost422,
	CompletionOpenaiDeploymentsModelCompletionsPostMutationResponse,
	CompletionOpenaiDeploymentsModelCompletionsPostPathParams,
	CompletionV1CompletionsPost422,
	CompletionV1CompletionsPostMutationResponse,
	CompletionV1CompletionsPostQueryParams,
	ConvertPromptFileToJsonUtilsDotpromptJsonConverterPost422,
	ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostMutationResponse,
	CountTokensV1MessagesCountTokensPostMutationResponse,
	CreateAssistantAssistantsPostMutationResponse,
	CreateAssistantV1AssistantsPostMutationResponse,
	CreateBatchBatchesPost422,
	CreateBatchBatchesPostMutationResponse,
	CreateBatchBatchesPostQueryParams,
	CreateBatchProviderV1BatchesPost422,
	CreateBatchProviderV1BatchesPostMutationResponse,
	CreateBatchProviderV1BatchesPostPathParams,
	CreateBatchV1BatchesPost422,
	CreateBatchV1BatchesPostMutationResponse,
	CreateBatchV1BatchesPostQueryParams,
	CreateContainerContainersPostMutationResponse,
	CreateContainerV1ContainersPostMutationResponse,
	CreateCredentialCredentialsPost422,
	CreateCredentialCredentialsPostMutationRequest,
	CreateCredentialCredentialsPostMutationResponse,
	CreateFileFilesPost422,
	CreateFileFilesPostMutationResponse,
	CreateFileFilesPostQueryParams,
	CreateFileProviderV1FilesPost422,
	CreateFileProviderV1FilesPostMutationResponse,
	CreateFileProviderV1FilesPostPathParams,
	CreateFileV1FilesPost422,
	CreateFileV1FilesPostMutationResponse,
	CreateFileV1FilesPostQueryParams,
	CreateFineTuningJobFineTuningJobsPost422,
	CreateFineTuningJobFineTuningJobsPostMutationRequest,
	CreateFineTuningJobFineTuningJobsPostMutationResponse,
	CreateFineTuningJobV1FineTuningJobsPost422,
	CreateFineTuningJobV1FineTuningJobsPostMutationRequest,
	CreateFineTuningJobV1FineTuningJobsPostMutationResponse,
	CreateGroupScimV2GroupsPost422,
	CreateGroupScimV2GroupsPostMutationRequest,
	CreateGroupScimV2GroupsPostMutationResponse,
	CreateGroupScimV2GroupsPostQueryParams,
	CreateGuardrailGuardrailsPost422,
	CreateGuardrailGuardrailsPostMutationRequest,
	CreateGuardrailGuardrailsPostMutationResponse,
	CreatePassThroughEndpointsConfigPassThroughEndpointPost422,
	CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationRequest,
	CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationResponse,
	CreatePromptPromptsPost422,
	CreatePromptPromptsPostMutationRequest,
	CreatePromptPromptsPostMutationResponse,
	CreateSearchToolSearchToolsPost422,
	CreateSearchToolSearchToolsPostMutationRequest,
	CreateSearchToolSearchToolsPostMutationResponse,
	CreateThreadsThreadsPostMutationResponse,
	CreateThreadsV1ThreadsPostMutationResponse,
	CreateUserScimV2UsersPost422,
	CreateUserScimV2UsersPostMutationRequest,
	CreateUserScimV2UsersPostMutationResponse,
	CreateUserScimV2UsersPostQueryParams,
	DeleteAllowedIpDeleteAllowedIpPost422,
	DeleteAllowedIpDeleteAllowedIpPostMutationRequest,
	DeleteAllowedIpDeleteAllowedIpPostMutationResponse,
	DeleteAssistantAssistantsAssistantIdDelete422,
	DeleteAssistantAssistantsAssistantIdDeleteMutationResponse,
	DeleteAssistantAssistantsAssistantIdDeletePathParams,
	DeleteAssistantV1AssistantsAssistantIdDelete422,
	DeleteAssistantV1AssistantsAssistantIdDeleteMutationResponse,
	DeleteAssistantV1AssistantsAssistantIdDeletePathParams,
	DeleteBudgetBudgetDeletePost422,
	DeleteBudgetBudgetDeletePostMutationRequest,
	DeleteBudgetBudgetDeletePostMutationResponse,
	DeleteContainerContainersContainerIdDelete422,
	DeleteContainerContainersContainerIdDeleteMutationResponse,
	DeleteContainerContainersContainerIdDeletePathParams,
	DeleteContainerV1ContainersContainerIdDelete422,
	DeleteContainerV1ContainersContainerIdDeleteMutationResponse,
	DeleteContainerV1ContainersContainerIdDeletePathParams,
	DeleteCredentialCredentialsCredentialNameDelete422,
	DeleteCredentialCredentialsCredentialNameDeleteMutationResponse,
	DeleteCredentialCredentialsCredentialNameDeletePathParams,
	DeleteEndUserCustomerDeletePost422,
	DeleteEndUserCustomerDeletePostMutationRequest,
	DeleteEndUserCustomerDeletePostMutationResponse,
	DeleteFileFilesFileIdDelete422,
	DeleteFileFilesFileIdDeleteMutationResponse,
	DeleteFileFilesFileIdDeletePathParams,
	DeleteFileFilesFileIdDeleteQueryParams,
	DeleteFileProviderV1FilesFileIdDelete422,
	DeleteFileProviderV1FilesFileIdDeleteMutationResponse,
	DeleteFileProviderV1FilesFileIdDeletePathParams,
	DeleteFileV1FilesFileIdDelete422,
	DeleteFileV1FilesFileIdDeleteMutationResponse,
	DeleteFileV1FilesFileIdDeletePathParams,
	DeleteFileV1FilesFileIdDeleteQueryParams,
	DeleteGroupScimV2GroupsGroupIdDelete422,
	DeleteGroupScimV2GroupsGroupIdDeleteMutationResponse,
	DeleteGroupScimV2GroupsGroupIdDeletePathParams,
	DeleteGroupScimV2GroupsGroupIdDeleteQueryParams,
	DeleteGuardrailGuardrailsGuardrailIdDelete422,
	DeleteGuardrailGuardrailsGuardrailIdDeleteMutationResponse,
	DeleteGuardrailGuardrailsGuardrailIdDeletePathParams,
	DeleteKeyFnKeyDeletePost422,
	DeleteKeyFnKeyDeletePostHeaderParams,
	DeleteKeyFnKeyDeletePostMutationRequest,
	DeleteKeyFnKeyDeletePostMutationResponse,
	DeleteModelModelDeletePost422,
	DeleteModelModelDeletePostMutationRequest,
	DeleteModelModelDeletePostMutationResponse,
	DeleteOrganizationOrganizationDeleteDelete422,
	DeleteOrganizationOrganizationDeleteDeleteMutationRequest,
	DeleteOrganizationOrganizationDeleteDeleteMutationResponse,
	DeletePassThroughEndpointsConfigPassThroughEndpointDelete422,
	DeletePassThroughEndpointsConfigPassThroughEndpointDeleteMutationResponse,
	DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams,
	DeletePromptPromptsPromptIdDelete422,
	DeletePromptPromptsPromptIdDeleteMutationResponse,
	DeletePromptPromptsPromptIdDeletePathParams,
	DeleteResponseOpenaiV1ResponsesResponseIdDelete422,
	DeleteResponseOpenaiV1ResponsesResponseIdDeleteMutationResponse,
	DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams,
	DeleteResponseResponsesResponseIdDelete422,
	DeleteResponseResponsesResponseIdDeleteMutationResponse,
	DeleteResponseResponsesResponseIdDeletePathParams,
	DeleteResponseV1ResponsesResponseIdDelete422,
	DeleteResponseV1ResponsesResponseIdDeleteMutationResponse,
	DeleteResponseV1ResponsesResponseIdDeletePathParams,
	DeleteSearchToolSearchToolsSearchToolIdDelete422,
	DeleteSearchToolSearchToolsSearchToolIdDeleteMutationResponse,
	DeleteSearchToolSearchToolsSearchToolIdDeletePathParams,
	DeleteTagTagDeletePost422,
	DeleteTagTagDeletePostMutationRequest,
	DeleteTagTagDeletePostMutationResponse,
	DeleteTeamTeamDeletePost422,
	DeleteTeamTeamDeletePostHeaderParams,
	DeleteTeamTeamDeletePostMutationRequest,
	DeleteTeamTeamDeletePostMutationResponse,
	DeleteUserScimV2UsersUserIdDelete422,
	DeleteUserScimV2UsersUserIdDeleteMutationResponse,
	DeleteUserScimV2UsersUserIdDeletePathParams,
	DeleteUserScimV2UsersUserIdDeleteQueryParams,
	DeleteUserUserDeletePost422,
	DeleteUserUserDeletePostHeaderParams,
	DeleteUserUserDeletePostMutationRequest,
	DeleteUserUserDeletePostMutationResponse,
	DeleteVectorStoreVectorStoreDeletePost422,
	DeleteVectorStoreVectorStoreDeletePostMutationRequest,
	DeleteVectorStoreVectorStoreDeletePostMutationResponse,
	DeprecatedInfoOrganizationOrganizationInfoPost422,
	DeprecatedInfoOrganizationOrganizationInfoPostMutationRequest,
	DeprecatedInfoOrganizationOrganizationInfoPostMutationResponse,
	DisableTeamLoggingTeamTeamIdDisableLoggingPost422,
	DisableTeamLoggingTeamTeamIdDisableLoggingPostMutationResponse,
	DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams,
	DynamicMcpRouteMcpServerNameMcpPatch2MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch2PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch3MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch3PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch4MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch4PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch5MutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatch5PathParams,
	DynamicMcpRouteMcpServerNameMcpPatch422,
	DynamicMcpRouteMcpServerNameMcpPatch2422,
	DynamicMcpRouteMcpServerNameMcpPatch3422,
	DynamicMcpRouteMcpServerNameMcpPatch4422,
	DynamicMcpRouteMcpServerNameMcpPatch5422,
	DynamicMcpRouteMcpServerNameMcpPatchMutationResponse,
	DynamicMcpRouteMcpServerNameMcpPatchPathParams,
	EditMcpServerV1McpServerPut422,
	EditMcpServerV1McpServerPutHeaderParams,
	EditMcpServerV1McpServerPutMutationRequest,
	EditMcpServerV1McpServerPutMutationResponse,
	EmbeddingsEmbeddingsPost422,
	EmbeddingsEmbeddingsPostMutationRequest,
	EmbeddingsEmbeddingsPostMutationResponse,
	EmbeddingsEnginesModelEmbeddingsPost422,
	EmbeddingsEnginesModelEmbeddingsPostMutationRequest,
	EmbeddingsEnginesModelEmbeddingsPostMutationResponse,
	EmbeddingsEnginesModelEmbeddingsPostPathParams,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPost422,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequest,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationResponse,
	EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams,
	EmbeddingsV1EmbeddingsPost422,
	EmbeddingsV1EmbeddingsPostMutationRequest,
	EmbeddingsV1EmbeddingsPostMutationResponse,
	EndUserInfoCustomerInfoGet422,
	EndUserInfoCustomerInfoGetQueryParams,
	EndUserInfoCustomerInfoGetQueryResponse,
	FetchAllMcpServersV1McpServerGetQueryResponse,
	FetchMcpServerV1McpServerServerIdGet422,
	FetchMcpServerV1McpServerServerIdGetPathParams,
	FetchMcpServerV1McpServerServerIdGetQueryResponse,
	GenerateKeyFnKeyGeneratePost422,
	GenerateKeyFnKeyGeneratePostHeaderParams,
	GenerateKeyFnKeyGeneratePostMutationRequest,
	GenerateKeyFnKeyGeneratePostMutationResponse,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePost422,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParams,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequest,
	GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationResponse,
	GetActiveTasksStatsDebugAsyncioTasksGetQueryResponse,
	GetAssistantsAssistantsGetQueryResponse,
	GetAssistantsV1AssistantsGetQueryResponse,
	GetAuditLogByIdAuditIdGet404,
	GetAuditLogByIdAuditIdGet422,
	GetAuditLogByIdAuditIdGet500,
	GetAuditLogByIdAuditIdGetPathParams,
	GetAuditLogByIdAuditIdGetQueryResponse,
	GetAuditLogsAuditGet422,
	GetAuditLogsAuditGetQueryParams,
	GetAuditLogsAuditGetQueryResponse,
	GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetQueryResponse,
	GetCacheSettingsCacheSettingsGetQueryResponse,
	GetCloudzeroSettingsCloudzeroSettingsGetQueryResponse,
	GetCostDiscountConfigConfigCostDiscountConfigGetQueryResponse,
	GetCredentialCredentialsByModelModelIdGet422,
	GetCredentialCredentialsByModelModelIdGetPathParams,
	GetCredentialCredentialsByModelModelIdGetQueryResponse,
	GetCredentialCredentialsByNameCredentialNameGet422,
	GetCredentialCredentialsByNameCredentialNameGetPathParams,
	GetCredentialCredentialsByNameCredentialNameGetQueryParams,
	GetCredentialCredentialsByNameCredentialNameGetQueryResponse,
	GetCredentialsCredentialsGetQueryResponse,
	GetDailyActiveUsersTagDauGet422,
	GetDailyActiveUsersTagDauGetQueryParams,
	GetDailyActiveUsersTagDauGetQueryResponse,
	GetDefaultTeamSettingsGetDefaultTeamSettingsGetQueryResponse,
	GetDistinctUserAgentTagsTagDistinctGetQueryResponse,
	GetEmailEventSettingsEmailEventSettingsGetQueryResponse,
	GetFileContentFilesFileIdContentGet422,
	GetFileContentFilesFileIdContentGetPathParams,
	GetFileContentFilesFileIdContentGetQueryParams,
	GetFileContentFilesFileIdContentGetQueryResponse,
	GetFileContentProviderV1FilesFileIdContentGet422,
	GetFileContentProviderV1FilesFileIdContentGetPathParams,
	GetFileContentProviderV1FilesFileIdContentGetQueryResponse,
	GetFileContentV1FilesFileIdContentGet422,
	GetFileContentV1FilesFileIdContentGetPathParams,
	GetFileContentV1FilesFileIdContentGetQueryParams,
	GetFileContentV1FilesFileIdContentGetQueryResponse,
	GetFileFilesFileIdGet422,
	GetFileFilesFileIdGetPathParams,
	GetFileFilesFileIdGetQueryParams,
	GetFileFilesFileIdGetQueryResponse,
	GetFileProviderV1FilesFileIdGet422,
	GetFileProviderV1FilesFileIdGetPathParams,
	GetFileProviderV1FilesFileIdGetQueryResponse,
	GetFileV1FilesFileIdGet422,
	GetFileV1FilesFileIdGetPathParams,
	GetFileV1FilesFileIdGetQueryParams,
	GetFileV1FilesFileIdGetQueryResponse,
	GetGlobalSpendReportGlobalSpendReportGet422,
	GetGlobalSpendReportGlobalSpendReportGetQueryParams,
	GetGlobalSpendReportGlobalSpendReportGetQueryResponse,
	GetGroupScimV2GroupsGroupIdGet422,
	GetGroupScimV2GroupsGroupIdGetPathParams,
	GetGroupScimV2GroupsGroupIdGetQueryParams,
	GetGroupScimV2GroupsGroupIdGetQueryResponse,
	GetGroupsScimV2GroupsGet422,
	GetGroupsScimV2GroupsGetQueryParams,
	GetGroupsScimV2GroupsGetQueryResponse,
	GetGuardrailInfoGuardrailsGuardrailIdGet422,
	GetGuardrailInfoGuardrailsGuardrailIdGetPathParams,
	GetGuardrailInfoGuardrailsGuardrailIdGetQueryResponse,
	GetGuardrailInfoGuardrailsGuardrailIdInfoGet422,
	GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams,
	GetGuardrailInfoGuardrailsGuardrailIdInfoGetQueryResponse,
	GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetQueryResponse,
	GetInternalUserSettingsGetInternalUserSettingsGetQueryResponse,
	GetMcpAccessGroupsV1McpAccessGroupsGetQueryResponse,
	GetMcpToolsV1McpToolsGetQueryResponse,
	GetMessagesThreadsThreadIdMessagesGet422,
	GetMessagesThreadsThreadIdMessagesGetPathParams,
	GetMessagesThreadsThreadIdMessagesGetQueryResponse,
	GetMessagesV1ThreadsThreadIdMessagesGet422,
	GetMessagesV1ThreadsThreadIdMessagesGetPathParams,
	GetMessagesV1ThreadsThreadIdMessagesGetQueryResponse,
	GetMonthlyActiveUsersTagMauGet422,
	GetMonthlyActiveUsersTagMauGetQueryParams,
	GetMonthlyActiveUsersTagMauGetQueryResponse,
	GetPassThroughEndpointsConfigPassThroughEndpointGet422,
	GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams,
	GetPassThroughEndpointsConfigPassThroughEndpointGetQueryResponse,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet422,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams,
	GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryResponse,
	GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGet422,
	GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams,
	GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryResponse,
	GetPromptInfoPromptsPromptIdGet422,
	GetPromptInfoPromptsPromptIdGetPathParams,
	GetPromptInfoPromptsPromptIdGetQueryResponse,
	GetPromptInfoPromptsPromptIdInfoGet422,
	GetPromptInfoPromptsPromptIdInfoGetPathParams,
	GetPromptInfoPromptsPromptIdInfoGetQueryResponse,
	GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetQueryResponse,
	GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet422,
	GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams,
	GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetQueryResponse,
	GetResponseInputItemsResponsesResponseIdInputItemsGet422,
	GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams,
	GetResponseInputItemsResponsesResponseIdInputItemsGetQueryResponse,
	GetResponseInputItemsV1ResponsesResponseIdInputItemsGet422,
	GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams,
	GetResponseInputItemsV1ResponsesResponseIdInputItemsGetQueryResponse,
	GetResponseOpenaiV1ResponsesResponseIdGet422,
	GetResponseOpenaiV1ResponsesResponseIdGetPathParams,
	GetResponseOpenaiV1ResponsesResponseIdGetQueryResponse,
	GetResponseResponsesResponseIdGet422,
	GetResponseResponsesResponseIdGetPathParams,
	GetResponseResponsesResponseIdGetQueryResponse,
	GetResponseV1ResponsesResponseIdGet422,
	GetResponseV1ResponsesResponseIdGetPathParams,
	GetResponseV1ResponsesResponseIdGetQueryResponse,
	GetRobotsRobotsTxtGetQueryResponse,
	GetRouterSettingsRouterSettingsGetQueryResponse,
	GetRoutesRoutesGetQueryResponse,
	GetSearchToolInfoSearchToolsSearchToolIdGet422,
	GetSearchToolInfoSearchToolsSearchToolIdGetPathParams,
	GetSearchToolInfoSearchToolsSearchToolIdGetQueryResponse,
	GetServiceProviderConfigScimV2ServiceProviderConfigGet422,
	GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams,
	GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryResponse,
	GetSsoSettingsGetSsoSettingsGetQueryResponse,
	GetTagDailyActivityTagDailyActivityGet422,
	GetTagDailyActivityTagDailyActivityGetQueryParams,
	GetTagDailyActivityTagDailyActivityGetQueryResponse,
	GetTagSummaryTagSummaryGet422,
	GetTagSummaryTagSummaryGetQueryParams,
	GetTagSummaryTagSummaryGetQueryResponse,
	GetTeamCallbacksTeamTeamIdCallbackGet422,
	GetTeamCallbacksTeamTeamIdCallbackGetPathParams,
	GetTeamCallbacksTeamTeamIdCallbackGetQueryResponse,
	GetTeamDailyActivityTeamDailyActivityGet422,
	GetTeamDailyActivityTeamDailyActivityGetQueryParams,
	GetTeamDailyActivityTeamDailyActivityGetQueryResponse,
	GetThreadThreadsThreadIdGet422,
	GetThreadThreadsThreadIdGetPathParams,
	GetThreadThreadsThreadIdGetQueryResponse,
	GetThreadV1ThreadsThreadIdGet422,
	GetThreadV1ThreadsThreadIdGetPathParams,
	GetThreadV1ThreadsThreadIdGetQueryResponse,
	GetUiConfigLitellmWellKnownLitellmUiConfigGetQueryResponse,
	GetUiConfigWellKnownLitellmUiConfigGetQueryResponse,
	GetUiThemeSettingsGetUiThemeSettingsGetQueryResponse,
	GetUserDailyActivityAggregatedUserDailyActivityAggregatedGet422,
	GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams,
	GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryResponse,
	GetUserDailyActivityUserDailyActivityGet422,
	GetUserDailyActivityUserDailyActivityGetQueryParams,
	GetUserDailyActivityUserDailyActivityGetQueryResponse,
	GetUserScimV2UsersUserIdGet422,
	GetUserScimV2UsersUserIdGetPathParams,
	GetUserScimV2UsersUserIdGetQueryParams,
	GetUserScimV2UsersUserIdGetQueryResponse,
	GetUsersScimV2UsersGet422,
	GetUsersScimV2UsersGetQueryParams,
	GetUsersScimV2UsersGetQueryResponse,
	GetUsersUserListGet422,
	GetUsersUserListGetQueryParams,
	GetUsersUserListGetQueryResponse,
	GetVectorStoreInfoVectorStoreInfoPost422,
	GetVectorStoreInfoVectorStoreInfoPostMutationRequest,
	GetVectorStoreInfoVectorStoreInfoPostMutationResponse,
	GetWeeklyActiveUsersTagWauGet422,
	GetWeeklyActiveUsersTagWauGetQueryParams,
	GetWeeklyActiveUsersTagWauGetQueryResponse,
	GlobalSpendResetGlobalSpendResetPostMutationResponse,
	GlobalViewSpendTagsGlobalSpendTagsGet422,
	GlobalViewSpendTagsGlobalSpendTagsGetQueryParams,
	GlobalViewSpendTagsGlobalSpendTagsGetQueryResponse,
	GoogleCountTokensModelsModelNameCountTokensPost422,
	GoogleCountTokensModelsModelNameCountTokensPostMutationResponse,
	GoogleCountTokensModelsModelNameCountTokensPostPathParams,
	GoogleCountTokensV1BetaModelsModelNameCountTokensPost422,
	GoogleCountTokensV1BetaModelsModelNameCountTokensPostMutationResponse,
	GoogleCountTokensV1BetaModelsModelNameCountTokensPostPathParams,
	GoogleGenerateContentModelsModelNameGenerateContentPost422,
	GoogleGenerateContentModelsModelNameGenerateContentPostMutationResponse,
	GoogleGenerateContentModelsModelNameGenerateContentPostPathParams,
	GoogleGenerateContentV1BetaModelsModelNameGenerateContentPost422,
	GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostMutationResponse,
	GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParams,
	GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPost422,
	GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostMutationResponse,
	GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams,
	GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost422,
	GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostMutationResponse,
	GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParams,
	HealthCheckAllMcpServersV1McpServerHealthGetQueryResponse,
	HealthCheckHistoryEndpointHealthHistoryGet422,
	HealthCheckHistoryEndpointHealthHistoryGetQueryParams,
	HealthCheckHistoryEndpointHealthHistoryGetQueryResponse,
	HealthCheckMcpServerV1McpServerServerIdHealthGet422,
	HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams,
	HealthCheckMcpServerV1McpServerServerIdHealthGetQueryResponse,
	HealthEndpointHealthGet422,
	HealthEndpointHealthGetQueryParams,
	HealthEndpointHealthGetQueryResponse,
	HealthLivelinessHealthLivelinessGetQueryResponse,
	HealthLivelinessHealthLivenessGetQueryResponse,
	HealthLivelinessOptionsHealthLivelinessOptionsMutationResponse,
	HealthLivelinessOptionsHealthLivenessOptionsMutationResponse,
	HealthReadinessHealthReadinessGetQueryResponse,
	HealthReadinessOptionsHealthReadinessOptionsMutationResponse,
	HealthServicesEndpointHealthServicesGet422,
	HealthServicesEndpointHealthServicesGetQueryParams,
	HealthServicesEndpointHealthServicesGetQueryResponse,
	HomeGetQueryResponse,
	ImageEditApiImagesEditsPost422,
	ImageEditApiImagesEditsPostMutationResponse,
	ImageEditApiImagesEditsPostQueryParams,
	ImageEditApiOpenaiDeploymentsModelImagesEditsPost422,
	ImageEditApiOpenaiDeploymentsModelImagesEditsPostMutationResponse,
	ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams,
	ImageEditApiV1ImagesEditsPost422,
	ImageEditApiV1ImagesEditsPostMutationResponse,
	ImageEditApiV1ImagesEditsPostQueryParams,
	ImageGenerationImagesGenerationsPost422,
	ImageGenerationImagesGenerationsPostMutationResponse,
	ImageGenerationImagesGenerationsPostQueryParams,
	ImageGenerationOpenaiDeploymentsModelImagesGenerationsPost422,
	ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostMutationResponse,
	ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams,
	ImageGenerationV1ImagesGenerationsPost422,
	ImageGenerationV1ImagesGenerationsPostMutationResponse,
	ImageGenerationV1ImagesGenerationsPostQueryParams,
	IndexCreateV1IndexesPost422,
	IndexCreateV1IndexesPostMutationRequest,
	IndexCreateV1IndexesPostMutationResponse,
	InfoBudgetBudgetInfoPost422,
	InfoBudgetBudgetInfoPostMutationRequest,
	InfoBudgetBudgetInfoPostMutationResponse,
	InfoKeyFnKeyInfoGet422,
	InfoKeyFnKeyInfoGetQueryParams,
	InfoKeyFnKeyInfoGetQueryResponse,
	InfoOrganizationOrganizationInfoGet422,
	InfoOrganizationOrganizationInfoGetQueryParams,
	InfoOrganizationOrganizationInfoGetQueryResponse,
	InfoTagTagInfoPost422,
	InfoTagTagInfoPostMutationRequest,
	InfoTagTagInfoPostMutationResponse,
	InitCloudzeroSettingsCloudzeroInitPost422,
	InitCloudzeroSettingsCloudzeroInitPostMutationRequest,
	InitCloudzeroSettingsCloudzeroInitPostMutationResponse,
	KeyAliasesKeyAliasesGetQueryResponse,
	KeyHealthKeyHealthPostMutationResponse,
	LatestHealthChecksEndpointHealthLatestGetQueryResponse,
	ListAvailableTeamsTeamAvailableGet422,
	ListAvailableTeamsTeamAvailableGetQueryParams,
	ListAvailableTeamsTeamAvailableGetQueryResponse,
	ListBatchesBatchesGet422,
	ListBatchesBatchesGetQueryParams,
	ListBatchesBatchesGetQueryResponse,
	ListBatchesProviderV1BatchesGet422,
	ListBatchesProviderV1BatchesGetPathParams,
	ListBatchesProviderV1BatchesGetQueryParams,
	ListBatchesProviderV1BatchesGetQueryResponse,
	ListBatchesV1BatchesGet422,
	ListBatchesV1BatchesGetQueryParams,
	ListBatchesV1BatchesGetQueryResponse,
	ListBudgetBudgetListGetQueryResponse,
	ListCallbacksCallbacksListGetQueryResponse,
	ListContainersContainersGetQueryResponse,
	ListContainersV1ContainersGetQueryResponse,
	ListEndUserCustomerListGetQueryResponse,
	ListFilesFilesGet422,
	ListFilesFilesGetQueryParams,
	ListFilesFilesGetQueryResponse,
	ListFilesProviderV1FilesGet422,
	ListFilesProviderV1FilesGetPathParams,
	ListFilesProviderV1FilesGetQueryParams,
	ListFilesProviderV1FilesGetQueryResponse,
	ListFilesV1FilesGet422,
	ListFilesV1FilesGetQueryParams,
	ListFilesV1FilesGetQueryResponse,
	ListFineTuningJobsFineTuningJobsGet422,
	ListFineTuningJobsFineTuningJobsGetQueryParams,
	ListFineTuningJobsFineTuningJobsGetQueryResponse,
	ListFineTuningJobsV1FineTuningJobsGet422,
	ListFineTuningJobsV1FineTuningJobsGetQueryParams,
	ListFineTuningJobsV1FineTuningJobsGetQueryResponse,
	ListGuardrailsGuardrailsListGetQueryResponse,
	ListGuardrailsV2V2GuardrailsListGetQueryResponse,
	ListKeysKeyListGet422,
	ListKeysKeyListGetQueryParams,
	ListKeysKeyListGetQueryResponse,
	ListOrganizationOrganizationListGetQueryResponse,
	ListPromptsPromptsListGetQueryResponse,
	ListSearchToolsSearchToolsListGetQueryResponse,
	ListTagsTagListGetQueryResponse,
	ListTeamTeamListGet422,
	ListTeamTeamListGetQueryParams,
	ListTeamTeamListGetQueryResponse,
	ListTeamV2V2TeamListGet422,
	ListTeamV2V2TeamListGetQueryParams,
	ListTeamV2V2TeamListGetQueryResponse,
	ListToolRestApiMcpRestToolsListGet422,
	ListToolRestApiMcpRestToolsListGetQueryParams,
	ListToolRestApiMcpRestToolsListGetQueryResponse,
	ListVectorStoresVectorStoreListGet422,
	ListVectorStoresVectorStoreListGetQueryParams,
	ListVectorStoresVectorStoreListGetQueryResponse,
	ModelGroupInfoModelGroupInfoGet422,
	ModelGroupInfoModelGroupInfoGetQueryParams,
	ModelGroupInfoModelGroupInfoGetQueryResponse,
	ModelInfoModelsModelIdGet422,
	ModelInfoModelsModelIdGetPathParams,
	ModelInfoModelsModelIdGetQueryResponse,
	ModelInfoV1ModelInfoGet422,
	ModelInfoV1ModelInfoGetQueryParams,
	ModelInfoV1ModelInfoGetQueryResponse,
	ModelInfoV1ModelsModelIdGet422,
	ModelInfoV1ModelsModelIdGetPathParams,
	ModelInfoV1ModelsModelIdGetQueryResponse,
	ModelInfoV1V1ModelInfoGet422,
	ModelInfoV1V1ModelInfoGetQueryParams,
	ModelInfoV1V1ModelInfoGetQueryResponse,
	ModelListModelsGet422,
	ModelListModelsGetQueryParams,
	ModelListModelsGetQueryResponse,
	ModelListV1ModelsGet422,
	ModelListV1ModelsGetQueryParams,
	ModelListV1ModelsGetQueryResponse,
	ModerationsModerationsPostMutationResponse,
	ModerationsV1ModerationsPostMutationResponse,
	NewBudgetBudgetNewPost422,
	NewBudgetBudgetNewPostMutationRequest,
	NewBudgetBudgetNewPostMutationResponse,
	NewEndUserCustomerNewPost422,
	NewEndUserCustomerNewPostMutationRequest,
	NewEndUserCustomerNewPostMutationResponse,
	NewOrganizationOrganizationNewPost422,
	NewOrganizationOrganizationNewPostMutationRequest,
	NewOrganizationOrganizationNewPostMutationResponse,
	NewTagTagNewPost422,
	NewTagTagNewPostMutationRequest,
	NewTagTagNewPostMutationResponse,
	NewTeamTeamNewPost422,
	NewTeamTeamNewPostHeaderParams,
	NewTeamTeamNewPostMutationRequest,
	NewTeamTeamNewPostMutationResponse,
	NewUserUserNewPost422,
	NewUserUserNewPostMutationRequest,
	NewUserUserNewPostMutationResponse,
	NewVectorStoreVectorStoreNewPost422,
	NewVectorStoreVectorStoreNewPostMutationRequest,
	NewVectorStoreVectorStoreNewPostMutationResponse,
	OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet422,
	OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams,
	OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetQueryResponse,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet422,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryResponse,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet422,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams,
	OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetQueryResponse,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceGet422,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryResponse,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet422,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams,
	OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetQueryResponse,
	OcrOcrPostMutationResponse,
	OcrV1OcrPostMutationResponse,
	OpenidConfigurationWellKnownOpenidConfigurationGetQueryResponse,
	OrganizationMemberAddOrganizationMemberAddPost422,
	OrganizationMemberAddOrganizationMemberAddPostMutationRequest,
	OrganizationMemberAddOrganizationMemberAddPostMutationResponse,
	OrganizationMemberDeleteOrganizationMemberDeleteDelete422,
	OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequest,
	OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationResponse,
	OrganizationMemberUpdateOrganizationMemberUpdatePatch422,
	OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationRequest,
	OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationResponse,
	PatchGroupScimV2GroupsGroupIdPatch422,
	PatchGroupScimV2GroupsGroupIdPatchMutationRequest,
	PatchGroupScimV2GroupsGroupIdPatchMutationResponse,
	PatchGroupScimV2GroupsGroupIdPatchPathParams,
	PatchGroupScimV2GroupsGroupIdPatchQueryParams,
	PatchGuardrailGuardrailsGuardrailIdPatch422,
	PatchGuardrailGuardrailsGuardrailIdPatchMutationRequest,
	PatchGuardrailGuardrailsGuardrailIdPatchMutationResponse,
	PatchGuardrailGuardrailsGuardrailIdPatchPathParams,
	PatchModelModelModelIdUpdatePatch422,
	PatchModelModelModelIdUpdatePatchMutationRequest,
	PatchModelModelModelIdUpdatePatchMutationResponse,
	PatchModelModelModelIdUpdatePatchPathParams,
	PatchPromptPromptsPromptIdPatch422,
	PatchPromptPromptsPromptIdPatchMutationRequest,
	PatchPromptPromptsPromptIdPatchMutationResponse,
	PatchPromptPromptsPromptIdPatchPathParams,
	PatchUserScimV2UsersUserIdPatch422,
	PatchUserScimV2UsersUserIdPatchMutationRequest,
	PatchUserScimV2UsersUserIdPatchMutationResponse,
	PatchUserScimV2UsersUserIdPatchPathParams,
	PatchUserScimV2UsersUserIdPatchQueryParams,
	ProviderBudgetsProviderBudgetsGetQueryResponse,
	PublicModelHubInfoPublicModelHubInfoGetQueryResponse,
	PublicModelHubPublicModelHubGetQueryResponse,
	RegenerateKeyFnKeyKeyRegeneratePost422,
	RegenerateKeyFnKeyKeyRegeneratePostHeaderParams,
	RegenerateKeyFnKeyKeyRegeneratePostMutationRequest,
	RegenerateKeyFnKeyKeyRegeneratePostMutationResponse,
	RegenerateKeyFnKeyKeyRegeneratePostPathParams,
	RegenerateKeyFnKeyRegeneratePost422,
	RegenerateKeyFnKeyRegeneratePostHeaderParams,
	RegenerateKeyFnKeyRegeneratePostMutationRequest,
	RegenerateKeyFnKeyRegeneratePostMutationResponse,
	RegenerateKeyFnKeyRegeneratePostQueryParams,
	RegisterClientMcpServerNameRegisterPost422,
	RegisterClientMcpServerNameRegisterPostMutationResponse,
	RegisterClientMcpServerNameRegisterPostPathParams,
	RegisterClientRegisterPost422,
	RegisterClientRegisterPostMutationResponse,
	RegisterClientRegisterPostQueryParams,
	RemoveMcpServerV1McpServerServerIdDelete422,
	RemoveMcpServerV1McpServerServerIdDeleteHeaderParams,
	RemoveMcpServerV1McpServerServerIdDeleteMutationResponse,
	RemoveMcpServerV1McpServerServerIdDeletePathParams,
	RerankRerankPostMutationResponse,
	RerankV1RerankPostMutationResponse,
	RerankV2RerankPostMutationResponse,
	ResetEventSettingsEmailEventSettingsResetPostMutationResponse,
	ResponsesApiOpenaiV1ResponsesPostMutationResponse,
	ResponsesApiResponsesPostMutationResponse,
	ResponsesApiV1ResponsesPostMutationResponse,
	RetrieveBatchBatchesBatchIdGet422,
	RetrieveBatchBatchesBatchIdGetPathParams,
	RetrieveBatchBatchesBatchIdGetQueryParams,
	RetrieveBatchBatchesBatchIdGetQueryResponse,
	RetrieveBatchProviderV1BatchesBatchIdGet422,
	RetrieveBatchProviderV1BatchesBatchIdGetPathParams,
	RetrieveBatchProviderV1BatchesBatchIdGetQueryResponse,
	RetrieveBatchV1BatchesBatchIdGet422,
	RetrieveBatchV1BatchesBatchIdGetPathParams,
	RetrieveBatchV1BatchesBatchIdGetQueryParams,
	RetrieveBatchV1BatchesBatchIdGetQueryResponse,
	RetrieveContainerContainersContainerIdGet422,
	RetrieveContainerContainersContainerIdGetPathParams,
	RetrieveContainerContainersContainerIdGetQueryResponse,
	RetrieveContainerV1ContainersContainerIdGet422,
	RetrieveContainerV1ContainersContainerIdGetPathParams,
	RetrieveContainerV1ContainersContainerIdGetQueryResponse,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGet422,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams,
	RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryResponse,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet422,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams,
	RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryResponse,
	RunThreadThreadsThreadIdRunsPost422,
	RunThreadThreadsThreadIdRunsPostMutationResponse,
	RunThreadThreadsThreadIdRunsPostPathParams,
	RunThreadV1ThreadsThreadIdRunsPost422,
	RunThreadV1ThreadsThreadIdRunsPostMutationResponse,
	RunThreadV1ThreadsThreadIdRunsPostPathParams,
	SearchSearchPost422,
	SearchSearchPostMutationResponse,
	SearchSearchPostQueryParams,
	SearchSearchSearchToolNamePost422,
	SearchSearchSearchToolNamePostMutationResponse,
	SearchSearchSearchToolNamePostPathParams,
	SearchV1SearchPost422,
	SearchV1SearchPostMutationResponse,
	SearchV1SearchPostQueryParams,
	SearchV1SearchSearchToolNamePost422,
	SearchV1SearchSearchToolNamePostMutationResponse,
	SearchV1SearchSearchToolNamePostPathParams,
	SharedHealthCheckStatusEndpointHealthSharedStatusGetQueryResponse,
	SupportedOpenaiParamsUtilsSupportedOpenaiParamsGet422,
	SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams,
	SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryResponse,
	TeamInfoTeamInfoGet422,
	TeamInfoTeamInfoGetQueryParams,
	TeamInfoTeamInfoGetQueryResponse,
	TeamMemberAddTeamMemberAddPost422,
	TeamMemberAddTeamMemberAddPostMutationRequest,
	TeamMemberAddTeamMemberAddPostMutationResponse,
	TeamMemberDeleteTeamMemberDeletePost422,
	TeamMemberDeleteTeamMemberDeletePostMutationRequest,
	TeamMemberDeleteTeamMemberDeletePostMutationResponse,
	TeamMemberPermissionsTeamPermissionsListGet422,
	TeamMemberPermissionsTeamPermissionsListGetQueryParams,
	TeamMemberPermissionsTeamPermissionsListGetQueryResponse,
	TeamMemberUpdateTeamMemberUpdatePost422,
	TeamMemberUpdateTeamMemberUpdatePostMutationRequest,
	TeamMemberUpdateTeamMemberUpdatePostMutationResponse,
	TeamModelAddTeamModelAddPost422,
	TeamModelAddTeamModelAddPostMutationRequest,
	TeamModelAddTeamModelAddPostMutationResponse,
	TeamModelDeleteTeamModelDeletePost422,
	TeamModelDeleteTeamModelDeletePostMutationRequest,
	TeamModelDeleteTeamModelDeletePostMutationResponse,
	TestCacheConnectionCacheSettingsTestPost422,
	TestCacheConnectionCacheSettingsTestPostMutationRequest,
	TestCacheConnectionCacheSettingsTestPostMutationResponse,
	TestConnectionMcpRestTestConnectionPost422,
	TestConnectionMcpRestTestConnectionPostMutationRequest,
	TestConnectionMcpRestTestConnectionPostMutationResponse,
	TestEndpointTestGetQueryResponse,
	TestModelConnectionHealthTestConnectionPost422,
	TestModelConnectionHealthTestConnectionPostMutationRequest,
	TestModelConnectionHealthTestConnectionPostMutationResponse,
	TestSearchToolConnectionSearchToolsTestConnectionPost422,
	TestSearchToolConnectionSearchToolsTestConnectionPostMutationRequest,
	TestSearchToolConnectionSearchToolsTestConnectionPostMutationResponse,
	TestToolsListMcpRestTestToolsListPost422,
	TestToolsListMcpRestTestToolsListPostMutationRequest,
	TestToolsListMcpRestTestToolsListPostMutationResponse,
	TokenCounterUtilsTokenCounterPost422,
	TokenCounterUtilsTokenCounterPostMutationRequest,
	TokenCounterUtilsTokenCounterPostMutationResponse,
	TokenCounterUtilsTokenCounterPostQueryParams,
	TokenEndpointMcpServerNameTokenPost422,
	TokenEndpointMcpServerNameTokenPostMutationResponse,
	TokenEndpointMcpServerNameTokenPostPathParams,
	TokenEndpointTokenPost422,
	TokenEndpointTokenPostMutationResponse,
	TokenEndpointTokenPostQueryParams,
	TransformRequestUtilsTransformRequestPost422,
	TransformRequestUtilsTransformRequestPostMutationRequest,
	TransformRequestUtilsTransformRequestPostMutationResponse,
	UnblockKeyKeyUnblockPost422,
	UnblockKeyKeyUnblockPostHeaderParams,
	UnblockKeyKeyUnblockPostMutationRequest,
	UnblockKeyKeyUnblockPostMutationResponse,
	UnblockTeamTeamUnblockPost422,
	UnblockTeamTeamUnblockPostMutationRequest,
	UnblockTeamTeamUnblockPostMutationResponse,
	UnblockUserCustomerUnblockPost422,
	UnblockUserCustomerUnblockPostMutationRequest,
	UnblockUserCustomerUnblockPostMutationResponse,
	UpdateBudgetBudgetUpdatePost422,
	UpdateBudgetBudgetUpdatePostMutationRequest,
	UpdateBudgetBudgetUpdatePostMutationResponse,
	UpdateCacheSettingsCacheSettingsPost422,
	UpdateCacheSettingsCacheSettingsPostMutationRequest,
	UpdateCacheSettingsCacheSettingsPostMutationResponse,
	UpdateCloudzeroSettingsCloudzeroSettingsPut422,
	UpdateCloudzeroSettingsCloudzeroSettingsPutMutationRequest,
	UpdateCloudzeroSettingsCloudzeroSettingsPutMutationResponse,
	UpdateCostDiscountConfigConfigCostDiscountConfigPatch422,
	UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequest,
	UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationResponse,
	UpdateCredentialCredentialsCredentialNamePatch422,
	UpdateCredentialCredentialsCredentialNamePatchMutationRequest,
	UpdateCredentialCredentialsCredentialNamePatchMutationResponse,
	UpdateCredentialCredentialsCredentialNamePatchPathParams,
	UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch422,
	UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequest,
	UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationResponse,
	UpdateEndUserCustomerUpdatePost422,
	UpdateEndUserCustomerUpdatePostMutationRequest,
	UpdateEndUserCustomerUpdatePostMutationResponse,
	UpdateEventSettingsEmailEventSettingsPatch422,
	UpdateEventSettingsEmailEventSettingsPatchMutationRequest,
	UpdateEventSettingsEmailEventSettingsPatchMutationResponse,
	UpdateGroupScimV2GroupsGroupIdPut422,
	UpdateGroupScimV2GroupsGroupIdPutMutationRequest,
	UpdateGroupScimV2GroupsGroupIdPutMutationResponse,
	UpdateGroupScimV2GroupsGroupIdPutPathParams,
	UpdateGroupScimV2GroupsGroupIdPutQueryParams,
	UpdateGuardrailGuardrailsGuardrailIdPut422,
	UpdateGuardrailGuardrailsGuardrailIdPutMutationRequest,
	UpdateGuardrailGuardrailsGuardrailIdPutMutationResponse,
	UpdateGuardrailGuardrailsGuardrailIdPutPathParams,
	UpdateInternalUserSettingsUpdateInternalUserSettingsPatch422,
	UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequest,
	UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationResponse,
	UpdateKeyFnKeyUpdatePost422,
	UpdateKeyFnKeyUpdatePostHeaderParams,
	UpdateKeyFnKeyUpdatePostMutationRequest,
	UpdateKeyFnKeyUpdatePostMutationResponse,
	UpdateModelModelUpdatePost422,
	UpdateModelModelUpdatePostMutationRequest,
	UpdateModelModelUpdatePostMutationResponse,
	UpdateOrganizationOrganizationUpdatePatchMutationResponse,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost422,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequest,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationResponse,
	UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams,
	UpdatePromptPromptsPromptIdPut422,
	UpdatePromptPromptsPromptIdPutMutationRequest,
	UpdatePromptPromptsPromptIdPutMutationResponse,
	UpdatePromptPromptsPromptIdPutPathParams,
	UpdatePublicModelGroupsModelGroupMakePublicPost422,
	UpdatePublicModelGroupsModelGroupMakePublicPostMutationRequest,
	UpdatePublicModelGroupsModelGroupMakePublicPostMutationResponse,
	UpdateSearchToolSearchToolsSearchToolIdPut422,
	UpdateSearchToolSearchToolsSearchToolIdPutMutationRequest,
	UpdateSearchToolSearchToolsSearchToolIdPutMutationResponse,
	UpdateSearchToolSearchToolsSearchToolIdPutPathParams,
	UpdateSsoSettingsUpdateSsoSettingsPatch422,
	UpdateSsoSettingsUpdateSsoSettingsPatchMutationRequest,
	UpdateSsoSettingsUpdateSsoSettingsPatchMutationResponse,
	UpdateTagTagUpdatePost422,
	UpdateTagTagUpdatePostMutationRequest,
	UpdateTagTagUpdatePostMutationResponse,
	UpdateTeamMemberPermissionsTeamPermissionsUpdatePost422,
	UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequest,
	UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationResponse,
	UpdateTeamTeamUpdatePost422,
	UpdateTeamTeamUpdatePostHeaderParams,
	UpdateTeamTeamUpdatePostMutationRequest,
	UpdateTeamTeamUpdatePostMutationResponse,
	UpdateUiThemeSettingsUpdateUiThemeSettingsPatch422,
	UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequest,
	UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationResponse,
	UpdateUsefulLinksModelHubUpdateUsefulLinksPost422,
	UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequest,
	UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationResponse,
	UpdateUserScimV2UsersUserIdPut422,
	UpdateUserScimV2UsersUserIdPutMutationRequest,
	UpdateUserScimV2UsersUserIdPutMutationResponse,
	UpdateUserScimV2UsersUserIdPutPathParams,
	UpdateUserScimV2UsersUserIdPutQueryParams,
	UpdateVectorStoreVectorStoreUpdatePost422,
	UpdateVectorStoreVectorStoreUpdatePostMutationRequest,
	UpdateVectorStoreVectorStoreUpdatePostMutationResponse,
	UploadLogoUploadLogoPost422,
	UploadLogoUploadLogoPostMutationResponse,
	UserInfoUserInfoGet422,
	UserInfoUserInfoGetQueryParams,
	UserInfoUserInfoGetQueryResponse,
	UserUpdateUserUpdatePost422,
	UserUpdateUserUpdatePostMutationRequest,
	UserUpdateUserUpdatePostMutationResponse,
	ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost422,
	ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequest,
	ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationResponse,
	VectorStoreCreateV1VectorStoresPostMutationResponse,
	VectorStoreCreateVectorStoresPostMutationResponse,
	VectorStoreSearchV1VectorStoresVectorStoreIdSearchPost422,
	VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostMutationResponse,
	VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams,
	VectorStoreSearchVectorStoresVectorStoreIdSearchPost422,
	VectorStoreSearchVectorStoresVectorStoreIdSearchPostMutationResponse,
	VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams,
	VideoContentV1VideosVideoIdContentGet422,
	VideoContentV1VideosVideoIdContentGetPathParams,
	VideoContentV1VideosVideoIdContentGetQueryResponse,
	VideoContentVideosVideoIdContentGet422,
	VideoContentVideosVideoIdContentGetPathParams,
	VideoContentVideosVideoIdContentGetQueryResponse,
	VideoGenerationV1VideosPost422,
	VideoGenerationV1VideosPostMutationResponse,
	VideoGenerationVideosPost422,
	VideoGenerationVideosPostMutationResponse,
	VideoListV1VideosGetQueryResponse,
	VideoListVideosGetQueryResponse,
	VideoRemixV1VideosVideoIdRemixPost422,
	VideoRemixV1VideosVideoIdRemixPostMutationResponse,
	VideoRemixV1VideosVideoIdRemixPostPathParams,
	VideoRemixVideosVideoIdRemixPost422,
	VideoRemixVideosVideoIdRemixPostMutationResponse,
	VideoRemixVideosVideoIdRemixPostPathParams,
	VideoStatusV1VideosVideoIdGet422,
	VideoStatusV1VideosVideoIdGetPathParams,
	VideoStatusV1VideosVideoIdGetQueryResponse,
	VideoStatusVideosVideoIdGet422,
	VideoStatusVideosVideoIdGetPathParams,
	VideoStatusVideosVideoIdGetQueryResponse,
	ViewSpendLogsSpendLogsGet422,
	ViewSpendLogsSpendLogsGetQueryParams,
	ViewSpendLogsSpendLogsGetQueryResponse,
	ViewSpendTagsSpendTagsGet422,
	ViewSpendTagsSpendTagsGetQueryParams,
	ViewSpendTagsSpendTagsGetQueryResponse,
	WebsocketVertexAiLivePassthroughEndpointQueryParams,
	WebsocketVertexAiLivePassthroughEndpointQueryResponse,
	WebsocketWebsocketEndpoint2QueryParams,
	WebsocketWebsocketEndpoint2QueryResponse,
	WebsocketWebsocketEndpointQueryParams,
	WebsocketWebsocketEndpointQueryResponse,
} from "./types";

/**
 * @description Use `/model/info` - to get detailed model information, example - pricing, mode, etc.This is just for compatibility with openai projects like aider.Query Parameters:- include_metadata: Include additional metadata in the response with fallback information- fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")                Defaults to "general" when include_metadata=true
 * @summary Model List
 * {@link /models}
 */
export async function modelListModelsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelListModelsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelListModelsGetQueryResponse,
		ErrorWrapper<ModelListModelsGet422>,
		null,
		Record<string, string>,
		ModelListModelsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/models`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Use `/model/info` - to get detailed model information, example - pricing, mode, etc.This is just for compatibility with openai projects like aider.Query Parameters:- include_metadata: Include additional metadata in the response with fallback information- fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")                Defaults to "general" when include_metadata=true
 * @summary Model List
 * {@link /v1/models}
 */
export async function modelListV1ModelsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelListV1ModelsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelListV1ModelsGetQueryResponse,
		ErrorWrapper<ModelListV1ModelsGet422>,
		null,
		Record<string, string>,
		ModelListV1ModelsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/models`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieve information about a specific model accessible to your API key.Returns model details only if the model is available to your API key/team.Returns 404 if the model doesn't exist or is not accessible.Follows OpenAI API specification for individual model retrieval.https://platform.openai.com/docs/api-reference/models/retrieve
 * @summary Model Info
 * {@link /models/:model_id}
 */
export async function modelInfoModelsModelIdGet({
	pathParams,
	config = {},
}: {
	pathParams: ModelInfoModelsModelIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		ModelInfoModelsModelIdGetQueryResponse,
		ErrorWrapper<ModelInfoModelsModelIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ModelInfoModelsModelIdGetPathParams
	>({ method: "GET", url: `/models/${pathParams["modelId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieve information about a specific model accessible to your API key.Returns model details only if the model is available to your API key/team.Returns 404 if the model doesn't exist or is not accessible.Follows OpenAI API specification for individual model retrieval.https://platform.openai.com/docs/api-reference/models/retrieve
 * @summary Model Info
 * {@link /v1/models/:model_id}
 */
export async function modelInfoV1ModelsModelIdGet({
	pathParams,
	config = {},
}: {
	pathParams: ModelInfoV1ModelsModelIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		ModelInfoV1ModelsModelIdGetQueryResponse,
		ErrorWrapper<ModelInfoV1ModelsModelIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ModelInfoV1ModelsModelIdGetPathParams
	>({ method: "GET", url: `/v1/models/${pathParams["modelId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /openai/deployments/:model/chat/completions}
 */
export async function chatCompletionOpenaiDeploymentsModelChatCompletionsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams;
	body: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationResponse,
		ErrorWrapper<
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost400
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost401
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost403
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost404
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost408
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost422
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost429
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost500
			| ChatCompletionOpenaiDeploymentsModelChatCompletionsPost503
		>,
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/chat/completions`,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /engines/:model/chat/completions}
 */
export async function chatCompletionEnginesModelChatCompletionsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: ChatCompletionEnginesModelChatCompletionsPostPathParams;
	body: ChatCompletionEnginesModelChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		ChatCompletionEnginesModelChatCompletionsPostMutationResponse,
		ErrorWrapper<ChatCompletionEnginesModelChatCompletionsPost422>,
		ChatCompletionEnginesModelChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		ChatCompletionEnginesModelChatCompletionsPostPathParams
	>({
		method: "POST",
		url: `/engines/${pathParams["model"]}/chat/completions`,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /chat/completions}
 */
export async function chatCompletionChatCompletionsPost({
	body,
	config = {},
}: {
	body: ChatCompletionChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ChatCompletionChatCompletionsPostMutationResponse,
		ErrorWrapper<ChatCompletionChatCompletionsPost422>,
		ChatCompletionChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/chat/completions`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat````bashcurl -X POST http://localhost:4000/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-4o",    "messages": [        {            "role": "user",            "content": "Hello!"        }    ]}'```
 * @summary Chat Completion
 * {@link /v1/chat/completions}
 */
export async function chatCompletionV1ChatCompletionsPost({
	body,
	config = {},
}: {
	body: ChatCompletionV1ChatCompletionsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ChatCompletionV1ChatCompletionsPostMutationResponse,
		ErrorWrapper<ChatCompletionV1ChatCompletionsPost422>,
		ChatCompletionV1ChatCompletionsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/chat/completions`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /openai/deployments/:model/completions}
 */
export async function completionOpenaiDeploymentsModelCompletionsPost({
	pathParams,
	config = {},
}: {
	pathParams: CompletionOpenaiDeploymentsModelCompletionsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		CompletionOpenaiDeploymentsModelCompletionsPostMutationResponse,
		ErrorWrapper<CompletionOpenaiDeploymentsModelCompletionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CompletionOpenaiDeploymentsModelCompletionsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/completions`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /engines/:model/completions}
 */
export async function completionEnginesModelCompletionsPost({
	pathParams,
	config = {},
}: {
	pathParams: CompletionEnginesModelCompletionsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		CompletionEnginesModelCompletionsPostMutationResponse,
		ErrorWrapper<CompletionEnginesModelCompletionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CompletionEnginesModelCompletionsPostPathParams
	>({ method: "POST", url: `/engines/${pathParams["model"]}/completions`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /completions}
 */
export async function completionCompletionsPost({
	queryParams,
	config = {},
}: {
	queryParams?: CompletionCompletionsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CompletionCompletionsPostMutationResponse,
		ErrorWrapper<CompletionCompletionsPost422>,
		null,
		Record<string, string>,
		CompletionCompletionsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/completions`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions````bashcurl -X POST http://localhost:4000/v1/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "gpt-3.5-turbo-instruct",    "prompt": "Once upon a time",    "max_tokens": 50,    "temperature": 0.7}'```
 * @summary Completion
 * {@link /v1/completions}
 */
export async function completionV1CompletionsPost({
	queryParams,
	config = {},
}: {
	queryParams?: CompletionV1CompletionsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CompletionV1CompletionsPostMutationResponse,
		ErrorWrapper<CompletionV1CompletionsPost422>,
		null,
		Record<string, string>,
		CompletionV1CompletionsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/completions`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /openai/deployments/:model/embeddings}
 */
export async function embeddingsOpenaiDeploymentsModelEmbeddingsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams;
	body: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsOpenaiDeploymentsModelEmbeddingsPost422>,
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/embeddings`,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /engines/:model/embeddings}
 */
export async function embeddingsEnginesModelEmbeddingsPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: EmbeddingsEnginesModelEmbeddingsPostPathParams;
	body: EmbeddingsEnginesModelEmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		EmbeddingsEnginesModelEmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsEnginesModelEmbeddingsPost422>,
		EmbeddingsEnginesModelEmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		EmbeddingsEnginesModelEmbeddingsPostPathParams
	>({ method: "POST", url: `/engines/${pathParams["model"]}/embeddings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /embeddings}
 */
export async function embeddingsEmbeddingsPost({
	body,
	config = {},
}: {
	body: EmbeddingsEmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EmbeddingsEmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsEmbeddingsPost422>,
		EmbeddingsEmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/embeddings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings````bashcurl -X POST http://localhost:4000/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer sk-1234" -d '{    "model": "text-embedding-ada-002",    "input": "The quick brown fox jumps over the lazy dog"}'```
 * @summary Embeddings
 * {@link /v1/embeddings}
 */
export async function embeddingsV1EmbeddingsPost({
	body,
	config = {},
}: {
	body: EmbeddingsV1EmbeddingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EmbeddingsV1EmbeddingsPostMutationResponse,
		ErrorWrapper<EmbeddingsV1EmbeddingsPost422>,
		EmbeddingsV1EmbeddingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/embeddings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.Quick Start```curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'```
 * @summary Moderations
 * {@link /moderations}
 */
export async function moderationsModerationsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModerationsModerationsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/moderations`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.Quick Start```curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'```
 * @summary Moderations
 * {@link /v1/moderations}
 */
export async function moderationsV1ModerationsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModerationsV1ModerationsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/moderations`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createSpeech
 * @summary Audio Speech
 * {@link /audio/speech}
 */
export async function audioSpeechAudioSpeechPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AudioSpeechAudioSpeechPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/audio/speech`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createSpeech
 * @summary Audio Speech
 * {@link /v1/audio/speech}
 */
export async function audioSpeechV1AudioSpeechPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AudioSpeechV1AudioSpeechPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/audio/speech`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 * @summary Audio Transcriptions
 * {@link /audio/transcriptions}
 */
export async function audioTranscriptionsAudioTranscriptionsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		AudioTranscriptionsAudioTranscriptionsPostMutationResponse,
		ErrorWrapper<AudioTranscriptionsAudioTranscriptionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/audio/transcriptions`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Same params as:https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 * @summary Audio Transcriptions
 * {@link /v1/audio/transcriptions}
 */
export async function audioTranscriptionsV1AudioTranscriptionsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		AudioTranscriptionsV1AudioTranscriptionsPostMutationResponse,
		ErrorWrapper<AudioTranscriptionsV1AudioTranscriptionsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/audio/transcriptions`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns a list of assistants.API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 * @summary Get Assistants
 * {@link /assistants}
 */
export async function getAssistantsAssistantsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAssistantsAssistantsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/assistants`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Create Assistant
 * {@link /assistants}
 */
export async function createAssistantAssistantsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateAssistantAssistantsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/assistants`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns a list of assistants.API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 * @summary Get Assistants
 * {@link /v1/assistants}
 */
export async function getAssistantsV1AssistantsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAssistantsV1AssistantsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/assistants`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Create Assistant
 * {@link /v1/assistants}
 */
export async function createAssistantV1AssistantsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateAssistantV1AssistantsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/assistants`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Delete Assistant
 * {@link /assistants/:assistant_id}
 */
export async function deleteAssistantAssistantsAssistantIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteAssistantAssistantsAssistantIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["assistant_id"]) {
		throw new Error(`Missing required path parameter: assistant_id`);
	}
	const data = await request<
		DeleteAssistantAssistantsAssistantIdDeleteMutationResponse,
		ErrorWrapper<DeleteAssistantAssistantsAssistantIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteAssistantAssistantsAssistantIdDeletePathParams
	>({ method: "DELETE", url: `/assistants/${pathParams["assistantId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete assistantAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 * @summary Delete Assistant
 * {@link /v1/assistants/:assistant_id}
 */
export async function deleteAssistantV1AssistantsAssistantIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteAssistantV1AssistantsAssistantIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["assistant_id"]) {
		throw new Error(`Missing required path parameter: assistant_id`);
	}
	const data = await request<
		DeleteAssistantV1AssistantsAssistantIdDeleteMutationResponse,
		ErrorWrapper<DeleteAssistantV1AssistantsAssistantIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteAssistantV1AssistantsAssistantIdDeletePathParams
	>({ method: "DELETE", url: `/v1/assistants/${pathParams["assistantId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 * @summary Create Threads
 * {@link /threads}
 */
export async function createThreadsThreadsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateThreadsThreadsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/threads`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 * @summary Create Threads
 * {@link /v1/threads}
 */
export async function createThreadsV1ThreadsPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateThreadsV1ThreadsPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/threads`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 * @summary Get Thread
 * {@link /threads/:thread_id}
 */
export async function getThreadThreadsThreadIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetThreadThreadsThreadIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetThreadThreadsThreadIdGetQueryResponse,
		ErrorWrapper<GetThreadThreadsThreadIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetThreadThreadsThreadIdGetPathParams
	>({ method: "GET", url: `/threads/${pathParams["threadId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a thread.API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 * @summary Get Thread
 * {@link /v1/threads/:thread_id}
 */
export async function getThreadV1ThreadsThreadIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetThreadV1ThreadsThreadIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetThreadV1ThreadsThreadIdGetQueryResponse,
		ErrorWrapper<GetThreadV1ThreadsThreadIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetThreadV1ThreadsThreadIdGetPathParams
	>({ method: "GET", url: `/v1/threads/${pathParams["threadId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a message.API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 * @summary Add Messages
 * {@link /threads/:thread_id/messages}
 */
export async function addMessagesThreadsThreadIdMessagesPost({
	pathParams,
	config = {},
}: {
	pathParams: AddMessagesThreadsThreadIdMessagesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		AddMessagesThreadsThreadIdMessagesPostMutationResponse,
		ErrorWrapper<AddMessagesThreadsThreadIdMessagesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		AddMessagesThreadsThreadIdMessagesPostPathParams
	>({ method: "POST", url: `/threads/${pathParams["threadId"]}/messages`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns a list of messages for a given thread.API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 * @summary Get Messages
 * {@link /threads/:thread_id/messages}
 */
export async function getMessagesThreadsThreadIdMessagesGet({
	pathParams,
	config = {},
}: {
	pathParams: GetMessagesThreadsThreadIdMessagesGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetMessagesThreadsThreadIdMessagesGetQueryResponse,
		ErrorWrapper<GetMessagesThreadsThreadIdMessagesGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetMessagesThreadsThreadIdMessagesGetPathParams
	>({ method: "GET", url: `/threads/${pathParams["threadId"]}/messages`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a message.API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 * @summary Add Messages
 * {@link /v1/threads/:thread_id/messages}
 */
export async function addMessagesV1ThreadsThreadIdMessagesPost({
	pathParams,
	config = {},
}: {
	pathParams: AddMessagesV1ThreadsThreadIdMessagesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		AddMessagesV1ThreadsThreadIdMessagesPostMutationResponse,
		ErrorWrapper<AddMessagesV1ThreadsThreadIdMessagesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		AddMessagesV1ThreadsThreadIdMessagesPostPathParams
	>({ method: "POST", url: `/v1/threads/${pathParams["threadId"]}/messages`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns a list of messages for a given thread.API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 * @summary Get Messages
 * {@link /v1/threads/:thread_id/messages}
 */
export async function getMessagesV1ThreadsThreadIdMessagesGet({
	pathParams,
	config = {},
}: {
	pathParams: GetMessagesV1ThreadsThreadIdMessagesGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		GetMessagesV1ThreadsThreadIdMessagesGetQueryResponse,
		ErrorWrapper<GetMessagesV1ThreadsThreadIdMessagesGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetMessagesV1ThreadsThreadIdMessagesGetPathParams
	>({ method: "GET", url: `/v1/threads/${pathParams["threadId"]}/messages`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a run.API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 * @summary Run Thread
 * {@link /threads/:thread_id/runs}
 */
export async function runThreadThreadsThreadIdRunsPost({
	pathParams,
	config = {},
}: {
	pathParams: RunThreadThreadsThreadIdRunsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		RunThreadThreadsThreadIdRunsPostMutationResponse,
		ErrorWrapper<RunThreadThreadsThreadIdRunsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RunThreadThreadsThreadIdRunsPostPathParams
	>({ method: "POST", url: `/threads/${pathParams["threadId"]}/runs`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a run.API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 * @summary Run Thread
 * {@link /v1/threads/:thread_id/runs}
 */
export async function runThreadV1ThreadsThreadIdRunsPost({
	pathParams,
	config = {},
}: {
	pathParams: RunThreadV1ThreadsThreadIdRunsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["thread_id"]) {
		throw new Error(`Missing required path parameter: thread_id`);
	}
	const data = await request<
		RunThreadV1ThreadsThreadIdRunsPostMutationResponse,
		ErrorWrapper<RunThreadV1ThreadsThreadIdRunsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RunThreadV1ThreadsThreadIdRunsPostPathParams
	>({ method: "POST", url: `/v1/threads/${pathParams["threadId"]}/runs`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Args:    request: TokenCountRequest    call_endpoint: bool - When set to "True" it will call the token counting endpoint - e.g Anthropic or Google AI Studio Token Counting APIs.Returns:    TokenCountResponse
 * @summary Token Counter
 * {@link /utils/token_counter}
 */
export async function tokenCounterUtilsTokenCounterPost({
	body,
	queryParams,
	config = {},
}: {
	body: TokenCounterUtilsTokenCounterPostMutationRequest;
	queryParams?: TokenCounterUtilsTokenCounterPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TokenCounterUtilsTokenCounterPostMutationResponse,
		ErrorWrapper<TokenCounterUtilsTokenCounterPost422>,
		TokenCounterUtilsTokenCounterPostMutationRequest,
		Record<string, string>,
		TokenCounterUtilsTokenCounterPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/utils/token_counter`, queryParams, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns supported openai params for a given litellm model namee.g. `gpt-4` vs `gpt-3.5-turbo`Example curl:```curl -X GET --location 'http://localhost:4000/utils/supported_openai_params?model=gpt-3.5-turbo-16k'         --header 'Authorization: Bearer sk-1234'```
 * @summary Supported Openai Params
 * {@link /utils/supported_openai_params}
 */
export async function supportedOpenaiParamsUtilsSupportedOpenaiParamsGet({
	queryParams,
	config = {},
}: {
	queryParams: SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryResponse,
		ErrorWrapper<SupportedOpenaiParamsUtilsSupportedOpenaiParamsGet422>,
		null,
		Record<string, string>,
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/utils/supported_openai_params`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Transform Request
 * {@link /utils/transform_request}
 */
export async function transformRequestUtilsTransformRequestPost({
	body,
	config = {},
}: {
	body: TransformRequestUtilsTransformRequestPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TransformRequestUtilsTransformRequestPostMutationResponse,
		ErrorWrapper<TransformRequestUtilsTransformRequestPost422>,
		TransformRequestUtilsTransformRequestPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/utils/transform_request`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)Parameters:    litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)    - When litellm_model_id is passed, it will return the info for that specific model    - When litellm_model_id is not passed, it will return the info for all modelsReturns:    Returns a dictionary containing information about each model.Example Response:```json{    "data": [                {                    "model_name": "fake-openai-endpoint",                    "litellm_params": {                        "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",                        "model": "openai/fake"                    },                    "model_info": {                        "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",                        "db_model": false                    }                }            ]}```
 * @summary Model Info V1
 * {@link /v1/model/info}
 */
export async function modelInfoV1V1ModelInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelInfoV1V1ModelInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelInfoV1V1ModelInfoGetQueryResponse,
		ErrorWrapper<ModelInfoV1V1ModelInfoGet422>,
		null,
		Record<string, string>,
		ModelInfoV1V1ModelInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/model/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)Parameters:    litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)    - When litellm_model_id is passed, it will return the info for that specific model    - When litellm_model_id is not passed, it will return the info for all modelsReturns:    Returns a dictionary containing information about each model.Example Response:```json{    "data": [                {                    "model_name": "fake-openai-endpoint",                    "litellm_params": {                        "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",                        "model": "openai/fake"                    },                    "model_info": {                        "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",                        "db_model": false                    }                }            ]}```
 * @summary Model Info V1
 * {@link /model/info}
 */
export async function modelInfoV1ModelInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelInfoV1ModelInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelInfoV1ModelInfoGetQueryResponse,
		ErrorWrapper<ModelInfoV1ModelInfoGet422>,
		null,
		Record<string, string>,
		ModelInfoV1ModelInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/model/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get information about all the deployments on litellm proxy, including config.yaml descriptions (except api key and api base)- /model_group/info returns all model groups. End users of proxy should use /model_group/info since those models will be used for /chat/completions, /embeddings, etc.- /model_group/info?model_group=rerank-english-v3.0 returns all model groups for a specific model group (`model_name` in config.yaml)Example Request (All Models):```shellcurl -X 'GET'     'http://localhost:4000/model_group/info'     -H 'accept: application/json'     -H 'x-api-key: sk-1234'```Example Request (Specific Model Group):```shellcurl -X 'GET'     'http://localhost:4000/model_group/info?model_group=rerank-english-v3.0'     -H 'accept: application/json'     -H 'Authorization: Bearer sk-1234'```Example Request (Specific Wildcard Model Group): (e.g. `model_name: openai/*` on config.yaml)```shellcurl -X 'GET'     'http://localhost:4000/model_group/info?model_group=openai/tts-1'-H 'accept: application/json'     -H 'Authorization: Bearersk-1234'```Learn how to use and set wildcard models [here](https://docs.litellm.ai/docs/wildcard_routing)Example Response:```json    {        "data": [            {            "model_group": "rerank-english-v3.0",            "providers": [                "cohere"            ],            "max_input_tokens": null,            "max_output_tokens": null,            "input_cost_per_token": 0.0,            "output_cost_per_token": 0.0,            "mode": null,            "tpm": null,            "rpm": null,            "supports_parallel_function_calling": false,            "supports_vision": false,            "supports_function_calling": false,            "supported_openai_params": [                "stream",                "temperature",                "max_tokens",                "logit_bias",                "top_p",                "frequency_penalty",                "presence_penalty",                "stop",                "n",                "extra_headers"            ]            },            {            "model_group": "gpt-3.5-turbo",            "providers": [                "openai"            ],            "max_input_tokens": 16385.0,            "max_output_tokens": 4096.0,            "input_cost_per_token": 1.5e-06,            "output_cost_per_token": 2e-06,            "mode": "chat",            "tpm": null,            "rpm": null,            "supports_parallel_function_calling": false,            "supports_vision": false,            "supports_function_calling": true,            "supported_openai_params": [                "frequency_penalty",                "logit_bias",                "logprobs",                "top_logprobs",                "max_tokens",                "max_completion_tokens",                "n",                "presence_penalty",                "seed",                "stop",                "stream",                "stream_options",                "temperature",                "top_p",                "tools",                "tool_choice",                "function_call",                "functions",                "max_retries",                "extra_headers",                "parallel_tool_calls",                "response_format"            ]            },            {            "model_group": "llava-hf",            "providers": [                "openai"            ],            "max_input_tokens": null,            "max_output_tokens": null,            "input_cost_per_token": 0.0,            "output_cost_per_token": 0.0,            "mode": null,            "tpm": null,            "rpm": null,            "supports_parallel_function_calling": false,            "supports_vision": true,            "supports_function_calling": false,            "supported_openai_params": [                "frequency_penalty",                "logit_bias",                "logprobs",                "top_logprobs",                "max_tokens",                "max_completion_tokens",                "n",                "presence_penalty",                "seed",                "stop",                "stream",                "stream_options",                "temperature",                "top_p",                "tools",                "tool_choice",                "function_call",                "functions",                "max_retries",                "extra_headers",                "parallel_tool_calls",                "response_format"            ]            }        ]        }```
 * @summary Model Group Info
 * {@link /model_group/info}
 */
export async function modelGroupInfoModelGroupInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: ModelGroupInfoModelGroupInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ModelGroupInfoModelGroupInfoGetQueryResponse,
		ErrorWrapper<ModelGroupInfoModelGroupInfoGet422>,
		null,
		Record<string, string>,
		ModelGroupInfoModelGroupInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/model_group/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Home
 * {@link /}
 */
export async function homeGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HomeGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a list of available routes in the FastAPI application.
 * @summary Get Routes
 * {@link /routes}
 */
export async function getRoutesRoutesGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetRoutesRoutesGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/routes`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses```bashcurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{    "model": "gpt-4o",    "input": "Tell me about AI"}'```
 * @summary Responses Api
 * {@link /openai/v1/responses}
 */
export async function responsesApiOpenaiV1ResponsesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResponsesApiOpenaiV1ResponsesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/openai/v1/responses`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses```bashcurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{    "model": "gpt-4o",    "input": "Tell me about AI"}'```
 * @summary Responses Api
 * {@link /responses}
 */
export async function responsesApiResponsesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResponsesApiResponsesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/responses`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses```bashcurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{    "model": "gpt-4o",    "input": "Tell me about AI"}'```
 * @summary Responses Api
 * {@link /v1/responses}
 */
export async function responsesApiV1ResponsesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResponsesApiV1ResponsesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/responses`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get```bashcurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Get Response
 * {@link /openai/v1/responses/:response_id}
 */
export async function getResponseOpenaiV1ResponsesResponseIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseOpenaiV1ResponsesResponseIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseOpenaiV1ResponsesResponseIdGetQueryResponse,
		ErrorWrapper<GetResponseOpenaiV1ResponsesResponseIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseOpenaiV1ResponsesResponseIdGetPathParams
	>({ method: "GET", url: `/openai/v1/responses/${pathParams["responseId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete```bashcurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Delete Response
 * {@link /openai/v1/responses/:response_id}
 */
export async function deleteResponseOpenaiV1ResponsesResponseIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		DeleteResponseOpenaiV1ResponsesResponseIdDeleteMutationResponse,
		ErrorWrapper<DeleteResponseOpenaiV1ResponsesResponseIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams
	>({
		method: "DELETE",
		url: `/openai/v1/responses/${pathParams["responseId"]}`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get```bashcurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Get Response
 * {@link /responses/:response_id}
 */
export async function getResponseResponsesResponseIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseResponsesResponseIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseResponsesResponseIdGetQueryResponse,
		ErrorWrapper<GetResponseResponsesResponseIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseResponsesResponseIdGetPathParams
	>({ method: "GET", url: `/responses/${pathParams["responseId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete```bashcurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Delete Response
 * {@link /responses/:response_id}
 */
export async function deleteResponseResponsesResponseIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteResponseResponsesResponseIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		DeleteResponseResponsesResponseIdDeleteMutationResponse,
		ErrorWrapper<DeleteResponseResponsesResponseIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteResponseResponsesResponseIdDeletePathParams
	>({ method: "DELETE", url: `/responses/${pathParams["responseId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get```bashcurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Get Response
 * {@link /v1/responses/:response_id}
 */
export async function getResponseV1ResponsesResponseIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseV1ResponsesResponseIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseV1ResponsesResponseIdGetQueryResponse,
		ErrorWrapper<GetResponseV1ResponsesResponseIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseV1ResponsesResponseIdGetPathParams
	>({ method: "GET", url: `/v1/responses/${pathParams["responseId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete```bashcurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"```
 * @summary Delete Response
 * {@link /v1/responses/:response_id}
 */
export async function deleteResponseV1ResponsesResponseIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteResponseV1ResponsesResponseIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		DeleteResponseV1ResponsesResponseIdDeleteMutationResponse,
		ErrorWrapper<DeleteResponseV1ResponsesResponseIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteResponseV1ResponsesResponseIdDeletePathParams
	>({ method: "DELETE", url: `/v1/responses/${pathParams["responseId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List input items for a response.
 * @summary Get Response Input Items
 * {@link /openai/v1/responses/:response_id/input_items}
 */
export async function getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetQueryResponse,
		ErrorWrapper<GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams
	>({
		method: "GET",
		url: `/openai/v1/responses/${pathParams["responseId"]}/input_items`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List input items for a response.
 * @summary Get Response Input Items
 * {@link /responses/:response_id/input_items}
 */
export async function getResponseInputItemsResponsesResponseIdInputItemsGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseInputItemsResponsesResponseIdInputItemsGetQueryResponse,
		ErrorWrapper<GetResponseInputItemsResponsesResponseIdInputItemsGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams
	>({ method: "GET", url: `/responses/${pathParams["responseId"]}/input_items`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List input items for a response.
 * @summary Get Response Input Items
 * {@link /v1/responses/:response_id/input_items}
 */
export async function getResponseInputItemsV1ResponsesResponseIdInputItemsGet({
	pathParams,
	config = {},
}: {
	pathParams: GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetQueryResponse,
		ErrorWrapper<GetResponseInputItemsV1ResponsesResponseIdInputItemsGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams
	>({
		method: "GET",
		url: `/v1/responses/${pathParams["responseId"]}/input_items`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel```bashcurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"```
 * @summary Cancel Response
 * {@link /openai/v1/responses/:response_id/cancel}
 */
export async function cancelResponseOpenaiV1ResponsesResponseIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostMutationResponse,
		ErrorWrapper<CancelResponseOpenaiV1ResponsesResponseIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams
	>({
		method: "POST",
		url: `/openai/v1/responses/${pathParams["responseId"]}/cancel`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel```bashcurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"```
 * @summary Cancel Response
 * {@link /responses/:response_id/cancel}
 */
export async function cancelResponseResponsesResponseIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelResponseResponsesResponseIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		CancelResponseResponsesResponseIdCancelPostMutationResponse,
		ErrorWrapper<CancelResponseResponsesResponseIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelResponseResponsesResponseIdCancelPostPathParams
	>({ method: "POST", url: `/responses/${pathParams["responseId"]}/cancel`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a response by ID.Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel```bashcurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"```
 * @summary Cancel Response
 * {@link /v1/responses/:response_id/cancel}
 */
export async function cancelResponseV1ResponsesResponseIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelResponseV1ResponsesResponseIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["response_id"]) {
		throw new Error(`Missing required path parameter: response_id`);
	}
	const data = await request<
		CancelResponseV1ResponsesResponseIdCancelPostMutationResponse,
		ErrorWrapper<CancelResponseV1ResponsesResponseIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelResponseV1ResponsesResponseIdCancelPostPathParams
	>({ method: "POST", url: `/v1/responses/${pathParams["responseId"]}/cancel`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create large batches of API requests for asynchronous processing.This is the equivalent of POST https://api.openai.com/v1/batchSupports Identical Params as: https://platform.openai.com/docs/api-reference/batchExample Curl```curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "input_file_id": "file-abc123",        "endpoint": "/v1/chat/completions",        "completion_window": "24h"}'```
 * @summary Create Batch
 * {@link /batches}
 */
export async function createBatchBatchesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateBatchBatchesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateBatchBatchesPostMutationResponse,
		ErrorWrapper<CreateBatchBatchesPost422>,
		null,
		Record<string, string>,
		CreateBatchBatchesPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/batches`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Lists This is the equivalent of GET https://api.openai.com/v1/batches/Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/listExample Curl```curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary List Batches
 * {@link /batches}
 */
export async function listBatchesBatchesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListBatchesBatchesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListBatchesBatchesGetQueryResponse,
		ErrorWrapper<ListBatchesBatchesGet422>,
		null,
		Record<string, string>,
		ListBatchesBatchesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/batches`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create large batches of API requests for asynchronous processing.This is the equivalent of POST https://api.openai.com/v1/batchSupports Identical Params as: https://platform.openai.com/docs/api-reference/batchExample Curl```curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "input_file_id": "file-abc123",        "endpoint": "/v1/chat/completions",        "completion_window": "24h"}'```
 * @summary Create Batch
 * {@link /v1/batches}
 */
export async function createBatchV1BatchesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateBatchV1BatchesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateBatchV1BatchesPostMutationResponse,
		ErrorWrapper<CreateBatchV1BatchesPost422>,
		null,
		Record<string, string>,
		CreateBatchV1BatchesPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/batches`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Lists This is the equivalent of GET https://api.openai.com/v1/batches/Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/listExample Curl```curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary List Batches
 * {@link /v1/batches}
 */
export async function listBatchesV1BatchesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListBatchesV1BatchesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListBatchesV1BatchesGetQueryResponse,
		ErrorWrapper<ListBatchesV1BatchesGet422>,
		null,
		Record<string, string>,
		ListBatchesV1BatchesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/batches`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create large batches of API requests for asynchronous processing.This is the equivalent of POST https://api.openai.com/v1/batchSupports Identical Params as: https://platform.openai.com/docs/api-reference/batchExample Curl```curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "input_file_id": "file-abc123",        "endpoint": "/v1/chat/completions",        "completion_window": "24h"}'```
 * @summary Create Batch
 * {@link /:provider/v1/batches}
 */
export async function createBatchProviderV1BatchesPost({
	pathParams,
	config = {},
}: {
	pathParams: CreateBatchProviderV1BatchesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		CreateBatchProviderV1BatchesPostMutationResponse,
		ErrorWrapper<CreateBatchProviderV1BatchesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CreateBatchProviderV1BatchesPostPathParams
	>({ method: "POST", url: `/${pathParams["provider"]}/v1/batches`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Lists This is the equivalent of GET https://api.openai.com/v1/batches/Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/listExample Curl```curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary List Batches
 * {@link /:provider/v1/batches}
 */
export async function listBatchesProviderV1BatchesGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: ListBatchesProviderV1BatchesGetPathParams;
	queryParams?: ListBatchesProviderV1BatchesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		ListBatchesProviderV1BatchesGetQueryResponse,
		ErrorWrapper<ListBatchesProviderV1BatchesGet422>,
		null,
		Record<string, string>,
		ListBatchesProviderV1BatchesGetQueryParams,
		ListBatchesProviderV1BatchesGetPathParams
	>({ method: "GET", url: `/${pathParams["provider"]}/v1/batches`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a batch.This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieveExample Curl```curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary Retrieve Batch
 * {@link /batches/:batch_id}
 */
export async function retrieveBatchBatchesBatchIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveBatchBatchesBatchIdGetPathParams;
	queryParams?: RetrieveBatchBatchesBatchIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		RetrieveBatchBatchesBatchIdGetQueryResponse,
		ErrorWrapper<RetrieveBatchBatchesBatchIdGet422>,
		null,
		Record<string, string>,
		RetrieveBatchBatchesBatchIdGetQueryParams,
		RetrieveBatchBatchesBatchIdGetPathParams
	>({ method: "GET", url: `/batches/${pathParams["batchId"]}`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a batch.This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieveExample Curl```curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary Retrieve Batch
 * {@link /v1/batches/:batch_id}
 */
export async function retrieveBatchV1BatchesBatchIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveBatchV1BatchesBatchIdGetPathParams;
	queryParams?: RetrieveBatchV1BatchesBatchIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		RetrieveBatchV1BatchesBatchIdGetQueryResponse,
		ErrorWrapper<RetrieveBatchV1BatchesBatchIdGet422>,
		null,
		Record<string, string>,
		RetrieveBatchV1BatchesBatchIdGetQueryParams,
		RetrieveBatchV1BatchesBatchIdGetPathParams
	>({ method: "GET", url: `/v1/batches/${pathParams["batchId"]}`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a batch.This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieveExample Curl```curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" ```
 * @summary Retrieve Batch
 * {@link /:provider/v1/batches/:batch_id}
 */
export async function retrieveBatchProviderV1BatchesBatchIdGet({
	pathParams,
	config = {},
}: {
	pathParams: RetrieveBatchProviderV1BatchesBatchIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		RetrieveBatchProviderV1BatchesBatchIdGetQueryResponse,
		ErrorWrapper<RetrieveBatchProviderV1BatchesBatchIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RetrieveBatchProviderV1BatchesBatchIdGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["provider"]}/v1/batches/${pathParams["batchId"]}`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a batch.This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancelSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancelExample Curl```curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST```
 * @summary Cancel Batch
 * {@link /batches/:batch_id/cancel}
 */
export async function cancelBatchBatchesBatchIdCancelPost({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: CancelBatchBatchesBatchIdCancelPostPathParams;
	queryParams?: CancelBatchBatchesBatchIdCancelPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		CancelBatchBatchesBatchIdCancelPostMutationResponse,
		ErrorWrapper<CancelBatchBatchesBatchIdCancelPost422>,
		null,
		Record<string, string>,
		CancelBatchBatchesBatchIdCancelPostQueryParams,
		CancelBatchBatchesBatchIdCancelPostPathParams
	>({
		method: "POST",
		url: `/batches/${pathParams["batchId"]}/cancel`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a batch.This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancelSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancelExample Curl```curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST```
 * @summary Cancel Batch
 * {@link /v1/batches/:batch_id/cancel}
 */
export async function cancelBatchV1BatchesBatchIdCancelPost({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: CancelBatchV1BatchesBatchIdCancelPostPathParams;
	queryParams?: CancelBatchV1BatchesBatchIdCancelPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}
	const data = await request<
		CancelBatchV1BatchesBatchIdCancelPostMutationResponse,
		ErrorWrapper<CancelBatchV1BatchesBatchIdCancelPost422>,
		null,
		Record<string, string>,
		CancelBatchV1BatchesBatchIdCancelPostQueryParams,
		CancelBatchV1BatchesBatchIdCancelPostPathParams
	>({
		method: "POST",
		url: `/v1/batches/${pathParams["batchId"]}/cancel`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a batch.This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancelSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancelExample Curl```curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST```
 * @summary Cancel Batch
 * {@link /:provider/v1/batches/:batch_id/cancel}
 */
export async function cancelBatchProviderV1BatchesBatchIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelBatchProviderV1BatchesBatchIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["batch_id"]) {
		throw new Error(`Missing required path parameter: batch_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		CancelBatchProviderV1BatchesBatchIdCancelPostMutationResponse,
		ErrorWrapper<CancelBatchProviderV1BatchesBatchIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelBatchProviderV1BatchesBatchIdCancelPostPathParams
	>({
		method: "POST",
		url: `/${pathParams["provider"]}/v1/batches/${pathParams["batchId"]}/cancel`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Public Model Hub
 * {@link /public/model_hub}
 */
export async function publicModelHubPublicModelHubGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		PublicModelHubPublicModelHubGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/public/model_hub`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Public Model Hub Info
 * {@link /public/model_hub/info}
 */
export async function publicModelHubInfoPublicModelHubInfoGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		PublicModelHubInfoPublicModelHubInfoGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/public/model_hub/info`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Rerank
 * {@link /rerank}
 */
export async function rerankRerankPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RerankRerankPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/rerank`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Rerank
 * {@link /v1/rerank}
 */
export async function rerankV1RerankPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RerankV1RerankPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/rerank`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Rerank
 * {@link /v2/rerank}
 */
export async function rerankV2RerankPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RerankV2RerankPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v2/rerank`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description OCR endpoint for extracting text from documents and images.Follows the Mistral OCR API spec:https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocrExample:```bashcurl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "mistral/mistral-ocr-latest",        "document": {            "type": "document_url",            "document_url": "https://arxiv.org/pdf/2201.04234"        }    }'```
 * @summary Ocr
 * {@link /ocr}
 */
export async function ocrOcrPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OcrOcrPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/ocr`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description OCR endpoint for extracting text from documents and images.Follows the Mistral OCR API spec:https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocrExample:```bashcurl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "mistral/mistral-ocr-latest",        "document": {            "type": "document_url",            "document_url": "https://arxiv.org/pdf/2201.04234"        }    }'```
 * @summary Ocr
 * {@link /v1/ocr}
 */
export async function ocrV1OcrPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OcrV1OcrPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/ocr`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video list endpoint for retrieving a list of videos.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"```
 * @summary Video List
 * {@link /videos}
 */
export async function videoListVideosGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VideoListVideosGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/videos`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video generation endpoint for creating videos from text prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "sora-2",        "prompt": "A beautiful sunset over the ocean"    }'```
 * @summary Video Generation
 * {@link /videos}
 */
export async function videoGenerationVideosPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		VideoGenerationVideosPostMutationResponse,
		ErrorWrapper<VideoGenerationVideosPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/videos`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video list endpoint for retrieving a list of videos.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"```
 * @summary Video List
 * {@link /v1/videos}
 */
export async function videoListV1VideosGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VideoListV1VideosGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/videos`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video generation endpoint for creating videos from text prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "model": "sora-2",        "prompt": "A beautiful sunset over the ocean"    }'```
 * @summary Video Generation
 * {@link /v1/videos}
 */
export async function videoGenerationV1VideosPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		VideoGenerationV1VideosPostMutationResponse,
		ErrorWrapper<VideoGenerationV1VideosPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/videos`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video status endpoint for retrieving video status and metadata.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"```
 * @summary Video Status
 * {@link /videos/:video_id}
 */
export async function videoStatusVideosVideoIdGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoStatusVideosVideoIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoStatusVideosVideoIdGetQueryResponse,
		ErrorWrapper<VideoStatusVideosVideoIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoStatusVideosVideoIdGetPathParams
	>({ method: "GET", url: `/videos/${pathParams["videoId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video status endpoint for retrieving video status and metadata.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"```
 * @summary Video Status
 * {@link /v1/videos/:video_id}
 */
export async function videoStatusV1VideosVideoIdGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoStatusV1VideosVideoIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoStatusV1VideosVideoIdGetQueryResponse,
		ErrorWrapper<VideoStatusV1VideosVideoIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoStatusV1VideosVideoIdGetPathParams
	>({ method: "GET", url: `/v1/videos/${pathParams["videoId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video content endpoint for downloading video content.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4```
 * @summary Video Content
 * {@link /videos/:video_id/content}
 */
export async function videoContentVideosVideoIdContentGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoContentVideosVideoIdContentGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoContentVideosVideoIdContentGetQueryResponse,
		ErrorWrapper<VideoContentVideosVideoIdContentGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoContentVideosVideoIdContentGetPathParams
	>({ method: "GET", url: `/videos/${pathParams["videoId"]}/content`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video content endpoint for downloading video content.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4```
 * @summary Video Content
 * {@link /v1/videos/:video_id/content}
 */
export async function videoContentV1VideosVideoIdContentGet({
	pathParams,
	config = {},
}: {
	pathParams: VideoContentV1VideosVideoIdContentGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoContentV1VideosVideoIdContentGetQueryResponse,
		ErrorWrapper<VideoContentV1VideosVideoIdContentGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoContentV1VideosVideoIdContentGetPathParams
	>({ method: "GET", url: `/v1/videos/${pathParams["videoId"]}/content`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video remix endpoint for remixing existing videos with new prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "prompt": "A new version with different colors"    }'```
 * @summary Video Remix
 * {@link /videos/:video_id/remix}
 */
export async function videoRemixVideosVideoIdRemixPost({
	pathParams,
	config = {},
}: {
	pathParams: VideoRemixVideosVideoIdRemixPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoRemixVideosVideoIdRemixPostMutationResponse,
		ErrorWrapper<VideoRemixVideosVideoIdRemixPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoRemixVideosVideoIdRemixPostPathParams
	>({ method: "POST", url: `/videos/${pathParams["videoId"]}/remix`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Video remix endpoint for remixing existing videos with new prompts.Follows the OpenAI Videos API spec:https://platform.openai.com/docs/api-reference/videosExample:```bashcurl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "prompt": "A new version with different colors"    }'```
 * @summary Video Remix
 * {@link /v1/videos/:video_id/remix}
 */
export async function videoRemixV1VideosVideoIdRemixPost({
	pathParams,
	config = {},
}: {
	pathParams: VideoRemixV1VideosVideoIdRemixPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["video_id"]) {
		throw new Error(`Missing required path parameter: video_id`);
	}
	const data = await request<
		VideoRemixV1VideosVideoIdRemixPostMutationResponse,
		ErrorWrapper<VideoRemixV1VideosVideoIdRemixPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VideoRemixV1VideosVideoIdRemixPostPathParams
	>({ method: "POST", url: `/v1/videos/${pathParams["videoId"]}/remix`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container list endpoint for retrieving a list of containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"```Or specify provider via header or query param:```bashcurl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"```
 * @summary List Containers
 * {@link /containers}
 */
export async function listContainersContainersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListContainersContainersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/containers`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container creation endpoint for creating new containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "name": "My Container",        "expires_after": {            "anchor": "last_active_at",            "minutes": 20        }    }'```Or specify provider via header:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{        "name": "My Container"    }'```
 * @summary Create Container
 * {@link /containers}
 */
export async function createContainerContainersPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateContainerContainersPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/containers`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container list endpoint for retrieving a list of containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"```Or specify provider via header or query param:```bashcurl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"```
 * @summary List Containers
 * {@link /v1/containers}
 */
export async function listContainersV1ContainersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListContainersV1ContainersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/containers`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container creation endpoint for creating new containers.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "name": "My Container",        "expires_after": {            "anchor": "last_active_at",            "minutes": 20        }    }'```Or specify provider via header:```bashcurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{        "name": "My Container"    }'```
 * @summary Create Container
 * {@link /v1/containers}
 */
export async function createContainerV1ContainersPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateContainerV1ContainersPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/containers`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container retrieve endpoint for getting details of a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Retrieve Container
 * {@link /containers/:container_id}
 */
export async function retrieveContainerContainersContainerIdGet({
	pathParams,
	config = {},
}: {
	pathParams: RetrieveContainerContainersContainerIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		RetrieveContainerContainersContainerIdGetQueryResponse,
		ErrorWrapper<RetrieveContainerContainersContainerIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RetrieveContainerContainersContainerIdGetPathParams
	>({ method: "GET", url: `/containers/${pathParams["containerId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container delete endpoint for deleting a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Delete Container
 * {@link /containers/:container_id}
 */
export async function deleteContainerContainersContainerIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteContainerContainersContainerIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		DeleteContainerContainersContainerIdDeleteMutationResponse,
		ErrorWrapper<DeleteContainerContainersContainerIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteContainerContainersContainerIdDeletePathParams
	>({ method: "DELETE", url: `/containers/${pathParams["containerId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container retrieve endpoint for getting details of a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Retrieve Container
 * {@link /v1/containers/:container_id}
 */
export async function retrieveContainerV1ContainersContainerIdGet({
	pathParams,
	config = {},
}: {
	pathParams: RetrieveContainerV1ContainersContainerIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		RetrieveContainerV1ContainersContainerIdGetQueryResponse,
		ErrorWrapper<RetrieveContainerV1ContainersContainerIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RetrieveContainerV1ContainersContainerIdGetPathParams
	>({ method: "GET", url: `/v1/containers/${pathParams["containerId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Container delete endpoint for deleting a specific container.Follows the OpenAI Containers API spec:https://platform.openai.com/docs/api-reference/containersExample:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"```Or specify provider via header:```bashcurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"```
 * @summary Delete Container
 * {@link /v1/containers/:container_id}
 */
export async function deleteContainerV1ContainersContainerIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteContainerV1ContainersContainerIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["container_id"]) {
		throw new Error(`Missing required path parameter: container_id`);
	}
	const data = await request<
		DeleteContainerV1ContainersContainerIdDeleteMutationResponse,
		ErrorWrapper<DeleteContainerV1ContainersContainerIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteContainerV1ContainersContainerIdDeletePathParams
	>({ method: "DELETE", url: `/v1/containers/${pathParams["containerId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /search}
 */
export async function searchSearchPost({
	queryParams,
	config = {},
}: {
	queryParams?: SearchSearchPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SearchSearchPostMutationResponse,
		ErrorWrapper<SearchSearchPost422>,
		null,
		Record<string, string>,
		SearchSearchPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/search`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /v1/search}
 */
export async function searchV1SearchPost({
	queryParams,
	config = {},
}: {
	queryParams?: SearchV1SearchPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SearchV1SearchPostMutationResponse,
		ErrorWrapper<SearchV1SearchPost422>,
		null,
		Record<string, string>,
		SearchV1SearchPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/search`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /search/:search_tool_name}
 */
export async function searchSearchSearchToolNamePost({
	pathParams,
	config = {},
}: {
	pathParams: SearchSearchSearchToolNamePostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_name"]) {
		throw new Error(`Missing required path parameter: search_tool_name`);
	}
	const data = await request<
		SearchSearchSearchToolNamePostMutationResponse,
		ErrorWrapper<SearchSearchSearchToolNamePost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		SearchSearchSearchToolNamePostPathParams
	>({ method: "POST", url: `/search/${pathParams["searchToolName"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Search endpoint for performing web searches.Follows the Perplexity Search API spec:https://docs.perplexity.ai/api-reference/search-postThe search_tool_name can be passed either:1. In the URL path: /v1/search/{search_tool_name}2. In the request body: {"search_tool_name": "..."}Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):```bashcurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Example with search_tool_name in body:```bashcurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{        "search_tool_name": "litellm-search",        "query": "latest AI developments 2024",        "max_results": 5,        "search_domain_filter": ["arxiv.org", "nature.com"],        "country": "US"    }'```Request Body Parameters (when search_tool_name not in URL):- search_tool_name (str, required if not in URL): Name of the search tool configured in router- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')When using URL path parameter, only Perplexity-compatible parameters are needed in body:- query (str or list[str], required): Search query- max_results (int, optional): Maximum number of results (1-20), default 10- search_domain_filter (list[str], optional): List of domains to filter (max 20)- max_tokens_per_page (int, optional): Max tokens per page, default 1024- country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')Response follows Perplexity Search API format:```json{    "object": "search",    "results": [        {            "title": "Result title",            "url": "https://example.com",            "snippet": "Result snippet...",            "date": "2024-01-01",            "last_updated": "2024-01-01"        }    ]}```
 * @summary Search
 * {@link /v1/search/:search_tool_name}
 */
export async function searchV1SearchSearchToolNamePost({
	pathParams,
	config = {},
}: {
	pathParams: SearchV1SearchSearchToolNamePostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_name"]) {
		throw new Error(`Missing required path parameter: search_tool_name`);
	}
	const data = await request<
		SearchV1SearchSearchToolNamePostMutationResponse,
		ErrorWrapper<SearchV1SearchSearchToolNamePost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		SearchV1SearchSearchToolNamePostPathParams
	>({ method: "POST", url: `/v1/search/${pathParams["searchToolName"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Image Generation
 * {@link /openai/deployments/:model/images/generations}
 */
export async function imageGenerationOpenaiDeploymentsModelImagesGenerationsPost({
	pathParams,
	config = {},
}: {
	pathParams: ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const data = await request<
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostMutationResponse,
		ErrorWrapper<ImageGenerationOpenaiDeploymentsModelImagesGenerationsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/images/generations`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Image Generation
 * {@link /images/generations}
 */
export async function imageGenerationImagesGenerationsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageGenerationImagesGenerationsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ImageGenerationImagesGenerationsPostMutationResponse,
		ErrorWrapper<ImageGenerationImagesGenerationsPost422>,
		null,
		Record<string, string>,
		ImageGenerationImagesGenerationsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/images/generations`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Image Generation
 * {@link /v1/images/generations}
 */
export async function imageGenerationV1ImagesGenerationsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageGenerationV1ImagesGenerationsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ImageGenerationV1ImagesGenerationsPostMutationResponse,
		ErrorWrapper<ImageGenerationV1ImagesGenerationsPost422>,
		null,
		Record<string, string>,
		ImageGenerationV1ImagesGenerationsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/v1/images/generations`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create```bashcurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'```
 * @summary Image Edit Api
 * {@link /openai/deployments/:model/images/edits}
 */
export async function imageEditApiOpenaiDeploymentsModelImagesEditsPost({
	pathParams,
	config = {},
}: {
	pathParams: ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model"]) {
		throw new Error(`Missing required path parameter: model`);
	}
	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostMutationResponse,
		ErrorWrapper<ImageEditApiOpenaiDeploymentsModelImagesEditsPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams
	>({
		method: "POST",
		url: `/openai/deployments/${pathParams["model"]}/images/edits`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create```bashcurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'```
 * @summary Image Edit Api
 * {@link /images/edits}
 */
export async function imageEditApiImagesEditsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageEditApiImagesEditsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ImageEditApiImagesEditsPostMutationResponse,
		ErrorWrapper<ImageEditApiImagesEditsPost422>,
		null,
		Record<string, string>,
		ImageEditApiImagesEditsPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/images/edits`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create```bashcurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'```
 * @summary Image Edit Api
 * {@link /v1/images/edits}
 */
export async function imageEditApiV1ImagesEditsPost({
	queryParams,
	config = {},
}: {
	queryParams?: ImageEditApiV1ImagesEditsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ImageEditApiV1ImagesEditsPostMutationResponse,
		ErrorWrapper<ImageEditApiV1ImagesEditsPost422>,
		null,
		Record<string, string>,
		ImageEditApiV1ImagesEditsPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/images/edits`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Creates a fine-tuning job which begins the process of creating a new model from a given dataset.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobsSupports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/createExample Curl:```curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{    "model": "gpt-3.5-turbo",    "training_file": "file-abc123",    "hyperparameters": {      "n_epochs": 4    }  }'```
 * @summary  (Enterprise) Create Fine-Tuning Job
 * {@link /fine_tuning/jobs}
 */
export async function createFineTuningJobFineTuningJobsPost({
	body,
	config = {},
}: {
	body: CreateFineTuningJobFineTuningJobsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateFineTuningJobFineTuningJobsPostMutationResponse,
		ErrorWrapper<CreateFineTuningJobFineTuningJobsPost422>,
		CreateFineTuningJobFineTuningJobsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/fine_tuning/jobs`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Lists fine-tuning jobs for the organization.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobsSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `after`: Identifier for the last job from the previous pagination request.- `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 * @summary  (Enterprise) List Fine-Tuning Jobs
 * {@link /fine_tuning/jobs}
 */
export async function listFineTuningJobsFineTuningJobsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFineTuningJobsFineTuningJobsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFineTuningJobsFineTuningJobsGetQueryResponse,
		ErrorWrapper<ListFineTuningJobsFineTuningJobsGet422>,
		null,
		Record<string, string>,
		ListFineTuningJobsFineTuningJobsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/fine_tuning/jobs`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Creates a fine-tuning job which begins the process of creating a new model from a given dataset.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobsSupports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/createExample Curl:```curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{    "model": "gpt-3.5-turbo",    "training_file": "file-abc123",    "hyperparameters": {      "n_epochs": 4    }  }'```
 * @summary  (Enterprise) Create Fine-Tuning Job
 * {@link /v1/fine_tuning/jobs}
 */
export async function createFineTuningJobV1FineTuningJobsPost({
	body,
	config = {},
}: {
	body: CreateFineTuningJobV1FineTuningJobsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateFineTuningJobV1FineTuningJobsPostMutationResponse,
		ErrorWrapper<CreateFineTuningJobV1FineTuningJobsPost422>,
		CreateFineTuningJobV1FineTuningJobsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/fine_tuning/jobs`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Lists fine-tuning jobs for the organization.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobsSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `after`: Identifier for the last job from the previous pagination request.- `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 * @summary  (Enterprise) List Fine-Tuning Jobs
 * {@link /v1/fine_tuning/jobs}
 */
export async function listFineTuningJobsV1FineTuningJobsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFineTuningJobsV1FineTuningJobsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFineTuningJobsV1FineTuningJobsGetQueryResponse,
		ErrorWrapper<ListFineTuningJobsV1FineTuningJobsGet422>,
		null,
		Record<string, string>,
		ListFineTuningJobsV1FineTuningJobsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/fine_tuning/jobs`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a fine-tuning job.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}Supported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 * @summary  (Enterprise) Retrieve Fine-Tuning Job
 * {@link /fine_tuning/jobs/:fine_tuning_job_id}
 */
export async function retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams;
	queryParams?: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryResponse,
		ErrorWrapper<RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGet422>,
		null,
		Record<string, string>,
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams,
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams
	>({
		method: "GET",
		url: `/fine_tuning/jobs/${pathParams["fineTuningJobId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieves a fine-tuning job.This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}Supported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 * @summary  (Enterprise) Retrieve Fine-Tuning Job
 * {@link /v1/fine_tuning/jobs/:fine_tuning_job_id}
 */
export async function retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams;
	queryParams?: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryResponse,
		ErrorWrapper<RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet422>,
		null,
		Record<string, string>,
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams,
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams
	>({
		method: "GET",
		url: `/v1/fine_tuning/jobs/${pathParams["fineTuningJobId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a fine-tuning job.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancelSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 * @summary  (Enterprise) Cancel Fine-Tuning Jobs
 * {@link /fine_tuning/jobs/:fine_tuning_job_id/cancel}
 */
export async function cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostMutationResponse,
		ErrorWrapper<CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams
	>({
		method: "POST",
		url: `/fine_tuning/jobs/${pathParams["fineTuningJobId"]}/cancel`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Cancel a fine-tuning job.This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancelSupported Query Params:- `custom_llm_provider`: Name of the LiteLLM provider- `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 * @summary  (Enterprise) Cancel Fine-Tuning Jobs
 * {@link /v1/fine_tuning/jobs/:fine_tuning_job_id/cancel}
 */
export async function cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost({
	pathParams,
	config = {},
}: {
	pathParams: CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["fine_tuning_job_id"]) {
		throw new Error(`Missing required path parameter: fine_tuning_job_id`);
	}
	const data = await request<
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostMutationResponse,
		ErrorWrapper<CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams
	>({
		method: "POST",
		url: `/v1/fine_tuning/jobs/${pathParams["fineTuningJobId"]}/cancel`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Search a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/search
 * @summary Vector Store Search
 * {@link /vector_stores/:vector_store_id/search}
 */
export async function vectorStoreSearchVectorStoresVectorStoreIdSearchPost({
	pathParams,
	config = {},
}: {
	pathParams: VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["vector_store_id"]) {
		throw new Error(`Missing required path parameter: vector_store_id`);
	}
	const data = await request<
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostMutationResponse,
		ErrorWrapper<VectorStoreSearchVectorStoresVectorStoreIdSearchPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams
	>({
		method: "POST",
		url: `/vector_stores/${pathParams["vectorStoreId"]}/search`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Search a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/search
 * @summary Vector Store Search
 * {@link /v1/vector_stores/:vector_store_id/search}
 */
export async function vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost({
	pathParams,
	config = {},
}: {
	pathParams: VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["vector_store_id"]) {
		throw new Error(`Missing required path parameter: vector_store_id`);
	}
	const data = await request<
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostMutationResponse,
		ErrorWrapper<VectorStoreSearchV1VectorStoresVectorStoreIdSearchPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams
	>({
		method: "POST",
		url: `/v1/vector_stores/${pathParams["vectorStoreId"]}/search`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/create
 * @summary Vector Store Create
 * {@link /vector_stores}
 */
export async function vectorStoreCreateVectorStoresPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VectorStoreCreateVectorStoresPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_stores`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a vector store.API Reference:https://platform.openai.com/docs/api-reference/vector-stores/create
 * @summary Vector Store Create
 * {@link /v1/vector_stores}
 */
export async function vectorStoreCreateV1VectorStoresPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		VectorStoreCreateV1VectorStoresPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/vector_stores`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create an index. Just writes the index to the database.```bashcurl -L -X POST 'http://0.0.0.0:4000/indexes/create'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -H 'LiteLLM-Beta: indexes_beta=v1'         -d '{         "index_name": "dall-e-3",        "vector_store_index": "real-index-name",        "vector_store_name": "azure-ai-search"    }'```
 * @summary Index Create
 * {@link /v1/indexes}
 */
export async function indexCreateV1IndexesPost({
	body,
	config = {},
}: {
	body: IndexCreateV1IndexesPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		IndexCreateV1IndexesPostMutationResponse,
		ErrorWrapper<IndexCreateV1IndexesPost422>,
		IndexCreateV1IndexesPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/indexes`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Get Credentials
 * {@link /credentials}
 */
export async function getCredentialsCredentialsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCredentialsCredentialsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/credentials`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.Stores credential in DB.Reloads credentials in memory.
 * @summary Create Credential
 * {@link /credentials}
 */
export async function createCredentialCredentialsPost({
	body,
	config = {},
}: {
	body: CreateCredentialCredentialsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateCredentialCredentialsPostMutationResponse,
		ErrorWrapper<CreateCredentialCredentialsPost422>,
		CreateCredentialCredentialsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/credentials`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Get Credential
 * {@link /credentials/by_model/:model_id}
 */
export async function getCredentialCredentialsByModelModelIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetCredentialCredentialsByModelModelIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		GetCredentialCredentialsByModelModelIdGetQueryResponse,
		ErrorWrapper<GetCredentialCredentialsByModelModelIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetCredentialCredentialsByModelModelIdGetPathParams
	>({ method: "GET", url: `/credentials/by_model/${pathParams["modelId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Get Credential
 * {@link /credentials/by_name/:credential_name}
 */
export async function getCredentialCredentialsByNameCredentialNameGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetCredentialCredentialsByNameCredentialNameGetPathParams;
	queryParams?: GetCredentialCredentialsByNameCredentialNameGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}
	const data = await request<
		GetCredentialCredentialsByNameCredentialNameGetQueryResponse,
		ErrorWrapper<GetCredentialCredentialsByNameCredentialNameGet422>,
		null,
		Record<string, string>,
		GetCredentialCredentialsByNameCredentialNameGetQueryParams,
		GetCredentialCredentialsByNameCredentialNameGetPathParams
	>({
		method: "GET",
		url: `/credentials/by_name/${pathParams["credentialName"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Delete Credential
 * {@link /credentials/:credential_name}
 */
export async function deleteCredentialCredentialsCredentialNameDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteCredentialCredentialsCredentialNameDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}
	const data = await request<
		DeleteCredentialCredentialsCredentialNameDeleteMutationResponse,
		ErrorWrapper<DeleteCredentialCredentialsCredentialNameDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteCredentialCredentialsCredentialNameDeletePathParams
	>({ method: "DELETE", url: `/credentials/${pathParams["credentialName"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] endpoint. This might change unexpectedly.
 * @summary Update Credential
 * {@link /credentials/:credential_name}
 */
export async function updateCredentialCredentialsCredentialNamePatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdateCredentialCredentialsCredentialNamePatchPathParams;
	body: UpdateCredentialCredentialsCredentialNamePatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["credential_name"]) {
		throw new Error(`Missing required path parameter: credential_name`);
	}
	const data = await request<
		UpdateCredentialCredentialsCredentialNamePatchMutationResponse,
		ErrorWrapper<UpdateCredentialCredentialsCredentialNamePatch422>,
		UpdateCredentialCredentialsCredentialNamePatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdateCredentialCredentialsCredentialNamePatchPathParams
	>({
		method: "PATCH",
		url: `/credentials/${pathParams["credentialName"]}`,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all MCP tools available for the current key, including those from access groups
 * @summary Get Mcp Tools
 * {@link /v1/mcp/tools}
 */
export async function getMcpToolsV1McpToolsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetMcpToolsV1McpToolsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/tools`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all available MCP access groups from the database AND config
 * @summary Get Mcp Access Groups
 * {@link /v1/mcp/access_groups}
 */
export async function getMcpAccessGroupsV1McpAccessGroupsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetMcpAccessGroupsV1McpAccessGroupsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/access_groups`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Perform health check on a specific MCP server
 * @summary Health Check Mcp Server
 * {@link /v1/mcp/server/:server_id/health}
 */
export async function healthCheckMcpServerV1McpServerServerIdHealthGet({
	pathParams,
	config = {},
}: {
	pathParams: HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["server_id"]) {
		throw new Error(`Missing required path parameter: server_id`);
	}
	const data = await request<
		HealthCheckMcpServerV1McpServerServerIdHealthGetQueryResponse,
		ErrorWrapper<HealthCheckMcpServerV1McpServerServerIdHealthGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams
	>({ method: "GET", url: `/v1/mcp/server/${pathParams["serverId"]}/health`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Perform health check on all accessible MCP servers
 * @summary Health Check All Mcp Servers
 * {@link /v1/mcp/server/health}
 */
export async function healthCheckAllMcpServersV1McpServerHealthGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthCheckAllMcpServersV1McpServerHealthGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/server/health`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns the mcp server list with associated teams
 * @summary Fetch All Mcp Servers
 * {@link /v1/mcp/server}
 */
export async function fetchAllMcpServersV1McpServerGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		FetchAllMcpServersV1McpServerGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v1/mcp/server`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allows creation of mcp servers
 * @summary Add Mcp Server
 * {@link /v1/mcp/server}
 */
export async function addMcpServerV1McpServerPost({
	body,
	headers,
	config = {},
}: {
	body?: AddMcpServerV1McpServerPostMutationRequest;
	headers?: AddMcpServerV1McpServerPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AddMcpServerV1McpServerPostMutationResponse,
		ErrorWrapper<AddMcpServerV1McpServerPost422>,
		AddMcpServerV1McpServerPostMutationRequest,
		AddMcpServerV1McpServerPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/mcp/server`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allows deleting mcp serves in the db
 * @summary Edit Mcp Server
 * {@link /v1/mcp/server}
 */
export async function editMcpServerV1McpServerPut({
	body,
	headers,
	config = {},
}: {
	body: EditMcpServerV1McpServerPutMutationRequest;
	headers?: EditMcpServerV1McpServerPutHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EditMcpServerV1McpServerPutMutationResponse,
		ErrorWrapper<EditMcpServerV1McpServerPut422>,
		EditMcpServerV1McpServerPutMutationRequest,
		EditMcpServerV1McpServerPutHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "PUT",
		url: `/v1/mcp/server`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns the mcp server info
 * @summary Fetch Mcp Server
 * {@link /v1/mcp/server/:server_id}
 */
export async function fetchMcpServerV1McpServerServerIdGet({
	pathParams,
	config = {},
}: {
	pathParams: FetchMcpServerV1McpServerServerIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["server_id"]) {
		throw new Error(`Missing required path parameter: server_id`);
	}
	const data = await request<
		FetchMcpServerV1McpServerServerIdGetQueryResponse,
		ErrorWrapper<FetchMcpServerV1McpServerServerIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		FetchMcpServerV1McpServerServerIdGetPathParams
	>({ method: "GET", url: `/v1/mcp/server/${pathParams["serverId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allows deleting mcp serves in the db
 * @summary Remove Mcp Server
 * {@link /v1/mcp/server/:server_id}
 */
export async function removeMcpServerV1McpServerServerIdDelete({
	pathParams,
	headers,
	config = {},
}: {
	pathParams: RemoveMcpServerV1McpServerServerIdDeletePathParams;
	headers?: RemoveMcpServerV1McpServerServerIdDeleteHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["server_id"]) {
		throw new Error(`Missing required path parameter: server_id`);
	}
	const data = await request<
		RemoveMcpServerV1McpServerServerIdDeleteMutationResponse,
		ErrorWrapper<RemoveMcpServerV1McpServerServerIdDelete422>,
		null,
		RemoveMcpServerV1McpServerServerIdDeleteHeaderParams,
		Record<string, string>,
		RemoveMcpServerV1McpServerServerIdDeletePathParams
	>({
		method: "DELETE",
		url: `/v1/mcp/server/${pathParams["serverId"]}`,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Use `{PROXY_BASE_URL}/anthropic/v1/messages` instead - [Docs](https://docs.litellm.ai/docs/anthropic_completion).This was a BETA endpoint that calls 100+ LLMs in the anthropic format.
 * @summary Anthropic Response
 * {@link /v1/messages}
 */
export async function anthropicResponseV1MessagesPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AnthropicResponseV1MessagesPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/messages`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Count tokens for Anthropic Messages API format.This endpoint follows the Anthropic Messages API token counting specification.It accepts the same parameters as the /v1/messages endpoint but returnstoken counts instead of generating a response.Example usage:```curl -X POST "http://localhost:4000/v1/messages/count_tokens?beta=true"       -H "Content-Type: application/json"       -H "Authorization: Bearer your-key"       -d '{    "model": "claude-3-sonnet-20240229",    "messages": [{"role": "user", "content": "Hello Claude!"}]  }'```Returns: {"input_tokens": <number>}
 * @summary Count Tokens
 * {@link /v1/messages/count_tokens}
 */
export async function countTokensV1MessagesCountTokensPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CountTokensV1MessagesCountTokensPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/v1/messages/count_tokens`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Google Generate Content
 * {@link /models/:model_name:generateContent}
 */
export async function googleGenerateContentModelsModelNameGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleGenerateContentModelsModelNameGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleGenerateContentModelsModelNameGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleGenerateContentModelsModelNameGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleGenerateContentModelsModelNameGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/models/${pathParams["modelName"]}:generateContent`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Google Generate Content
 * {@link /v1beta/models/:model_name:generateContent}
 */
export async function googleGenerateContentV1BetaModelsModelNameGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleGenerateContentV1BetaModelsModelNameGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/v1beta/models/${pathParams["modelName"]}:generateContent`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Google Stream Generate Content
 * {@link /models/:model_name:streamGenerateContent}
 */
export async function googleStreamGenerateContentModelsModelNameStreamGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/models/${pathParams["modelName"]}:streamGenerateContent`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Google Stream Generate Content
 * {@link /v1beta/models/:model_name:streamGenerateContent}
 */
export async function googleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostMutationResponse,
		ErrorWrapper<GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParams
	>({
		method: "POST",
		url: `/v1beta/models/${pathParams["modelName"]}:streamGenerateContent`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description ```jsonreturn {    "totalTokens": 31,    "totalBillableCharacters": 96,    "promptTokensDetails": [        {        "modality": "TEXT",        "tokenCount": 31        }    ]}```
 * @summary Google Count Tokens
 * {@link /models/:model_name:countTokens}
 */
export async function googleCountTokensModelsModelNameCountTokensPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleCountTokensModelsModelNameCountTokensPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleCountTokensModelsModelNameCountTokensPostMutationResponse,
		ErrorWrapper<GoogleCountTokensModelsModelNameCountTokensPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleCountTokensModelsModelNameCountTokensPostPathParams
	>({ method: "POST", url: `/models/${pathParams["modelName"]}:countTokens`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description ```jsonreturn {    "totalTokens": 31,    "totalBillableCharacters": 96,    "promptTokensDetails": [        {        "modality": "TEXT",        "tokenCount": 31        }    ]}```
 * @summary Google Count Tokens
 * {@link /v1beta/models/:model_name:countTokens}
 */
export async function googleCountTokensV1BetaModelsModelNameCountTokensPost({
	pathParams,
	config = {},
}: {
	pathParams: GoogleCountTokensV1BetaModelsModelNameCountTokensPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_name"]) {
		throw new Error(`Missing required path parameter: model_name`);
	}
	const data = await request<
		GoogleCountTokensV1BetaModelsModelNameCountTokensPostMutationResponse,
		ErrorWrapper<GoogleCountTokensV1BetaModelsModelNameCountTokensPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GoogleCountTokensV1BetaModelsModelNameCountTokensPostPathParams
	>({
		method: "POST",
		url: `/v1beta/models/${pathParams["modelName"]}:countTokens`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description GET configured pass through endpoint.If no endpoint_id given, return all configured endpoints.
 * @summary Get Pass Through Endpoints
 * {@link /config/pass_through_endpoint/team/:team_id}
 */
export async function getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams;
	queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryResponse,
		ErrorWrapper<GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet422>,
		null,
		Record<string, string>,
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams,
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams
	>({
		method: "GET",
		url: `/config/pass_through_endpoint/team/${pathParams["teamId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description GET configured pass through endpoint.If no endpoint_id given, return all configured endpoints.
 * @summary Get Pass Through Endpoints
 * {@link /config/pass_through_endpoint}
 */
export async function getPassThroughEndpointsConfigPassThroughEndpointGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetPassThroughEndpointsConfigPassThroughEndpointGetQueryResponse,
		ErrorWrapper<GetPassThroughEndpointsConfigPassThroughEndpointGet422>,
		null,
		Record<string, string>,
		GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/config/pass_through_endpoint`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create new pass-through endpoint
 * @summary Create Pass Through Endpoints
 * {@link /config/pass_through_endpoint}
 */
export async function createPassThroughEndpointsConfigPassThroughEndpointPost({
	body,
	config = {},
}: {
	body: CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationResponse,
		ErrorWrapper<CreatePassThroughEndpointsConfigPassThroughEndpointPost422>,
		CreatePassThroughEndpointsConfigPassThroughEndpointPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/config/pass_through_endpoint`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a pass-through endpoint by ID.Returns - the deleted endpoint
 * @summary Delete Pass Through Endpoints
 * {@link /config/pass_through_endpoint}
 */
export async function deletePassThroughEndpointsConfigPassThroughEndpointDelete({
	queryParams,
	config = {},
}: {
	queryParams: DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeletePassThroughEndpointsConfigPassThroughEndpointDeleteMutationResponse,
		ErrorWrapper<DeletePassThroughEndpointsConfigPassThroughEndpointDelete422>,
		null,
		Record<string, string>,
		DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams,
		Record<string, string>
	>({ method: "DELETE", url: `/config/pass_through_endpoint`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update a pass-through endpoint by ID.
 * @summary Update Pass Through Endpoints
 * {@link /config/pass_through_endpoint/:endpoint_id}
 */
export async function updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams;
	body: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["endpoint_id"]) {
		throw new Error(`Missing required path parameter: endpoint_id`);
	}
	const data = await request<
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationResponse,
		ErrorWrapper<UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost422>,
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams
	>({
		method: "POST",
		url: `/config/pass_through_endpoint/${pathParams["endpointId"]}`,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [DEPRECATED] use `/health/liveliness` instead.A test endpoint that pings the proxy server to check if it's healthy.Parameters:    request (Request): The incoming request.Returns:    dict: A dictionary containing the route of the request URL.
 * @summary Test Endpoint
 * {@link /test}
 */
export async function testEndpointTestGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestEndpointTestGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/test`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Use this admin-only endpoint to check if the service is healthy.Example:```curl -L -X GET 'http://0.0.0.0:4000/health/services?service=datadog'     -H 'Authorization: Bearer sk-1234'```
 * @summary Health Services Endpoint
 * {@link /health/services}
 */
export async function healthServicesEndpointHealthServicesGet({
	queryParams,
	config = {},
}: {
	queryParams: HealthServicesEndpointHealthServicesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthServicesEndpointHealthServicesGetQueryResponse,
		ErrorWrapper<HealthServicesEndpointHealthServicesGet422>,
		null,
		Record<string, string>,
		HealthServicesEndpointHealthServicesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/health/services`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description  USE `/health/liveliness` to health check the proxy See more  https://docs.litellm.ai/docs/proxy/healthCheck the health of all the endpoints in config.yamlTo run health checks in the background, add this to config.yaml:```general_settings:    # ... other settings    background_health_checks: True```else, the health checks will be run on models when /health is called.
 * @summary Health Endpoint
 * {@link /health}
 */
export async function healthEndpointHealthGet({
	queryParams,
	config = {},
}: {
	queryParams?: HealthEndpointHealthGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthEndpointHealthGetQueryResponse,
		ErrorWrapper<HealthEndpointHealthGet422>,
		null,
		Record<string, string>,
		HealthEndpointHealthGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/health`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get health check history for modelsReturns historical health check data with optional filtering.
 * @summary Health Check History Endpoint
 * {@link /health/history}
 */
export async function healthCheckHistoryEndpointHealthHistoryGet({
	queryParams,
	config = {},
}: {
	queryParams?: HealthCheckHistoryEndpointHealthHistoryGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthCheckHistoryEndpointHealthHistoryGetQueryResponse,
		ErrorWrapper<HealthCheckHistoryEndpointHealthHistoryGet422>,
		null,
		Record<string, string>,
		HealthCheckHistoryEndpointHealthHistoryGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/health/history`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the latest health check status for all modelsReturns the most recent health check result for each model.
 * @summary Latest Health Checks Endpoint
 * {@link /health/latest}
 */
export async function latestHealthChecksEndpointHealthLatestGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		LatestHealthChecksEndpointHealthLatestGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/latest`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the status of shared health check coordination across pods.Returns information about Redis connectivity, lock status, and cache status.
 * @summary Shared Health Check Status Endpoint
 * {@link /health/shared-status}
 */
export async function sharedHealthCheckStatusEndpointHealthSharedStatusGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		SharedHealthCheckStatusEndpointHealthSharedStatusGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/shared-status`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns a list of litellm level settingsThis is useful for debugging and ensuring the proxy server is configured correctly.Response schema:```{    "alerting": _alerting,    "litellm.callbacks": litellm_callbacks,    "litellm.input_callback": litellm_input_callbacks,    "litellm.failure_callback": litellm_failure_callbacks,    "litellm.success_callback": litellm_success_callbacks,    "litellm._async_success_callback": litellm_async_success_callbacks,    "litellm._async_failure_callback": litellm_async_failure_callbacks,    "litellm._async_input_callback": litellm_async_input_callbacks,    "all_litellm_callbacks": all_litellm_callbacks,    "num_callbacks": len(all_litellm_callbacks),    "num_alerting": _num_alerting,    "litellm.request_timeout": litellm.request_timeout,}```
 * @summary Active Callbacks
 * {@link /active/callbacks}
 */
export async function activeCallbacksActiveCallbacksGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ActiveCallbacksActiveCallbacksGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/active/callbacks`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns a list of litellm level settingsThis is useful for debugging and ensuring the proxy server is configured correctly.Response schema:```{    "alerting": _alerting,    "litellm.callbacks": litellm_callbacks,    "litellm.input_callback": litellm_input_callbacks,    "litellm.failure_callback": litellm_failure_callbacks,    "litellm.success_callback": litellm_success_callbacks,    "litellm._async_success_callback": litellm_async_success_callbacks,    "litellm._async_failure_callback": litellm_async_failure_callbacks,    "litellm._async_input_callback": litellm_async_input_callbacks,    "all_litellm_callbacks": all_litellm_callbacks,    "num_callbacks": len(all_litellm_callbacks),    "num_alerting": _num_alerting,    "litellm.request_timeout": litellm.request_timeout,}```
 * @summary Active Callbacks
 * {@link /settings}
 */
export async function activeCallbacksSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ActiveCallbacksSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Unprotected endpoint for checking if worker can receive requests
 * @summary Health Readiness
 * {@link /health/readiness}
 */
export async function healthReadinessHealthReadinessGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthReadinessHealthReadinessGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/readiness`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Options endpoint for health/readiness check.
 * @summary Health Readiness Options
 * {@link /health/readiness}
 */
export async function healthReadinessOptionsHealthReadinessOptions({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthReadinessOptionsHealthReadinessOptionsMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "OPTIONS", url: `/health/readiness`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Unprotected endpoint for checking if worker is alive
 * @summary Health Liveliness
 * {@link /health/liveness}
 */
export async function healthLivelinessHealthLivenessGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessHealthLivenessGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/liveness`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Options endpoint for health/liveliness check.
 * @summary Health Liveliness Options
 * {@link /health/liveness}
 */
export async function healthLivelinessOptionsHealthLivenessOptions({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessOptionsHealthLivenessOptionsMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "OPTIONS", url: `/health/liveness`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Unprotected endpoint for checking if worker is alive
 * @summary Health Liveliness
 * {@link /health/liveliness}
 */
export async function healthLivelinessHealthLivelinessGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessHealthLivelinessGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/health/liveliness`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Options endpoint for health/liveliness check.
 * @summary Health Liveliness Options
 * {@link /health/liveliness}
 */
export async function healthLivelinessOptionsHealthLivelinessOptions({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		HealthLivelinessOptionsHealthLivelinessOptionsMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "OPTIONS", url: `/health/liveliness`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Test a direct connection to a specific model.This endpoint allows you to verify if your proxy can successfully connect to a specific model.It's useful for troubleshooting model connectivity issues without going through the full proxy routing.Example:```bashcurl -X POST 'http://localhost:4000/health/test_connection' \  -H 'Authorization: Bearer sk-1234' \  -H 'Content-Type: application/json' \  -d '{    "litellm_params": {        "model": "gpt-4",        "custom_llm_provider": "azure_ai",        "litellm_credential_name": null,        "api_key": "6xxxxxxx",        "api_base": "https://litellm8397336933.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21",    },    "mode": "chat"  }'```Returns:    dict: A dictionary containing the health check result with either success information or error details.
 * @summary Test Model Connection
 * {@link /health/test_connection}
 */
export async function testModelConnectionHealthTestConnectionPost({
	body,
	config = {},
}: {
	body?: TestModelConnectionHealthTestConnectionPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestModelConnectionHealthTestConnectionPostMutationResponse,
		ErrorWrapper<TestModelConnectionHealthTestConnectionPost422>,
		TestModelConnectionHealthTestConnectionPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/health/test_connection`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Generate an API key based on the provided data.Docs: https://docs.litellm.ai/docs/proxy/virtual_keysParameters:- duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- key_alias: Optional[str] - User defined key alias- key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.- team_id: Optional[str] - The team id of the key- user_id: Optional[str] - The user id of the key- organization_id: Optional[str] - The organization id of the key. If not set, and team_id is set, the organization id will be the same as the team id. If conflict, an error will be raised.- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.- models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)- aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models- config: Optional[dict] - any key-specific configs, overrides config in config.yaml- spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend- send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key- max_budget: Optional[float] - Specify max budget for a given key.- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.- metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- guardrails: Optional[List[str]] - List of active guardrails for the key- permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.- model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.- model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.- tpm_limit_type: Optional[str] - Type of tpm limit. Options: "best_effort_throughput" (no error if we're overallocating tpm), "guaranteed_throughput" (raise an error if we're overallocating tpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".- rpm_limit_type: Optional[str] - Type of rpm limit. Options: "best_effort_throughput" (no error if we're overallocating rpm), "guaranteed_throughput" (raise an error if we're overallocating rpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request- blocked: Optional[bool] - Whether the key is blocked.- rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)- tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)- soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]- allowed_passthrough_routes: Optional[list] - List of allowed pass through endpoints for the key. Store the actual endpoint or store a wildcard pattern for a set of endpoints. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through endpoints the key can access, without specifying the routes. If allowed_routes is specified, allowed_pass_through_endpoints is ignored.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- key_type: Optional[str] - Type of key that determines default allowed routes. Options: "llm_api" (can call LLM API routes), "management" (can call management routes), "read_only" (can only call info/read routes), "default" (uses default allowed routes). Defaults to "default".- prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.- auto_rotate: Optional[bool] - Whether this key should be automatically rotated (regenerated)- rotation_interval: Optional[str] - How often to auto-rotate this key (e.g., '30s', '30m', '30h', '30d'). Required if auto_rotate=True.- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.Examples:1. Allow users to turn on/off pii masking```bashcurl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "permissions": {"allow_pii_controls": true}}'```Returns:- key: (str) The generated api key- expires: (datetime) Datetime object for when key expires.- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * @summary Generate Key Fn
 * {@link /key/generate}
 */
export async function generateKeyFnKeyGeneratePost({
	body,
	headers,
	config = {},
}: {
	body?: GenerateKeyFnKeyGeneratePostMutationRequest;
	headers?: GenerateKeyFnKeyGeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GenerateKeyFnKeyGeneratePostMutationResponse,
		ErrorWrapper<GenerateKeyFnKeyGeneratePost422>,
		GenerateKeyFnKeyGeneratePostMutationRequest,
		GenerateKeyFnKeyGeneratePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/generate`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Generate a Service Account API key based on the provided data. This key does not belong to any user. It belongs to the team.Why use a service account key?- Prevent key from being deleted when user is deleted.- Apply team limits, not team member limits to key.Docs: https://docs.litellm.ai/docs/proxy/virtual_keysParameters:- duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- key_alias: Optional[str] - User defined key alias- key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.- team_id: Optional[str] - The team id of the key- user_id: Optional[str] - [NON-FUNCTIONAL] THIS WILL BE IGNORED. The user id of the key- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.- models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)- aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models- config: Optional[dict] - any key-specific configs, overrides config in config.yaml- spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend- send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key- max_budget: Optional[float] - Specify max budget for a given key.- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.- metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- guardrails: Optional[List[str]] - List of active guardrails for the key- permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.- model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.- model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.- tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request- blocked: Optional[bool] - Whether the key is blocked.- rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)- tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)- soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.Examples:- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.1. Allow users to turn on/off pii masking```bashcurl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "permissions": {"allow_pii_controls": true}}'```Returns:- key: (str) The generated api key- expires: (datetime) Datetime object for when key expires.- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * @summary Generate Service Account Key Fn
 * {@link /key/service-account/generate}
 */
export async function generateServiceAccountKeyFnKeyServiceAccountGeneratePost({
	body,
	headers,
	config = {},
}: {
	body?: GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequest;
	headers?: GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationResponse,
		ErrorWrapper<GenerateServiceAccountKeyFnKeyServiceAccountGeneratePost422>,
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequest,
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/service-account/generate`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an existing API key's parameters.Parameters:- key: str - The key to update- key_alias: Optional[str] - User-friendly key alias- user_id: Optional[str] - User ID associated with key- team_id: Optional[str] - Team ID associated with key- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.- models: Optional[list] - Model_name's a user is allowed to call- tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)- spend: Optional[float] - Amount spent by key- max_budget: Optional[float] - Max budget for key- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)- soft_budget: Optional[float] - [TODO] Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.- max_parallel_requests: Optional[int] - Rate limit for parallel requests- metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}- tpm_limit: Optional[int] - Tokens per minute limit- rpm_limit: Optional[int] - Requests per minute limit- model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}- model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}- tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"- allowed_cache_controls: Optional[list] - List of allowed cache control values- duration: Optional[str] - Key validity duration ("30d", "1h", etc.)- permissions: Optional[dict] - Key-specific permissions- send_invite_email: Optional[bool] - Send invite email to user_id- guardrails: Optional[List[str]] - List of active guardrails for the key- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.- blocked: Optional[bool] - Whether the key is blocked- aliases: Optional[dict] - Model aliases for the key - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)- config: Optional[dict] - [DEPRECATED PARAM] Key-specific config.- temp_budget_increase: Optional[float] - Temporary budget increase for the key (Enterprise only).- temp_budget_expiry: Optional[str] - Expiry time for the temporary budget increase (Enterprise only).- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]- allowed_passthrough_routes: Optional[list] - List of allowed pass through routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through routes the key can access, without specifying the routes. If allowed_routes is specified, allowed_passthrough_routes is ignored.- prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- auto_rotate: Optional[bool] - Whether this key should be automatically rotated- rotation_interval: Optional[str] - How often to rotate this key (e.g., '30d', '90d'). Required if auto_rotate=True- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.Example:```bashcurl --location 'http://0.0.0.0:4000/key/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "key": "sk-1234",    "key_alias": "my-key",    "user_id": "user-1234",    "team_id": "team-1234",    "max_budget": 100,    "metadata": {"any_key": "any-val"},}'```
 * @summary Update Key Fn
 * {@link /key/update}
 */
export async function updateKeyFnKeyUpdatePost({
	body,
	headers,
	config = {},
}: {
	body: UpdateKeyFnKeyUpdatePostMutationRequest;
	headers?: UpdateKeyFnKeyUpdatePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateKeyFnKeyUpdatePostMutationResponse,
		ErrorWrapper<UpdateKeyFnKeyUpdatePost422>,
		UpdateKeyFnKeyUpdatePostMutationRequest,
		UpdateKeyFnKeyUpdatePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/update`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a key from the key management system.Parameters::- keys (List[str]): A list of keys or hashed keys to delete. Example {"keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}- key_aliases (List[str]): A list of key aliases to delete. Can be passed instead of `keys`.Example {"key_aliases": ["alias1", "alias2"]}Returns:- deleted_keys (List[str]): A list of deleted keys. Example {"deleted_keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}Example:```bashcurl --location 'http://0.0.0.0:4000/key/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "keys": ["sk-QWrxEynunsNpV1zT48HIrw"]}'```Raises:    HTTPException: If an error occurs during key deletion.
 * @summary Delete Key Fn
 * {@link /key/delete}
 */
export async function deleteKeyFnKeyDeletePost({
	body,
	headers,
	config = {},
}: {
	body?: DeleteKeyFnKeyDeletePostMutationRequest;
	headers?: DeleteKeyFnKeyDeletePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteKeyFnKeyDeletePostMutationResponse,
		ErrorWrapper<DeleteKeyFnKeyDeletePost422>,
		DeleteKeyFnKeyDeletePostMutationRequest,
		DeleteKeyFnKeyDeletePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/delete`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Retrieve information about a key.Parameters:    key: Optional[str] = Query parameter representing the key in the request    user_api_key_dict: UserAPIKeyAuth = Dependency representing the user's API keyReturns:    Dict containing the key and its associated informationExample Curl:```curl -X GET "http://0.0.0.0:4000/key/info?key=sk-02Wr4IAlN3NvPXvL5JVvDA" -H "Authorization: Bearer sk-1234"```Example Curl - if no key is passed, it will use the Key Passed in Authorization Header```curl -X GET "http://0.0.0.0:4000/key/info" -H "Authorization: Bearer sk-02Wr4IAlN3NvPXvL5JVvDA"```
 * @summary Info Key Fn
 * {@link /key/info}
 */
export async function infoKeyFnKeyInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: InfoKeyFnKeyInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoKeyFnKeyInfoGetQueryResponse,
		ErrorWrapper<InfoKeyFnKeyInfoGet422>,
		null,
		Record<string, string>,
		InfoKeyFnKeyInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/key/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Regenerate an existing API key while optionally updating its parameters.Parameters:- key: str (path parameter) - The key to regenerate- data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update    - key: Optional[str] - The key to regenerate.    - new_master_key: Optional[str] - The new master key to use, if key is the master key.    - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.    - key_alias: Optional[str] - User-friendly key alias    - user_id: Optional[str] - User ID associated with key    - team_id: Optional[str] - Team ID associated with key    - models: Optional[list] - Model_name's a user is allowed to call    - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)    - spend: Optional[float] - Amount spent by key    - max_budget: Optional[float] - Max budget for key    - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}    - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)    - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.    - max_parallel_requests: Optional[int] - Rate limit for parallel requests    - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}    - tpm_limit: Optional[int] - Tokens per minute limit    - rpm_limit: Optional[int] - Requests per minute limit    - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}    - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}    - allowed_cache_controls: Optional[list] - List of allowed cache control values    - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)    - permissions: Optional[dict] - Key-specific permissions    - guardrails: Optional[List[str]] - List of active guardrails for the key    - blocked: Optional[bool] - Whether the key is blockedReturns:- GenerateKeyResponse containing the new key and its updated parametersExample:```bashcurl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "max_budget": 100,    "metadata": {"team": "core-infra"},    "models": ["gpt-4", "gpt-3.5-turbo"]}'```Note: This is an Enterprise feature. It requires a premium license to use.
 * @summary Regenerate Key Fn
 * {@link /key/regenerate}
 */
export async function regenerateKeyFnKeyRegeneratePost({
	body,
	queryParams,
	headers,
	config = {},
}: {
	body?: RegenerateKeyFnKeyRegeneratePostMutationRequest;
	queryParams?: RegenerateKeyFnKeyRegeneratePostQueryParams;
	headers?: RegenerateKeyFnKeyRegeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RegenerateKeyFnKeyRegeneratePostMutationResponse,
		ErrorWrapper<RegenerateKeyFnKeyRegeneratePost422>,
		RegenerateKeyFnKeyRegeneratePostMutationRequest,
		RegenerateKeyFnKeyRegeneratePostHeaderParams,
		RegenerateKeyFnKeyRegeneratePostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/regenerate`,
		queryParams,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Regenerate an existing API key while optionally updating its parameters.Parameters:- key: str (path parameter) - The key to regenerate- data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update    - key: Optional[str] - The key to regenerate.    - new_master_key: Optional[str] - The new master key to use, if key is the master key.    - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.    - key_alias: Optional[str] - User-friendly key alias    - user_id: Optional[str] - User ID associated with key    - team_id: Optional[str] - Team ID associated with key    - models: Optional[list] - Model_name's a user is allowed to call    - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)    - spend: Optional[float] - Amount spent by key    - max_budget: Optional[float] - Max budget for key    - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}    - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)    - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.    - max_parallel_requests: Optional[int] - Rate limit for parallel requests    - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}    - tpm_limit: Optional[int] - Tokens per minute limit    - rpm_limit: Optional[int] - Requests per minute limit    - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}    - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}    - allowed_cache_controls: Optional[list] - List of allowed cache control values    - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)    - permissions: Optional[dict] - Key-specific permissions    - guardrails: Optional[List[str]] - List of active guardrails for the key    - blocked: Optional[bool] - Whether the key is blockedReturns:- GenerateKeyResponse containing the new key and its updated parametersExample:```bashcurl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "max_budget": 100,    "metadata": {"team": "core-infra"},    "models": ["gpt-4", "gpt-3.5-turbo"]}'```Note: This is an Enterprise feature. It requires a premium license to use.
 * @summary Regenerate Key Fn
 * {@link /key/:key/regenerate}
 */
export async function regenerateKeyFnKeyKeyRegeneratePost({
	pathParams,
	body,
	headers,
	config = {},
}: {
	pathParams: RegenerateKeyFnKeyKeyRegeneratePostPathParams;
	body?: RegenerateKeyFnKeyKeyRegeneratePostMutationRequest;
	headers?: RegenerateKeyFnKeyKeyRegeneratePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["key"]) {
		throw new Error(`Missing required path parameter: key`);
	}
	const data = await request<
		RegenerateKeyFnKeyKeyRegeneratePostMutationResponse,
		ErrorWrapper<RegenerateKeyFnKeyKeyRegeneratePost422>,
		RegenerateKeyFnKeyKeyRegeneratePostMutationRequest,
		RegenerateKeyFnKeyKeyRegeneratePostHeaderParams,
		Record<string, string>,
		RegenerateKeyFnKeyKeyRegeneratePostPathParams
	>({
		method: "POST",
		url: `/key/${pathParams["key"]}/regenerate`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List all keys for a given user / team / organization.Returns:    {        "keys": List[str] or List[UserAPIKeyAuth],        "total_count": int,        "current_page": int,        "total_pages": int,    }
 * @summary List Keys
 * {@link /key/list}
 */
export async function listKeysKeyListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListKeysKeyListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListKeysKeyListGetQueryResponse,
		ErrorWrapper<ListKeysKeyListGet422>,
		null,
		Record<string, string>,
		ListKeysKeyListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/key/list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Lists all key aliasesReturns:    {        "aliases": List[str]    }
 * @summary Key Aliases
 * {@link /key/aliases}
 */
export async function keyAliasesKeyAliasesGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		KeyAliasesKeyAliasesGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/key/aliases`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Block an Virtual key from making any requests.Parameters:- key: str - The key to block. Can be either the unhashed key (sk-...) or the hashed key value Example:```bashcurl --location 'http://0.0.0.0:4000/key/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"}'```Note: This is an admin-only endpoint. Only proxy admins can block keys.
 * @summary Block Key
 * {@link /key/block}
 */
export async function blockKeyKeyBlockPost({
	body,
	headers,
	config = {},
}: {
	body: BlockKeyKeyBlockPostMutationRequest;
	headers?: BlockKeyKeyBlockPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BlockKeyKeyBlockPostMutationResponse,
		ErrorWrapper<BlockKeyKeyBlockPost422>,
		BlockKeyKeyBlockPostMutationRequest,
		BlockKeyKeyBlockPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/block`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Unblock a Virtual key to allow it to make requests again.Parameters:- key: str - The key to unblock. Can be either the unhashed key (sk-...) or the hashed key valueExample:```bashcurl --location 'http://0.0.0.0:4000/key/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"}'```Note: This is an admin-only endpoint. Only proxy admins can unblock keys.
 * @summary Unblock Key
 * {@link /key/unblock}
 */
export async function unblockKeyKeyUnblockPost({
	body,
	headers,
	config = {},
}: {
	body: UnblockKeyKeyUnblockPostMutationRequest;
	headers?: UnblockKeyKeyUnblockPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UnblockKeyKeyUnblockPostMutationResponse,
		ErrorWrapper<UnblockKeyKeyUnblockPost422>,
		UnblockKeyKeyUnblockPostMutationRequest,
		UnblockKeyKeyUnblockPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/key/unblock`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Check the health of the keyChecks:- If key based logging is configured correctly - sends a test logUsage Pass the key in the request header```bashcurl -X POST "http://localhost:4000/key/health"      -H "Authorization: Bearer sk-1234"      -H "Content-Type: application/json"```Response when logging callbacks are setup correctly:```json{  "key": "healthy",  "logging_callbacks": {    "callbacks": [      "gcs_bucket"    ],    "status": "healthy",    "details": "No logger exceptions triggered, system is healthy. Manually check if logs were sent to ['gcs_bucket']"  }}```Response when logging callbacks are not setup correctly:```json{  "key": "unhealthy",  "logging_callbacks": {    "callbacks": [      "gcs_bucket"    ],    "status": "unhealthy",    "details": "Logger exceptions triggered, system is unhealthy: Failed to load vertex credentials. Check to see if credentials containing partial/invalid information."  }}```
 * @summary Key Health
 * {@link /key/health}
 */
export async function keyHealthKeyHealthPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		KeyHealthKeyHealthPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/key/health`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Use this to create a new INTERNAL user with a budget.Internal Users can access LiteLLM Admin UI to make keys, request access to models.This creates a new user and generates a new api key for the new user. The new api key is returned.Returns user id, budget + new key.Parameters:- user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.- user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.- teams: Optional[list] - specify a list of team id's a user belongs to.- user_email: Optional[str] - Specify a user email.- send_invite_email: Optional[bool] - Specify if an invite email should be sent.- user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`- max_budget: Optional[float] - Specify max budget for a given user.- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").- models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models). Set to ['no-default-models'] to block all model access. Restricting user to only team-based model access.- tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)- rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)- auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response- aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)- config: Optional[dict] - [DEPRECATED PARAM] User-specific config.- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-- blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.- guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user- permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.- metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.- soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.- model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)- model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)- model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)- spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").- team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None. - duration: Optional[str] - Duration for the key auto-created on `/user/new`. Default is None.- key_alias: Optional[str] - Alias for the key auto-created on `/user/new`. Default is None.- sso_user_id: Optional[str] - The id of the user in the SSO provider.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.- prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.- organizations: List[str] - List of organization id's the user is a member ofReturns:- key: (str) The generated api key for the user- expires: (datetime) Datetime object for when key expires.- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.- max_budget: (float|None) Max budget for given user.Usage Example ```shell curl -X POST "http://localhost:4000/user/new"      -H "Content-Type: application/json"      -H "Authorization: Bearer sk-1234"      -d '{     "username": "new_user",     "email": "new_user@example.com" }'```
 * @summary New User
 * {@link /user/new}
 */
export async function newUserUserNewPost({
	body,
	config = {},
}: {
	body?: NewUserUserNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewUserUserNewPostMutationResponse,
		ErrorWrapper<NewUserUserNewPost422>,
		NewUserUserNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/user/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [10/07/2024]Note: To get all users (+pagination), use `/user/list` endpoint.Use this to get user information. (user row + all user key info)Example request```curl -X GET 'http://localhost:4000/user/info?user_id=krrish7%40berri.ai'     --header 'Authorization: Bearer sk-1234'```
 * @summary User Info
 * {@link /user/info}
 */
export async function userInfoUserInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: UserInfoUserInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UserInfoUserInfoGetQueryResponse,
		ErrorWrapper<UserInfoUserInfoGet422>,
		null,
		Record<string, string>,
		UserInfoUserInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Example curl ```curl --location 'http://0.0.0.0:4000/user/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "user_id": "test-litellm-user-4",    "user_role": "proxy_admin_viewer"}'```Parameters:    - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.    - user_email: Optional[str] - Specify a user email.    - password: Optional[str] - Specify a user password.    - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.    - teams: Optional[list] - specify a list of team id's a user belongs to.    - send_invite_email: Optional[bool] - Specify if an invite email should be sent.    - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`    - max_budget: Optional[float] - Specify max budget for a given user.    - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").    - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)    - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)    - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)    - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response    - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)    - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.    - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-    - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.    - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user    - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.    - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }    - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.    - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.    - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)    - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)    - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)    - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").    - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.     - duration: Optional[str] - [NOT IMPLEMENTED].    - key_alias: Optional[str] - [NOT IMPLEMENTED].    - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.    - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.
 * @summary User Update
 * {@link /user/update}
 */
export async function userUpdateUserUpdatePost({
	body,
	config = {},
}: {
	body?: UserUpdateUserUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UserUpdateUserUpdatePostMutationResponse,
		ErrorWrapper<UserUpdateUserUpdatePost422>,
		UserUpdateUserUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/user/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Bulk update multiple users at once.This endpoint allows updating multiple users in a single request. Each user updateis processed independently - if some updates fail, others will still succeed.Parameters:- users: Optional[List[UpdateUserRequest]] - List of specific user update requests- all_users: Optional[bool] - Set to true to update all users in the system- user_updates: Optional[UpdateUserRequest] - Updates to apply when all_users=TrueReturns:- results: List of individual update results- total_requested: Total number of users requested for update- successful_updates: Number of successful updates- failed_updates: Number of failed updatesExample request for specific users:```bashcurl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "users": [        {            "user_id": "user1",            "user_role": "internal_user",            "max_budget": 100.0        },        {            "user_email": "user2@example.com",             "user_role": "internal_user_viewer",            "max_budget": 50.0        }    ]}'```Example request for all users:```bashcurl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "all_users": true,    "user_updates": {        "user_role": "internal_user",        "max_budget": 50.0    }}'```
 * @summary Bulk User Update
 * {@link /user/bulk_update}
 */
export async function bulkUserUpdateUserBulkUpdatePost({
	body,
	headers,
	config = {},
}: {
	body?: BulkUserUpdateUserBulkUpdatePostMutationRequest;
	headers?: BulkUserUpdateUserBulkUpdatePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BulkUserUpdateUserBulkUpdatePostMutationResponse,
		ErrorWrapper<BulkUserUpdateUserBulkUpdatePost422>,
		BulkUserUpdateUserBulkUpdatePostMutationRequest,
		BulkUserUpdateUserBulkUpdatePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/user/bulk_update`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a paginated list of users with filtering and sorting options.Parameters:    role: Optional[str]        Filter users by role. Can be one of:        - proxy_admin        - proxy_admin_viewer        - internal_user        - internal_user_viewer    user_ids: Optional[str]        Get list of users by user_ids. Comma separated list of user_ids.    sso_ids: Optional[str]        Get list of users by sso_ids. Comma separated list of sso_ids.    user_email: Optional[str]        Filter users by partial email match    team: Optional[str]        Filter users by team id. Will match if user has this team in their teams array.    page: int        The page number to return    page_size: int        The number of items per page    sort_by: Optional[str]        Column to sort by (e.g. 'user_id', 'user_email', 'created_at', 'spend')    sort_order: Optional[str]        Sort order ('asc' or 'desc')
 * @summary Get Users
 * {@link /user/list}
 */
export async function getUsersUserListGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUsersUserListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUsersUserListGetQueryResponse,
		ErrorWrapper<GetUsersUserListGet422>,
		null,
		Record<string, string>,
		GetUsersUserListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description delete user and associated user keys```curl --location 'http://0.0.0.0:4000/user/delete' --header 'Authorization: Bearer sk-1234' --header 'Content-Type: application/json' --data-raw '{    "user_ids": ["45e3e396-ee08-4a61-a88e-16b3ce7e0849"]}'```Parameters:- user_ids: List[str] - The list of user id's to be deleted.
 * @summary Delete User
 * {@link /user/delete}
 */
export async function deleteUserUserDeletePost({
	body,
	headers,
	config = {},
}: {
	body: DeleteUserUserDeletePostMutationRequest;
	headers?: DeleteUserUserDeletePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteUserUserDeletePostMutationResponse,
		ErrorWrapper<DeleteUserUserDeletePost422>,
		DeleteUserUserDeletePostMutationRequest,
		DeleteUserUserDeletePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/user/delete`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] This is a beta endpoint. It will change.Meant to optimize querying spend data for analytics for a user.Returns:(by date)- spend- prompt_tokens- completion_tokens- cache_read_input_tokens- cache_creation_input_tokens- total_tokens- api_requests- breakdown by model, api_key, provider
 * @summary Get User Daily Activity
 * {@link /user/daily/activity}
 */
export async function getUserDailyActivityUserDailyActivityGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUserDailyActivityUserDailyActivityGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUserDailyActivityUserDailyActivityGetQueryResponse,
		ErrorWrapper<GetUserDailyActivityUserDailyActivityGet422>,
		null,
		Record<string, string>,
		GetUserDailyActivityUserDailyActivityGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/daily/activity`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Aggregated analytics for a user's daily activity without pagination.Returns the same response shape as the paginated endpoint with page metadata set to single-page.
 * @summary Get User Daily Activity Aggregated
 * {@link /user/daily/activity/aggregated}
 */
export async function getUserDailyActivityAggregatedUserDailyActivityAggregatedGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryResponse,
		ErrorWrapper<GetUserDailyActivityAggregatedUserDailyActivityAggregatedGet422>,
		null,
		Record<string, string>,
		GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/user/daily/activity/aggregated`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allow users to create a new team. Apply user permissions to their team. [Detailed Doc on setting team budgets](https://docs.litellm.ai/docs/proxy/team_budgets)Parameters:- team_alias: Optional[str] - User defined team alias- team_id: Optional[str] - The team id of the user. If none passed, we'll generate it.- members_with_roles: List[{"role": "admin" or "user", "user_id": "<user-id>"}] - A list of users and their roles in the team. Get user_id when making a new user via `/user/new`.- team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]- metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"extra_info": "some info"}- model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit for this team - applied across all keys for this team. - model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit for this team - applied across all keys for this team.- tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit- rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit- rpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of RPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating RPM, or "best_effort_throughput" for best effort enforcement.- tpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of TPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating TPM, or "best_effort_throughput" for best effort enforcement.- max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget- budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)- models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.- blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.- members: Optional[List] - Control team members via `/team/member/add` and `/team/member/delete`.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)- guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.- team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.- team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.- team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"- prompts: Optional[List[str]] - List of allowed prompts for the team. If specified, the team will only be able to use these specific prompts.- allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.Returns:- team_id: (str) Unique team id - used for tracking spend across multiple keys for same team id._deprecated_params:- admins: list - A list of user_id's for the admin role- users: list - A list of user_id's for the user roleExample Request:```curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{  "team_alias": "my-new-team_2",  "members_with_roles": [{"role": "admin", "user_id": "user-1234"},    {"role": "user", "user_id": "user-2434"}]}'``` ```curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{            "team_alias": "QA Prod Bot",            "max_budget": 0.000000001,            "budget_duration": "1d"        }'```
 * @summary New Team
 * {@link /team/new}
 */
export async function newTeamTeamNewPost({
	body,
	headers,
	config = {},
}: {
	body?: NewTeamTeamNewPostMutationRequest;
	headers?: NewTeamTeamNewPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewTeamTeamNewPostMutationResponse,
		ErrorWrapper<NewTeamTeamNewPost422>,
		NewTeamTeamNewPostMutationRequest,
		NewTeamTeamNewPostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/team/new`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Use `/team/member_add` AND `/team/member/delete` to add/remove new team membersYou can now update team budget / rate limits via /team/updateParameters:- team_id: str - The team id of the user. Required param.- team_alias: Optional[str] - User defined team alias- team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]- metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }- tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit- rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit- max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget- budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)- models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)- guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.- object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.- team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.- team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.- team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.- team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"- allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.- model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit per model for this team. Example: {"gpt-4": 100, "gpt-3.5-turbo": 200}- model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit per model for this team. Example: {"gpt-4": 10000, "gpt-3.5-turbo": 20000}Example - update team TPM Limit- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.```curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",    "tpm_limit": 100}'```Example - Update Team `max_budget` budget```curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",    "max_budget": 10}'```
 * @summary Update Team
 * {@link /team/update}
 */
export async function updateTeamTeamUpdatePost({
	body,
	headers,
	config = {},
}: {
	body: UpdateTeamTeamUpdatePostMutationRequest;
	headers?: UpdateTeamTeamUpdatePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateTeamTeamUpdatePostMutationResponse,
		ErrorWrapper<UpdateTeamTeamUpdatePost422>,
		UpdateTeamTeamUpdatePostMutationRequest,
		UpdateTeamTeamUpdatePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/team/update`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Add new members (either via user_email or user_id) to a teamIf user doesn't exist, new user row will also be added to User TableOnly proxy_admin or admin of team, allowed to access this endpoint.```curl -X POST 'http://0.0.0.0:4000/team/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{"team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849", "member": {"role": "user", "user_id": "krrish247652@berri.ai"}}'```
 * @summary Team Member Add
 * {@link /team/member_add}
 */
export async function teamMemberAddTeamMemberAddPost({
	body,
	config = {},
}: {
	body: TeamMemberAddTeamMemberAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberAddTeamMemberAddPostMutationResponse,
		ErrorWrapper<TeamMemberAddTeamMemberAddPost422>,
		TeamMemberAddTeamMemberAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/member_add`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA]delete members (either via user_email or user_id) from a teamIf user doesn't exist, an exception will be raised```curl -X POST 'http://0.0.0.0:8000/team/member_delete' -H 'Authorization: Bearer sk-1234' -H 'Content-Type: application/json' -d '{    "team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",    "user_id": "krrish247652@berri.ai"}'```
 * @summary Team Member Delete
 * {@link /team/member_delete}
 */
export async function teamMemberDeleteTeamMemberDeletePost({
	body,
	config = {},
}: {
	body: TeamMemberDeleteTeamMemberDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberDeleteTeamMemberDeletePostMutationResponse,
		ErrorWrapper<TeamMemberDeleteTeamMemberDeletePost422>,
		TeamMemberDeleteTeamMemberDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/member_delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA]Update team member budgets and team member role
 * @summary Team Member Update
 * {@link /team/member_update}
 */
export async function teamMemberUpdateTeamMemberUpdatePost({
	body,
	config = {},
}: {
	body: TeamMemberUpdateTeamMemberUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberUpdateTeamMemberUpdatePostMutationResponse,
		ErrorWrapper<TeamMemberUpdateTeamMemberUpdatePost422>,
		TeamMemberUpdateTeamMemberUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/member_update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Bulk add multiple members to a team at once.This endpoint reuses the same logic as /team/member_add but provides a bulk-friendly response format.Parameters:- team_id: str - The ID of the team to add members to- members: List[Member] - List of members to add to the team- all_users: Optional[bool] - Flag to add all users on Proxy to the team- max_budget_in_team: Optional[float] - Maximum budget allocated to each user within the teamReturns:- results: List of individual member addition results- total_requested: Total number of members requested for addition- successful_additions: Number of successful additions  - failed_additions: Number of failed additions- updated_team: The updated team objectExample request:```bashcurl --location 'http://0.0.0.0:4000/team/bulk_member_add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234",    "members": [        {            "user_id": "user1",            "role": "user"        },        {            "user_email": "user2@example.com",            "role": "admin"        }    ],    "max_budget_in_team": 100.0}'```
 * @summary Bulk Team Member Add
 * {@link /team/bulk_member_add}
 */
export async function bulkTeamMemberAddTeamBulkMemberAddPost({
	body,
	config = {},
}: {
	body: BulkTeamMemberAddTeamBulkMemberAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BulkTeamMemberAddTeamBulkMemberAddPostMutationResponse,
		ErrorWrapper<BulkTeamMemberAddTeamBulkMemberAddPost422>,
		BulkTeamMemberAddTeamBulkMemberAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/bulk_member_add`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description delete team and associated team keysParameters:- team_ids: List[str] - Required. List of team IDs to delete. Example: ["team-1234", "team-5678"]```curl --location 'http://0.0.0.0:4000/team/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{    "team_ids": ["8d916b1c-510d-4894-a334-1c16a93344f5"]}'```
 * @summary Delete Team
 * {@link /team/delete}
 */
export async function deleteTeamTeamDeletePost({
	body,
	headers,
	config = {},
}: {
	body: DeleteTeamTeamDeletePostMutationRequest;
	headers?: DeleteTeamTeamDeletePostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteTeamTeamDeletePostMutationResponse,
		ErrorWrapper<DeleteTeamTeamDeletePost422>,
		DeleteTeamTeamDeletePostMutationRequest,
		DeleteTeamTeamDeletePostHeaderParams,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/team/delete`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description get info on team + related keysParameters:- team_id: str - Required. The unique identifier of the team to get info on.```curl --location 'http://localhost:4000/team/info?team_id=your_team_id_here'     --header 'Authorization: Bearer your_api_key_here'```
 * @summary Team Info
 * {@link /team/info}
 */
export async function teamInfoTeamInfoGet({
	queryParams,
	config = {},
}: {
	queryParams?: TeamInfoTeamInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamInfoTeamInfoGetQueryResponse,
		ErrorWrapper<TeamInfoTeamInfoGet422>,
		null,
		Record<string, string>,
		TeamInfoTeamInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Blocks all calls from keys with this team id.Parameters:- team_id: str - Required. The unique identifier of the team to block.Example:```curl --location 'http://0.0.0.0:4000/team/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234"}'```Returns:- The updated team record with blocked=True
 * @summary Block Team
 * {@link /team/block}
 */
export async function blockTeamTeamBlockPost({
	body,
	config = {},
}: {
	body: BlockTeamTeamBlockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BlockTeamTeamBlockPostMutationResponse,
		ErrorWrapper<BlockTeamTeamBlockPost422>,
		BlockTeamTeamBlockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/block`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Blocks all calls from keys with this team id.Parameters:- team_id: str - Required. The unique identifier of the team to unblock.Example:```curl --location 'http://0.0.0.0:4000/team/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234"}'```
 * @summary Unblock Team
 * {@link /team/unblock}
 */
export async function unblockTeamTeamUnblockPost({
	body,
	config = {},
}: {
	body: UnblockTeamTeamUnblockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UnblockTeamTeamUnblockPostMutationResponse,
		ErrorWrapper<UnblockTeamTeamUnblockPost422>,
		UnblockTeamTeamUnblockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/unblock`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary List Available Teams
 * {@link /team/available}
 */
export async function listAvailableTeamsTeamAvailableGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListAvailableTeamsTeamAvailableGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListAvailableTeamsTeamAvailableGetQueryResponse,
		ErrorWrapper<ListAvailableTeamsTeamAvailableGet422>,
		null,
		Record<string, string>,
		ListAvailableTeamsTeamAvailableGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/available`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a paginated list of teams with filtering and sorting options.Parameters:    user_id: Optional[str]        Only return teams which this user belongs to    organization_id: Optional[str]        Only return teams which belong to this organization    team_id: Optional[str]        Filter teams by exact team_id match    team_alias: Optional[str]        Filter teams by partial team_alias match    page: int        The page number to return    page_size: int        The number of items per page    sort_by: Optional[str]        Column to sort by (e.g. 'team_id', 'team_alias', 'created_at')    sort_order: str        Sort order ('asc' or 'desc')
 * @summary List Team V2
 * {@link /v2/team/list}
 */
export async function listTeamV2V2TeamListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListTeamV2V2TeamListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListTeamV2V2TeamListGetQueryResponse,
		ErrorWrapper<ListTeamV2V2TeamListGet422>,
		null,
		Record<string, string>,
		ListTeamV2V2TeamListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v2/team/list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description ```curl --location --request GET 'http://0.0.0.0:4000/team/list'         --header 'Authorization: Bearer sk-1234'```Parameters:- user_id: str - Optional. If passed will only return teams that the user_id is a member of.- organization_id: str - Optional. If passed will only return teams that belong to the organization_id. Pass 'default_organization' to get all teams without organization_id.
 * @summary List Team
 * {@link /team/list}
 */
export async function listTeamTeamListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListTeamTeamListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListTeamTeamListGetQueryResponse,
		ErrorWrapper<ListTeamTeamListGet422>,
		null,
		Record<string, string>,
		ListTeamTeamListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Add models to a team's allowed model list. Only proxy admin or team admin can add models.Parameters:- team_id: str - Required. The team to add models to- models: List[str] - Required. List of models to add to the teamExample Request:```curl --location 'http://0.0.0.0:4000/team/model/add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234",    "models": ["gpt-4", "claude-2"]}'```
 * @summary Team Model Add
 * {@link /team/model/add}
 */
export async function teamModelAddTeamModelAddPost({
	body,
	config = {},
}: {
	body: TeamModelAddTeamModelAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamModelAddTeamModelAddPostMutationResponse,
		ErrorWrapper<TeamModelAddTeamModelAddPost422>,
		TeamModelAddTeamModelAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/model/add`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Remove models from a team's allowed model list. Only proxy admin or team admin can remove models.Parameters:- team_id: str - Required. The team to remove models from- models: List[str] - Required. List of models to remove from the teamExample Request:```curl --location 'http://0.0.0.0:4000/team/model/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "team_id": "team-1234",    "models": ["gpt-4"]}'```
 * @summary Team Model Delete
 * {@link /team/model/delete}
 */
export async function teamModelDeleteTeamModelDeletePost({
	body,
	config = {},
}: {
	body: TeamModelDeleteTeamModelDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamModelDeleteTeamModelDeletePostMutationResponse,
		ErrorWrapper<TeamModelDeleteTeamModelDeletePost422>,
		TeamModelDeleteTeamModelDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/model/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the team member permissions for a team
 * @summary Team Member Permissions
 * {@link /team/permissions_list}
 */
export async function teamMemberPermissionsTeamPermissionsListGet({
	queryParams,
	config = {},
}: {
	queryParams?: TeamMemberPermissionsTeamPermissionsListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TeamMemberPermissionsTeamPermissionsListGetQueryResponse,
		ErrorWrapper<TeamMemberPermissionsTeamPermissionsListGet422>,
		null,
		Record<string, string>,
		TeamMemberPermissionsTeamPermissionsListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/permissions_list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update the team member permissions for a team
 * @summary Update Team Member Permissions
 * {@link /team/permissions_update}
 */
export async function updateTeamMemberPermissionsTeamPermissionsUpdatePost({
	body,
	config = {},
}: {
	body: UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationResponse,
		ErrorWrapper<UpdateTeamMemberPermissionsTeamPermissionsUpdatePost422>,
		UpdateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/team/permissions_update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get daily activity for specific teams or all teams.Args:    team_ids (Optional[str]): Comma-separated list of team IDs to filter by. If not provided, returns data for all teams.    start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).    end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).    model (Optional[str]): Filter by model name.    api_key (Optional[str]): Filter by API key.    page (int): Page number for pagination.    page_size (int): Number of items per page.    exclude_team_ids (Optional[str]): Comma-separated list of team IDs to exclude.Returns:    SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 * @summary Get Team Daily Activity
 * {@link /team/daily/activity}
 */
export async function getTeamDailyActivityTeamDailyActivityGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetTeamDailyActivityTeamDailyActivityGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetTeamDailyActivityTeamDailyActivityGetQueryResponse,
		ErrorWrapper<GetTeamDailyActivityTeamDailyActivityGet422>,
		null,
		Record<string, string>,
		GetTeamDailyActivityTeamDailyActivityGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/team/daily/activity`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Return SCIM Service Provider Configuration.
 * @summary Get Service Provider Config
 * {@link /scim/v2/ServiceProviderConfig}
 */
export async function getServiceProviderConfigScimV2ServiceProviderConfigGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryResponse,
		ErrorWrapper<GetServiceProviderConfigScimV2ServiceProviderConfigGet422>,
		null,
		Record<string, string>,
		GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/scim/v2/ServiceProviderConfig`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a list of users according to SCIM v2 protocol
 * @summary Get Users
 * {@link /scim/v2/Users}
 */
export async function getUsersScimV2UsersGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetUsersScimV2UsersGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUsersScimV2UsersGetQueryResponse,
		ErrorWrapper<GetUsersScimV2UsersGet422>,
		null,
		Record<string, string>,
		GetUsersScimV2UsersGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/scim/v2/Users`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a user according to SCIM v2 protocol
 * @summary Create User
 * {@link /scim/v2/Users}
 */
export async function createUserScimV2UsersPost({
	body,
	queryParams,
	config = {},
}: {
	body: CreateUserScimV2UsersPostMutationRequest;
	queryParams?: CreateUserScimV2UsersPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateUserScimV2UsersPostMutationResponse,
		ErrorWrapper<CreateUserScimV2UsersPost422>,
		CreateUserScimV2UsersPostMutationRequest,
		Record<string, string>,
		CreateUserScimV2UsersPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/scim/v2/Users`, queryParams, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a single user by ID according to SCIM v2 protocol
 * @summary Get User
 * {@link /scim/v2/Users/:user_id}
 */
export async function getUserScimV2UsersUserIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetUserScimV2UsersUserIdGetPathParams;
	queryParams?: GetUserScimV2UsersUserIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		GetUserScimV2UsersUserIdGetQueryResponse,
		ErrorWrapper<GetUserScimV2UsersUserIdGet422>,
		null,
		Record<string, string>,
		GetUserScimV2UsersUserIdGetQueryParams,
		GetUserScimV2UsersUserIdGetPathParams
	>({
		method: "GET",
		url: `/scim/v2/Users/${pathParams["userId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update a user according to SCIM v2 protocol (full replacement)
 * @summary Update User
 * {@link /scim/v2/Users/:user_id}
 */
export async function updateUserScimV2UsersUserIdPut({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: UpdateUserScimV2UsersUserIdPutPathParams;
	body: UpdateUserScimV2UsersUserIdPutMutationRequest;
	queryParams?: UpdateUserScimV2UsersUserIdPutQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		UpdateUserScimV2UsersUserIdPutMutationResponse,
		ErrorWrapper<UpdateUserScimV2UsersUserIdPut422>,
		UpdateUserScimV2UsersUserIdPutMutationRequest,
		Record<string, string>,
		UpdateUserScimV2UsersUserIdPutQueryParams,
		UpdateUserScimV2UsersUserIdPutPathParams
	>({
		method: "PUT",
		url: `/scim/v2/Users/${pathParams["userId"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a user according to SCIM v2 protocol
 * @summary Delete User
 * {@link /scim/v2/Users/:user_id}
 */
export async function deleteUserScimV2UsersUserIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteUserScimV2UsersUserIdDeletePathParams;
	queryParams?: DeleteUserScimV2UsersUserIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		DeleteUserScimV2UsersUserIdDeleteMutationResponse,
		ErrorWrapper<DeleteUserScimV2UsersUserIdDelete422>,
		null,
		Record<string, string>,
		DeleteUserScimV2UsersUserIdDeleteQueryParams,
		DeleteUserScimV2UsersUserIdDeletePathParams
	>({
		method: "DELETE",
		url: `/scim/v2/Users/${pathParams["userId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Patch a user according to SCIM v2 protocol
 * @summary Patch User
 * {@link /scim/v2/Users/:user_id}
 */
export async function patchUserScimV2UsersUserIdPatch({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: PatchUserScimV2UsersUserIdPatchPathParams;
	body: PatchUserScimV2UsersUserIdPatchMutationRequest;
	queryParams?: PatchUserScimV2UsersUserIdPatchQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["user_id"]) {
		throw new Error(`Missing required path parameter: user_id`);
	}
	const data = await request<
		PatchUserScimV2UsersUserIdPatchMutationResponse,
		ErrorWrapper<PatchUserScimV2UsersUserIdPatch422>,
		PatchUserScimV2UsersUserIdPatchMutationRequest,
		Record<string, string>,
		PatchUserScimV2UsersUserIdPatchQueryParams,
		PatchUserScimV2UsersUserIdPatchPathParams
	>({
		method: "PATCH",
		url: `/scim/v2/Users/${pathParams["userId"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a list of groups according to SCIM v2 protocol
 * @summary Get Groups
 * {@link /scim/v2/Groups}
 */
export async function getGroupsScimV2GroupsGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetGroupsScimV2GroupsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetGroupsScimV2GroupsGetQueryResponse,
		ErrorWrapper<GetGroupsScimV2GroupsGet422>,
		null,
		Record<string, string>,
		GetGroupsScimV2GroupsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/scim/v2/Groups`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a group according to SCIM v2 protocol
 * @summary Create Group
 * {@link /scim/v2/Groups}
 */
export async function createGroupScimV2GroupsPost({
	body,
	queryParams,
	config = {},
}: {
	body: CreateGroupScimV2GroupsPostMutationRequest;
	queryParams?: CreateGroupScimV2GroupsPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateGroupScimV2GroupsPostMutationResponse,
		ErrorWrapper<CreateGroupScimV2GroupsPost422>,
		CreateGroupScimV2GroupsPostMutationRequest,
		Record<string, string>,
		CreateGroupScimV2GroupsPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/scim/v2/Groups`, queryParams, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get a single group by ID according to SCIM v2 protocol
 * @summary Get Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function getGroupScimV2GroupsGroupIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetGroupScimV2GroupsGroupIdGetPathParams;
	queryParams?: GetGroupScimV2GroupsGroupIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		GetGroupScimV2GroupsGroupIdGetQueryResponse,
		ErrorWrapper<GetGroupScimV2GroupsGroupIdGet422>,
		null,
		Record<string, string>,
		GetGroupScimV2GroupsGroupIdGetQueryParams,
		GetGroupScimV2GroupsGroupIdGetPathParams
	>({
		method: "GET",
		url: `/scim/v2/Groups/${pathParams["groupId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update a group according to SCIM v2 protocol
 * @summary Update Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function updateGroupScimV2GroupsGroupIdPut({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: UpdateGroupScimV2GroupsGroupIdPutPathParams;
	body: UpdateGroupScimV2GroupsGroupIdPutMutationRequest;
	queryParams?: UpdateGroupScimV2GroupsGroupIdPutQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		UpdateGroupScimV2GroupsGroupIdPutMutationResponse,
		ErrorWrapper<UpdateGroupScimV2GroupsGroupIdPut422>,
		UpdateGroupScimV2GroupsGroupIdPutMutationRequest,
		Record<string, string>,
		UpdateGroupScimV2GroupsGroupIdPutQueryParams,
		UpdateGroupScimV2GroupsGroupIdPutPathParams
	>({
		method: "PUT",
		url: `/scim/v2/Groups/${pathParams["groupId"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a group according to SCIM v2 protocol
 * @summary Delete Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function deleteGroupScimV2GroupsGroupIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteGroupScimV2GroupsGroupIdDeletePathParams;
	queryParams?: DeleteGroupScimV2GroupsGroupIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		DeleteGroupScimV2GroupsGroupIdDeleteMutationResponse,
		ErrorWrapper<DeleteGroupScimV2GroupsGroupIdDelete422>,
		null,
		Record<string, string>,
		DeleteGroupScimV2GroupsGroupIdDeleteQueryParams,
		DeleteGroupScimV2GroupsGroupIdDeletePathParams
	>({
		method: "DELETE",
		url: `/scim/v2/Groups/${pathParams["groupId"]}`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Patch a group according to SCIM v2 protocol
 * @summary Patch Group
 * {@link /scim/v2/Groups/:group_id}
 */
export async function patchGroupScimV2GroupsGroupIdPatch({
	pathParams,
	body,
	queryParams,
	config = {},
}: {
	pathParams: PatchGroupScimV2GroupsGroupIdPatchPathParams;
	body: PatchGroupScimV2GroupsGroupIdPatchMutationRequest;
	queryParams?: PatchGroupScimV2GroupsGroupIdPatchQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["group_id"]) {
		throw new Error(`Missing required path parameter: group_id`);
	}
	const data = await request<
		PatchGroupScimV2GroupsGroupIdPatchMutationResponse,
		ErrorWrapper<PatchGroupScimV2GroupsGroupIdPatch422>,
		PatchGroupScimV2GroupsGroupIdPatchMutationRequest,
		Record<string, string>,
		PatchGroupScimV2GroupsGroupIdPatchQueryParams,
		PatchGroupScimV2GroupsGroupIdPatchPathParams
	>({
		method: "PATCH",
		url: `/scim/v2/Groups/${pathParams["groupId"]}`,
		queryParams,
		body,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allow orgs to own teamsSet org level budgets + model access.Only admins can create orgs.# Parameters- organization_alias: *str* - The name of the organization.- models: *List* - The models the organization has access to.- budget_id: *Optional[str]* - The id for a budget (tpm/rpm/max budget) for the organization.### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###- max_budget: *Optional[float]* - Max budget for org- tpm_limit: *Optional[int]* - Max tpm limit for org- rpm_limit: *Optional[int]* - Max rpm limit for org- model_rpm_limit: *Optional[Dict[str, int]]* - The RPM (Requests Per Minute) limit per model for this organization.- model_tpm_limit: *Optional[Dict[str, int]]* - The TPM (Tokens Per Minute) limit per model for this organization.- max_parallel_requests: *Optional[int]* - [Not Implemented Yet] Max parallel requests for org- soft_budget: *Optional[float]* - [Not Implemented Yet] Get a slack alert when this soft budget is reached. Don't block requests.- model_max_budget: *Optional[dict]* - Max budget for a specific model- budget_duration: *Optional[str]* - Frequency of reseting org budget- metadata: *Optional[dict]* - Metadata for organization, store information for organization. Example metadata - {"extra_info": "some info"}- blocked: *bool* - Flag indicating if the org is blocked or not - will stop all calls from keys with this org_id.- tags: *Optional[List[str]]* - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).- organization_id: *Optional[str]* - The organization id of the team. Default is None. Create via `/organization/new`.- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)- object_permission: Optional[LiteLLM_ObjectPermissionBase] - organization-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.Case 1: Create new org **without** a budget_id```bashcurl --location 'http://0.0.0.0:4000/organization/new' --header 'Authorization: Bearer sk-1234' --header 'Content-Type: application/json' --data '{    "organization_alias": "my-secret-org",    "models": ["model1", "model2"],    "max_budget": 100}'```Case 2: Create new org **with** a budget_id```bashcurl --location 'http://0.0.0.0:4000/organization/new' --header 'Authorization: Bearer sk-1234' --header 'Content-Type: application/json' --data '{    "organization_alias": "my-secret-org",    "models": ["model1", "model2"],    "budget_id": "428eeaa8-f3ac-4e85-a8fb-7dc8d7aa8689"}'```
 * @summary New Organization
 * {@link /organization/new}
 */
export async function newOrganizationOrganizationNewPost({
	body,
	config = {},
}: {
	body: NewOrganizationOrganizationNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewOrganizationOrganizationNewPostMutationResponse,
		ErrorWrapper<NewOrganizationOrganizationNewPost422>,
		NewOrganizationOrganizationNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/organization/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an organization
 * @summary Update Organization
 * {@link /organization/update}
 */
export async function updateOrganizationOrganizationUpdatePatch({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateOrganizationOrganizationUpdatePatchMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/organization/update`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete an organization# Parameters:- organization_ids: List[str] - The organization ids to delete.
 * @summary Delete Organization
 * {@link /organization/delete}
 */
export async function deleteOrganizationOrganizationDeleteDelete({
	body,
	config = {},
}: {
	body: DeleteOrganizationOrganizationDeleteDeleteMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteOrganizationOrganizationDeleteDeleteMutationResponse,
		ErrorWrapper<DeleteOrganizationOrganizationDeleteDelete422>,
		DeleteOrganizationOrganizationDeleteDeleteMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "DELETE", url: `/organization/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description ```curl --location --request GET 'http://0.0.0.0:4000/organization/list'         --header 'Authorization: Bearer sk-1234'```
 * @summary List Organization
 * {@link /organization/list}
 */
export async function listOrganizationOrganizationListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListOrganizationOrganizationListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/organization/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the org specific information
 * @summary Info Organization
 * {@link /organization/info}
 */
export async function infoOrganizationOrganizationInfoGet({
	queryParams,
	config = {},
}: {
	queryParams: InfoOrganizationOrganizationInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoOrganizationOrganizationInfoGetQueryResponse,
		ErrorWrapper<InfoOrganizationOrganizationInfoGet422>,
		null,
		Record<string, string>,
		InfoOrganizationOrganizationInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/organization/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description DEPRECATED: Use GET /organization/info instead
 * @summary Deprecated Info Organization
 * {@link /organization/info}
 */
export async function deprecatedInfoOrganizationOrganizationInfoPost({
	body,
	config = {},
}: {
	body: DeprecatedInfoOrganizationOrganizationInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeprecatedInfoOrganizationOrganizationInfoPostMutationResponse,
		ErrorWrapper<DeprecatedInfoOrganizationOrganizationInfoPost422>,
		DeprecatedInfoOrganizationOrganizationInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/organization/info`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA]Add new members (either via user_email or user_id) to an organizationIf user doesn't exist, new user row will also be added to User TableOnly proxy_admin or org_admin of organization, allowed to access this endpoint.# Parameters:- organization_id: str (required)- member: Union[List[Member], Member] (required)    - role: Literal[LitellmUserRoles] (required)    - user_id: Optional[str]    - user_email: Optional[str]Note: Either user_id or user_email must be provided for each member.Example:```curl -X POST 'http://0.0.0.0:4000/organization/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{    "organization_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",    "member": {        "role": "internal_user",        "user_id": "krrish247652@berri.ai"    },    "max_budget_in_organization": 100.0}'```The following is executed in this function:1. Check if organization exists2. Creates a new Internal User if the user_id or user_email is not found in LiteLLM_UserTable3. Add Internal User to the `LiteLLM_OrganizationMembership` table
 * @summary Organization Member Add
 * {@link /organization/member_add}
 */
export async function organizationMemberAddOrganizationMemberAddPost({
	body,
	config = {},
}: {
	body: OrganizationMemberAddOrganizationMemberAddPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OrganizationMemberAddOrganizationMemberAddPostMutationResponse,
		ErrorWrapper<OrganizationMemberAddOrganizationMemberAddPost422>,
		OrganizationMemberAddOrganizationMemberAddPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/organization/member_add`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update a member's role in an organization
 * @summary Organization Member Update
 * {@link /organization/member_update}
 */
export async function organizationMemberUpdateOrganizationMemberUpdatePatch({
	body,
	config = {},
}: {
	body: OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationResponse,
		ErrorWrapper<OrganizationMemberUpdateOrganizationMemberUpdatePatch422>,
		OrganizationMemberUpdateOrganizationMemberUpdatePatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/organization/member_update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a member from an organization
 * @summary Organization Member Delete
 * {@link /organization/member_delete}
 */
export async function organizationMemberDeleteOrganizationMemberDeleteDelete({
	body,
	config = {},
}: {
	body: OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationResponse,
		ErrorWrapper<OrganizationMemberDeleteOrganizationMemberDeleteDelete422>,
		OrganizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "DELETE", url: `/organization/member_delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] Reject calls with this end-user idParameters:- user_ids (List[str], required): The unique `user_id`s for the users to block    (any /chat/completion call with this user={end-user-id} param, will be rejected.)    ```    curl -X POST "http://0.0.0.0:8000/user/block"    -H "Authorization: Bearer sk-1234"    -d '{    "user_ids": [<user_id>, ...]    }'    ```
 * @summary Block User
 * {@link /customer/block}
 */
export async function blockUserCustomerBlockPost({
	body,
	config = {},
}: {
	body: BlockUserCustomerBlockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BlockUserCustomerBlockPostMutationResponse,
		ErrorWrapper<BlockUserCustomerBlockPost422>,
		BlockUserCustomerBlockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/block`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [BETA] Unblock calls with this user idExample```curl -X POST "http://0.0.0.0:8000/user/unblock"-H "Authorization: Bearer sk-1234"-d '{"user_ids": [<user_id>, ...]}'```
 * @summary Unblock User
 * {@link /customer/unblock}
 */
export async function unblockUserCustomerUnblockPost({
	body,
	config = {},
}: {
	body: UnblockUserCustomerUnblockPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UnblockUserCustomerUnblockPostMutationResponse,
		ErrorWrapper<UnblockUserCustomerUnblockPost422>,
		UnblockUserCustomerUnblockPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/unblock`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allow creating a new Customer Parameters:- user_id: str - The unique identifier for the user.- alias: Optional[str] - A human-friendly alias for the user.- blocked: bool - Flag to allow or disallow requests for this end-user. Default is False.- max_budget: Optional[float] - The maximum budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.- budget_id: Optional[str] - The identifier for an existing budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.- allowed_model_region: Optional[Union[Literal["eu"], Literal["us"]]] - Require all user requests to use models in this specific region.- default_model: Optional[str] - If no equivalent model in the allowed region, default all requests to this model.- metadata: Optional[dict] = Metadata for customer, store information for customer. Example metadata = {"data_training_opt_out": True}- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").- tpm_limit: Optional[int] - [Not Implemented Yet] Specify tpm limit for a given customer (Tokens per minute)- rpm_limit: Optional[int] - [Not Implemented Yet] Specify rpm limit for a given customer (Requests per minute)- model_max_budget: Optional[dict] - [Not Implemented Yet] Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d"}}- max_parallel_requests: Optional[int] - [Not Implemented Yet] Specify max parallel requests for a given customer.- soft_budget: Optional[float] - [Not Implemented Yet] Get alerts when customer crosses given budget, doesn't block requests.- spend: Optional[float] - Specify initial spend for a given customer.- budget_reset_at: Optional[str] - Specify the date and time when the budget should be reset.- Allow specifying allowed regions - Allow specifying default modelExample curl:```curl --location 'http://0.0.0.0:4000/customer/new'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "user_id" : "ishaan-jaff-3",        "allowed_region": "eu",        "budget_id": "free_tier",        "default_model": "azure/gpt-3.5-turbo-eu" <- all calls from this user, use this model?     }'    # return end-user object```NOTE: This used to be called `/end_user/new`, we will still be maintaining compatibility for /end_user/XXX for these endpoints
 * @summary New End User
 * {@link /customer/new}
 */
export async function newEndUserCustomerNewPost({
	body,
	config = {},
}: {
	body: NewEndUserCustomerNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewEndUserCustomerNewPostMutationResponse,
		ErrorWrapper<NewEndUserCustomerNewPost422>,
		NewEndUserCustomerNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get information about an end-user. An `end_user` is a customer (external user) of the proxy.Parameters:- end_user_id (str, required): The unique identifier for the end-userExample curl:```curl -X GET 'http://localhost:4000/customer/info?end_user_id=test-litellm-user-4'         -H 'Authorization: Bearer sk-1234'```
 * @summary End User Info
 * {@link /customer/info}
 */
export async function endUserInfoCustomerInfoGet({
	queryParams,
	config = {},
}: {
	queryParams: EndUserInfoCustomerInfoGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		EndUserInfoCustomerInfoGetQueryResponse,
		ErrorWrapper<EndUserInfoCustomerInfoGet422>,
		null,
		Record<string, string>,
		EndUserInfoCustomerInfoGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/customer/info`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Example curl Parameters:- user_id: str- alias: Optional[str] = None  # human-friendly alias- blocked: bool = False  # allow/disallow requests for this end-user- max_budget: Optional[float] = None- budget_id: Optional[str] = None  # give either a budget_id or max_budget- allowed_model_region: Optional[AllowedModelRegion] = (    None  # require all user requests to use models in this specific region)- default_model: Optional[str] = (    None  # if no equivalent model in allowed region - default all requests to this model)Example curl:```curl --location 'http://0.0.0.0:4000/customer/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{    "user_id": "test-litellm-user-4",    "budget_id": "paid_tier"}'See below for all params ```
 * @summary Update End User
 * {@link /customer/update}
 */
export async function updateEndUserCustomerUpdatePost({
	body,
	config = {},
}: {
	body: UpdateEndUserCustomerUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateEndUserCustomerUpdatePostMutationResponse,
		ErrorWrapper<UpdateEndUserCustomerUpdatePost422>,
		UpdateEndUserCustomerUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete multiple end-users.Parameters:- user_ids (List[str], required): The unique `user_id`s for the users to deleteExample curl:```curl --location 'http://0.0.0.0:4000/customer/delete'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{        "user_ids" :["ishaan-jaff-5"]}'See below for all params ```
 * @summary Delete End User
 * {@link /customer/delete}
 */
export async function deleteEndUserCustomerDeletePost({
	body,
	config = {},
}: {
	body: DeleteEndUserCustomerDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteEndUserCustomerDeletePostMutationResponse,
		ErrorWrapper<DeleteEndUserCustomerDeletePost422>,
		DeleteEndUserCustomerDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/customer/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description [Admin-only] List all available customersExample curl:```curl --location --request GET 'http://0.0.0.0:4000/customer/list'         --header 'Authorization: Bearer sk-1234'```
 * @summary List End User
 * {@link /customer/list}
 */
export async function listEndUserCustomerListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListEndUserCustomerListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/customer/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description LiteLLM Enterprise - View Spend Per Request TagExample Request:```curl -X GET "http://0.0.0.0:8000/spend/tags" -H "Authorization: Bearer sk-1234"```Spend with Start Date and End Date```curl -X GET "http://0.0.0.0:8000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"```
 * @summary View Spend Tags
 * {@link /spend/tags}
 */
export async function viewSpendTagsSpendTagsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ViewSpendTagsSpendTagsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ViewSpendTagsSpendTagsGetQueryResponse,
		ErrorWrapper<ViewSpendTagsSpendTagsGet422>,
		null,
		Record<string, string>,
		ViewSpendTagsSpendTagsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/spend/tags`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get Daily Spend per Team, based on specific startTime and endTime. Per team, view usage by each key, model[    {        "group-by-day": "2024-05-10",        "teams": [            {                "team_name": "team-1"                "spend": 10,                "keys": [                    "key": "1213",                    "usage": {                        "model-1": {                                "cost": 12.50,                                "input_tokens": 1000,                                "output_tokens": 5000,                                "requests": 100                            },                            "audio-modelname1": {                            "cost": 25.50,                            "seconds": 25,                            "requests": 50                    },                    }                }        ]    ]}
 * @summary Get Global Spend Report
 * {@link /global/spend/report}
 */
export async function getGlobalSpendReportGlobalSpendReportGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetGlobalSpendReportGlobalSpendReportGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetGlobalSpendReportGlobalSpendReportGetQueryResponse,
		ErrorWrapper<GetGlobalSpendReportGlobalSpendReportGet422>,
		null,
		Record<string, string>,
		GetGlobalSpendReportGlobalSpendReportGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/global/spend/report`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description LiteLLM Enterprise - View Spend Per Request Tag. Used by LiteLLM UIExample Request:```curl -X GET "http://0.0.0.0:4000/spend/tags" -H "Authorization: Bearer sk-1234"```Spend with Start Date and End Date```curl -X GET "http://0.0.0.0:4000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"```
 * @summary Global View Spend Tags
 * {@link /global/spend/tags}
 */
export async function globalViewSpendTagsGlobalSpendTagsGet({
	queryParams,
	config = {},
}: {
	queryParams?: GlobalViewSpendTagsGlobalSpendTagsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GlobalViewSpendTagsGlobalSpendTagsGetQueryResponse,
		ErrorWrapper<GlobalViewSpendTagsGlobalSpendTagsGet422>,
		null,
		Record<string, string>,
		GlobalViewSpendTagsGlobalSpendTagsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/global/spend/tags`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Accepts all the params of completion_cost.Calculate spend **before** making call:Note: If you see a spend of $0.0 you need to set custom_pricing for your model: https://docs.litellm.ai/docs/proxy/custom_pricing```curl --location 'http://localhost:4000/spend/calculate'--header 'Authorization: Bearer sk-1234'--header 'Content-Type: application/json'--data '{    "model": "anthropic.claude-v2",    "messages": [{"role": "user", "content": "Hey, how'''s it going?"}]}'```Calculate spend **after** making call:```curl --location 'http://localhost:4000/spend/calculate'--header 'Authorization: Bearer sk-1234'--header 'Content-Type: application/json'--data '{    "completion_response": {        "id": "chatcmpl-123",        "object": "chat.completion",        "created": 1677652288,        "model": "gpt-3.5-turbo-0125",        "system_fingerprint": "fp_44709d6fcb",        "choices": [{            "index": 0,            "message": {                "role": "assistant",                "content": "Hello there, how may I assist you today?"            },            "logprobs": null,            "finish_reason": "stop"        }]        "usage": {            "prompt_tokens": 9,            "completion_tokens": 12,            "total_tokens": 21        }    }}'```
 * @summary Calculate Spend
 * {@link /spend/calculate}
 */
export async function calculateSpendSpendCalculatePost({
	body,
	config = {},
}: {
	body?: CalculateSpendSpendCalculatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CalculateSpendSpendCalculatePostMutationResponse,
		ErrorWrapper<CalculateSpendSpendCalculatePost422>,
		CalculateSpendSpendCalculatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/spend/calculate`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description View all spend logs, if request_id is provided, only logs for that request_id will be returnedWhen start_date and end_date are provided:- summarize=true (default): Returns aggregated spend data grouped by date (maintains backward compatibility)- summarize=false: Returns filtered individual log entries within the date rangeExample Request for all logs```curl -X GET "http://0.0.0.0:8000/spend/logs" -H "Authorization: Bearer sk-1234"```Example Request for specific request_id```curl -X GET "http://0.0.0.0:8000/spend/logs?request_id=chatcmpl-6dcb2540-d3d7-4e49-bb27-291f863f112e" -H "Authorization: Bearer sk-1234"```Example Request for specific api_key```curl -X GET "http://0.0.0.0:8000/spend/logs?api_key=sk-Fn8Ej39NkBQmUagFEoUWPQ" -H "Authorization: Bearer sk-1234"```Example Request for specific user_id```curl -X GET "http://0.0.0.0:8000/spend/logs?user_id=ishaan@berri.ai" -H "Authorization: Bearer sk-1234"```Example Request for date range with individual logs (unsummarized)```curl -X GET "http://0.0.0.0:8000/spend/logs?start_date=2024-01-01&end_date=2024-01-02&summarize=false" -H "Authorization: Bearer sk-1234"```
 * @summary View Spend Logs
 * {@link /spend/logs}
 */
export async function viewSpendLogsSpendLogsGet({
	queryParams,
	config = {},
}: {
	queryParams?: ViewSpendLogsSpendLogsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ViewSpendLogsSpendLogsGetQueryResponse,
		ErrorWrapper<ViewSpendLogsSpendLogsGet422>,
		null,
		Record<string, string>,
		ViewSpendLogsSpendLogsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/spend/logs`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description ADMIN ONLY / MASTER KEY Only EndpointGlobally reset spend for All API Keys and Teams, maintain LiteLLM_SpendLogs1. LiteLLM_SpendLogs will maintain the logs on spend, no data gets deleted from there2. LiteLLM_VerificationTokens spend will be set = 03. LiteLLM_TeamTable spend will be set = 0
 * @summary Global Spend Reset
 * {@link /global/spend/reset}
 */
export async function globalSpendResetGlobalSpendResetPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GlobalSpendResetGlobalSpendResetPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/global/spend/reset`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Provider Budget Routing - Get Budget, Spend Details https://docs.litellm.ai/docs/proxy/provider_budget_routingUse this endpoint to check current budget, spend and budget reset time for a providerExample Request```bashcurl -X GET http://localhost:4000/provider/budgets     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"```Example Response```json{    "providers": {        "openai": {            "budget_limit": 1e-12,            "time_period": "1d",            "spend": 0.0,            "budget_reset_at": null        },        "azure": {            "budget_limit": 100.0,            "time_period": "1d",            "spend": 0.0,            "budget_reset_at": null        },        "anthropic": {            "budget_limit": 100.0,            "time_period": "10d",            "spend": 0.0,            "budget_reset_at": null        },        "vertex_ai": {            "budget_limit": 100.0,            "time_period": "12d",            "spend": 0.0,            "budget_reset_at": null        }    }}```
 * @summary Provider Budgets
 * {@link /provider/budgets}
 */
export async function providerBudgetsProviderBudgetsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ProviderBudgetsProviderBudgetsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/provider/budgets`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description View current CloudZero settings.Returns the current CloudZero configuration with the API key masked for security.Only the first 4 and last 4 characters of the API key are shown.Only admin users can view CloudZero settings.
 * @summary Get Cloudzero Settings
 * {@link /cloudzero/settings}
 */
export async function getCloudzeroSettingsCloudzeroSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCloudzeroSettingsCloudzeroSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cloudzero/settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update existing CloudZero settings.Allows updating individual CloudZero configuration fields without requiring all fields.Only provided fields will be updated; others will remain unchanged.Parameters:- api_key: (Optional) New CloudZero API key for authentication- connection_id: (Optional) New CloudZero connection ID for data submission- timezone: (Optional) New timezone for date handlingOnly admin users can update CloudZero settings.
 * @summary Update Cloudzero Settings
 * {@link /cloudzero/settings}
 */
export async function updateCloudzeroSettingsCloudzeroSettingsPut({
	body,
	config = {},
}: {
	body?: UpdateCloudzeroSettingsCloudzeroSettingsPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateCloudzeroSettingsCloudzeroSettingsPutMutationResponse,
		ErrorWrapper<UpdateCloudzeroSettingsCloudzeroSettingsPut422>,
		UpdateCloudzeroSettingsCloudzeroSettingsPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PUT", url: `/cloudzero/settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Initialize CloudZero settings and store in the database.This endpoint stores the CloudZero API key, connection ID, and timezone configurationin the proxy database for use by the CloudZero logger.Parameters:- api_key: CloudZero API key for authentication- connection_id: CloudZero connection ID for data submission- timezone: Timezone for date handling (default: UTC)Only admin users can configure CloudZero settings.
 * @summary Init Cloudzero Settings
 * {@link /cloudzero/init}
 */
export async function initCloudzeroSettingsCloudzeroInitPost({
	body,
	config = {},
}: {
	body: InitCloudzeroSettingsCloudzeroInitPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InitCloudzeroSettingsCloudzeroInitPostMutationResponse,
		ErrorWrapper<InitCloudzeroSettingsCloudzeroInitPost422>,
		InitCloudzeroSettingsCloudzeroInitPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cloudzero/init`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Perform a dry run export using the CloudZero logger.This endpoint uses the CloudZero logger to perform a dry run export,which returns the data that would be exported without actually sending it to CloudZero.Parameters:- limit: Optional limit on number of records to process (default: 10000)Returns:- usage_data: Sample of the raw usage data (first 50 records)- cbf_data: CloudZero CBF formatted data ready for export- summary: Statistics including total cost, tokens, and record countsOnly admin users can perform CloudZero exports.
 * @summary Cloudzero Dry Run Export
 * {@link /cloudzero/dry-run}
 */
export async function cloudzeroDryRunExportCloudzeroDryRunPost({
	body,
	config = {},
}: {
	body?: CloudzeroDryRunExportCloudzeroDryRunPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CloudzeroDryRunExportCloudzeroDryRunPostMutationResponse,
		ErrorWrapper<CloudzeroDryRunExportCloudzeroDryRunPost422>,
		CloudzeroDryRunExportCloudzeroDryRunPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cloudzero/dry-run`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Perform an actual export using the CloudZero logger.This endpoint uses the CloudZero logger to export usage data to CloudZero AnyCost API.Parameters:- limit: Optional limit on number of records to export- operation: CloudZero operation type ("replace_hourly" or "sum", default: "replace_hourly")Only admin users can perform CloudZero exports.
 * @summary Cloudzero Export
 * {@link /cloudzero/export}
 */
export async function cloudzeroExportCloudzeroExportPost({
	body,
	config = {},
}: {
	body?: CloudzeroExportCloudzeroExportPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CloudzeroExportCloudzeroExportPostMutationResponse,
		ErrorWrapper<CloudzeroExportCloudzeroExportPost422>,
		CloudzeroExportCloudzeroExportPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cloudzero/export`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Endpoint for checking if cache can be pinged
 * @summary Cache Ping
 * {@link /cache/ping}
 */
export async function cachePingCachePingGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CachePingCachePingGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cache/ping`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Endpoint for deleting a key from the cache. All responses from litellm proxy have `x-litellm-cache-key` in the headersParameters:- **keys**: *Optional[List[str]]* - A list of keys to delete from the cache. Example {"keys": ["key1", "key2"]}```shellcurl -X POST "http://0.0.0.0:4000/cache/delete"     -H "Authorization: Bearer sk-1234"     -d '{"keys": ["key1", "key2"]}'```
 * @summary Cache Delete
 * {@link /cache/delete}
 */
export async function cacheDeleteCacheDeletePost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CacheDeleteCacheDeletePostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/delete`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Endpoint for getting /redis/info
 * @summary Cache Redis Info
 * {@link /cache/redis/info}
 */
export async function cacheRedisInfoCacheRedisInfoGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CacheRedisInfoCacheRedisInfoGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cache/redis/info`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description A function to flush all items from the cache. (All items will be deleted from the cache with this)Raises HTTPException if the cache is not initialized or if the cache type does not support flushing.Returns a dictionary with the status of the operation.Usage:```curl -X POST http://0.0.0.0:4000/cache/flushall -H "Authorization: Bearer sk-1234"```
 * @summary Cache Flushall
 * {@link /cache/flushall}
 */
export async function cacheFlushallCacheFlushallPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CacheFlushallCacheFlushallPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/flushall`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List the guardrails that are available on the proxy server [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/guardrails/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrails": [        {        "guardrail_name": "bedrock-pre-guard",        "guardrail_info": {            "params": [            {                "name": "toxicity_score",                "type": "float",                "description": "Score between 0-1 indicating content toxicity level"            },            {                "name": "pii_detection",                "type": "boolean"            }            ]        }        }    ]}```
 * @summary List Guardrails
 * {@link /guardrails/list}
 */
export async function listGuardrailsGuardrailsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListGuardrailsGuardrailsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/guardrails/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List the guardrails that are available in the database using GuardrailRegistry [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/v2/guardrails/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrails": [        {            "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",            "guardrail_name": "my-bedrock-guard",            "litellm_params": {                "guardrail": "bedrock",                "mode": "pre_call",                "guardrailIdentifier": "ff6ujrregl1q",                "guardrailVersion": "DRAFT",                "default_on": true            },            "guardrail_info": {                "description": "Bedrock content moderation guardrail"            }        }    ]}```
 * @summary List Guardrails V2
 * {@link /v2/guardrails/list}
 */
export async function listGuardrailsV2V2GuardrailsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListGuardrailsV2V2GuardrailsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/v2/guardrails/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a new guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X POST "http://localhost:4000/guardrails" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "guardrail": {            "guardrail_name": "my-bedrock-guard",            "litellm_params": {                "guardrail": "bedrock",                "mode": "pre_call",                "guardrailIdentifier": "ff6ujrregl1q",                "guardrailVersion": "DRAFT",                "default_on": true            },            "guardrail_info": {                "description": "Bedrock content moderation guardrail"            }        }    }'```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "my-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Create Guardrail
 * {@link /guardrails}
 */
export async function createGuardrailGuardrailsPost({
	body,
	config = {},
}: {
	body: CreateGuardrailGuardrailsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateGuardrailGuardrailsPostMutationResponse,
		ErrorWrapper<CreateGuardrailGuardrailsPost422>,
		CreateGuardrailGuardrailsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/guardrails`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an existing guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X PUT "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "guardrail": {            "guardrail_name": "updated-bedrock-guard",            "litellm_params": {                "guardrail": "bedrock",                "mode": "pre_call",                "guardrailIdentifier": "ff6ujrregl1q",                "guardrailVersion": "1.0",                "default_on": true            },            "guardrail_info": {                "description": "Updated Bedrock content moderation guardrail"            }        }    }'```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "updated-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "1.0",        "default_on": true    },    "guardrail_info": {        "description": "Updated Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T13:45:12.345Z"}```
 * @summary Update Guardrail
 * {@link /guardrails/:guardrail_id}
 */
export async function updateGuardrailGuardrailsGuardrailIdPut({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdateGuardrailGuardrailsGuardrailIdPutPathParams;
	body: UpdateGuardrailGuardrailsGuardrailIdPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		UpdateGuardrailGuardrailsGuardrailIdPutMutationResponse,
		ErrorWrapper<UpdateGuardrailGuardrailsGuardrailIdPut422>,
		UpdateGuardrailGuardrailsGuardrailIdPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdateGuardrailGuardrailsGuardrailIdPutPathParams
	>({ method: "PUT", url: `/guardrails/${pathParams["guardrailId"]}`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X DELETE "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "message": "Guardrail 123e4567-e89b-12d3-a456-426614174000 deleted successfully"}```
 * @summary Delete Guardrail
 * {@link /guardrails/:guardrail_id}
 */
export async function deleteGuardrailGuardrailsGuardrailIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteGuardrailGuardrailsGuardrailIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		DeleteGuardrailGuardrailsGuardrailIdDeleteMutationResponse,
		ErrorWrapper<DeleteGuardrailGuardrailsGuardrailIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteGuardrailGuardrailsGuardrailIdDeletePathParams
	>({ method: "DELETE", url: `/guardrails/${pathParams["guardrailId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Partially update an existing guardrail [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)This endpoint allows updating specific fields of a guardrail without sending the entire object.Only the following fields can be updated:- guardrail_name: The name of the guardrail- default_on: Whether the guardrail is enabled by default- guardrail_info: Additional information about the guardrailExample Request:```bashcurl -X PATCH "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "guardrail_name": "updated-name",        "default_on": true,        "guardrail_info": {            "description": "Updated description"        }    }'```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "updated-name",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Updated description"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T14:22:33.456Z"}```
 * @summary Patch Guardrail
 * {@link /guardrails/:guardrail_id}
 */
export async function patchGuardrailGuardrailsGuardrailIdPatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: PatchGuardrailGuardrailsGuardrailIdPatchPathParams;
	body?: PatchGuardrailGuardrailsGuardrailIdPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		PatchGuardrailGuardrailsGuardrailIdPatchMutationResponse,
		ErrorWrapper<PatchGuardrailGuardrailsGuardrailIdPatch422>,
		PatchGuardrailGuardrailsGuardrailIdPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		PatchGuardrailGuardrailsGuardrailIdPatchPathParams
	>({ method: "PATCH", url: `/guardrails/${pathParams["guardrailId"]}`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get detailed information about a specific guardrail by ID [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "my-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Get Guardrail Info
 * {@link /guardrails/:guardrail_id}
 */
export async function getGuardrailInfoGuardrailsGuardrailIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetGuardrailInfoGuardrailsGuardrailIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		GetGuardrailInfoGuardrailsGuardrailIdGetQueryResponse,
		ErrorWrapper<GetGuardrailInfoGuardrailsGuardrailIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetGuardrailInfoGuardrailsGuardrailIdGetPathParams
	>({ method: "GET", url: `/guardrails/${pathParams["guardrailId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get detailed information about a specific guardrail by ID [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)Example Request:```bashcurl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",    "guardrail_name": "my-bedrock-guard",    "litellm_params": {        "guardrail": "bedrock",        "mode": "pre_call",        "guardrailIdentifier": "ff6ujrregl1q",        "guardrailVersion": "DRAFT",        "default_on": true    },    "guardrail_info": {        "description": "Bedrock content moderation guardrail"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Get Guardrail Info
 * {@link /guardrails/:guardrail_id/info}
 */
export async function getGuardrailInfoGuardrailsGuardrailIdInfoGet({
	pathParams,
	config = {},
}: {
	pathParams: GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["guardrail_id"]) {
		throw new Error(`Missing required path parameter: guardrail_id`);
	}
	const data = await request<
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetQueryResponse,
		ErrorWrapper<GetGuardrailInfoGuardrailsGuardrailIdInfoGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams
	>({ method: "GET", url: `/guardrails/${pathParams["guardrailId"]}/info`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the UI settings for the guardrailsReturns:- Supported entities for guardrails- Supported modes for guardrails- PII entity categories for UI organization- Content filter settings (patterns and categories)
 * @summary Get Guardrail Ui Settings
 * {@link /guardrails/ui/add_guardrail_settings}
 */
export async function getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/guardrails/ui/add_guardrail_settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Validate a blocked_words YAML file content.Args:    request: Dictionary with 'file_content' key containing the YAML stringReturns:    Dictionary with 'valid' boolean and either 'message'/'errors' depending on resultExample Request:```json{    "file_content": "blocked_words:\n  - keyword: \"test\"\n    action: \"BLOCK\""}```Example Success Response:```json{    "valid": true,    "message": "Valid YAML file with 2 blocked words"}```Example Error Response:```json{    "valid": false,    "errors": ["Entry 0: missing 'action' field"]}```
 * @summary Validate Blocked Words File
 * {@link /guardrails/validate_blocked_words_file}
 */
export async function validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost({
	body,
	config = {},
}: {
	body?: ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationResponse,
		ErrorWrapper<ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost422>,
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/guardrails/validate_blocked_words_file`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get provider-specific parameters for different guardrail types.Returns a dictionary mapping guardrail providers to their specific parameters,including parameter names, descriptions, and whether they are required.Example Response:```json{    "bedrock": {        "guardrailIdentifier": {            "description": "The ID of your guardrail on Bedrock",            "required": true,            "type": null        },        "guardrailVersion": {            "description": "The version of your Bedrock guardrail (e.g., DRAFT or version number)",            "required": true,            "type": null        }    },    "azure_content_safety_text_moderation": {        "api_key": {            "description": "API key for the Azure Content Safety Text Moderation guardrail",            "required": false,            "type": null        },        "optional_params": {            "description": "Optional parameters for the Azure Content Safety Text Moderation guardrail",            "required": true,            "type": "nested",            "fields": {                "severity_threshold": {                    "description": "Severity threshold for the Azure Content Safety Text Moderation guardrail across all categories",                    "required": false,                    "type": null                },                "categories": {                    "description": "Categories to scan for the Azure Content Safety Text Moderation guardrail",                    "required": false,                    "type": "multiselect",                    "options": ["Hate", "SelfHarm", "Sexual", "Violence"],                    "default_value": None                }            }        }    }}```
 * @summary Get Provider Specific Params
 * {@link /guardrails/ui/provider_specific_params}
 */
export async function getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/guardrails/ui/provider_specific_params`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Apply a guardrail to text input and return the processed result.This endpoint allows testing guardrails by applying them to custom text inputs.
 * @summary Apply Guardrail
 * {@link /apply_guardrail}
 */
export async function applyGuardrailApplyGuardrailPost({
	body,
	config = {},
}: {
	body: ApplyGuardrailApplyGuardrailPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ApplyGuardrailApplyGuardrailPostMutationResponse,
		ErrorWrapper<ApplyGuardrailApplyGuardrailPost422>,
		ApplyGuardrailApplyGuardrailPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/apply_guardrail`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Mask PII from a given text, requires a guardrail to be added to litellm.
 * @summary Apply Guardrail
 * {@link /guardrails/apply_guardrail}
 */
export async function applyGuardrailGuardrailsApplyGuardrailPost({
	body,
	config = {},
}: {
	body: ApplyGuardrailGuardrailsApplyGuardrailPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ApplyGuardrailGuardrailsApplyGuardrailPostMutationResponse,
		ErrorWrapper<ApplyGuardrailGuardrailsApplyGuardrailPost422>,
		ApplyGuardrailGuardrailsApplyGuardrailPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/guardrails/apply_guardrail`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List all search tools that are available in the database.Example Request:```bashcurl -X GET "http://localhost:4000/search_tools/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "search_tools": [        {            "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",            "search_tool_name": "litellm-search",            "litellm_params": {                "search_provider": "perplexity",                "api_key": "sk-***",                "api_base": "https://api.perplexity.ai"            },            "search_tool_info": {                "description": "Perplexity search tool"            },            "created_at": "2023-11-09T12:34:56.789Z",            "updated_at": "2023-11-09T12:34:56.789Z"        }    ]}```
 * @summary List Search Tools
 * {@link /search_tools/list}
 */
export async function listSearchToolsSearchToolsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListSearchToolsSearchToolsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/search_tools/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a new search tool.Example Request:```bashcurl -X POST "http://localhost:4000/search_tools" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "search_tool": {            "search_tool_name": "litellm-search",            "litellm_params": {                "search_provider": "perplexity",                "api_key": "sk-..."            },            "search_tool_info": {                "description": "Perplexity search tool"            }        }    }'```Example Response:```json{    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",    "search_tool_name": "litellm-search",    "litellm_params": {        "search_provider": "perplexity",        "api_key": "sk-..."    },    "search_tool_info": {        "description": "Perplexity search tool"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Create Search Tool
 * {@link /search_tools}
 */
export async function createSearchToolSearchToolsPost({
	body,
	config = {},
}: {
	body: CreateSearchToolSearchToolsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreateSearchToolSearchToolsPostMutationResponse,
		ErrorWrapper<CreateSearchToolSearchToolsPost422>,
		CreateSearchToolSearchToolsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/search_tools`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an existing search tool.Example Request:```bashcurl -X PUT "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "search_tool": {            "search_tool_name": "updated-search",            "litellm_params": {                "search_provider": "perplexity",                "api_key": "sk-new-key"            },            "search_tool_info": {                "description": "Updated search tool"            }        }    }'```Example Response:```json{    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",    "search_tool_name": "updated-search",    "litellm_params": {        "search_provider": "perplexity",        "api_key": "sk-new-key"    },    "search_tool_info": {        "description": "Updated search tool"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T13:45:12.345Z"}```
 * @summary Update Search Tool
 * {@link /search_tools/:search_tool_id}
 */
export async function updateSearchToolSearchToolsSearchToolIdPut({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdateSearchToolSearchToolsSearchToolIdPutPathParams;
	body: UpdateSearchToolSearchToolsSearchToolIdPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_id"]) {
		throw new Error(`Missing required path parameter: search_tool_id`);
	}
	const data = await request<
		UpdateSearchToolSearchToolsSearchToolIdPutMutationResponse,
		ErrorWrapper<UpdateSearchToolSearchToolsSearchToolIdPut422>,
		UpdateSearchToolSearchToolsSearchToolIdPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdateSearchToolSearchToolsSearchToolIdPutPathParams
	>({ method: "PUT", url: `/search_tools/${pathParams["searchToolId"]}`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a search tool.Example Request:```bashcurl -X DELETE "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "message": "Search tool 123e4567-e89b-12d3-a456-426614174000 deleted successfully",    "search_tool_name": "litellm-search"}```
 * @summary Delete Search Tool
 * {@link /search_tools/:search_tool_id}
 */
export async function deleteSearchToolSearchToolsSearchToolIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteSearchToolSearchToolsSearchToolIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_id"]) {
		throw new Error(`Missing required path parameter: search_tool_id`);
	}
	const data = await request<
		DeleteSearchToolSearchToolsSearchToolIdDeleteMutationResponse,
		ErrorWrapper<DeleteSearchToolSearchToolsSearchToolIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteSearchToolSearchToolsSearchToolIdDeletePathParams
	>({ method: "DELETE", url: `/search_tools/${pathParams["searchToolId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get detailed information about a specific search tool by ID.Example Request:```bashcurl -X GET "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",    "search_tool_name": "litellm-search",    "litellm_params": {        "search_provider": "perplexity",        "api_key": "sk-***"    },    "search_tool_info": {        "description": "Perplexity search tool"    },    "created_at": "2023-11-09T12:34:56.789Z",    "updated_at": "2023-11-09T12:34:56.789Z"}```
 * @summary Get Search Tool Info
 * {@link /search_tools/:search_tool_id}
 */
export async function getSearchToolInfoSearchToolsSearchToolIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetSearchToolInfoSearchToolsSearchToolIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["search_tool_id"]) {
		throw new Error(`Missing required path parameter: search_tool_id`);
	}
	const data = await request<
		GetSearchToolInfoSearchToolsSearchToolIdGetQueryResponse,
		ErrorWrapper<GetSearchToolInfoSearchToolsSearchToolIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetSearchToolInfoSearchToolsSearchToolIdGetPathParams
	>({ method: "GET", url: `/search_tools/${pathParams["searchToolId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Test connection to a search provider with the given configuration.Makes a simple test search query to verify the API key and configuration are valid.Example Request:```bashcurl -X POST "http://localhost:4000/search_tools/test_connection" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "litellm_params": {            "search_provider": "perplexity",            "api_key": "sk-..."        }    }'```Example Response (Success):```json{    "status": "success",    "message": "Successfully connected to perplexity search provider",    "test_query": "test",    "results_count": 5}```Example Response (Failure):```json{    "status": "error",    "message": "Authentication failed: Invalid API key",    "error_type": "AuthenticationError"}```
 * @summary Test Search Tool Connection
 * {@link /search_tools/test_connection}
 */
export async function testSearchToolConnectionSearchToolsTestConnectionPost({
	body,
	config = {},
}: {
	body: TestSearchToolConnectionSearchToolsTestConnectionPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestSearchToolConnectionSearchToolsTestConnectionPostMutationResponse,
		ErrorWrapper<TestSearchToolConnectionSearchToolsTestConnectionPost422>,
		TestSearchToolConnectionSearchToolsTestConnectionPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/search_tools/test_connection`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the list of available search providers with their configuration fields.Auto-discovers search providers and their UI-friendly names from transformation configs.Example Request:```bashcurl -X GET "http://localhost:4000/search_tools/ui/available_providers" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "providers": [        {            "provider_name": "perplexity",            "ui_friendly_name": "Perplexity"        },        {            "provider_name": "tavily",            "ui_friendly_name": "Tavily"        }    ]}```
 * @summary Get Available Search Providers
 * {@link /search_tools/ui/available_providers}
 */
export async function getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/search_tools/ui/available_providers`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List the prompts that are available on the proxy server [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X GET "http://localhost:4000/prompts/list" -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "prompts": [        {            "prompt_id": "my_prompt_id",            "litellm_params": {                "prompt_id": "my_prompt_id",                "prompt_integration": "dotprompt",                "prompt_directory": "/path/to/prompts"            },            "prompt_info": {                "prompt_type": "config"            },            "created_at": "2023-11-09T12:34:56.789Z",            "updated_at": "2023-11-09T12:34:56.789Z"        }    ]}```
 * @summary List Prompts
 * {@link /prompts/list}
 */
export async function listPromptsPromptsListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListPromptsPromptsListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/prompts/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get detailed information about a specific prompt by ID, including prompt content     [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)    Example Request:    ```bash    curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \        -H "Authorization: Bearer <your_api_key>"    ```    Example Response:    ```json    {        "prompt_id": "my_prompt_id",        "litellm_params": {            "prompt_id": "my_prompt_id",            "prompt_integration": "dotprompt",            "prompt_directory": "/path/to/prompts"        },        "prompt_info": {            "prompt_type": "config"        },        "created_at": "2023-11-09T12:34:56.789Z",        "updated_at": "2023-11-09T12:34:56.789Z",        "content": "System: You are a helpful assistant.User: {{user_message}}"    }    ```
 * @summary Get Prompt Info
 * {@link /prompts/:prompt_id/info}
 */
export async function getPromptInfoPromptsPromptIdInfoGet({
	pathParams,
	config = {},
}: {
	pathParams: GetPromptInfoPromptsPromptIdInfoGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		GetPromptInfoPromptsPromptIdInfoGetQueryResponse,
		ErrorWrapper<GetPromptInfoPromptsPromptIdInfoGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetPromptInfoPromptsPromptIdInfoGetPathParams
	>({ method: "GET", url: `/prompts/${pathParams["promptId"]}/info`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get detailed information about a specific prompt by ID, including prompt content     [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)    Example Request:    ```bash    curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \        -H "Authorization: Bearer <your_api_key>"    ```    Example Response:    ```json    {        "prompt_id": "my_prompt_id",        "litellm_params": {            "prompt_id": "my_prompt_id",            "prompt_integration": "dotprompt",            "prompt_directory": "/path/to/prompts"        },        "prompt_info": {            "prompt_type": "config"        },        "created_at": "2023-11-09T12:34:56.789Z",        "updated_at": "2023-11-09T12:34:56.789Z",        "content": "System: You are a helpful assistant.User: {{user_message}}"    }    ```
 * @summary Get Prompt Info
 * {@link /prompts/:prompt_id}
 */
export async function getPromptInfoPromptsPromptIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetPromptInfoPromptsPromptIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		GetPromptInfoPromptsPromptIdGetQueryResponse,
		ErrorWrapper<GetPromptInfoPromptsPromptIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetPromptInfoPromptsPromptIdGetPathParams
	>({ method: "GET", url: `/prompts/${pathParams["promptId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an existing prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X PUT "http://localhost:4000/prompts/my_prompt_id" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "prompt_id": "my_prompt",        "litellm_params": {            "prompt_id": "my_prompt",                "prompt_integration": "dotprompt",                "prompt_directory": "/path/to/prompts"            },            "prompt_info": {                "prompt_type": "config"            }        }    }'```
 * @summary Update Prompt
 * {@link /prompts/:prompt_id}
 */
export async function updatePromptPromptsPromptIdPut({
	pathParams,
	body,
	config = {},
}: {
	pathParams: UpdatePromptPromptsPromptIdPutPathParams;
	body: UpdatePromptPromptsPromptIdPutMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		UpdatePromptPromptsPromptIdPutMutationResponse,
		ErrorWrapper<UpdatePromptPromptsPromptIdPut422>,
		UpdatePromptPromptsPromptIdPutMutationRequest,
		Record<string, string>,
		Record<string, string>,
		UpdatePromptPromptsPromptIdPutPathParams
	>({ method: "PUT", url: `/prompts/${pathParams["promptId"]}`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X DELETE "http://localhost:4000/prompts/my_prompt_id" \    -H "Authorization: Bearer <your_api_key>"```Example Response:```json{    "message": "Prompt my_prompt_id deleted successfully"}```
 * @summary Delete Prompt
 * {@link /prompts/:prompt_id}
 */
export async function deletePromptPromptsPromptIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeletePromptPromptsPromptIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		DeletePromptPromptsPromptIdDeleteMutationResponse,
		ErrorWrapper<DeletePromptPromptsPromptIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeletePromptPromptsPromptIdDeletePathParams
	>({ method: "DELETE", url: `/prompts/${pathParams["promptId"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Partially update an existing prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)This endpoint allows updating specific fields of a prompt without sending the entire object.Only the following fields can be updated:- litellm_params: LiteLLM parameters for the prompt- prompt_info: Additional information about the promptExample Request:```bashcurl -X PATCH "http://localhost:4000/prompts/my_prompt_id" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "prompt_info": {            "prompt_type": "db"        }    }'```
 * @summary Patch Prompt
 * {@link /prompts/:prompt_id}
 */
export async function patchPromptPromptsPromptIdPatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: PatchPromptPromptsPromptIdPatchPathParams;
	body?: PatchPromptPromptsPromptIdPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["prompt_id"]) {
		throw new Error(`Missing required path parameter: prompt_id`);
	}
	const data = await request<
		PatchPromptPromptsPromptIdPatchMutationResponse,
		ErrorWrapper<PatchPromptPromptsPromptIdPatch422>,
		PatchPromptPromptsPromptIdPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		PatchPromptPromptsPromptIdPatchPathParams
	>({ method: "PATCH", url: `/prompts/${pathParams["promptId"]}`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a new prompt [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)Example Request:```bashcurl -X POST "http://localhost:4000/prompts" \    -H "Authorization: Bearer <your_api_key>" \    -H "Content-Type: application/json" \    -d '{        "prompt_id": "my_prompt",        "litellm_params": {            "prompt_id": "json_prompt",            "prompt_integration": "dotprompt",            ### EITHER prompt_directory OR prompt_data MUST BE PROVIDED            "prompt_directory": "/path/to/dotprompt/folder",            "prompt_data": {"json_prompt": {"content": "This is a prompt", "metadata": {"model": "gpt-4"}}}        },        "prompt_info": {            "prompt_type": "config"        }    }'```
 * @summary Create Prompt
 * {@link /prompts}
 */
export async function createPromptPromptsPost({
	body,
	config = {},
}: {
	body: CreatePromptPromptsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CreatePromptPromptsPostMutationResponse,
		ErrorWrapper<CreatePromptPromptsPost422>,
		CreatePromptPromptsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/prompts`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Convert a .prompt file to JSON format.This endpoint accepts a .prompt file upload and returns the equivalent JSON representationthat can be stored in a database or used programmatically.Returns the JSON structure with 'content' and 'metadata' fields.
 * @summary Convert Prompt File To Json
 * {@link /utils/dotprompt_json_converter}
 */
export async function convertPromptFileToJsonUtilsDotpromptJsonConverterPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostMutationResponse,
		ErrorWrapper<ConvertPromptFileToJsonUtilsDotpromptJsonConverterPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/utils/dotprompt_json_converter`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description View List of Active Logging Callbacks
 * @summary List Callbacks
 * {@link /callbacks/list}
 */
export async function listCallbacksCallbacksListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListCallbacksCallbacksListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/callbacks/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns:  total_active_tasks: int  by_name: { coroutine_name: count }
 * @summary Get Active Tasks Stats
 * {@link /debug/asyncio-tasks}
 */
export async function getActiveTasksStatsDebugAsyncioTasksGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetActiveTasksStatsDebugAsyncioTasksGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/debug/asyncio-tasks`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Add Allowed Ip
 * {@link /add/allowed_ip}
 */
export async function addAllowedIpAddAllowedIpPost({
	body,
	config = {},
}: {
	body: AddAllowedIpAddAllowedIpPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AddAllowedIpAddAllowedIpPostMutationResponse,
		ErrorWrapper<AddAllowedIpAddAllowedIpPost422>,
		AddAllowedIpAddAllowedIpPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/add/allowed_ip`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Delete Allowed Ip
 * {@link /delete/allowed_ip}
 */
export async function deleteAllowedIpDeleteAllowedIpPost({
	body,
	config = {},
}: {
	body: DeleteAllowedIpDeleteAllowedIpPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteAllowedIpDeleteAllowedIpPostMutationResponse,
		ErrorWrapper<DeleteAllowedIpDeleteAllowedIpPost422>,
		DeleteAllowedIpDeleteAllowedIpPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/delete/allowed_ip`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all SSO settings from the litellm_settings configuration.Returns a structured object with values and descriptions for UI display.
 * @summary Get Internal User Settings
 * {@link /get/internal_user_settings}
 */
export async function getInternalUserSettingsGetInternalUserSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetInternalUserSettingsGetInternalUserSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/internal_user_settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all SSO settings from the litellm_settings configuration.Returns a structured object with values and descriptions for UI display.
 * @summary Get Default Team Settings
 * {@link /get/default_team_settings}
 */
export async function getDefaultTeamSettingsGetDefaultTeamSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetDefaultTeamSettingsGetDefaultTeamSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/default_team_settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update the default internal user parameters for SSO users.These settings will be applied to new users who sign in via SSO.
 * @summary Update Internal User Settings
 * {@link /update/internal_user_settings}
 */
export async function updateInternalUserSettingsUpdateInternalUserSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationResponse,
		ErrorWrapper<UpdateInternalUserSettingsUpdateInternalUserSettingsPatch422>,
		UpdateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/internal_user_settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update the default team parameters for SSO users.These settings will be applied to new teams created from SSO.
 * @summary Update Default Team Settings
 * {@link /update/default_team_settings}
 */
export async function updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationResponse,
		ErrorWrapper<UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch422>,
		UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/default_team_settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all SSO configuration settings from the dedicated SSO table.Returns a structured object with values and descriptions for UI display.
 * @summary Get Sso Settings
 * {@link /get/sso_settings}
 */
export async function getSsoSettingsGetSsoSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetSsoSettingsGetSsoSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/sso_settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update SSO configuration by saving to the dedicated SSO table.
 * @summary Update Sso Settings
 * {@link /update/sso_settings}
 */
export async function updateSsoSettingsUpdateSsoSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateSsoSettingsUpdateSsoSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateSsoSettingsUpdateSsoSettingsPatchMutationResponse,
		ErrorWrapper<UpdateSsoSettingsUpdateSsoSettingsPatch422>,
		UpdateSsoSettingsUpdateSsoSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/sso_settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get UI theme configuration from the litellm_settings.Returns current logo settings for UI customization.Note: This endpoint is public (no authentication required) so all users can see custom branding.Only the /update/ui_theme_settings endpoint requires authentication for admins to change settings.
 * @summary Get Ui Theme Settings
 * {@link /get/ui_theme_settings}
 */
export async function getUiThemeSettingsGetUiThemeSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUiThemeSettingsGetUiThemeSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/get/ui_theme_settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update UI theme configuration.Updates logo settings for the admin UI.
 * @summary Update Ui Theme Settings
 * {@link /update/ui_theme_settings}
 */
export async function updateUiThemeSettingsUpdateUiThemeSettingsPatch({
	body,
	config = {},
}: {
	body?: UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationResponse,
		ErrorWrapper<UpdateUiThemeSettingsUpdateUiThemeSettingsPatch422>,
		UpdateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/update/ui_theme_settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Upload a custom logo for the admin UI.Accepts image files (PNG, JPG, JPEG, SVG) and stores them for use in the UI.
 * @summary Upload Logo
 * {@link /upload/logo}
 */
export async function uploadLogoUploadLogoPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		UploadLogoUploadLogoPostMutationResponse,
		ErrorWrapper<UploadLogoUploadLogoPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({
		method: "POST",
		url: `/upload/logo`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Upload a file that can be used across - Assistants API, Batch API This is the equivalent of POST https://api.openai.com/v1/filesSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/createExample Curl```curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"```
 * @summary Create File
 * {@link /files}
 */
export async function createFileFilesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateFileFilesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		CreateFileFilesPostMutationResponse,
		ErrorWrapper<CreateFileFilesPost422>,
		null,
		Record<string, string>,
		CreateFileFilesPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/files`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/listExample Curl```curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"```
 * @summary List Files
 * {@link /files}
 */
export async function listFilesFilesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFilesFilesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFilesFilesGetQueryResponse,
		ErrorWrapper<ListFilesFilesGet422>,
		null,
		Record<string, string>,
		ListFilesFilesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/files`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Upload a file that can be used across - Assistants API, Batch API This is the equivalent of POST https://api.openai.com/v1/filesSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/createExample Curl```curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"```
 * @summary Create File
 * {@link /v1/files}
 */
export async function createFileV1FilesPost({
	queryParams,
	config = {},
}: {
	queryParams?: CreateFileV1FilesPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		CreateFileV1FilesPostMutationResponse,
		ErrorWrapper<CreateFileV1FilesPost422>,
		null,
		Record<string, string>,
		CreateFileV1FilesPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/v1/files`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/listExample Curl```curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"```
 * @summary List Files
 * {@link /v1/files}
 */
export async function listFilesV1FilesGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListFilesV1FilesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListFilesV1FilesGetQueryResponse,
		ErrorWrapper<ListFilesV1FilesGet422>,
		null,
		Record<string, string>,
		ListFilesV1FilesGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/files`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Upload a file that can be used across - Assistants API, Batch API This is the equivalent of POST https://api.openai.com/v1/filesSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/createExample Curl```curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"```
 * @summary Create File
 * {@link /:provider/v1/files}
 */
export async function createFileProviderV1FilesPost({
	pathParams,
	config = {},
}: {
	pathParams: CreateFileProviderV1FilesPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const formData = new FormData();
	if (body) {
		Object.keys(body).forEach((key) => {
			const value = body[key as keyof typeof body];
			if (
				typeof key === "string" &&
				(typeof value === "string" || (value as Blob) instanceof Blob)
			) {
				formData.append(key, value as unknown as string);
			}
		});
	}
	const data = await request<
		CreateFileProviderV1FilesPostMutationResponse,
		ErrorWrapper<CreateFileProviderV1FilesPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		CreateFileProviderV1FilesPostPathParams
	>({
		method: "POST",
		url: `/${pathParams["provider"]}/v1/files`,
		...requestConfig,
		headers: { "Content-Type": "multipart/form-data", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/listExample Curl```curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"```
 * @summary List Files
 * {@link /:provider/v1/files}
 */
export async function listFilesProviderV1FilesGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: ListFilesProviderV1FilesGetPathParams;
	queryParams?: ListFilesProviderV1FilesGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		ListFilesProviderV1FilesGetQueryResponse,
		ErrorWrapper<ListFilesProviderV1FilesGet422>,
		null,
		Record<string, string>,
		ListFilesProviderV1FilesGetQueryParams,
		ListFilesProviderV1FilesGetPathParams
	>({ method: "GET", url: `/${pathParams["provider"]}/v1/files`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/contentSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contentsExample Curl```curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"```
 * @summary Get File Content
 * {@link /files/:file_id/content}
 */
export async function getFileContentFilesFileIdContentGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileContentFilesFileIdContentGetPathParams;
	queryParams?: GetFileContentFilesFileIdContentGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileContentFilesFileIdContentGetQueryResponse,
		ErrorWrapper<GetFileContentFilesFileIdContentGet422>,
		null,
		Record<string, string>,
		GetFileContentFilesFileIdContentGetQueryParams,
		GetFileContentFilesFileIdContentGetPathParams
	>({
		method: "GET",
		url: `/files/${pathParams["fileId"]}/content`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/contentSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contentsExample Curl```curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"```
 * @summary Get File Content
 * {@link /v1/files/:file_id/content}
 */
export async function getFileContentV1FilesFileIdContentGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileContentV1FilesFileIdContentGetPathParams;
	queryParams?: GetFileContentV1FilesFileIdContentGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileContentV1FilesFileIdContentGetQueryResponse,
		ErrorWrapper<GetFileContentV1FilesFileIdContentGet422>,
		null,
		Record<string, string>,
		GetFileContentV1FilesFileIdContentGetQueryParams,
		GetFileContentV1FilesFileIdContentGetPathParams
	>({
		method: "GET",
		url: `/v1/files/${pathParams["fileId"]}/content`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/contentSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contentsExample Curl```curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"```
 * @summary Get File Content
 * {@link /:provider/v1/files/:file_id/content}
 */
export async function getFileContentProviderV1FilesFileIdContentGet({
	pathParams,
	config = {},
}: {
	pathParams: GetFileContentProviderV1FilesFileIdContentGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		GetFileContentProviderV1FilesFileIdContentGetQueryResponse,
		ErrorWrapper<GetFileContentProviderV1FilesFileIdContentGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetFileContentProviderV1FilesFileIdContentGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["provider"]}/v1/files/${pathParams["fileId"]}/content`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieveExample Curl```curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"```
 * @summary Get File
 * {@link /files/:file_id}
 */
export async function getFileFilesFileIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileFilesFileIdGetPathParams;
	queryParams?: GetFileFilesFileIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileFilesFileIdGetQueryResponse,
		ErrorWrapper<GetFileFilesFileIdGet422>,
		null,
		Record<string, string>,
		GetFileFilesFileIdGetQueryParams,
		GetFileFilesFileIdGetPathParams
	>({ method: "GET", url: `/files/${pathParams["fileId"]}`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Deletes a specified file. that can be used across - Assistants API, Batch API This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/deleteExample Curl```curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"```
 * @summary Delete File
 * {@link /files/:file_id}
 */
export async function deleteFileFilesFileIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteFileFilesFileIdDeletePathParams;
	queryParams?: DeleteFileFilesFileIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		DeleteFileFilesFileIdDeleteMutationResponse,
		ErrorWrapper<DeleteFileFilesFileIdDelete422>,
		null,
		Record<string, string>,
		DeleteFileFilesFileIdDeleteQueryParams,
		DeleteFileFilesFileIdDeletePathParams
	>({ method: "DELETE", url: `/files/${pathParams["fileId"]}`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieveExample Curl```curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"```
 * @summary Get File
 * {@link /v1/files/:file_id}
 */
export async function getFileV1FilesFileIdGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: GetFileV1FilesFileIdGetPathParams;
	queryParams?: GetFileV1FilesFileIdGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		GetFileV1FilesFileIdGetQueryResponse,
		ErrorWrapper<GetFileV1FilesFileIdGet422>,
		null,
		Record<string, string>,
		GetFileV1FilesFileIdGetQueryParams,
		GetFileV1FilesFileIdGetPathParams
	>({ method: "GET", url: `/v1/files/${pathParams["fileId"]}`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Deletes a specified file. that can be used across - Assistants API, Batch API This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/deleteExample Curl```curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"```
 * @summary Delete File
 * {@link /v1/files/:file_id}
 */
export async function deleteFileV1FilesFileIdDelete({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: DeleteFileV1FilesFileIdDeletePathParams;
	queryParams?: DeleteFileV1FilesFileIdDeleteQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}
	const data = await request<
		DeleteFileV1FilesFileIdDeleteMutationResponse,
		ErrorWrapper<DeleteFileV1FilesFileIdDelete422>,
		null,
		Record<string, string>,
		DeleteFileV1FilesFileIdDeleteQueryParams,
		DeleteFileV1FilesFileIdDeletePathParams
	>({ method: "DELETE", url: `/v1/files/${pathParams["fileId"]}`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Returns information about a specific file. that can be used across - Assistants API, Batch API This is the equivalent of GET https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieveExample Curl```curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"```
 * @summary Get File
 * {@link /:provider/v1/files/:file_id}
 */
export async function getFileProviderV1FilesFileIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetFileProviderV1FilesFileIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		GetFileProviderV1FilesFileIdGetQueryResponse,
		ErrorWrapper<GetFileProviderV1FilesFileIdGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetFileProviderV1FilesFileIdGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["provider"]}/v1/files/${pathParams["fileId"]}`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Deletes a specified file. that can be used across - Assistants API, Batch API This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/deleteExample Curl```curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"```
 * @summary Delete File
 * {@link /:provider/v1/files/:file_id}
 */
export async function deleteFileProviderV1FilesFileIdDelete({
	pathParams,
	config = {},
}: {
	pathParams: DeleteFileProviderV1FilesFileIdDeletePathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["file_id"]) {
		throw new Error(`Missing required path parameter: file_id`);
	}

	if (!pathParams["provider"]) {
		throw new Error(`Missing required path parameter: provider`);
	}
	const data = await request<
		DeleteFileProviderV1FilesFileIdDeleteMutationResponse,
		ErrorWrapper<DeleteFileProviderV1FilesFileIdDelete422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DeleteFileProviderV1FilesFileIdDeletePathParams
	>({
		method: "DELETE",
		url: `/${pathParams["provider"]}/v1/files/${pathParams["fileId"]}`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Add a success/failure callback to a teamUse this if if you want different teams to have different success/failure callbacksParameters:- callback_name (Literal["langfuse", "langsmith", "gcs"], required): The name of the callback to add- callback_type (Literal["success", "failure", "success_and_failure"], required): The type of callback to add. One of:    - "success": Callback for successful LLM calls    - "failure": Callback for failed LLM calls    - "success_and_failure": Callback for both successful and failed LLM calls- callback_vars (StandardCallbackDynamicParams, required): A dictionary of variables to pass to the callback    - langfuse_public_key: The public key for the Langfuse callback    - langfuse_secret_key: The secret key for the Langfuse callback    - langfuse_secret: The secret for the Langfuse callback    - langfuse_host: The host for the Langfuse callback    - gcs_bucket_name: The name of the GCS bucket    - gcs_path_service_account: The path to the GCS service account    - langsmith_api_key: The API key for the Langsmith callback    - langsmith_project: The project for the Langsmith callback    - langsmith_base_url: The base URL for the Langsmith callbackExample curl:```curl -X POST 'http:/localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -d '{    "callback_name": "langfuse",    "callback_type": "success",    "callback_vars": {"langfuse_public_key": "pk-lf-xxxx1", "langfuse_secret_key": "sk-xxxxx"}    }'```This means for the team where team_id = dbe2f686-a686-4896-864a-4c3924458709, all LLM calls will be logged to langfuse using the public key pk-lf-xxxx1 and the secret key sk-xxxxx
 * @summary Add Team Callbacks
 * {@link /team/:team_id/callback}
 */
export async function addTeamCallbacksTeamTeamIdCallbackPost({
	pathParams,
	body,
	headers,
	config = {},
}: {
	pathParams: AddTeamCallbacksTeamTeamIdCallbackPostPathParams;
	body: AddTeamCallbacksTeamTeamIdCallbackPostMutationRequest;
	headers?: AddTeamCallbacksTeamTeamIdCallbackPostHeaderParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		AddTeamCallbacksTeamTeamIdCallbackPostMutationResponse,
		ErrorWrapper<AddTeamCallbacksTeamTeamIdCallbackPost422>,
		AddTeamCallbacksTeamTeamIdCallbackPostMutationRequest,
		AddTeamCallbacksTeamTeamIdCallbackPostHeaderParams,
		Record<string, string>,
		AddTeamCallbacksTeamTeamIdCallbackPostPathParams
	>({
		method: "POST",
		url: `/team/${pathParams["teamId"]}/callback`,
		body,
		...requestConfig,
		headers: { ...headers, ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the success/failure callbacks and variables for a teamParameters:- team_id (str, required): The unique identifier for the teamExample curl:```curl -X GET 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Authorization: Bearer sk-1234'```This will return the callback settings for the team with id dbe2f686-a686-4896-864a-4c3924458709Returns {        "status": "success",        "data": {            "team_id": team_id,            "success_callbacks": team_callback_settings_obj.success_callback,            "failure_callbacks": team_callback_settings_obj.failure_callback,            "callback_vars": team_callback_settings_obj.callback_vars,        },    }
 * @summary Get Team Callbacks
 * {@link /team/:team_id/callback}
 */
export async function getTeamCallbacksTeamTeamIdCallbackGet({
	pathParams,
	config = {},
}: {
	pathParams: GetTeamCallbacksTeamTeamIdCallbackGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		GetTeamCallbacksTeamTeamIdCallbackGetQueryResponse,
		ErrorWrapper<GetTeamCallbacksTeamTeamIdCallbackGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetTeamCallbacksTeamTeamIdCallbackGetPathParams
	>({ method: "GET", url: `/team/${pathParams["teamId"]}/callback`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Disable all logging callbacks for a teamParameters:- team_id (str, required): The unique identifier for the teamExample curl:```curl -X POST 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/disable_logging'         -H 'Authorization: Bearer sk-1234'```
 * @summary Disable Team Logging
 * {@link /team/:team_id/disable_logging}
 */
export async function disableTeamLoggingTeamTeamIdDisableLoggingPost({
	pathParams,
	config = {},
}: {
	pathParams: DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["team_id"]) {
		throw new Error(`Missing required path parameter: team_id`);
	}
	const data = await request<
		DisableTeamLoggingTeamTeamIdDisableLoggingPostMutationResponse,
		ErrorWrapper<DisableTeamLoggingTeamTeamIdDisableLoggingPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams
	>({ method: "POST", url: `/team/${pathParams["teamId"]}/disable_logging`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a new budget object. Can apply this to teams, orgs, end-users, keys.Parameters:- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)- budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.- max_budget: Optional[float] - The max budget for the budget.- soft_budget: Optional[float] - The soft budget for the budget.- max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.- tpm_limit: Optional[int] - The tokens per minute limit for the budget.- rpm_limit: Optional[int] - The requests per minute limit for the budget.- model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}- budget_reset_at: Optional[datetime] - Datetime when the initial budget is reset. Default is now.
 * @summary New Budget
 * {@link /budget/new}
 */
export async function newBudgetBudgetNewPost({
	body,
	config = {},
}: {
	body?: NewBudgetBudgetNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewBudgetBudgetNewPostMutationResponse,
		ErrorWrapper<NewBudgetBudgetNewPost422>,
		NewBudgetBudgetNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an existing budget object.Parameters:- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)- budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.- max_budget: Optional[float] - The max budget for the budget.- soft_budget: Optional[float] - The soft budget for the budget.- max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.- tpm_limit: Optional[int] - The tokens per minute limit for the budget.- rpm_limit: Optional[int] - The requests per minute limit for the budget.- model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}- budget_reset_at: Optional[datetime] - Update the Datetime when the budget was last reset.
 * @summary Update Budget
 * {@link /budget/update}
 */
export async function updateBudgetBudgetUpdatePost({
	body,
	config = {},
}: {
	body?: UpdateBudgetBudgetUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateBudgetBudgetUpdatePostMutationResponse,
		ErrorWrapper<UpdateBudgetBudgetUpdatePost422>,
		UpdateBudgetBudgetUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get the budget id specific informationParameters:- budgets: List[str] - The list of budget ids to get information for
 * @summary Info Budget
 * {@link /budget/info}
 */
export async function infoBudgetBudgetInfoPost({
	body,
	config = {},
}: {
	body: InfoBudgetBudgetInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoBudgetBudgetInfoPostMutationResponse,
		ErrorWrapper<InfoBudgetBudgetInfoPost422>,
		InfoBudgetBudgetInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/info`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get list of configurable params + current value for a budget item + description of each fieldUsed on Admin UI.Query Parameters:- budget_id: str - The budget id to get information for
 * @summary Budget Settings
 * {@link /budget/settings}
 */
export async function budgetSettingsBudgetSettingsGet({
	queryParams,
	config = {},
}: {
	queryParams: BudgetSettingsBudgetSettingsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		BudgetSettingsBudgetSettingsGetQueryResponse,
		ErrorWrapper<BudgetSettingsBudgetSettingsGet422>,
		null,
		Record<string, string>,
		BudgetSettingsBudgetSettingsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/budget/settings`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List all the created budgets in proxy db. Used on Admin UI.
 * @summary List Budget
 * {@link /budget/list}
 */
export async function listBudgetBudgetListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListBudgetBudgetListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/budget/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete budgetParameters:- id: str - The budget id to delete
 * @summary Delete Budget
 * {@link /budget/delete}
 */
export async function deleteBudgetBudgetDeletePost({
	body,
	config = {},
}: {
	body: DeleteBudgetBudgetDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteBudgetBudgetDeletePostMutationResponse,
		ErrorWrapper<DeleteBudgetBudgetDeletePost422>,
		DeleteBudgetBudgetDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/budget/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description PATCH Endpoint for partial model updates.Only updates the fields specified in the request while preserving other existing values.Follows proper PATCH semantics by only modifying provided fields.Args:    model_id: The ID of the model to update    patch_data: The fields to update and their new values    user_api_key_dict: User authentication informationReturns:    Updated model informationRaises:    ProxyException: For various error conditions including authentication and database errors
 * @summary Patch Model
 * {@link /model/:model_id/update}
 */
export async function patchModelModelModelIdUpdatePatch({
	pathParams,
	body,
	config = {},
}: {
	pathParams: PatchModelModelModelIdUpdatePatchPathParams;
	body?: PatchModelModelModelIdUpdatePatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["model_id"]) {
		throw new Error(`Missing required path parameter: model_id`);
	}
	const data = await request<
		PatchModelModelModelIdUpdatePatchMutationResponse,
		ErrorWrapper<PatchModelModelModelIdUpdatePatch422>,
		PatchModelModelModelIdUpdatePatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		PatchModelModelModelIdUpdatePatchPathParams
	>({ method: "PATCH", url: `/model/${pathParams["modelId"]}/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allows deleting models in the model list in the config.yaml
 * @summary Delete Model
 * {@link /model/delete}
 */
export async function deleteModelModelDeletePost({
	body,
	config = {},
}: {
	body: DeleteModelModelDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteModelModelDeletePostMutationResponse,
		ErrorWrapper<DeleteModelModelDeletePost422>,
		DeleteModelModelDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Allows adding new models to the model list in the config.yaml
 * @summary Add New Model
 * {@link /model/new}
 */
export async function addNewModelModelNewPost({
	body,
	config = {},
}: {
	body: AddNewModelModelNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AddNewModelModelNewPostMutationResponse,
		ErrorWrapper<AddNewModelModelNewPost422>,
		AddNewModelModelNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Edit existing model params
 * @summary Update Model
 * {@link /model/update}
 */
export async function updateModelModelUpdatePost({
	body,
	config = {},
}: {
	body?: UpdateModelModelUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateModelModelUpdatePostMutationResponse,
		ErrorWrapper<UpdateModelModelUpdatePost422>,
		UpdateModelModelUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update which model groups are public
 * @summary Update Public Model Groups
 * {@link /model_group/make_public}
 */
export async function updatePublicModelGroupsModelGroupMakePublicPost({
	body,
	config = {},
}: {
	body: UpdatePublicModelGroupsModelGroupMakePublicPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdatePublicModelGroupsModelGroupMakePublicPostMutationResponse,
		ErrorWrapper<UpdatePublicModelGroupsModelGroupMakePublicPost422>,
		UpdatePublicModelGroupsModelGroupMakePublicPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model_group/make_public`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update useful links
 * @summary Update Useful Links
 * {@link /model_hub/update_useful_links}
 */
export async function updateUsefulLinksModelHubUpdateUsefulLinksPost({
	body,
	config = {},
}: {
	body: UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationResponse,
		ErrorWrapper<UpdateUsefulLinksModelHubUpdateUsefulLinksPost422>,
		UpdateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/model_hub/update_useful_links`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a new tag.Parameters:- name: str - The name of the tag- description: Optional[str] - Description of what this tag represents- models: List[str] - List of either 'model_id' or 'model_name' allowed for this tag- budget_id: Optional[str] - The id for a budget (tpm/rpm/max budget) for the tag### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###- max_budget: Optional[float] - Max budget for tag- tpm_limit: Optional[int] - Max tpm limit for tag- rpm_limit: Optional[int] - Max rpm limit for tag- max_parallel_requests: Optional[int] - Max parallel requests for tag- soft_budget: Optional[float] - Get a slack alert when this soft budget is reached- model_max_budget: Optional[dict] - Max budget for a specific model- budget_duration: Optional[str] - Frequency of resetting tag budget
 * @summary New Tag
 * {@link /tag/new}
 */
export async function newTagTagNewPost({
	body,
	config = {},
}: {
	body: NewTagTagNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewTagTagNewPostMutationResponse,
		ErrorWrapper<NewTagTagNewPost422>,
		NewTagTagNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update an existing tag.Parameters:- name: str - The name of the tag to update- description: Optional[str] - Updated description- models: List[str] - Updated list of allowed LLM models- budget_id: Optional[str] - The id for a budget to associate with the tag### BUDGET UPDATE PARAMS ###- max_budget: Optional[float] - Max budget for tag- tpm_limit: Optional[int] - Max tpm limit for tag- rpm_limit: Optional[int] - Max rpm limit for tag- max_parallel_requests: Optional[int] - Max parallel requests for tag- soft_budget: Optional[float] - Get a slack alert when this soft budget is reached- model_max_budget: Optional[dict] - Max budget for a specific model- budget_duration: Optional[str] - Frequency of resetting tag budget
 * @summary Update Tag
 * {@link /tag/update}
 */
export async function updateTagTagUpdatePost({
	body,
	config = {},
}: {
	body: UpdateTagTagUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateTagTagUpdatePostMutationResponse,
		ErrorWrapper<UpdateTagTagUpdatePost422>,
		UpdateTagTagUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get information about specific tags.Parameters:- names: List[str] - List of tag names to get information for
 * @summary Info Tag
 * {@link /tag/info}
 */
export async function infoTagTagInfoPost({
	body,
	config = {},
}: {
	body: InfoTagTagInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		InfoTagTagInfoPostMutationResponse,
		ErrorWrapper<InfoTagTagInfoPost422>,
		InfoTagTagInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/info`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List all available tags with their budget information.
 * @summary List Tags
 * {@link /tag/list}
 */
export async function listTagsTagListGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListTagsTagListGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/tag/list`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a tag.Parameters:- name: str - The name of the tag to delete
 * @summary Delete Tag
 * {@link /tag/delete}
 */
export async function deleteTagTagDeletePost({
	body,
	config = {},
}: {
	body: DeleteTagTagDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteTagTagDeletePostMutationResponse,
		ErrorWrapper<DeleteTagTagDeletePost422>,
		DeleteTagTagDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/tag/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get daily activity for specific tags or all tags.Args:    tags (Optional[str]): Comma-separated list of tags to filter by. If not provided, returns data for all tags.    start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).    end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).    model (Optional[str]): Filter by model name.    api_key (Optional[str]): Filter by API key.    page (int): Page number for pagination.    page_size (int): Number of items per page.Returns:    SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 * @summary Get Tag Daily Activity
 * {@link /tag/daily/activity}
 */
export async function getTagDailyActivityTagDailyActivityGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetTagDailyActivityTagDailyActivityGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetTagDailyActivityTagDailyActivityGetQueryResponse,
		ErrorWrapper<GetTagDailyActivityTagDailyActivityGet422>,
		null,
		Record<string, string>,
		GetTagDailyActivityTagDailyActivityGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/daily/activity`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get current cost discount configuration.Returns the cost_discount_config from litellm_settings.
 * @summary Get Cost Discount Config
 * {@link /config/cost_discount_config}
 */
export async function getCostDiscountConfigConfigCostDiscountConfigGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCostDiscountConfigConfigCostDiscountConfigGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/config/cost_discount_config`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update cost discount configuration.Updates the cost_discount_config in litellm_settings.Discounts should be between 0 and 1 (e.g., 0.05 = 5% discount).Example:```json{    "vertex_ai": 0.05,    "gemini": 0.05,    "openai": 0.01}```
 * @summary Update Cost Discount Config
 * {@link /config/cost_discount_config}
 */
export async function updateCostDiscountConfigConfigCostDiscountConfigPatch({
	body,
	config = {},
}: {
	body?: UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationResponse,
		ErrorWrapper<UpdateCostDiscountConfigConfigCostDiscountConfigPatch422>,
		UpdateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/config/cost_discount_config`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get router configuration and available settings.Returns:- fields: List of all configurable router settings with their metadata (type, description, default, options)          The routing_strategy field includes available options extracted from the Router class- current_values: Current values of router settings from config
 * @summary Get Router Settings
 * {@link /router/settings}
 */
export async function getRouterSettingsRouterSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetRouterSettingsRouterSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/router/settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get cache configuration and available settings.Returns:- fields: List of all configurable cache settings with their metadata (type, description, default, options)- current_values: Current values of cache settings from database
 * @summary Get Cache Settings
 * {@link /cache/settings}
 */
export async function getCacheSettingsCacheSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetCacheSettingsCacheSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/cache/settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Save cache settings to database and initialize cache.This endpoint:1. Encrypts sensitive fields (passwords, etc.)2. Saves to LiteLLM_CacheConfig table3. Reinitializes cache with new settings
 * @summary Update Cache Settings
 * {@link /cache/settings}
 */
export async function updateCacheSettingsCacheSettingsPost({
	body,
	config = {},
}: {
	body: UpdateCacheSettingsCacheSettingsPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateCacheSettingsCacheSettingsPostMutationResponse,
		ErrorWrapper<UpdateCacheSettingsCacheSettingsPost422>,
		UpdateCacheSettingsCacheSettingsPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Test cache connection with provided credentials.Creates a temporary cache instance and uses its test_connection methodto verify the credentials work without affecting global state.
 * @summary Test Cache Connection
 * {@link /cache/settings/test}
 */
export async function testCacheConnectionCacheSettingsTestPost({
	body,
	config = {},
}: {
	body: TestCacheConnectionCacheSettingsTestPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestCacheConnectionCacheSettingsTestPostMutationResponse,
		ErrorWrapper<TestCacheConnectionCacheSettingsTestPost422>,
		TestCacheConnectionCacheSettingsTestPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/cache/settings/test`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all distinct user agent tags up to a maximum of {MAX_TAGS} tags.This endpoint returns all unique user agent tags found in the database,sorted by frequency of usage.Returns:    DistinctTagsResponse: List of distinct user agent tags
 * @summary Get Distinct User Agent Tags
 * {@link /tag/distinct}
 */
export async function getDistinctUserAgentTagsTagDistinctGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetDistinctUserAgentTagsTagDistinctGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/tag/distinct`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get Daily Active Users (DAU) by tags for the last {MAX_DAYS} days ending on UTC today + 1 day.This endpoint efficiently calculates unique users per tag for each of the last {MAX_DAYS} daysusing a single optimized SQL query, perfect for dashboard time series visualization.Args:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    ActiveUsersAnalyticsResponse: DAU data by tag for each of the last {MAX_DAYS} days
 * @summary Get Daily Active Users
 * {@link /tag/dau}
 */
export async function getDailyActiveUsersTagDauGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetDailyActiveUsersTagDauGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetDailyActiveUsersTagDauGetQueryResponse,
		ErrorWrapper<GetDailyActiveUsersTagDauGet422>,
		null,
		Record<string, string>,
		GetDailyActiveUsersTagDauGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/dau`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get Weekly Active Users (WAU) by tags for the last {MAX_WEEKS} weeks ending on UTC today + 1 day.Shows week-by-week breakdown:- Week 1 (Jan 1): Earliest week (7 weeks ago)- Week 2 (Jan 8): Next week (6 weeks ago)- Week 3 (Jan 15): Next week (5 weeks ago)- ... and so on for {MAX_WEEKS} weeks total- Week 7: Most recent week ending on UTC today + 1 dayArgs:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    ActiveUsersAnalyticsResponse: WAU data by tag for each of the last {MAX_WEEKS} weeks with descriptive week labels (e.g., "Week 1 (Jan 1)")
 * @summary Get Weekly Active Users
 * {@link /tag/wau}
 */
export async function getWeeklyActiveUsersTagWauGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetWeeklyActiveUsersTagWauGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetWeeklyActiveUsersTagWauGetQueryResponse,
		ErrorWrapper<GetWeeklyActiveUsersTagWauGet422>,
		null,
		Record<string, string>,
		GetWeeklyActiveUsersTagWauGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/wau`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get Monthly Active Users (MAU) by tags for the last {MAX_MONTHS} months ending on UTC today + 1 day.Shows month-by-month breakdown:- Month 1 (Nov): Earliest month (7 months ago, 30-day period)- Month 2 (Dec): Next month (6 months ago)- Month 3 (Jan): Next month (5 months ago)- ... and so on for {MAX_MONTHS} months total- Month 7: Most recent month ending on UTC today + 1 dayArgs:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    ActiveUsersAnalyticsResponse: MAU data by tag for each of the last {MAX_MONTHS} months with descriptive month labels (e.g., "Month 1 (Nov)")
 * @summary Get Monthly Active Users
 * {@link /tag/mau}
 */
export async function getMonthlyActiveUsersTagMauGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetMonthlyActiveUsersTagMauGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetMonthlyActiveUsersTagMauGetQueryResponse,
		ErrorWrapper<GetMonthlyActiveUsersTagMauGet422>,
		null,
		Record<string, string>,
		GetMonthlyActiveUsersTagMauGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/mau`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get summary analytics for tags including unique users, requests, tokens, and spend.Args:    start_date: Start date for the analytics period (YYYY-MM-DD)    end_date: End date for the analytics period (YYYY-MM-DD)    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    Returns:    TagSummaryResponse: Summary analytics data by tag
 * @summary Get Tag Summary
 * {@link /tag/summary}
 */
export async function getTagSummaryTagSummaryGet({
	queryParams,
	config = {},
}: {
	queryParams: GetTagSummaryTagSummaryGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetTagSummaryTagSummaryGetQueryResponse,
		ErrorWrapper<GetTagSummaryTagSummaryGet422>,
		null,
		Record<string, string>,
		GetTagSummaryTagSummaryGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/summary`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get per-user analytics including successful requests, tokens, and spend by individual users.This endpoint provides usage metrics broken down by individual users based on theirtag activity during the last 30 days ending on UTC today + 1 day.Args:    tag_filter: Optional filter to specific tag (legacy)    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)    page: Page number for pagination    page_size: Number of items per page    Returns:    PerUserAnalyticsResponse: Analytics data broken down by individual users for the last 30 days
 * @summary Get Per User Analytics
 * {@link /tag/user-agent/per-user-analytics}
 */
export async function getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryResponse,
		ErrorWrapper<GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGet422>,
		null,
		Record<string, string>,
		GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/tag/user-agent/per-user-analytics`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Create a new vector store.Parameters:- vector_store_id: str - Unique identifier for the vector store- custom_llm_provider: str - Provider of the vector store- vector_store_name: Optional[str] - Name of the vector store- vector_store_description: Optional[str] - Description of the vector store- vector_store_metadata: Optional[Dict] - Additional metadata for the vector store
 * @summary New Vector Store
 * {@link /vector_store/new}
 */
export async function newVectorStoreVectorStoreNewPost({
	body,
	config = {},
}: {
	body?: NewVectorStoreVectorStoreNewPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		NewVectorStoreVectorStoreNewPostMutationResponse,
		ErrorWrapper<NewVectorStoreVectorStoreNewPost422>,
		NewVectorStoreVectorStoreNewPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/new`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List all available vector stores with optional filtering and pagination.Combines both in-memory vector stores and those stored in the database.Parameters:- page: int - Page number for pagination (default: 1)- page_size: int - Number of items per page (default: 100)
 * @summary List Vector Stores
 * {@link /vector_store/list}
 */
export async function listVectorStoresVectorStoreListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListVectorStoresVectorStoreListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListVectorStoresVectorStoreListGetQueryResponse,
		ErrorWrapper<ListVectorStoresVectorStoreListGet422>,
		null,
		Record<string, string>,
		ListVectorStoresVectorStoreListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/vector_store/list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Delete a vector store.Parameters:- vector_store_id: str - ID of the vector store to delete
 * @summary Delete Vector Store
 * {@link /vector_store/delete}
 */
export async function deleteVectorStoreVectorStoreDeletePost({
	body,
	config = {},
}: {
	body: DeleteVectorStoreVectorStoreDeletePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		DeleteVectorStoreVectorStoreDeletePostMutationResponse,
		ErrorWrapper<DeleteVectorStoreVectorStoreDeletePost422>,
		DeleteVectorStoreVectorStoreDeletePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/delete`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Return a single vector store's details
 * @summary Get Vector Store Info
 * {@link /vector_store/info}
 */
export async function getVectorStoreInfoVectorStoreInfoPost({
	body,
	config = {},
}: {
	body: GetVectorStoreInfoVectorStoreInfoPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetVectorStoreInfoVectorStoreInfoPostMutationResponse,
		ErrorWrapper<GetVectorStoreInfoVectorStoreInfoPost422>,
		GetVectorStoreInfoVectorStoreInfoPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/info`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update vector store details
 * @summary Update Vector Store
 * {@link /vector_store/update}
 */
export async function updateVectorStoreVectorStoreUpdatePost({
	body,
	config = {},
}: {
	body: UpdateVectorStoreVectorStoreUpdatePostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateVectorStoreVectorStoreUpdatePostMutationResponse,
		ErrorWrapper<UpdateVectorStoreVectorStoreUpdatePost422>,
		UpdateVectorStoreVectorStoreUpdatePostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/vector_store/update`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all email event settings
 * @summary Get Email Event Settings
 * {@link /email/event_settings}
 */
export async function getEmailEventSettingsEmailEventSettingsGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetEmailEventSettingsEmailEventSettingsGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/email/event_settings`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Update the settings for email events
 * @summary Update Event Settings
 * {@link /email/event_settings}
 */
export async function updateEventSettingsEmailEventSettingsPatch({
	body,
	config = {},
}: {
	body: UpdateEventSettingsEmailEventSettingsPatchMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		UpdateEventSettingsEmailEventSettingsPatchMutationResponse,
		ErrorWrapper<UpdateEventSettingsEmailEventSettingsPatch422>,
		UpdateEventSettingsEmailEventSettingsPatchMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "PATCH", url: `/email/event_settings`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Reset all email event settings to default (new user invitations on, virtual key creation off)
 * @summary Reset Event Settings
 * {@link /email/event_settings/reset}
 */
export async function resetEventSettingsEmailEventSettingsResetPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ResetEventSettingsEmailEventSettingsResetPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/email/event_settings/reset`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get all audit logs with filtering and pagination.Returns a paginated response of audit logs matching the specified filters.
 * @summary Get Audit Logs
 * {@link /audit}
 */
export async function getAuditLogsAuditGet({
	queryParams,
	config = {},
}: {
	queryParams?: GetAuditLogsAuditGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetAuditLogsAuditGetQueryResponse,
		ErrorWrapper<GetAuditLogsAuditGet422>,
		null,
		Record<string, string>,
		GetAuditLogsAuditGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/audit`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Get detailed information about a specific audit log entry by its ID.Args:    id (str): The unique identifier of the audit log entryReturns:    AuditLogResponse: Detailed information about the audit log entryRaises:    HTTPException: If the audit log is not found or if there's a database connection error
 * @summary Get Audit Log By Id
 * {@link /audit/:id}
 */
export async function getAuditLogByIdAuditIdGet({
	pathParams,
	config = {},
}: {
	pathParams: GetAuditLogByIdAuditIdGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["id"]) {
		throw new Error(`Missing required path parameter: id`);
	}
	const data = await request<
		GetAuditLogByIdAuditIdGetQueryResponse,
		ErrorWrapper<
			GetAuditLogByIdAuditIdGet404 | GetAuditLogByIdAuditIdGet422 | GetAuditLogByIdAuditIdGet500
		>,
		null,
		Record<string, string>,
		Record<string, string>,
		GetAuditLogByIdAuditIdGetPathParams
	>({ method: "GET", url: `/audit/${pathParams["id"]}`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description For keys with `max_users` set, return the list of users that are allowed to use the key.
 * @summary Available Enterprise Users
 * {@link /user/available_users}
 */
export async function availableEnterpriseUsersUserAvailableUsersGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AvailableEnterpriseUsersUserAvailableUsersGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/user/available_users`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Block all web crawlers from indexing the proxy server endpointsThis is useful for ensuring that the API endpoints aren't indexed by search engines
 * @summary Get Robots
 * {@link /robots.txt}
 */
export async function getRobotsRobotsTxtGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetRobotsRobotsTxtGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/robots.txt`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Get Ui Config
 * {@link /litellm/.well-known/litellm-ui-config}
 */
export async function getUiConfigLitellmWellKnownLitellmUiConfigGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUiConfigLitellmWellKnownLitellmUiConfigGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/litellm/.well-known/litellm-ui-config`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Get Ui Config
 * {@link /.well-known/litellm-ui-config}
 */
export async function getUiConfigWellKnownLitellmUiConfigGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		GetUiConfigWellKnownLitellmUiConfigGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/.well-known/litellm-ui-config`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch4({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch4PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch4MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch4422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch4PathParams
	>({ method: "PATCH", url: `/${pathParams["mcpServerName"]}/mcp`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch2({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch2PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch2MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch2422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch2PathParams
	>({ method: "POST", url: `/${pathParams["mcpServerName"]}/mcp`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatchPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatchMutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatchPathParams
	>({ method: "OPTIONS", url: `/${pathParams["mcpServerName"]}/mcp`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch3({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch3PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch3MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch3422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch3PathParams
	>({ method: "PUT", url: `/${pathParams["mcpServerName"]}/mcp`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Handle dynamic MCP server routes like /github_mcp/mcp
 * @summary Dynamic Mcp Route
 * {@link /:mcp_server_name/mcp}
 */
export async function dynamicMcpRouteMcpServerNameMcpPatch5({
	pathParams,
	config = {},
}: {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch5PathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		DynamicMcpRouteMcpServerNameMcpPatch5MutationResponse,
		ErrorWrapper<DynamicMcpRouteMcpServerNameMcpPatch5422>,
		null,
		Record<string, string>,
		Record<string, string>,
		DynamicMcpRouteMcpServerNameMcpPatch5PathParams
	>({ method: "DELETE", url: `/${pathParams["mcpServerName"]}/mcp`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description List all available tools with information about the server they belong to.Example response:{    "tools": [        {            "name": "create_zap",            "description": "Create a new zap",            "inputSchema": "tool_input_schema",            "mcp_info": {                "server_name": "zapier",                "logo_url": "https://www.zapier.com/logo.png",            }        }    ],    "error": null,    "message": "Successfully retrieved tools"}
 * @summary List Tool Rest Api
 * {@link /mcp-rest/tools/list}
 */
export async function listToolRestApiMcpRestToolsListGet({
	queryParams,
	config = {},
}: {
	queryParams?: ListToolRestApiMcpRestToolsListGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		ListToolRestApiMcpRestToolsListGetQueryResponse,
		ErrorWrapper<ListToolRestApiMcpRestToolsListGet422>,
		null,
		Record<string, string>,
		ListToolRestApiMcpRestToolsListGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/mcp-rest/tools/list`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description REST API to call a specific MCP tool with the provided arguments
 * @summary Call Tool Rest Api
 * {@link /mcp-rest/tools/call}
 */
export async function callToolRestApiMcpRestToolsCallPost({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CallToolRestApiMcpRestToolsCallPostMutationResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/mcp-rest/tools/call`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Test if we can connect to the provided MCP server before adding it
 * @summary Test Connection
 * {@link /mcp-rest/test/connection}
 */
export async function testConnectionMcpRestTestConnectionPost({
	body,
	config = {},
}: {
	body?: TestConnectionMcpRestTestConnectionPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestConnectionMcpRestTestConnectionPostMutationResponse,
		ErrorWrapper<TestConnectionMcpRestTestConnectionPost422>,
		TestConnectionMcpRestTestConnectionPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/mcp-rest/test/connection`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Preview tools available from MCP server before adding it
 * @summary Test Tools List
 * {@link /mcp-rest/test/tools/list}
 */
export async function testToolsListMcpRestTestToolsListPost({
	body,
	config = {},
}: {
	body?: TestToolsListMcpRestTestToolsListPostMutationRequest;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TestToolsListMcpRestTestToolsListPostMutationResponse,
		ErrorWrapper<TestToolsListMcpRestTestToolsListPost422>,
		TestToolsListMcpRestTestToolsListPostMutationRequest,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "POST", url: `/mcp-rest/test/tools/list`, body, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Authorize
 * {@link /authorize}
 */
export async function authorizeAuthorizeGet({
	queryParams,
	config = {},
}: {
	queryParams: AuthorizeAuthorizeGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		AuthorizeAuthorizeGetQueryResponse,
		ErrorWrapper<AuthorizeAuthorizeGet422>,
		null,
		Record<string, string>,
		AuthorizeAuthorizeGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/authorize`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Authorize
 * {@link /:mcp_server_name/authorize}
 */
export async function authorizeMcpServerNameAuthorizeGet({
	pathParams,
	queryParams,
	config = {},
}: {
	pathParams: AuthorizeMcpServerNameAuthorizeGetPathParams;
	queryParams: AuthorizeMcpServerNameAuthorizeGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		AuthorizeMcpServerNameAuthorizeGetQueryResponse,
		ErrorWrapper<AuthorizeMcpServerNameAuthorizeGet422>,
		null,
		Record<string, string>,
		AuthorizeMcpServerNameAuthorizeGetQueryParams,
		AuthorizeMcpServerNameAuthorizeGetPathParams
	>({
		method: "GET",
		url: `/${pathParams["mcpServerName"]}/authorize`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Accept the authorization code from client and exchange it for OAuth token.Supports PKCE flow by forwarding code_verifier to upstream provider.1. Call the token endpoint with PKCE parameters2. Store the user's token in the db - and generate a LiteLLM virtual key3. Return the token4. Return a virtual key in this response
 * @summary Token Endpoint
 * {@link /token}
 */
export async function tokenEndpointTokenPost({
	queryParams,
	config = {},
}: {
	queryParams?: TokenEndpointTokenPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		TokenEndpointTokenPostMutationResponse,
		ErrorWrapper<TokenEndpointTokenPost422>,
		null,
		Record<string, string>,
		TokenEndpointTokenPostQueryParams,
		Record<string, string>
	>({
		method: "POST",
		url: `/token`,
		queryParams,
		...requestConfig,
		headers: { "Content-Type": "application/x-www-form-urlencoded", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description Accept the authorization code from client and exchange it for OAuth token.Supports PKCE flow by forwarding code_verifier to upstream provider.1. Call the token endpoint with PKCE parameters2. Store the user's token in the db - and generate a LiteLLM virtual key3. Return the token4. Return a virtual key in this response
 * @summary Token Endpoint
 * {@link /:mcp_server_name/token}
 */
export async function tokenEndpointMcpServerNameTokenPost({
	pathParams,
	config = {},
}: {
	pathParams: TokenEndpointMcpServerNameTokenPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		TokenEndpointMcpServerNameTokenPostMutationResponse,
		ErrorWrapper<TokenEndpointMcpServerNameTokenPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		TokenEndpointMcpServerNameTokenPostPathParams
	>({
		method: "POST",
		url: `/${pathParams["mcpServerName"]}/token`,
		...requestConfig,
		headers: { "Content-Type": "application/x-www-form-urlencoded", ...requestConfig.headers },
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Callback
 * {@link /callback}
 */
export async function callbackCallbackGet({
	queryParams,
	config = {},
}: {
	queryParams: CallbackCallbackGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		CallbackCallbackGetQueryResponse,
		ErrorWrapper<CallbackCallbackGet422>,
		null,
		Record<string, string>,
		CallbackCallbackGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/callback`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Oauth Protected Resource Mcp
 * {@link /.well-known/oauth-protected-resource}
 */
export async function oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet({
	queryParams,
	config = {},
}: {
	queryParams?: OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryResponse,
		ErrorWrapper<OauthProtectedResourceMcpWellKnownOauthProtectedResourceGet422>,
		null,
		Record<string, string>,
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/.well-known/oauth-protected-resource`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Oauth Protected Resource Mcp
 * {@link /.well-known/oauth-protected-resource/:mcp_server_name/mcp}
 */
export async function oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet({
	pathParams,
	config = {},
}: {
	pathParams: OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetQueryResponse,
		ErrorWrapper<OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams
	>({
		method: "GET",
		url: `/.well-known/oauth-protected-resource/${pathParams["mcpServerName"]}/mcp`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Oauth Authorization Server Root
 * {@link /.well-known/oauth-authorization-server}
 */
export async function oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet({
	queryParams,
	config = {},
}: {
	queryParams?: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryResponse,
		ErrorWrapper<OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet422>,
		null,
		Record<string, string>,
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams,
		Record<string, string>
	>({
		method: "GET",
		url: `/.well-known/oauth-authorization-server`,
		queryParams,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Oauth Authorization Server Mcp
 * {@link /.well-known/oauth-authorization-server/:mcp_server_name}
 */
export async function oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet({
	pathParams,
	config = {},
}: {
	pathParams: OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetQueryResponse,
		ErrorWrapper<OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams
	>({
		method: "GET",
		url: `/.well-known/oauth-authorization-server/${pathParams["mcpServerName"]}`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Openid Configuration
 * {@link /.well-known/openid-configuration}
 */
export async function openidConfigurationWellKnownOpenidConfigurationGet({
	config = {},
}: {
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		OpenidConfigurationWellKnownOpenidConfigurationGetQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		Record<string, string>,
		Record<string, string>
	>({ method: "GET", url: `/.well-known/openid-configuration`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Oauth Authorization Server Root
 * {@link /.well-known/oauth-authorization-server/:mcp_server_name/mcp}
 */
export async function oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet({
	pathParams,
	config = {},
}: {
	pathParams: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetQueryResponse,
		ErrorWrapper<OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet422>,
		null,
		Record<string, string>,
		Record<string, string>,
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams
	>({
		method: "GET",
		url: `/.well-known/oauth-authorization-server/${pathParams["mcpServerName"]}/mcp`,
		...requestConfig,
	});
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Register Client
 * {@link /register}
 */
export async function registerClientRegisterPost({
	queryParams,
	config = {},
}: {
	queryParams?: RegisterClientRegisterPostQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		RegisterClientRegisterPostMutationResponse,
		ErrorWrapper<RegisterClientRegisterPost422>,
		null,
		Record<string, string>,
		RegisterClientRegisterPostQueryParams,
		Record<string, string>
	>({ method: "POST", url: `/register`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @summary Register Client
 * {@link /:mcp_server_name/register}
 */
export async function registerClientMcpServerNameRegisterPost({
	pathParams,
	config = {},
}: {
	pathParams: RegisterClientMcpServerNameRegisterPostPathParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	if (!pathParams["mcp_server_name"]) {
		throw new Error(`Missing required path parameter: mcp_server_name`);
	}
	const data = await request<
		RegisterClientMcpServerNameRegisterPostMutationResponse,
		ErrorWrapper<RegisterClientMcpServerNameRegisterPost422>,
		null,
		Record<string, string>,
		Record<string, string>,
		RegisterClientMcpServerNameRegisterPostPathParams
	>({ method: "POST", url: `/${pathParams["mcpServerName"]}/register`, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description WebSocket connection endpoint
 * @summary WebSocket: vertex_ai_live_passthrough_endpoint
 * {@link /vertex_ai/live}
 */
export async function websocketVertexAiLivePassthroughEndpoint({
	queryParams,
	config = {},
}: {
	queryParams?: WebsocketVertexAiLivePassthroughEndpointQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		WebsocketVertexAiLivePassthroughEndpointQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		WebsocketVertexAiLivePassthroughEndpointQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/vertex_ai/live`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description WebSocket connection endpoint
 * @summary WebSocket: websocket_endpoint
 * {@link /realtime}
 */
export async function websocketWebsocketEndpoint({
	queryParams,
	config = {},
}: {
	queryParams: WebsocketWebsocketEndpointQueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		WebsocketWebsocketEndpointQueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		WebsocketWebsocketEndpointQueryParams,
		Record<string, string>
	>({ method: "GET", url: `/realtime`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

/**
 * @description WebSocket connection endpoint
 * @summary WebSocket: websocket_endpoint
 * {@link /v1/realtime}
 */
export async function websocketWebsocketEndpoint2({
	queryParams,
	config = {},
}: {
	queryParams: WebsocketWebsocketEndpoint2QueryParams;
	config?: Partial<FetcherConfig> & { client?: typeof client };
}): Promise<Promise<CallToolResult>> {
	const { client: request = client, ...requestConfig } = config;

	const data = await request<
		WebsocketWebsocketEndpoint2QueryResponse,
		ErrorWrapper<Error>,
		null,
		Record<string, string>,
		WebsocketWebsocketEndpoint2QueryParams,
		Record<string, string>
	>({ method: "GET", url: `/v1/realtime`, queryParams, ...requestConfig });
	return { content: [{ type: "text", text: JSON.stringify(data) }] };
}

import type { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";

export function initMcpTools<Server>(serverLike: Server, config: FetcherConfig) {
	const server = serverLike as McpServer;

	server.registerTool(
		"modelListModelsGet",
		{
			description:
				'Use `/model/info` - to get detailed model information, example - pricing, mode, etc.\n\nThis is just for compatibility with openai projects like aider.\n\nQuery Parameters:\n- include_metadata: Include additional metadata in the response with fallback information\n- fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")\n                Defaults to "general" when include_metadata=true',
			inputSchema: { queryParams: modelListModelsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await modelListModelsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"modelListV1ModelsGet",
		{
			description:
				'Use `/model/info` - to get detailed model information, example - pricing, mode, etc.\n\nThis is just for compatibility with openai projects like aider.\n\nQuery Parameters:\n- include_metadata: Include additional metadata in the response with fallback information\n- fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")\n                Defaults to "general" when include_metadata=true',
			inputSchema: { queryParams: modelListV1ModelsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await modelListV1ModelsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"modelInfoModelsModelIdGet",
		{
			description:
				"Retrieve information about a specific model accessible to your API key.\n\nReturns model details only if the model is available to your API key/team.\nReturns 404 if the model doesn't exist or is not accessible.\n\nFollows OpenAI API specification for individual model retrieval.\nhttps://platform.openai.com/docs/api-reference/models/retrieve",
			inputSchema: { modelId: modelInfoModelsModelIdGetPathParamsSchema.shape["model_id"] },
		},
		async ({ modelId }) => {
			try {
				return await modelInfoModelsModelIdGet({ pathParams: { modelId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"modelInfoV1ModelsModelIdGet",
		{
			description:
				"Retrieve information about a specific model accessible to your API key.\n\nReturns model details only if the model is available to your API key/team.\nReturns 404 if the model doesn't exist or is not accessible.\n\nFollows OpenAI API specification for individual model retrieval.\nhttps://platform.openai.com/docs/api-reference/models/retrieve",
			inputSchema: { modelId: modelInfoV1ModelsModelIdGetPathParamsSchema.shape["model_id"] },
		},
		async ({ modelId }) => {
			try {
				return await modelInfoV1ModelsModelIdGet({ pathParams: { modelId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"chatCompletionOpenaiDeploymentsModelChatCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Chat API https://platform.openai.com/docs/api-reference/chat`\n\n```bash\ncurl -X POST http://localhost:4000/v1/chat/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-4o",\n    "messages": [\n        {\n            "role": "user",\n            "content": "Hello!"\n        }\n    ]\n}\'\n```',
			inputSchema: {
				model:
					chatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParamsSchema.shape["model"],
				body: chatCompletionOpenaiDeploymentsModelChatCompletionsPostMutationRequestSchema,
			},
		},
		async ({ model, body }) => {
			try {
				return await chatCompletionOpenaiDeploymentsModelChatCompletionsPost({
					pathParams: { model },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"chatCompletionEnginesModelChatCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Chat API https://platform.openai.com/docs/api-reference/chat`\n\n```bash\ncurl -X POST http://localhost:4000/v1/chat/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-4o",\n    "messages": [\n        {\n            "role": "user",\n            "content": "Hello!"\n        }\n    ]\n}\'\n```',
			inputSchema: {
				model: chatCompletionEnginesModelChatCompletionsPostPathParamsSchema.shape["model"],
				body: chatCompletionEnginesModelChatCompletionsPostMutationRequestSchema,
			},
		},
		async ({ model, body }) => {
			try {
				return await chatCompletionEnginesModelChatCompletionsPost({
					pathParams: { model },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"chatCompletionChatCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Chat API https://platform.openai.com/docs/api-reference/chat`\n\n```bash\ncurl -X POST http://localhost:4000/v1/chat/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-4o",\n    "messages": [\n        {\n            "role": "user",\n            "content": "Hello!"\n        }\n    ]\n}\'\n```',
			inputSchema: { body: chatCompletionChatCompletionsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await chatCompletionChatCompletionsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"chatCompletionV1ChatCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Chat API https://platform.openai.com/docs/api-reference/chat`\n\n```bash\ncurl -X POST http://localhost:4000/v1/chat/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-4o",\n    "messages": [\n        {\n            "role": "user",\n            "content": "Hello!"\n        }\n    ]\n}\'\n```',
			inputSchema: { body: chatCompletionV1ChatCompletionsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await chatCompletionV1ChatCompletionsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"completionOpenaiDeploymentsModelCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Completions API https://platform.openai.com/docs/api-reference/completions`\n\n```bash\ncurl -X POST http://localhost:4000/v1/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-3.5-turbo-instruct",\n    "prompt": "Once upon a time",\n    "max_tokens": 50,\n    "temperature": 0.7\n}\'\n```',
			inputSchema: {
				model: completionOpenaiDeploymentsModelCompletionsPostPathParamsSchema.shape["model"],
			},
		},
		async ({ model }) => {
			try {
				return await completionOpenaiDeploymentsModelCompletionsPost({
					pathParams: { model },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"completionEnginesModelCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Completions API https://platform.openai.com/docs/api-reference/completions`\n\n```bash\ncurl -X POST http://localhost:4000/v1/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-3.5-turbo-instruct",\n    "prompt": "Once upon a time",\n    "max_tokens": 50,\n    "temperature": 0.7\n}\'\n```',
			inputSchema: { model: completionEnginesModelCompletionsPostPathParamsSchema.shape["model"] },
		},
		async ({ model }) => {
			try {
				return await completionEnginesModelCompletionsPost({ pathParams: { model }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"completionCompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Completions API https://platform.openai.com/docs/api-reference/completions`\n\n```bash\ncurl -X POST http://localhost:4000/v1/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-3.5-turbo-instruct",\n    "prompt": "Once upon a time",\n    "max_tokens": 50,\n    "temperature": 0.7\n}\'\n```',
			inputSchema: { queryParams: completionCompletionsPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await completionCompletionsPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"completionV1CompletionsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Completions API https://platform.openai.com/docs/api-reference/completions`\n\n```bash\ncurl -X POST http://localhost:4000/v1/completions \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "gpt-3.5-turbo-instruct",\n    "prompt": "Once upon a time",\n    "max_tokens": 50,\n    "temperature": 0.7\n}\'\n```',
			inputSchema: { queryParams: completionV1CompletionsPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await completionV1CompletionsPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"embeddingsOpenaiDeploymentsModelEmbeddingsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Embeddings API https://platform.openai.com/docs/api-reference/embeddings`\n\n```bash\ncurl -X POST http://localhost:4000/v1/embeddings \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "text-embedding-ada-002",\n    "input": "The quick brown fox jumps over the lazy dog"\n}\'\n```',
			inputSchema: {
				model: embeddingsOpenaiDeploymentsModelEmbeddingsPostPathParamsSchema.shape["model"],
				body: embeddingsOpenaiDeploymentsModelEmbeddingsPostMutationRequestSchema,
			},
		},
		async ({ model, body }) => {
			try {
				return await embeddingsOpenaiDeploymentsModelEmbeddingsPost({
					pathParams: { model },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"embeddingsEnginesModelEmbeddingsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Embeddings API https://platform.openai.com/docs/api-reference/embeddings`\n\n```bash\ncurl -X POST http://localhost:4000/v1/embeddings \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "text-embedding-ada-002",\n    "input": "The quick brown fox jumps over the lazy dog"\n}\'\n```',
			inputSchema: {
				model: embeddingsEnginesModelEmbeddingsPostPathParamsSchema.shape["model"],
				body: embeddingsEnginesModelEmbeddingsPostMutationRequestSchema,
			},
		},
		async ({ model, body }) => {
			try {
				return await embeddingsEnginesModelEmbeddingsPost({ pathParams: { model }, body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"embeddingsEmbeddingsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Embeddings API https://platform.openai.com/docs/api-reference/embeddings`\n\n```bash\ncurl -X POST http://localhost:4000/v1/embeddings \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "text-embedding-ada-002",\n    "input": "The quick brown fox jumps over the lazy dog"\n}\'\n```',
			inputSchema: { body: embeddingsEmbeddingsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await embeddingsEmbeddingsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"embeddingsV1EmbeddingsPost",
		{
			description:
				'Follows the exact same API spec as `OpenAI\'s Embeddings API https://platform.openai.com/docs/api-reference/embeddings`\n\n```bash\ncurl -X POST http://localhost:4000/v1/embeddings \n-H "Content-Type: application/json" \n-H "Authorization: Bearer sk-1234" \n-d \'{\n    "model": "text-embedding-ada-002",\n    "input": "The quick brown fox jumps over the lazy dog"\n}\'\n```',
			inputSchema: { body: embeddingsV1EmbeddingsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await embeddingsV1EmbeddingsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"moderationsModerationsPost",
		{
			description:
				"The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.\nQuick Start\n```\ncurl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{\"input\": \"Sample text goes here\", \"model\": \"text-moderation-stable\"}'\n```",
		},
		async () => {
			try {
				return await moderationsModerationsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"moderationsV1ModerationsPost",
		{
			description:
				"The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.\nQuick Start\n```\ncurl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{\"input\": \"Sample text goes here\", \"model\": \"text-moderation-stable\"}'\n```",
		},
		async () => {
			try {
				return await moderationsV1ModerationsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"audioSpeechAudioSpeechPost",
		{
			description:
				"Same params as:\n\nhttps://platform.openai.com/docs/api-reference/audio/createSpeech",
		},
		async () => {
			try {
				return await audioSpeechAudioSpeechPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"audioSpeechV1AudioSpeechPost",
		{
			description:
				"Same params as:\n\nhttps://platform.openai.com/docs/api-reference/audio/createSpeech",
		},
		async () => {
			try {
				return await audioSpeechV1AudioSpeechPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"audioTranscriptionsAudioTranscriptionsPost",
		{
			description:
				"Same params as:\n\nhttps://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl",
		},
		async () => {
			try {
				return await audioTranscriptionsAudioTranscriptionsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"audioTranscriptionsV1AudioTranscriptionsPost",
		{
			description:
				"Same params as:\n\nhttps://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl",
		},
		async () => {
			try {
				return await audioTranscriptionsV1AudioTranscriptionsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getAssistantsAssistantsGet",
		{
			description:
				"Returns a list of assistants.\n\nAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants",
		},
		async () => {
			try {
				return await getAssistantsAssistantsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createAssistantAssistantsPost",
		{
			description:
				"Create assistant\n\nAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant",
		},
		async () => {
			try {
				return await createAssistantAssistantsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getAssistantsV1AssistantsGet",
		{
			description:
				"Returns a list of assistants.\n\nAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants",
		},
		async () => {
			try {
				return await getAssistantsV1AssistantsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createAssistantV1AssistantsPost",
		{
			description:
				"Create assistant\n\nAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant",
		},
		async () => {
			try {
				return await createAssistantV1AssistantsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteAssistantAssistantsAssistantIdDelete",
		{
			description:
				"Delete assistant\n\nAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant",
			inputSchema: {
				assistantId:
					deleteAssistantAssistantsAssistantIdDeletePathParamsSchema.shape["assistant_id"],
			},
		},
		async ({ assistantId }) => {
			try {
				return await deleteAssistantAssistantsAssistantIdDelete({
					pathParams: { assistantId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteAssistantV1AssistantsAssistantIdDelete",
		{
			description:
				"Delete assistant\n\nAPI Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant",
			inputSchema: {
				assistantId:
					deleteAssistantV1AssistantsAssistantIdDeletePathParamsSchema.shape["assistant_id"],
			},
		},
		async ({ assistantId }) => {
			try {
				return await deleteAssistantV1AssistantsAssistantIdDelete({
					pathParams: { assistantId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createThreadsThreadsPost",
		{
			description:
				"Create a thread.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/threads/createThread",
		},
		async () => {
			try {
				return await createThreadsThreadsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createThreadsV1ThreadsPost",
		{
			description:
				"Create a thread.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/threads/createThread",
		},
		async () => {
			try {
				return await createThreadsV1ThreadsPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getThreadThreadsThreadIdGet",
		{
			description:
				"Retrieves a thread.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/threads/getThread",
			inputSchema: { threadId: getThreadThreadsThreadIdGetPathParamsSchema.shape["thread_id"] },
		},
		async ({ threadId }) => {
			try {
				return await getThreadThreadsThreadIdGet({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getThreadV1ThreadsThreadIdGet",
		{
			description:
				"Retrieves a thread.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/threads/getThread",
			inputSchema: { threadId: getThreadV1ThreadsThreadIdGetPathParamsSchema.shape["thread_id"] },
		},
		async ({ threadId }) => {
			try {
				return await getThreadV1ThreadsThreadIdGet({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"addMessagesThreadsThreadIdMessagesPost",
		{
			description:
				"Create a message.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/messages/createMessage",
			inputSchema: {
				threadId: addMessagesThreadsThreadIdMessagesPostPathParamsSchema.shape["thread_id"],
			},
		},
		async ({ threadId }) => {
			try {
				return await addMessagesThreadsThreadIdMessagesPost({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getMessagesThreadsThreadIdMessagesGet",
		{
			description:
				"Returns a list of messages for a given thread.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/messages/listMessages",
			inputSchema: {
				threadId: getMessagesThreadsThreadIdMessagesGetPathParamsSchema.shape["thread_id"],
			},
		},
		async ({ threadId }) => {
			try {
				return await getMessagesThreadsThreadIdMessagesGet({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"addMessagesV1ThreadsThreadIdMessagesPost",
		{
			description:
				"Create a message.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/messages/createMessage",
			inputSchema: {
				threadId: addMessagesV1ThreadsThreadIdMessagesPostPathParamsSchema.shape["thread_id"],
			},
		},
		async ({ threadId }) => {
			try {
				return await addMessagesV1ThreadsThreadIdMessagesPost({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getMessagesV1ThreadsThreadIdMessagesGet",
		{
			description:
				"Returns a list of messages for a given thread.\n\nAPI Reference - https://platform.openai.com/docs/api-reference/messages/listMessages",
			inputSchema: {
				threadId: getMessagesV1ThreadsThreadIdMessagesGetPathParamsSchema.shape["thread_id"],
			},
		},
		async ({ threadId }) => {
			try {
				return await getMessagesV1ThreadsThreadIdMessagesGet({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"runThreadThreadsThreadIdRunsPost",
		{
			description:
				"Create a run.\n\nAPI Reference: https://platform.openai.com/docs/api-reference/runs/createRun",
			inputSchema: {
				threadId: runThreadThreadsThreadIdRunsPostPathParamsSchema.shape["thread_id"],
			},
		},
		async ({ threadId }) => {
			try {
				return await runThreadThreadsThreadIdRunsPost({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"runThreadV1ThreadsThreadIdRunsPost",
		{
			description:
				"Create a run.\n\nAPI Reference: https://platform.openai.com/docs/api-reference/runs/createRun",
			inputSchema: {
				threadId: runThreadV1ThreadsThreadIdRunsPostPathParamsSchema.shape["thread_id"],
			},
		},
		async ({ threadId }) => {
			try {
				return await runThreadV1ThreadsThreadIdRunsPost({ pathParams: { threadId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"tokenCounterUtilsTokenCounterPost",
		{
			description:
				'Args:\n    request: TokenCountRequest\n    call_endpoint: bool - When set to "True" it will call the token counting endpoint - e.g Anthropic or Google AI Studio Token Counting APIs.\n\nReturns:\n    TokenCountResponse',
			inputSchema: {
				body: tokenCounterUtilsTokenCounterPostMutationRequestSchema,
				queryParams: tokenCounterUtilsTokenCounterPostQueryParamsSchema,
			},
		},
		async ({ body, queryParams }) => {
			try {
				return await tokenCounterUtilsTokenCounterPost({ body, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"supportedOpenaiParamsUtilsSupportedOpenaiParamsGet",
		{
			description:
				"Returns supported openai params for a given litellm model name\n\ne.g. `gpt-4` vs `gpt-3.5-turbo`\n\nExample curl:\n```\ncurl -X GET --location 'http://localhost:4000/utils/supported_openai_params?model=gpt-3.5-turbo-16k'         --header 'Authorization: Bearer sk-1234'\n```",
			inputSchema: {
				queryParams: supportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await supportedOpenaiParamsUtilsSupportedOpenaiParamsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"transformRequestUtilsTransformRequestPost",
		{
			description: "Make a POST request to /utils/transform_request",
			inputSchema: { body: transformRequestUtilsTransformRequestPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await transformRequestUtilsTransformRequestPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"modelInfoV1V1ModelInfoGet",
		{
			description:
				'Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)\n\nParameters:\n    litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)\n\n    - When litellm_model_id is passed, it will return the info for that specific model\n    - When litellm_model_id is not passed, it will return the info for all models\n\nReturns:\n    Returns a dictionary containing information about each model.\n\nExample Response:\n```json\n{\n    "data": [\n                {\n                    "model_name": "fake-openai-endpoint",\n                    "litellm_params": {\n                        "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",\n                        "model": "openai/fake"\n                    },\n                    "model_info": {\n                        "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",\n                        "db_model": false\n                    }\n                }\n            ]\n}\n\n```',
			inputSchema: { queryParams: modelInfoV1V1ModelInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await modelInfoV1V1ModelInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"modelInfoV1ModelInfoGet",
		{
			description:
				'Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)\n\nParameters:\n    litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)\n\n    - When litellm_model_id is passed, it will return the info for that specific model\n    - When litellm_model_id is not passed, it will return the info for all models\n\nReturns:\n    Returns a dictionary containing information about each model.\n\nExample Response:\n```json\n{\n    "data": [\n                {\n                    "model_name": "fake-openai-endpoint",\n                    "litellm_params": {\n                        "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",\n                        "model": "openai/fake"\n                    },\n                    "model_info": {\n                        "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",\n                        "db_model": false\n                    }\n                }\n            ]\n}\n\n```',
			inputSchema: { queryParams: modelInfoV1ModelInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await modelInfoV1ModelInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"modelGroupInfoModelGroupInfoGet",
		{
			description:
				'Get information about all the deployments on litellm proxy, including config.yaml descriptions (except api key and api base)\n\n- /model_group/info returns all model groups. End users of proxy should use /model_group/info since those models will be used for /chat/completions, /embeddings, etc.\n- /model_group/info?model_group=rerank-english-v3.0 returns all model groups for a specific model group (`model_name` in config.yaml)\n\n\n\nExample Request (All Models):\n```shell\ncurl -X \'GET\'     \'http://localhost:4000/model_group/info\'     -H \'accept: application/json\'     -H \'x-api-key: sk-1234\'\n```\n\nExample Request (Specific Model Group):\n```shell\ncurl -X \'GET\'     \'http://localhost:4000/model_group/info?model_group=rerank-english-v3.0\'     -H \'accept: application/json\'     -H \'Authorization: Bearer sk-1234\'\n```\n\nExample Request (Specific Wildcard Model Group): (e.g. `model_name: openai/*` on config.yaml)\n```shell\ncurl -X \'GET\'     \'http://localhost:4000/model_group/info?model_group=openai/tts-1\'\n-H \'accept: application/json\'     -H \'Authorization: Bearersk-1234\'\n```\n\nLearn how to use and set wildcard models [here](https://docs.litellm.ai/docs/wildcard_routing)\n\nExample Response:\n```json\n    {\n        "data": [\n            {\n            "model_group": "rerank-english-v3.0",\n            "providers": [\n                "cohere"\n            ],\n            "max_input_tokens": null,\n            "max_output_tokens": null,\n            "input_cost_per_token": 0.0,\n            "output_cost_per_token": 0.0,\n            "mode": null,\n            "tpm": null,\n            "rpm": null,\n            "supports_parallel_function_calling": false,\n            "supports_vision": false,\n            "supports_function_calling": false,\n            "supported_openai_params": [\n                "stream",\n                "temperature",\n                "max_tokens",\n                "logit_bias",\n                "top_p",\n                "frequency_penalty",\n                "presence_penalty",\n                "stop",\n                "n",\n                "extra_headers"\n            ]\n            },\n            {\n            "model_group": "gpt-3.5-turbo",\n            "providers": [\n                "openai"\n            ],\n            "max_input_tokens": 16385.0,\n            "max_output_tokens": 4096.0,\n            "input_cost_per_token": 1.5e-06,\n            "output_cost_per_token": 2e-06,\n            "mode": "chat",\n            "tpm": null,\n            "rpm": null,\n            "supports_parallel_function_calling": false,\n            "supports_vision": false,\n            "supports_function_calling": true,\n            "supported_openai_params": [\n                "frequency_penalty",\n                "logit_bias",\n                "logprobs",\n                "top_logprobs",\n                "max_tokens",\n                "max_completion_tokens",\n                "n",\n                "presence_penalty",\n                "seed",\n                "stop",\n                "stream",\n                "stream_options",\n                "temperature",\n                "top_p",\n                "tools",\n                "tool_choice",\n                "function_call",\n                "functions",\n                "max_retries",\n                "extra_headers",\n                "parallel_tool_calls",\n                "response_format"\n            ]\n            },\n            {\n            "model_group": "llava-hf",\n            "providers": [\n                "openai"\n            ],\n            "max_input_tokens": null,\n            "max_output_tokens": null,\n            "input_cost_per_token": 0.0,\n            "output_cost_per_token": 0.0,\n            "mode": null,\n            "tpm": null,\n            "rpm": null,\n            "supports_parallel_function_calling": false,\n            "supports_vision": true,\n            "supports_function_calling": false,\n            "supported_openai_params": [\n                "frequency_penalty",\n                "logit_bias",\n                "logprobs",\n                "top_logprobs",\n                "max_tokens",\n                "max_completion_tokens",\n                "n",\n                "presence_penalty",\n                "seed",\n                "stop",\n                "stream",\n                "stream_options",\n                "temperature",\n                "top_p",\n                "tools",\n                "tool_choice",\n                "function_call",\n                "functions",\n                "max_retries",\n                "extra_headers",\n                "parallel_tool_calls",\n                "response_format"\n            ]\n            }\n        ]\n        }\n```',
			inputSchema: { queryParams: modelGroupInfoModelGroupInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await modelGroupInfoModelGroupInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool("homeGet", { description: "Make a GET request to /" }, async () => {
		try {
			return await homeGet({ config });
		} catch (error) {
			return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
		}
	});

	server.registerTool(
		"getRoutesRoutesGet",
		{ description: "Get a list of available routes in the FastAPI application." },
		async () => {
			try {
				return await getRoutesRoutesGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"responsesApiOpenaiV1ResponsesPost",
		{
			description:
				'Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses\n\n```bash\ncurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d \'{\n    "model": "gpt-4o",\n    "input": "Tell me about AI"\n}\'\n```',
		},
		async () => {
			try {
				return await responsesApiOpenaiV1ResponsesPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"responsesApiResponsesPost",
		{
			description:
				'Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses\n\n```bash\ncurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d \'{\n    "model": "gpt-4o",\n    "input": "Tell me about AI"\n}\'\n```',
		},
		async () => {
			try {
				return await responsesApiResponsesPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"responsesApiV1ResponsesPost",
		{
			description:
				'Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses\n\n```bash\ncurl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d \'{\n    "model": "gpt-4o",\n    "input": "Tell me about AI"\n}\'\n```',
		},
		async () => {
			try {
				return await responsesApiV1ResponsesPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getResponseOpenaiV1ResponsesResponseIdGet",
		{
			description:
				'Get a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get\n\n```bash\ncurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId: getResponseOpenaiV1ResponsesResponseIdGetPathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await getResponseOpenaiV1ResponsesResponseIdGet({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteResponseOpenaiV1ResponsesResponseIdDelete",
		{
			description:
				'Delete a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete\n\n```bash\ncurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId:
					deleteResponseOpenaiV1ResponsesResponseIdDeletePathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await deleteResponseOpenaiV1ResponsesResponseIdDelete({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getResponseResponsesResponseIdGet",
		{
			description:
				'Get a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get\n\n```bash\ncurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId: getResponseResponsesResponseIdGetPathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await getResponseResponsesResponseIdGet({ pathParams: { responseId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteResponseResponsesResponseIdDelete",
		{
			description:
				'Delete a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete\n\n```bash\ncurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId: deleteResponseResponsesResponseIdDeletePathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await deleteResponseResponsesResponseIdDelete({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getResponseV1ResponsesResponseIdGet",
		{
			description:
				'Get a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get\n\n```bash\ncurl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId: getResponseV1ResponsesResponseIdGetPathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await getResponseV1ResponsesResponseIdGet({ pathParams: { responseId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteResponseV1ResponsesResponseIdDelete",
		{
			description:
				'Delete a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete\n\n```bash\ncurl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId: deleteResponseV1ResponsesResponseIdDeletePathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await deleteResponseV1ResponsesResponseIdDelete({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet",
		{
			description: "List input items for a response.",
			inputSchema: {
				responseId:
					getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParamsSchema.shape[
						"response_id"
					],
			},
		},
		async ({ responseId }) => {
			try {
				return await getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getResponseInputItemsResponsesResponseIdInputItemsGet",
		{
			description: "List input items for a response.",
			inputSchema: {
				responseId:
					getResponseInputItemsResponsesResponseIdInputItemsGetPathParamsSchema.shape[
						"response_id"
					],
			},
		},
		async ({ responseId }) => {
			try {
				return await getResponseInputItemsResponsesResponseIdInputItemsGet({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getResponseInputItemsV1ResponsesResponseIdInputItemsGet",
		{
			description: "List input items for a response.",
			inputSchema: {
				responseId:
					getResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParamsSchema.shape[
						"response_id"
					],
			},
		},
		async ({ responseId }) => {
			try {
				return await getResponseInputItemsV1ResponsesResponseIdInputItemsGet({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelResponseOpenaiV1ResponsesResponseIdCancelPost",
		{
			description:
				'Cancel a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel\n\n```bash\ncurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId:
					cancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await cancelResponseOpenaiV1ResponsesResponseIdCancelPost({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelResponseResponsesResponseIdCancelPost",
		{
			description:
				'Cancel a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel\n\n```bash\ncurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId:
					cancelResponseResponsesResponseIdCancelPostPathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await cancelResponseResponsesResponseIdCancelPost({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelResponseV1ResponsesResponseIdCancelPost",
		{
			description:
				'Cancel a response by ID.\n\nFollows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel\n\n```bash\ncurl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: {
				responseId:
					cancelResponseV1ResponsesResponseIdCancelPostPathParamsSchema.shape["response_id"],
			},
		},
		async ({ responseId }) => {
			try {
				return await cancelResponseV1ResponsesResponseIdCancelPost({
					pathParams: { responseId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createBatchBatchesPost",
		{
			description:
				'Create large batches of API requests for asynchronous processing.\nThis is the equivalent of POST https://api.openai.com/v1/batch\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "input_file_id": "file-abc123",\n        "endpoint": "/v1/chat/completions",\n        "completion_window": "24h"\n}\'\n```',
			inputSchema: { queryParams: createBatchBatchesPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await createBatchBatchesPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listBatchesBatchesGet",
		{
			description:
				'Lists \nThis is the equivalent of GET https://api.openai.com/v1/batches/\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" \n```',
			inputSchema: { queryParams: listBatchesBatchesGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listBatchesBatchesGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createBatchV1BatchesPost",
		{
			description:
				'Create large batches of API requests for asynchronous processing.\nThis is the equivalent of POST https://api.openai.com/v1/batch\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "input_file_id": "file-abc123",\n        "endpoint": "/v1/chat/completions",\n        "completion_window": "24h"\n}\'\n```',
			inputSchema: { queryParams: createBatchV1BatchesPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await createBatchV1BatchesPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listBatchesV1BatchesGet",
		{
			description:
				'Lists \nThis is the equivalent of GET https://api.openai.com/v1/batches/\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" \n```',
			inputSchema: { queryParams: listBatchesV1BatchesGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listBatchesV1BatchesGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createBatchProviderV1BatchesPost",
		{
			description:
				'Create large batches of API requests for asynchronous processing.\nThis is the equivalent of POST https://api.openai.com/v1/batch\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "input_file_id": "file-abc123",\n        "endpoint": "/v1/chat/completions",\n        "completion_window": "24h"\n}\'\n```',
			inputSchema: { provider: createBatchProviderV1BatchesPostPathParamsSchema.shape["provider"] },
		},
		async ({ provider }) => {
			try {
				return await createBatchProviderV1BatchesPost({ pathParams: { provider }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listBatchesProviderV1BatchesGet",
		{
			description:
				'Lists \nThis is the equivalent of GET https://api.openai.com/v1/batches/\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" \n```',
			inputSchema: {
				provider: listBatchesProviderV1BatchesGetPathParamsSchema.shape["provider"],
				queryParams: listBatchesProviderV1BatchesGetQueryParamsSchema,
			},
		},
		async ({ provider, queryParams }) => {
			try {
				return await listBatchesProviderV1BatchesGet({
					pathParams: { provider },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveBatchBatchesBatchIdGet",
		{
			description:
				'Retrieves a batch.\nThis is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" \n```',
			inputSchema: {
				batchId: retrieveBatchBatchesBatchIdGetPathParamsSchema.shape["batch_id"],
				queryParams: retrieveBatchBatchesBatchIdGetQueryParamsSchema,
			},
		},
		async ({ batchId, queryParams }) => {
			try {
				return await retrieveBatchBatchesBatchIdGet({
					pathParams: { batchId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveBatchV1BatchesBatchIdGet",
		{
			description:
				'Retrieves a batch.\nThis is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" \n```',
			inputSchema: {
				batchId: retrieveBatchV1BatchesBatchIdGetPathParamsSchema.shape["batch_id"],
				queryParams: retrieveBatchV1BatchesBatchIdGetQueryParamsSchema,
			},
		},
		async ({ batchId, queryParams }) => {
			try {
				return await retrieveBatchV1BatchesBatchIdGet({
					pathParams: { batchId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveBatchProviderV1BatchesBatchIdGet",
		{
			description:
				'Retrieves a batch.\nThis is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json" \n```',
			inputSchema: {
				provider: retrieveBatchProviderV1BatchesBatchIdGetPathParamsSchema.shape["provider"],
				batchId: retrieveBatchProviderV1BatchesBatchIdGetPathParamsSchema.shape["batch_id"],
			},
		},
		async ({ provider, batchId }) => {
			try {
				return await retrieveBatchProviderV1BatchesBatchIdGet({
					pathParams: { provider, batchId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelBatchBatchesBatchIdCancelPost",
		{
			description:
				'Cancel a batch.\nThis is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST\n\n```',
			inputSchema: {
				batchId: cancelBatchBatchesBatchIdCancelPostPathParamsSchema.shape["batch_id"],
				queryParams: cancelBatchBatchesBatchIdCancelPostQueryParamsSchema,
			},
		},
		async ({ batchId, queryParams }) => {
			try {
				return await cancelBatchBatchesBatchIdCancelPost({
					pathParams: { batchId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelBatchV1BatchesBatchIdCancelPost",
		{
			description:
				'Cancel a batch.\nThis is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST\n\n```',
			inputSchema: {
				batchId: cancelBatchV1BatchesBatchIdCancelPostPathParamsSchema.shape["batch_id"],
				queryParams: cancelBatchV1BatchesBatchIdCancelPostQueryParamsSchema,
			},
		},
		async ({ batchId, queryParams }) => {
			try {
				return await cancelBatchV1BatchesBatchIdCancelPost({
					pathParams: { batchId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelBatchProviderV1BatchesBatchIdCancelPost",
		{
			description:
				'Cancel a batch.\nThis is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel\n\nExample Curl\n```\ncurl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST\n\n```',
			inputSchema: {
				batchId: cancelBatchProviderV1BatchesBatchIdCancelPostPathParamsSchema.shape["batch_id"],
				provider: cancelBatchProviderV1BatchesBatchIdCancelPostPathParamsSchema.shape["provider"],
			},
		},
		async ({ batchId, provider }) => {
			try {
				return await cancelBatchProviderV1BatchesBatchIdCancelPost({
					pathParams: { batchId, provider },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"publicModelHubPublicModelHubGet",
		{ description: "Make a GET request to /public/model_hub" },
		async () => {
			try {
				return await publicModelHubPublicModelHubGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"publicModelHubInfoPublicModelHubInfoGet",
		{ description: "Make a GET request to /public/model_hub/info" },
		async () => {
			try {
				return await publicModelHubInfoPublicModelHubInfoGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"rerankRerankPost",
		{ description: "Make a POST request to /rerank" },
		async () => {
			try {
				return await rerankRerankPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"rerankV1RerankPost",
		{ description: "Make a POST request to /v1/rerank" },
		async () => {
			try {
				return await rerankV1RerankPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"rerankV2RerankPost",
		{ description: "Make a POST request to /v2/rerank" },
		async () => {
			try {
				return await rerankV2RerankPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"ocrOcrPost",
		{
			description:
				'OCR endpoint for extracting text from documents and images.\n\nFollows the Mistral OCR API spec:\nhttps://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocr\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "model": "mistral/mistral-ocr-latest",\n        "document": {\n            "type": "document_url",\n            "document_url": "https://arxiv.org/pdf/2201.04234"\n        }\n    }\'\n```',
		},
		async () => {
			try {
				return await ocrOcrPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"ocrV1OcrPost",
		{
			description:
				'OCR endpoint for extracting text from documents and images.\n\nFollows the Mistral OCR API spec:\nhttps://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocr\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "model": "mistral/mistral-ocr-latest",\n        "document": {\n            "type": "document_url",\n            "document_url": "https://arxiv.org/pdf/2201.04234"\n        }\n    }\'\n```',
		},
		async () => {
			try {
				return await ocrV1OcrPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoListVideosGet",
		{
			description:
				'Video list endpoint for retrieving a list of videos.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"\n```',
		},
		async () => {
			try {
				return await videoListVideosGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoGenerationVideosPost",
		{
			description:
				'Video generation endpoint for creating videos from text prompts.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "model": "sora-2",\n        "prompt": "A beautiful sunset over the ocean"\n    }\'\n```',
		},
		async () => {
			try {
				return await videoGenerationVideosPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoListV1VideosGet",
		{
			description:
				'Video list endpoint for retrieving a list of videos.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"\n```',
		},
		async () => {
			try {
				return await videoListV1VideosGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoGenerationV1VideosPost",
		{
			description:
				'Video generation endpoint for creating videos from text prompts.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "model": "sora-2",\n        "prompt": "A beautiful sunset over the ocean"\n    }\'\n```',
		},
		async () => {
			try {
				return await videoGenerationV1VideosPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoStatusVideosVideoIdGet",
		{
			description:
				'Video status endpoint for retrieving video status and metadata.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: { videoId: videoStatusVideosVideoIdGetPathParamsSchema.shape["video_id"] },
		},
		async ({ videoId }) => {
			try {
				return await videoStatusVideosVideoIdGet({ pathParams: { videoId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoStatusV1VideosVideoIdGet",
		{
			description:
				'Video status endpoint for retrieving video status and metadata.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: { videoId: videoStatusV1VideosVideoIdGetPathParamsSchema.shape["video_id"] },
		},
		async ({ videoId }) => {
			try {
				return await videoStatusV1VideosVideoIdGet({ pathParams: { videoId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoContentVideosVideoIdContentGet",
		{
			description:
				'Video content endpoint for downloading video content.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4\n```',
			inputSchema: {
				videoId: videoContentVideosVideoIdContentGetPathParamsSchema.shape["video_id"],
			},
		},
		async ({ videoId }) => {
			try {
				return await videoContentVideosVideoIdContentGet({ pathParams: { videoId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoContentV1VideosVideoIdContentGet",
		{
			description:
				'Video content endpoint for downloading video content.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4\n```',
			inputSchema: {
				videoId: videoContentV1VideosVideoIdContentGetPathParamsSchema.shape["video_id"],
			},
		},
		async ({ videoId }) => {
			try {
				return await videoContentV1VideosVideoIdContentGet({ pathParams: { videoId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoRemixVideosVideoIdRemixPost",
		{
			description:
				'Video remix endpoint for remixing existing videos with new prompts.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "prompt": "A new version with different colors"\n    }\'\n```',
			inputSchema: { videoId: videoRemixVideosVideoIdRemixPostPathParamsSchema.shape["video_id"] },
		},
		async ({ videoId }) => {
			try {
				return await videoRemixVideosVideoIdRemixPost({ pathParams: { videoId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"videoRemixV1VideosVideoIdRemixPost",
		{
			description:
				'Video remix endpoint for remixing existing videos with new prompts.\n\nFollows the OpenAI Videos API spec:\nhttps://platform.openai.com/docs/api-reference/videos\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "prompt": "A new version with different colors"\n    }\'\n```',
			inputSchema: {
				videoId: videoRemixV1VideosVideoIdRemixPostPathParamsSchema.shape["video_id"],
			},
		},
		async ({ videoId }) => {
			try {
				return await videoRemixV1VideosVideoIdRemixPost({ pathParams: { videoId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listContainersContainersGet",
		{
			description:
				'Container list endpoint for retrieving a list of containers.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"\n```\n\nOr specify provider via header or query param:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"\n```',
		},
		async () => {
			try {
				return await listContainersContainersGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createContainerContainersPost",
		{
			description:
				'Container creation endpoint for creating new containers.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "name": "My Container",\n        "expires_after": {\n            "anchor": "last_active_at",\n            "minutes": 20\n        }\n    }\'\n```\n\nOr specify provider via header:\n```bash\ncurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d \'{\n        "name": "My Container"\n    }\'\n```',
		},
		async () => {
			try {
				return await createContainerContainersPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listContainersV1ContainersGet",
		{
			description:
				'Container list endpoint for retrieving a list of containers.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"\n```\n\nOr specify provider via header or query param:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"\n```',
		},
		async () => {
			try {
				return await listContainersV1ContainersGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createContainerV1ContainersPost",
		{
			description:
				'Container creation endpoint for creating new containers.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "name": "My Container",\n        "expires_after": {\n            "anchor": "last_active_at",\n            "minutes": 20\n        }\n    }\'\n```\n\nOr specify provider via header:\n```bash\ncurl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d \'{\n        "name": "My Container"\n    }\'\n```',
		},
		async () => {
			try {
				return await createContainerV1ContainersPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveContainerContainersContainerIdGet",
		{
			description:
				'Container retrieve endpoint for getting details of a specific container.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"\n```\n\nOr specify provider via header:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"\n```',
			inputSchema: {
				containerId:
					retrieveContainerContainersContainerIdGetPathParamsSchema.shape["container_id"],
			},
		},
		async ({ containerId }) => {
			try {
				return await retrieveContainerContainersContainerIdGet({
					pathParams: { containerId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteContainerContainersContainerIdDelete",
		{
			description:
				'Container delete endpoint for deleting a specific container.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"\n```\n\nOr specify provider via header:\n```bash\ncurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"\n```',
			inputSchema: {
				containerId:
					deleteContainerContainersContainerIdDeletePathParamsSchema.shape["container_id"],
			},
		},
		async ({ containerId }) => {
			try {
				return await deleteContainerContainersContainerIdDelete({
					pathParams: { containerId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveContainerV1ContainersContainerIdGet",
		{
			description:
				'Container retrieve endpoint for getting details of a specific container.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"\n```\n\nOr specify provider via header:\n```bash\ncurl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"\n```',
			inputSchema: {
				containerId:
					retrieveContainerV1ContainersContainerIdGetPathParamsSchema.shape["container_id"],
			},
		},
		async ({ containerId }) => {
			try {
				return await retrieveContainerV1ContainersContainerIdGet({
					pathParams: { containerId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteContainerV1ContainersContainerIdDelete",
		{
			description:
				'Container delete endpoint for deleting a specific container.\n\nFollows the OpenAI Containers API spec:\nhttps://platform.openai.com/docs/api-reference/containers\n\nExample:\n```bash\ncurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"\n```\n\nOr specify provider via header:\n```bash\ncurl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"\n```',
			inputSchema: {
				containerId:
					deleteContainerV1ContainersContainerIdDeletePathParamsSchema.shape["container_id"],
			},
		},
		async ({ containerId }) => {
			try {
				return await deleteContainerV1ContainersContainerIdDelete({
					pathParams: { containerId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"searchSearchPost",
		{
			description:
				'Search endpoint for performing web searches.\n\nFollows the Perplexity Search API spec:\nhttps://docs.perplexity.ai/api-reference/search-post\n\nThe search_tool_name can be passed either:\n1. In the URL path: /v1/search/{search_tool_name}\n2. In the request body: {"search_tool_name": "..."}\n\nExample with search_tool_name in URL (recommended - keeps body Perplexity-compatible):\n```bash\ncurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nExample with search_tool_name in body:\n```bash\ncurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "search_tool_name": "litellm-search",\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nRequest Body Parameters (when search_tool_name not in URL):\n- search_tool_name (str, required if not in URL): Name of the search tool configured in router\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nWhen using URL path parameter, only Perplexity-compatible parameters are needed in body:\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nResponse follows Perplexity Search API format:\n```json\n{\n    "object": "search",\n    "results": [\n        {\n            "title": "Result title",\n            "url": "https://example.com",\n            "snippet": "Result snippet...",\n            "date": "2024-01-01",\n            "last_updated": "2024-01-01"\n        }\n    ]\n}\n```',
			inputSchema: { queryParams: searchSearchPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await searchSearchPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"searchV1SearchPost",
		{
			description:
				'Search endpoint for performing web searches.\n\nFollows the Perplexity Search API spec:\nhttps://docs.perplexity.ai/api-reference/search-post\n\nThe search_tool_name can be passed either:\n1. In the URL path: /v1/search/{search_tool_name}\n2. In the request body: {"search_tool_name": "..."}\n\nExample with search_tool_name in URL (recommended - keeps body Perplexity-compatible):\n```bash\ncurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nExample with search_tool_name in body:\n```bash\ncurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "search_tool_name": "litellm-search",\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nRequest Body Parameters (when search_tool_name not in URL):\n- search_tool_name (str, required if not in URL): Name of the search tool configured in router\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nWhen using URL path parameter, only Perplexity-compatible parameters are needed in body:\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nResponse follows Perplexity Search API format:\n```json\n{\n    "object": "search",\n    "results": [\n        {\n            "title": "Result title",\n            "url": "https://example.com",\n            "snippet": "Result snippet...",\n            "date": "2024-01-01",\n            "last_updated": "2024-01-01"\n        }\n    ]\n}\n```',
			inputSchema: { queryParams: searchV1SearchPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await searchV1SearchPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"searchSearchSearchToolNamePost",
		{
			description:
				'Search endpoint for performing web searches.\n\nFollows the Perplexity Search API spec:\nhttps://docs.perplexity.ai/api-reference/search-post\n\nThe search_tool_name can be passed either:\n1. In the URL path: /v1/search/{search_tool_name}\n2. In the request body: {"search_tool_name": "..."}\n\nExample with search_tool_name in URL (recommended - keeps body Perplexity-compatible):\n```bash\ncurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nExample with search_tool_name in body:\n```bash\ncurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "search_tool_name": "litellm-search",\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nRequest Body Parameters (when search_tool_name not in URL):\n- search_tool_name (str, required if not in URL): Name of the search tool configured in router\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nWhen using URL path parameter, only Perplexity-compatible parameters are needed in body:\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nResponse follows Perplexity Search API format:\n```json\n{\n    "object": "search",\n    "results": [\n        {\n            "title": "Result title",\n            "url": "https://example.com",\n            "snippet": "Result snippet...",\n            "date": "2024-01-01",\n            "last_updated": "2024-01-01"\n        }\n    ]\n}\n```',
			inputSchema: {
				searchToolName: searchSearchSearchToolNamePostPathParamsSchema.shape["search_tool_name"],
			},
		},
		async ({ searchToolName }) => {
			try {
				return await searchSearchSearchToolNamePost({ pathParams: { searchToolName }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"searchV1SearchSearchToolNamePost",
		{
			description:
				'Search endpoint for performing web searches.\n\nFollows the Perplexity Search API spec:\nhttps://docs.perplexity.ai/api-reference/search-post\n\nThe search_tool_name can be passed either:\n1. In the URL path: /v1/search/{search_tool_name}\n2. In the request body: {"search_tool_name": "..."}\n\nExample with search_tool_name in URL (recommended - keeps body Perplexity-compatible):\n```bash\ncurl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nExample with search_tool_name in body:\n```bash\ncurl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d \'{\n        "search_tool_name": "litellm-search",\n        "query": "latest AI developments 2024",\n        "max_results": 5,\n        "search_domain_filter": ["arxiv.org", "nature.com"],\n        "country": "US"\n    }\'\n```\n\nRequest Body Parameters (when search_tool_name not in URL):\n- search_tool_name (str, required if not in URL): Name of the search tool configured in router\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nWhen using URL path parameter, only Perplexity-compatible parameters are needed in body:\n- query (str or list[str], required): Search query\n- max_results (int, optional): Maximum number of results (1-20), default 10\n- search_domain_filter (list[str], optional): List of domains to filter (max 20)\n- max_tokens_per_page (int, optional): Max tokens per page, default 1024\n- country (str, optional): Country code filter (e.g., \'US\', \'GB\', \'DE\')\n\nResponse follows Perplexity Search API format:\n```json\n{\n    "object": "search",\n    "results": [\n        {\n            "title": "Result title",\n            "url": "https://example.com",\n            "snippet": "Result snippet...",\n            "date": "2024-01-01",\n            "last_updated": "2024-01-01"\n        }\n    ]\n}\n```',
			inputSchema: {
				searchToolName: searchV1SearchSearchToolNamePostPathParamsSchema.shape["search_tool_name"],
			},
		},
		async ({ searchToolName }) => {
			try {
				return await searchV1SearchSearchToolNamePost({ pathParams: { searchToolName }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"imageGenerationOpenaiDeploymentsModelImagesGenerationsPost",
		{
			description: "Make a POST request to /openai/deployments/{model}/images/generations",
			inputSchema: {
				model:
					imageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParamsSchema.shape["model"],
			},
		},
		async ({ model }) => {
			try {
				return await imageGenerationOpenaiDeploymentsModelImagesGenerationsPost({
					pathParams: { model },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"imageGenerationImagesGenerationsPost",
		{
			description: "Make a POST request to /images/generations",
			inputSchema: { queryParams: imageGenerationImagesGenerationsPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await imageGenerationImagesGenerationsPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"imageGenerationV1ImagesGenerationsPost",
		{
			description: "Make a POST request to /v1/images/generations",
			inputSchema: { queryParams: imageGenerationV1ImagesGenerationsPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await imageGenerationV1ImagesGenerationsPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"imageEditApiOpenaiDeploymentsModelImagesEditsPost",
		{
			description:
				'Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create\n\n```bash\ncurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r \'.data[0].b64_json\' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F \'prompt=Create a studio ghibli image of this\'\n```',
			inputSchema: {
				model: imageEditApiOpenaiDeploymentsModelImagesEditsPostPathParamsSchema.shape["model"],
			},
		},
		async ({ model }) => {
			try {
				return await imageEditApiOpenaiDeploymentsModelImagesEditsPost({
					pathParams: { model },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"imageEditApiImagesEditsPost",
		{
			description:
				'Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create\n\n```bash\ncurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r \'.data[0].b64_json\' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F \'prompt=Create a studio ghibli image of this\'\n```',
			inputSchema: { queryParams: imageEditApiImagesEditsPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await imageEditApiImagesEditsPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"imageEditApiV1ImagesEditsPost",
		{
			description:
				'Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create\n\n```bash\ncurl -s -D >(grep -i x-request-id >&2)     -o >(jq -r \'.data[0].b64_json\' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F \'prompt=Create a studio ghibli image of this\'\n```',
			inputSchema: { queryParams: imageEditApiV1ImagesEditsPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await imageEditApiV1ImagesEditsPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createFineTuningJobFineTuningJobsPost",
		{
			description:
				'Creates a fine-tuning job which begins the process of creating a new model from a given dataset.\nThis is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create\n\nExample Curl:\n```\ncurl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d \'{\n    "model": "gpt-3.5-turbo",\n    "training_file": "file-abc123",\n    "hyperparameters": {\n      "n_epochs": 4\n    }\n  }\'\n```',
			inputSchema: { body: createFineTuningJobFineTuningJobsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await createFineTuningJobFineTuningJobsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listFineTuningJobsFineTuningJobsGet",
		{
			description:
				"Lists fine-tuning jobs for the organization.\nThis is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs\n\nSupported Query Params:\n- `custom_llm_provider`: Name of the LiteLLM provider\n- `after`: Identifier for the last job from the previous pagination request.\n- `limit`: Number of fine-tuning jobs to retrieve (default is 20).",
			inputSchema: { queryParams: listFineTuningJobsFineTuningJobsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listFineTuningJobsFineTuningJobsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createFineTuningJobV1FineTuningJobsPost",
		{
			description:
				'Creates a fine-tuning job which begins the process of creating a new model from a given dataset.\nThis is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create\n\nExample Curl:\n```\ncurl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d \'{\n    "model": "gpt-3.5-turbo",\n    "training_file": "file-abc123",\n    "hyperparameters": {\n      "n_epochs": 4\n    }\n  }\'\n```',
			inputSchema: { body: createFineTuningJobV1FineTuningJobsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await createFineTuningJobV1FineTuningJobsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listFineTuningJobsV1FineTuningJobsGet",
		{
			description:
				"Lists fine-tuning jobs for the organization.\nThis is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs\n\nSupported Query Params:\n- `custom_llm_provider`: Name of the LiteLLM provider\n- `after`: Identifier for the last job from the previous pagination request.\n- `limit`: Number of fine-tuning jobs to retrieve (default is 20).",
			inputSchema: { queryParams: listFineTuningJobsV1FineTuningJobsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listFineTuningJobsV1FineTuningJobsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet",
		{
			description:
				"Retrieves a fine-tuning job.\nThis is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}\n\nSupported Query Params:\n- `custom_llm_provider`: Name of the LiteLLM provider\n- `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.",
			inputSchema: {
				fineTuningJobId:
					retrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParamsSchema.shape[
						"fine_tuning_job_id"
					],
				queryParams: retrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParamsSchema,
			},
		},
		async ({ fineTuningJobId, queryParams }) => {
			try {
				return await retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet({
					pathParams: { fineTuningJobId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet",
		{
			description:
				"Retrieves a fine-tuning job.\nThis is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}\n\nSupported Query Params:\n- `custom_llm_provider`: Name of the LiteLLM provider\n- `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.",
			inputSchema: {
				fineTuningJobId:
					retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParamsSchema.shape[
						"fine_tuning_job_id"
					],
				queryParams: retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParamsSchema,
			},
		},
		async ({ fineTuningJobId, queryParams }) => {
			try {
				return await retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet({
					pathParams: { fineTuningJobId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost",
		{
			description:
				"Cancel a fine-tuning job.\n\nThis is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel\n\nSupported Query Params:\n- `custom_llm_provider`: Name of the LiteLLM provider\n- `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.",
			inputSchema: {
				fineTuningJobId:
					cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParamsSchema.shape[
						"fine_tuning_job_id"
					],
			},
		},
		async ({ fineTuningJobId }) => {
			try {
				return await cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost({
					pathParams: { fineTuningJobId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost",
		{
			description:
				"Cancel a fine-tuning job.\n\nThis is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel\n\nSupported Query Params:\n- `custom_llm_provider`: Name of the LiteLLM provider\n- `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.",
			inputSchema: {
				fineTuningJobId:
					cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParamsSchema.shape[
						"fine_tuning_job_id"
					],
			},
		},
		async ({ fineTuningJobId }) => {
			try {
				return await cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost({
					pathParams: { fineTuningJobId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"vectorStoreSearchVectorStoresVectorStoreIdSearchPost",
		{
			description:
				"Search a vector store.\n\nAPI Reference:\nhttps://platform.openai.com/docs/api-reference/vector-stores/search",
			inputSchema: {
				vectorStoreId:
					vectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParamsSchema.shape[
						"vector_store_id"
					],
			},
		},
		async ({ vectorStoreId }) => {
			try {
				return await vectorStoreSearchVectorStoresVectorStoreIdSearchPost({
					pathParams: { vectorStoreId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost",
		{
			description:
				"Search a vector store.\n\nAPI Reference:\nhttps://platform.openai.com/docs/api-reference/vector-stores/search",
			inputSchema: {
				vectorStoreId:
					vectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParamsSchema.shape[
						"vector_store_id"
					],
			},
		},
		async ({ vectorStoreId }) => {
			try {
				return await vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost({
					pathParams: { vectorStoreId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"vectorStoreCreateVectorStoresPost",
		{
			description:
				"Create a vector store.\n\nAPI Reference:\nhttps://platform.openai.com/docs/api-reference/vector-stores/create",
		},
		async () => {
			try {
				return await vectorStoreCreateVectorStoresPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"vectorStoreCreateV1VectorStoresPost",
		{
			description:
				"Create a vector store.\n\nAPI Reference:\nhttps://platform.openai.com/docs/api-reference/vector-stores/create",
		},
		async () => {
			try {
				return await vectorStoreCreateV1VectorStoresPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"indexCreateV1IndexesPost",
		{
			description:
				'Create an index. Just writes the index to the database.\n\n```bash\ncurl -L -X POST \'http://0.0.0.0:4000/indexes/create\'         -H \'Content-Type: application/json\'         -H \'Authorization: Bearer sk-1234\'         -H \'LiteLLM-Beta: indexes_beta=v1\'         -d \'{ \n        "index_name": "dall-e-3",\n        "vector_store_index": "real-index-name",\n        "vector_store_name": "azure-ai-search"\n    }\'\n```',
			inputSchema: { body: indexCreateV1IndexesPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await indexCreateV1IndexesPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getCredentialsCredentialsGet",
		{ description: "[BETA] endpoint. This might change unexpectedly." },
		async () => {
			try {
				return await getCredentialsCredentialsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createCredentialCredentialsPost",
		{
			description:
				"[BETA] endpoint. This might change unexpectedly.\nStores credential in DB.\nReloads credentials in memory.",
			inputSchema: { body: createCredentialCredentialsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await createCredentialCredentialsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getCredentialCredentialsByModelModelIdGet",
		{
			description: "[BETA] endpoint. This might change unexpectedly.",
			inputSchema: {
				credentialName:
					getCredentialCredentialsByModelModelIdGetPathParamsSchema.shape["credential_name"],
				modelId: getCredentialCredentialsByModelModelIdGetPathParamsSchema.shape["model_id"],
			},
		},
		async ({ credentialName, modelId }) => {
			try {
				return await getCredentialCredentialsByModelModelIdGet({
					pathParams: { credentialName, modelId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getCredentialCredentialsByNameCredentialNameGet",
		{
			description: "[BETA] endpoint. This might change unexpectedly.",
			inputSchema: {
				credentialName:
					getCredentialCredentialsByNameCredentialNameGetPathParamsSchema.shape["credential_name"],
				queryParams: getCredentialCredentialsByNameCredentialNameGetQueryParamsSchema,
			},
		},
		async ({ credentialName, queryParams }) => {
			try {
				return await getCredentialCredentialsByNameCredentialNameGet({
					pathParams: { credentialName },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteCredentialCredentialsCredentialNameDelete",
		{
			description: "[BETA] endpoint. This might change unexpectedly.",
			inputSchema: {
				credentialName:
					deleteCredentialCredentialsCredentialNameDeletePathParamsSchema.shape["credential_name"],
			},
		},
		async ({ credentialName }) => {
			try {
				return await deleteCredentialCredentialsCredentialNameDelete({
					pathParams: { credentialName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateCredentialCredentialsCredentialNamePatch",
		{
			description: "[BETA] endpoint. This might change unexpectedly.",
			inputSchema: {
				credentialName:
					updateCredentialCredentialsCredentialNamePatchPathParamsSchema.shape["credential_name"],
				body: updateCredentialCredentialsCredentialNamePatchMutationRequestSchema,
			},
		},
		async ({ credentialName, body }) => {
			try {
				return await updateCredentialCredentialsCredentialNamePatch({
					pathParams: { credentialName },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getMcpToolsV1McpToolsGet",
		{
			description:
				"Get all MCP tools available for the current key, including those from access groups",
		},
		async () => {
			try {
				return await getMcpToolsV1McpToolsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getMcpAccessGroupsV1McpAccessGroupsGet",
		{ description: "Get all available MCP access groups from the database AND config" },
		async () => {
			try {
				return await getMcpAccessGroupsV1McpAccessGroupsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthCheckMcpServerV1McpServerServerIdHealthGet",
		{
			description: "Perform health check on a specific MCP server",
			inputSchema: {
				serverId:
					healthCheckMcpServerV1McpServerServerIdHealthGetPathParamsSchema.shape["server_id"],
			},
		},
		async ({ serverId }) => {
			try {
				return await healthCheckMcpServerV1McpServerServerIdHealthGet({
					pathParams: { serverId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthCheckAllMcpServersV1McpServerHealthGet",
		{ description: "Perform health check on all accessible MCP servers" },
		async () => {
			try {
				return await healthCheckAllMcpServersV1McpServerHealthGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"fetchAllMcpServersV1McpServerGet",
		{ description: "Returns the mcp server list with associated teams" },
		async () => {
			try {
				return await fetchAllMcpServersV1McpServerGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"addMcpServerV1McpServerPost",
		{
			description: "Allows creation of mcp servers",
			inputSchema: {
				body: addMcpServerV1McpServerPostMutationRequestSchema,
				headers: addMcpServerV1McpServerPostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await addMcpServerV1McpServerPost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"editMcpServerV1McpServerPut",
		{
			description: "Allows deleting mcp serves in the db",
			inputSchema: {
				body: editMcpServerV1McpServerPutMutationRequestSchema,
				headers: editMcpServerV1McpServerPutHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await editMcpServerV1McpServerPut({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"fetchMcpServerV1McpServerServerIdGet",
		{
			description: "Returns the mcp server info",
			inputSchema: {
				serverId: fetchMcpServerV1McpServerServerIdGetPathParamsSchema.shape["server_id"],
			},
		},
		async ({ serverId }) => {
			try {
				return await fetchMcpServerV1McpServerServerIdGet({ pathParams: { serverId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"removeMcpServerV1McpServerServerIdDelete",
		{
			description: "Allows deleting mcp serves in the db",
			inputSchema: {
				serverId: removeMcpServerV1McpServerServerIdDeletePathParamsSchema.shape["server_id"],
				headers: removeMcpServerV1McpServerServerIdDeleteHeaderParamsSchema,
			},
		},
		async ({ serverId, headers }) => {
			try {
				return await removeMcpServerV1McpServerServerIdDelete({
					pathParams: { serverId },
					headers,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"anthropicResponseV1MessagesPost",
		{
			description:
				"Use `{PROXY_BASE_URL}/anthropic/v1/messages` instead - [Docs](https://docs.litellm.ai/docs/anthropic_completion).\n\nThis was a BETA endpoint that calls 100+ LLMs in the anthropic format.",
		},
		async () => {
			try {
				return await anthropicResponseV1MessagesPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"countTokensV1MessagesCountTokensPost",
		{
			description:
				'Count tokens for Anthropic Messages API format.\n\nThis endpoint follows the Anthropic Messages API token counting specification.\nIt accepts the same parameters as the /v1/messages endpoint but returns\ntoken counts instead of generating a response.\n\nExample usage:\n```\ncurl -X POST "http://localhost:4000/v1/messages/count_tokens?beta=true"       -H "Content-Type: application/json"       -H "Authorization: Bearer your-key"       -d \'{\n    "model": "claude-3-sonnet-20240229",\n    "messages": [{"role": "user", "content": "Hello Claude!"}]\n  }\'\n```\n\nReturns: {"input_tokens": <number>}',
		},
		async () => {
			try {
				return await countTokensV1MessagesCountTokensPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"googleGenerateContentModelsModelNameGenerateContentPost",
		{
			description: "Make a POST request to /models/{model_name}:generateContent",
			inputSchema: {
				modelName:
					googleGenerateContentModelsModelNameGenerateContentPostPathParamsSchema.shape[
						"model_name"
					],
			},
		},
		async ({ modelName }) => {
			try {
				return await googleGenerateContentModelsModelNameGenerateContentPost({
					pathParams: { modelName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"googleGenerateContentV1betaModelsModelNameGenerateContentPost",
		{
			description: "Make a POST request to /v1beta/models/{model_name}:generateContent",
			inputSchema: {
				modelName:
					googleGenerateContentV1BetaModelsModelNameGenerateContentPostPathParamsSchema.shape[
						"model_name"
					],
			},
		},
		async ({ modelName }) => {
			try {
				return await googleGenerateContentV1BetaModelsModelNameGenerateContentPost({
					pathParams: { modelName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"googleStreamGenerateContentModelsModelNameStreamGenerateContentPost",
		{
			description: "Make a POST request to /models/{model_name}:streamGenerateContent",
			inputSchema: {
				modelName:
					googleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParamsSchema.shape[
						"model_name"
					],
			},
		},
		async ({ modelName }) => {
			try {
				return await googleStreamGenerateContentModelsModelNameStreamGenerateContentPost({
					pathParams: { modelName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"googleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPost",
		{
			description: "Make a POST request to /v1beta/models/{model_name}:streamGenerateContent",
			inputSchema: {
				modelName:
					googleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostPathParamsSchema
						.shape["model_name"],
			},
		},
		async ({ modelName }) => {
			try {
				return await googleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost({
					pathParams: { modelName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"googleCountTokensModelsModelNameCountTokensPost",
		{
			description:
				'```json\nreturn {\n    "totalTokens": 31,\n    "totalBillableCharacters": 96,\n    "promptTokensDetails": [\n        {\n        "modality": "TEXT",\n        "tokenCount": 31\n        }\n    ]\n}\n```',
			inputSchema: {
				modelName:
					googleCountTokensModelsModelNameCountTokensPostPathParamsSchema.shape["model_name"],
			},
		},
		async ({ modelName }) => {
			try {
				return await googleCountTokensModelsModelNameCountTokensPost({
					pathParams: { modelName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"googleCountTokensV1betaModelsModelNameCountTokensPost",
		{
			description:
				'```json\nreturn {\n    "totalTokens": 31,\n    "totalBillableCharacters": 96,\n    "promptTokensDetails": [\n        {\n        "modality": "TEXT",\n        "tokenCount": 31\n        }\n    ]\n}\n```',
			inputSchema: {
				modelName:
					googleCountTokensV1BetaModelsModelNameCountTokensPostPathParamsSchema.shape["model_name"],
			},
		},
		async ({ modelName }) => {
			try {
				return await googleCountTokensV1BetaModelsModelNameCountTokensPost({
					pathParams: { modelName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet",
		{
			description:
				"GET configured pass through endpoint.\n\nIf no endpoint_id given, return all configured endpoints.",
			inputSchema: {
				teamId:
					getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParamsSchema.shape[
						"team_id"
					],
				queryParams: getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParamsSchema,
			},
		},
		async ({ teamId, queryParams }) => {
			try {
				return await getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet({
					pathParams: { teamId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getPassThroughEndpointsConfigPassThroughEndpointGet",
		{
			description:
				"GET configured pass through endpoint.\n\nIf no endpoint_id given, return all configured endpoints.",
			inputSchema: {
				queryParams: getPassThroughEndpointsConfigPassThroughEndpointGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await getPassThroughEndpointsConfigPassThroughEndpointGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createPassThroughEndpointsConfigPassThroughEndpointPost",
		{
			description: "Create new pass-through endpoint",
			inputSchema: {
				body: createPassThroughEndpointsConfigPassThroughEndpointPostMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await createPassThroughEndpointsConfigPassThroughEndpointPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deletePassThroughEndpointsConfigPassThroughEndpointDelete",
		{
			description: "Delete a pass-through endpoint by ID.\n\nReturns - the deleted endpoint",
			inputSchema: {
				queryParams: deletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await deletePassThroughEndpointsConfigPassThroughEndpointDelete({
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost",
		{
			description: "Update a pass-through endpoint by ID.",
			inputSchema: {
				endpointId:
					updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParamsSchema.shape[
						"endpoint_id"
					],
				body: updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostMutationRequestSchema,
			},
		},
		async ({ endpointId, body }) => {
			try {
				return await updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost({
					pathParams: { endpointId },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"testEndpointTestGet",
		{
			description:
				"[DEPRECATED] use `/health/liveliness` instead.\n\nA test endpoint that pings the proxy server to check if it's healthy.\n\nParameters:\n    request (Request): The incoming request.\n\nReturns:\n    dict: A dictionary containing the route of the request URL.",
		},
		async () => {
			try {
				return await testEndpointTestGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthServicesEndpointHealthServicesGet",
		{
			description:
				"Use this admin-only endpoint to check if the service is healthy.\n\nExample:\n```\ncurl -L -X GET 'http://0.0.0.0:4000/health/services?service=datadog'     -H 'Authorization: Bearer sk-1234'\n```",
			inputSchema: { queryParams: healthServicesEndpointHealthServicesGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await healthServicesEndpointHealthServicesGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthEndpointHealthGet",
		{
			description:
				" USE `/health/liveliness` to health check the proxy \n\nSee more  https://docs.litellm.ai/docs/proxy/health\n\n\nCheck the health of all the endpoints in config.yaml\n\nTo run health checks in the background, add this to config.yaml:\n```\ngeneral_settings:\n    # ... other settings\n    background_health_checks: True\n```\nelse, the health checks will be run on models when /health is called.",
			inputSchema: { queryParams: healthEndpointHealthGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await healthEndpointHealthGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthCheckHistoryEndpointHealthHistoryGet",
		{
			description:
				"Get health check history for models\n\nReturns historical health check data with optional filtering.",
			inputSchema: { queryParams: healthCheckHistoryEndpointHealthHistoryGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await healthCheckHistoryEndpointHealthHistoryGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"latestHealthChecksEndpointHealthLatestGet",
		{
			description:
				"Get the latest health check status for all models\n\nReturns the most recent health check result for each model.",
		},
		async () => {
			try {
				return await latestHealthChecksEndpointHealthLatestGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"sharedHealthCheckStatusEndpointHealthSharedStatusGet",
		{
			description:
				"Get the status of shared health check coordination across pods.\n\nReturns information about Redis connectivity, lock status, and cache status.",
		},
		async () => {
			try {
				return await sharedHealthCheckStatusEndpointHealthSharedStatusGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"activeCallbacksActiveCallbacksGet",
		{
			description:
				'Returns a list of litellm level settings\n\nThis is useful for debugging and ensuring the proxy server is configured correctly.\n\nResponse schema:\n```\n{\n    "alerting": _alerting,\n    "litellm.callbacks": litellm_callbacks,\n    "litellm.input_callback": litellm_input_callbacks,\n    "litellm.failure_callback": litellm_failure_callbacks,\n    "litellm.success_callback": litellm_success_callbacks,\n    "litellm._async_success_callback": litellm_async_success_callbacks,\n    "litellm._async_failure_callback": litellm_async_failure_callbacks,\n    "litellm._async_input_callback": litellm_async_input_callbacks,\n    "all_litellm_callbacks": all_litellm_callbacks,\n    "num_callbacks": len(all_litellm_callbacks),\n    "num_alerting": _num_alerting,\n    "litellm.request_timeout": litellm.request_timeout,\n}\n```',
		},
		async () => {
			try {
				return await activeCallbacksActiveCallbacksGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"activeCallbacksSettingsGet",
		{
			description:
				'Returns a list of litellm level settings\n\nThis is useful for debugging and ensuring the proxy server is configured correctly.\n\nResponse schema:\n```\n{\n    "alerting": _alerting,\n    "litellm.callbacks": litellm_callbacks,\n    "litellm.input_callback": litellm_input_callbacks,\n    "litellm.failure_callback": litellm_failure_callbacks,\n    "litellm.success_callback": litellm_success_callbacks,\n    "litellm._async_success_callback": litellm_async_success_callbacks,\n    "litellm._async_failure_callback": litellm_async_failure_callbacks,\n    "litellm._async_input_callback": litellm_async_input_callbacks,\n    "all_litellm_callbacks": all_litellm_callbacks,\n    "num_callbacks": len(all_litellm_callbacks),\n    "num_alerting": _num_alerting,\n    "litellm.request_timeout": litellm.request_timeout,\n}\n```',
		},
		async () => {
			try {
				return await activeCallbacksSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthReadinessHealthReadinessGet",
		{ description: "Unprotected endpoint for checking if worker can receive requests" },
		async () => {
			try {
				return await healthReadinessHealthReadinessGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"health_readiness_options_health_readiness_options",
		{ description: "Options endpoint for health/readiness check." },
		async () => {
			try {
				return await healthReadinessOptionsHealthReadinessOptions({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthLivelinessHealthLivenessGet",
		{ description: "Unprotected endpoint for checking if worker is alive" },
		async () => {
			try {
				return await healthLivelinessHealthLivenessGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"health_liveliness_options_health_liveness_options",
		{ description: "Options endpoint for health/liveliness check." },
		async () => {
			try {
				return await healthLivelinessOptionsHealthLivenessOptions({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"healthLivelinessHealthLivelinessGet",
		{ description: "Unprotected endpoint for checking if worker is alive" },
		async () => {
			try {
				return await healthLivelinessHealthLivelinessGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"health_liveliness_options_health_liveliness_options",
		{ description: "Options endpoint for health/liveliness check." },
		async () => {
			try {
				return await healthLivelinessOptionsHealthLivelinessOptions({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"testModelConnectionHealthTestConnectionPost",
		{
			description:
				'Test a direct connection to a specific model.\n\nThis endpoint allows you to verify if your proxy can successfully connect to a specific model.\nIt\'s useful for troubleshooting model connectivity issues without going through the full proxy routing.\n\nExample:\n```bash\ncurl -X POST \'http://localhost:4000/health/test_connection\' \\\n  -H \'Authorization: Bearer sk-1234\' \\\n  -H \'Content-Type: application/json\' \\\n  -d \'{\n    "litellm_params": {\n        "model": "gpt-4",\n        "custom_llm_provider": "azure_ai",\n        "litellm_credential_name": null,\n        "api_key": "6xxxxxxx",\n        "api_base": "https://litellm8397336933.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21",\n    },\n    "mode": "chat"\n  }\'\n```\n\nReturns:\n    dict: A dictionary containing the health check result with either success information or error details.',
			inputSchema: { body: testModelConnectionHealthTestConnectionPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await testModelConnectionHealthTestConnectionPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"generateKeyFnKeyGeneratePost",
		{
			description:
				'Generate an API key based on the provided data.\n\nDocs: https://docs.litellm.ai/docs/proxy/virtual_keys\n\nParameters:\n- duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").\n- key_alias: Optional[str] - User defined key alias\n- key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.\n- team_id: Optional[str] - The team id of the key\n- user_id: Optional[str] - The user id of the key\n- organization_id: Optional[str] - The organization id of the key. If not set, and team_id is set, the organization id will be the same as the team id. If conflict, an error will be raised.\n- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.\n- models: Optional[list] - Model_name\'s a user is allowed to call. (if empty, key is allowed to call all models)\n- aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models\n- config: Optional[dict] - any key-specific configs, overrides config in config.yaml\n- spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend\n- send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key\n- max_budget: Optional[float] - Specify max budget for a given key.\n- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").\n- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user\'s parallel requests > x.\n- metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }\n- guardrails: Optional[List[str]] - List of active guardrails for the key\n- permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}\n- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.\n- model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.\n- model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.\n- tpm_limit_type: Optional[str] - Type of tpm limit. Options: "best_effort_throughput" (no error if we\'re overallocating tpm), "guaranteed_throughput" (raise an error if we\'re overallocating tpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".\n- rpm_limit_type: Optional[str] - Type of rpm limit. Options: "best_effort_throughput" (no error if we\'re overallocating rpm), "guaranteed_throughput" (raise an error if we\'re overallocating rpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".\n- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request\n- blocked: Optional[bool] - Whether the key is blocked.\n- rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)\n- tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)\n- soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.\n- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).\n- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.\n- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)\n- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.\n- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]\n- allowed_passthrough_routes: Optional[list] - List of allowed pass through endpoints for the key. Store the actual endpoint or store a wildcard pattern for a set of endpoints. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through endpoints the key can access, without specifying the routes. If allowed_routes is specified, allowed_pass_through_endpoints is ignored.\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.\n- key_type: Optional[str] - Type of key that determines default allowed routes. Options: "llm_api" (can call LLM API routes), "management" (can call management routes), "read_only" (can only call info/read routes), "default" (uses default allowed routes). Defaults to "default".\n- prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.\n- auto_rotate: Optional[bool] - Whether this key should be automatically rotated (regenerated)\n- rotation_interval: Optional[str] - How often to auto-rotate this key (e.g., \'30s\', \'30m\', \'30h\', \'30d\'). Required if auto_rotate=True.\n- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.\n\n\nExamples:\n\n1. Allow users to turn on/off pii masking\n\n```bash\ncurl --location \'http://0.0.0.0:4000/key/generate\'         --header \'Authorization: Bearer sk-1234\'         --header \'Content-Type: application/json\'         --data \'{\n        "permissions": {"allow_pii_controls": true}\n}\'\n```\n\nReturns:\n- key: (str) The generated api key\n- expires: (datetime) Datetime object for when key expires.\n- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.',
			inputSchema: {
				body: generateKeyFnKeyGeneratePostMutationRequestSchema,
				headers: generateKeyFnKeyGeneratePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await generateKeyFnKeyGeneratePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"generateServiceAccountKeyFnKeyServiceAccountGeneratePost",
		{
			description:
				'Generate a Service Account API key based on the provided data. This key does not belong to any user. It belongs to the team.\n\nWhy use a service account key?\n- Prevent key from being deleted when user is deleted.\n- Apply team limits, not team member limits to key.\n\nDocs: https://docs.litellm.ai/docs/proxy/virtual_keys\n\nParameters:\n- duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").\n- key_alias: Optional[str] - User defined key alias\n- key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.\n- team_id: Optional[str] - The team id of the key\n- user_id: Optional[str] - [NON-FUNCTIONAL] THIS WILL BE IGNORED. The user id of the key\n- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.\n- models: Optional[list] - Model_name\'s a user is allowed to call. (if empty, key is allowed to call all models)\n- aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models\n- config: Optional[dict] - any key-specific configs, overrides config in config.yaml\n- spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend\n- send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key\n- max_budget: Optional[float] - Specify max budget for a given key.\n- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").\n- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user\'s parallel requests > x.\n- metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }\n- guardrails: Optional[List[str]] - List of active guardrails for the key\n- permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}\n- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.\n- model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.\n- model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.\n- tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"\n- rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"\n- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request\n- blocked: Optional[bool] - Whether the key is blocked.\n- rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)\n- tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)\n- soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.\n- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).\n- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)\n- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.\nExamples:\n- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.\n\n\n1. Allow users to turn on/off pii masking\n\n```bash\ncurl --location \'http://0.0.0.0:4000/key/generate\'         --header \'Authorization: Bearer sk-1234\'         --header \'Content-Type: application/json\'         --data \'{\n        "permissions": {"allow_pii_controls": true}\n}\'\n```\n\nReturns:\n- key: (str) The generated api key\n- expires: (datetime) Datetime object for when key expires.\n- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.',
			inputSchema: {
				body: generateServiceAccountKeyFnKeyServiceAccountGeneratePostMutationRequestSchema,
				headers: generateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await generateServiceAccountKeyFnKeyServiceAccountGeneratePost({
					body,
					headers,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateKeyFnKeyUpdatePost",
		{
			description:
				'Update an existing API key\'s parameters.\n\nParameters:\n- key: str - The key to update\n- key_alias: Optional[str] - User-friendly key alias\n- user_id: Optional[str] - User ID associated with key\n- team_id: Optional[str] - Team ID associated with key\n- budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.\n- models: Optional[list] - Model_name\'s a user is allowed to call\n- tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)\n- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.\n- enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)\n- spend: Optional[float] - Amount spent by key\n- max_budget: Optional[float] - Max budget for key\n- model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}\n- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)\n- soft_budget: Optional[float] - [TODO] Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.\n- max_parallel_requests: Optional[int] - Rate limit for parallel requests\n- metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}\n- tpm_limit: Optional[int] - Tokens per minute limit\n- rpm_limit: Optional[int] - Requests per minute limit\n- model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}\n- model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}\n- tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"\n- rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"\n- allowed_cache_controls: Optional[list] - List of allowed cache control values\n- duration: Optional[str] - Key validity duration ("30d", "1h", etc.)\n- permissions: Optional[dict] - Key-specific permissions\n- send_invite_email: Optional[bool] - Send invite email to user_id\n- guardrails: Optional[List[str]] - List of active guardrails for the key\n- prompts: Optional[List[str]] - List of prompts that the key is allowed to use.\n- blocked: Optional[bool] - Whether the key is blocked\n- aliases: Optional[dict] - Model aliases for the key - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)\n- config: Optional[dict] - [DEPRECATED PARAM] Key-specific config.\n- temp_budget_increase: Optional[float] - Temporary budget increase for the key (Enterprise only).\n- temp_budget_expiry: Optional[str] - Expiry time for the temporary budget increase (Enterprise only).\n- allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]\n- allowed_passthrough_routes: Optional[list] - List of allowed pass through routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through routes the key can access, without specifying the routes. If allowed_routes is specified, allowed_passthrough_routes is ignored.\n- prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.\n- auto_rotate: Optional[bool] - Whether this key should be automatically rotated\n- rotation_interval: Optional[str] - How often to rotate this key (e.g., \'30d\', \'90d\'). Required if auto_rotate=True\n- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.\n\nExample:\n```bash\ncurl --location \'http://0.0.0.0:4000/key/update\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "key": "sk-1234",\n    "key_alias": "my-key",\n    "user_id": "user-1234",\n    "team_id": "team-1234",\n    "max_budget": 100,\n    "metadata": {"any_key": "any-val"},\n}\'\n```',
			inputSchema: {
				body: updateKeyFnKeyUpdatePostMutationRequestSchema,
				headers: updateKeyFnKeyUpdatePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await updateKeyFnKeyUpdatePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteKeyFnKeyDeletePost",
		{
			description:
				'Delete a key from the key management system.\n\nParameters::\n- keys (List[str]): A list of keys or hashed keys to delete. Example {"keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}\n- key_aliases (List[str]): A list of key aliases to delete. Can be passed instead of `keys`.Example {"key_aliases": ["alias1", "alias2"]}\n\nReturns:\n- deleted_keys (List[str]): A list of deleted keys. Example {"deleted_keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}\n\nExample:\n```bash\ncurl --location \'http://0.0.0.0:4000/key/delete\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "keys": ["sk-QWrxEynunsNpV1zT48HIrw"]\n}\'\n```\n\nRaises:\n    HTTPException: If an error occurs during key deletion.',
			inputSchema: {
				body: deleteKeyFnKeyDeletePostMutationRequestSchema,
				headers: deleteKeyFnKeyDeletePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await deleteKeyFnKeyDeletePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"infoKeyFnKeyInfoGet",
		{
			description:
				'Retrieve information about a key.\nParameters:\n    key: Optional[str] = Query parameter representing the key in the request\n    user_api_key_dict: UserAPIKeyAuth = Dependency representing the user\'s API key\nReturns:\n    Dict containing the key and its associated information\n\nExample Curl:\n```\ncurl -X GET "http://0.0.0.0:4000/key/info?key=sk-02Wr4IAlN3NvPXvL5JVvDA" -H "Authorization: Bearer sk-1234"\n```\n\nExample Curl - if no key is passed, it will use the Key Passed in Authorization Header\n```\ncurl -X GET "http://0.0.0.0:4000/key/info" -H "Authorization: Bearer sk-02Wr4IAlN3NvPXvL5JVvDA"\n```',
			inputSchema: { queryParams: infoKeyFnKeyInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await infoKeyFnKeyInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"regenerateKeyFnKeyRegeneratePost",
		{
			description:
				'Regenerate an existing API key while optionally updating its parameters.\n\nParameters:\n- key: str (path parameter) - The key to regenerate\n- data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update\n    - key: Optional[str] - The key to regenerate.\n    - new_master_key: Optional[str] - The new master key to use, if key is the master key.\n    - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.\n    - key_alias: Optional[str] - User-friendly key alias\n    - user_id: Optional[str] - User ID associated with key\n    - team_id: Optional[str] - Team ID associated with key\n    - models: Optional[list] - Model_name\'s a user is allowed to call\n    - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)\n    - spend: Optional[float] - Amount spent by key\n    - max_budget: Optional[float] - Max budget for key\n    - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}\n    - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)\n    - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.\n    - max_parallel_requests: Optional[int] - Rate limit for parallel requests\n    - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}\n    - tpm_limit: Optional[int] - Tokens per minute limit\n    - rpm_limit: Optional[int] - Requests per minute limit\n    - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}\n    - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}\n    - allowed_cache_controls: Optional[list] - List of allowed cache control values\n    - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)\n    - permissions: Optional[dict] - Key-specific permissions\n    - guardrails: Optional[List[str]] - List of active guardrails for the key\n    - blocked: Optional[bool] - Whether the key is blocked\n\n\nReturns:\n- GenerateKeyResponse containing the new key and its updated parameters\n\nExample:\n```bash\ncurl --location --request POST \'http://localhost:4000/key/sk-1234/regenerate\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data-raw \'{\n    "max_budget": 100,\n    "metadata": {"team": "core-infra"},\n    "models": ["gpt-4", "gpt-3.5-turbo"]\n}\'\n```\n\nNote: This is an Enterprise feature. It requires a premium license to use.',
			inputSchema: {
				body: regenerateKeyFnKeyRegeneratePostMutationRequestSchema,
				queryParams: regenerateKeyFnKeyRegeneratePostQueryParamsSchema,
				headers: regenerateKeyFnKeyRegeneratePostHeaderParamsSchema,
			},
		},
		async ({ body, queryParams, headers }) => {
			try {
				return await regenerateKeyFnKeyRegeneratePost({ body, queryParams, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"regenerateKeyFnKeyKeyRegeneratePost",
		{
			description:
				'Regenerate an existing API key while optionally updating its parameters.\n\nParameters:\n- key: str (path parameter) - The key to regenerate\n- data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update\n    - key: Optional[str] - The key to regenerate.\n    - new_master_key: Optional[str] - The new master key to use, if key is the master key.\n    - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.\n    - key_alias: Optional[str] - User-friendly key alias\n    - user_id: Optional[str] - User ID associated with key\n    - team_id: Optional[str] - Team ID associated with key\n    - models: Optional[list] - Model_name\'s a user is allowed to call\n    - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)\n    - spend: Optional[float] - Amount spent by key\n    - max_budget: Optional[float] - Max budget for key\n    - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}\n    - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)\n    - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.\n    - max_parallel_requests: Optional[int] - Rate limit for parallel requests\n    - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}\n    - tpm_limit: Optional[int] - Tokens per minute limit\n    - rpm_limit: Optional[int] - Requests per minute limit\n    - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}\n    - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}\n    - allowed_cache_controls: Optional[list] - List of allowed cache control values\n    - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)\n    - permissions: Optional[dict] - Key-specific permissions\n    - guardrails: Optional[List[str]] - List of active guardrails for the key\n    - blocked: Optional[bool] - Whether the key is blocked\n\n\nReturns:\n- GenerateKeyResponse containing the new key and its updated parameters\n\nExample:\n```bash\ncurl --location --request POST \'http://localhost:4000/key/sk-1234/regenerate\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data-raw \'{\n    "max_budget": 100,\n    "metadata": {"team": "core-infra"},\n    "models": ["gpt-4", "gpt-3.5-turbo"]\n}\'\n```\n\nNote: This is an Enterprise feature. It requires a premium license to use.',
			inputSchema: {
				key: regenerateKeyFnKeyKeyRegeneratePostPathParamsSchema.shape["key"],
				body: regenerateKeyFnKeyKeyRegeneratePostMutationRequestSchema,
				headers: regenerateKeyFnKeyKeyRegeneratePostHeaderParamsSchema,
			},
		},
		async ({ key, body, headers }) => {
			try {
				return await regenerateKeyFnKeyKeyRegeneratePost({
					pathParams: { key },
					body,
					headers,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listKeysKeyListGet",
		{
			description:
				'List all keys for a given user / team / organization.\n\nReturns:\n    {\n        "keys": List[str] or List[UserAPIKeyAuth],\n        "total_count": int,\n        "current_page": int,\n        "total_pages": int,\n    }',
			inputSchema: { queryParams: listKeysKeyListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listKeysKeyListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"keyAliasesKeyAliasesGet",
		{
			description: 'Lists all key aliases\n\nReturns:\n    {\n        "aliases": List[str]\n    }',
		},
		async () => {
			try {
				return await keyAliasesKeyAliasesGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"blockKeyKeyBlockPost",
		{
			description:
				"Block an Virtual key from making any requests.\n\nParameters:\n- key: str - The key to block. Can be either the unhashed key (sk-...) or the hashed key value\n\n Example:\n```bash\ncurl --location 'http://0.0.0.0:4000/key/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{\n    \"key\": \"sk-Fn8Ej39NxjAXrvpUGKghGw\"\n}'\n```\n\nNote: This is an admin-only endpoint. Only proxy admins can block keys.",
			inputSchema: {
				body: blockKeyKeyBlockPostMutationRequestSchema,
				headers: blockKeyKeyBlockPostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await blockKeyKeyBlockPost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"unblockKeyKeyUnblockPost",
		{
			description:
				"Unblock a Virtual key to allow it to make requests again.\n\nParameters:\n- key: str - The key to unblock. Can be either the unhashed key (sk-...) or the hashed key value\n\nExample:\n```bash\ncurl --location 'http://0.0.0.0:4000/key/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{\n    \"key\": \"sk-Fn8Ej39NxjAXrvpUGKghGw\"\n}'\n```\n\nNote: This is an admin-only endpoint. Only proxy admins can unblock keys.",
			inputSchema: {
				body: unblockKeyKeyUnblockPostMutationRequestSchema,
				headers: unblockKeyKeyUnblockPostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await unblockKeyKeyUnblockPost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"keyHealthKeyHealthPost",
		{
			description:
				'Check the health of the key\n\nChecks:\n- If key based logging is configured correctly - sends a test log\n\nUsage \n\nPass the key in the request header\n\n```bash\ncurl -X POST "http://localhost:4000/key/health"      -H "Authorization: Bearer sk-1234"      -H "Content-Type: application/json"\n```\n\nResponse when logging callbacks are setup correctly:\n\n```json\n{\n  "key": "healthy",\n  "logging_callbacks": {\n    "callbacks": [\n      "gcs_bucket"\n    ],\n    "status": "healthy",\n    "details": "No logger exceptions triggered, system is healthy. Manually check if logs were sent to [\'gcs_bucket\']"\n  }\n}\n```\n\n\nResponse when logging callbacks are not setup correctly:\n```json\n{\n  "key": "unhealthy",\n  "logging_callbacks": {\n    "callbacks": [\n      "gcs_bucket"\n    ],\n    "status": "unhealthy",\n    "details": "Logger exceptions triggered, system is unhealthy: Failed to load vertex credentials. Check to see if credentials containing partial/invalid information."\n  }\n}\n```',
		},
		async () => {
			try {
				return await keyHealthKeyHealthPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newUserUserNewPost",
		{
			description:
				'Use this to create a new INTERNAL user with a budget.\nInternal Users can access LiteLLM Admin UI to make keys, request access to models.\nThis creates a new user and generates a new api key for the new user. The new api key is returned.\n\nReturns user id, budget + new key.\n\nParameters:\n- user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.\n- user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.\n- teams: Optional[list] - specify a list of team id\'s a user belongs to.\n- user_email: Optional[str] - Specify a user email.\n- send_invite_email: Optional[bool] - Specify if an invite email should be sent.\n- user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`\n- max_budget: Optional[float] - Specify max budget for a given user.\n- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").\n- models: Optional[list] - Model_name\'s a user is allowed to call. (if empty, key is allowed to call all models). Set to [\'no-default-models\'] to block all model access. Restricting user to only team-based model access.\n- tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)\n- rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)\n- auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response\n- aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)\n- config: Optional[dict] - [DEPRECATED PARAM] User-specific config.\n- allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-\n- blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.\n- guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user\n- permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.\n- metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }\n- max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user\'s parallel requests > x.\n- soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn\'t block requests.\n- model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)\n- model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)\n- model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)\n- spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").\n- team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None. \n- duration: Optional[str] - Duration for the key auto-created on `/user/new`. Default is None.\n- key_alias: Optional[str] - Alias for the key auto-created on `/user/new`. Default is None.\n- sso_user_id: Optional[str] - The id of the user in the SSO provider.\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.\n- prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.\n- organizations: List[str] - List of organization id\'s the user is a member of\nReturns:\n- key: (str) The generated api key for the user\n- expires: (datetime) Datetime object for when key expires.\n- user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.\n- max_budget: (float|None) Max budget for given user.\n\nUsage Example \n\n```shell\n curl -X POST "http://localhost:4000/user/new"      -H "Content-Type: application/json"      -H "Authorization: Bearer sk-1234"      -d \'{\n     "username": "new_user",\n     "email": "new_user@example.com"\n }\'\n```',
			inputSchema: { body: newUserUserNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await newUserUserNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"userInfoUserInfoGet",
		{
			description:
				"[10/07/2024]\nNote: To get all users (+pagination), use `/user/list` endpoint.\n\n\nUse this to get user information. (user row + all user key info)\n\nExample request\n```\ncurl -X GET 'http://localhost:4000/user/info?user_id=krrish7%40berri.ai'     --header 'Authorization: Bearer sk-1234'\n```",
			inputSchema: { queryParams: userInfoUserInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await userInfoUserInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"userUpdateUserUpdatePost",
		{
			description:
				'Example curl \n\n```\ncurl --location \'http://0.0.0.0:4000/user/update\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "user_id": "test-litellm-user-4",\n    "user_role": "proxy_admin_viewer"\n}\'\n```\n\nParameters:\n    - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.\n    - user_email: Optional[str] - Specify a user email.\n    - password: Optional[str] - Specify a user password.\n    - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.\n    - teams: Optional[list] - specify a list of team id\'s a user belongs to.\n    - send_invite_email: Optional[bool] - Specify if an invite email should be sent.\n    - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`\n    - max_budget: Optional[float] - Specify max budget for a given user.\n    - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").\n    - models: Optional[list] - Model_name\'s a user is allowed to call. (if empty, key is allowed to call all models)\n    - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)\n    - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)\n    - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response\n    - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)\n    - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.\n    - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-\n    - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.\n    - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user\n    - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.\n    - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }\n    - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user\'s parallel requests > x.\n    - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn\'t block requests.\n    - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)\n    - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)\n    - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)\n    - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").\n    - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None. \n    - duration: Optional[str] - [NOT IMPLEMENTED].\n    - key_alias: Optional[str] - [NOT IMPLEMENTED].\n    - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.\n    - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.',
			inputSchema: { body: userUpdateUserUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await userUpdateUserUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"bulkUserUpdateUserBulkUpdatePost",
		{
			description:
				'Bulk update multiple users at once.\n\nThis endpoint allows updating multiple users in a single request. Each user update\nis processed independently - if some updates fail, others will still succeed.\n\nParameters:\n- users: Optional[List[UpdateUserRequest]] - List of specific user update requests\n- all_users: Optional[bool] - Set to true to update all users in the system\n- user_updates: Optional[UpdateUserRequest] - Updates to apply when all_users=True\n\nReturns:\n- results: List of individual update results\n- total_requested: Total number of users requested for update\n- successful_updates: Number of successful updates\n- failed_updates: Number of failed updates\n\nExample request for specific users:\n```bash\ncurl --location \'http://0.0.0.0:4000/user/bulk_update\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "users": [\n        {\n            "user_id": "user1",\n            "user_role": "internal_user",\n            "max_budget": 100.0\n        },\n        {\n            "user_email": "user2@example.com", \n            "user_role": "internal_user_viewer",\n            "max_budget": 50.0\n        }\n    ]\n}\'\n```\n\nExample request for all users:\n```bash\ncurl --location \'http://0.0.0.0:4000/user/bulk_update\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "all_users": true,\n    "user_updates": {\n        "user_role": "internal_user",\n        "max_budget": 50.0\n    }\n}\'\n```',
			inputSchema: {
				body: bulkUserUpdateUserBulkUpdatePostMutationRequestSchema,
				headers: bulkUserUpdateUserBulkUpdatePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await bulkUserUpdateUserBulkUpdatePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUsersUserListGet",
		{
			description:
				"Get a paginated list of users with filtering and sorting options.\n\nParameters:\n    role: Optional[str]\n        Filter users by role. Can be one of:\n        - proxy_admin\n        - proxy_admin_viewer\n        - internal_user\n        - internal_user_viewer\n    user_ids: Optional[str]\n        Get list of users by user_ids. Comma separated list of user_ids.\n    sso_ids: Optional[str]\n        Get list of users by sso_ids. Comma separated list of sso_ids.\n    user_email: Optional[str]\n        Filter users by partial email match\n    team: Optional[str]\n        Filter users by team id. Will match if user has this team in their teams array.\n    page: int\n        The page number to return\n    page_size: int\n        The number of items per page\n    sort_by: Optional[str]\n        Column to sort by (e.g. 'user_id', 'user_email', 'created_at', 'spend')\n    sort_order: Optional[str]\n        Sort order ('asc' or 'desc')",
			inputSchema: { queryParams: getUsersUserListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getUsersUserListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteUserUserDeletePost",
		{
			description:
				"delete user and associated user keys\n\n```\ncurl --location 'http://0.0.0.0:4000/user/delete' \n--header 'Authorization: Bearer sk-1234' \n--header 'Content-Type: application/json' \n--data-raw '{\n    \"user_ids\": [\"45e3e396-ee08-4a61-a88e-16b3ce7e0849\"]\n}'\n```\n\nParameters:\n- user_ids: List[str] - The list of user id's to be deleted.",
			inputSchema: {
				body: deleteUserUserDeletePostMutationRequestSchema,
				headers: deleteUserUserDeletePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await deleteUserUserDeletePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUserDailyActivityUserDailyActivityGet",
		{
			description:
				"[BETA] This is a beta endpoint. It will change.\n\nMeant to optimize querying spend data for analytics for a user.\n\nReturns:\n(by date)\n- spend\n- prompt_tokens\n- completion_tokens\n- cache_read_input_tokens\n- cache_creation_input_tokens\n- total_tokens\n- api_requests\n- breakdown by model, api_key, provider",
			inputSchema: { queryParams: getUserDailyActivityUserDailyActivityGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getUserDailyActivityUserDailyActivityGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUserDailyActivityAggregatedUserDailyActivityAggregatedGet",
		{
			description:
				"Aggregated analytics for a user's daily activity without pagination.\nReturns the same response shape as the paginated endpoint with page metadata set to single-page.",
			inputSchema: {
				queryParams: getUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await getUserDailyActivityAggregatedUserDailyActivityAggregatedGet({
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newTeamTeamNewPost",
		{
			description:
				'Allow users to create a new team. Apply user permissions to their team.\n\n [Detailed Doc on setting team budgets](https://docs.litellm.ai/docs/proxy/team_budgets)\n\n\nParameters:\n- team_alias: Optional[str] - User defined team alias\n- team_id: Optional[str] - The team id of the user. If none passed, we\'ll generate it.\n- members_with_roles: List[{"role": "admin" or "user", "user_id": "<user-id>"}] - A list of users and their roles in the team. Get user_id when making a new user via `/user/new`.\n- team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]\n- metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"extra_info": "some info"}\n- model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit for this team - applied across all keys for this team. \n- model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit for this team - applied across all keys for this team.\n- tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit\n- rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit\n- rpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of RPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating RPM, or "best_effort_throughput" for best effort enforcement.\n- tpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of TPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating TPM, or "best_effort_throughput" for best effort enforcement.\n- max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget\n- budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)\n- models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.\n- blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.\n- members: Optional[List] - Control team members via `/team/member/add` and `/team/member/delete`.\n- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).\n- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.\n- organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.\n- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)\n- guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)\n- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.\n- team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.\n- team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.\n- team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.\n- team_member_key_duration: Optional[str] - The duration for a team member\'s key. e.g. "1d", "1w", "1mo"\n- prompts: Optional[List[str]] - List of allowed prompts for the team. If specified, the team will only be able to use these specific prompts.\n- allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.\n- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.\n\n\n\nReturns:\n- team_id: (str) Unique team id - used for tracking spend across multiple keys for same team id.\n\n_deprecated_params:\n- admins: list - A list of user_id\'s for the admin role\n- users: list - A list of user_id\'s for the user role\n\nExample Request:\n```\ncurl --location \'http://0.0.0.0:4000/team/new\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n  "team_alias": "my-new-team_2",\n  "members_with_roles": [{"role": "admin", "user_id": "user-1234"},\n    {"role": "user", "user_id": "user-2434"}]\n}\'\n\n```\n\n ```\ncurl --location \'http://0.0.0.0:4000/team/new\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n            "team_alias": "QA Prod Bot",\n            "max_budget": 0.000000001,\n            "budget_duration": "1d"\n        }\'\n```',
			inputSchema: {
				body: newTeamTeamNewPostMutationRequestSchema,
				headers: newTeamTeamNewPostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await newTeamTeamNewPost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateTeamTeamUpdatePost",
		{
			description:
				'Use `/team/member_add` AND `/team/member/delete` to add/remove new team members\n\nYou can now update team budget / rate limits via /team/update\n\nParameters:\n- team_id: str - The team id of the user. Required param.\n- team_alias: Optional[str] - User defined team alias\n- team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]\n- metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }\n- tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit\n- rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit\n- max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget\n- budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)\n- models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.\n- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.\n- blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.\n- tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).\n- organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.\n- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)\n- guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)\n- prompts: Optional[List[str]] - List of prompts that the team is allowed to use.\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.\n- team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.\n- team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.\n- team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.\n- team_member_key_duration: Optional[str] - The duration for a team member\'s key. e.g. "1d", "1w", "1mo"\n- allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.\n- model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit per model for this team. Example: {"gpt-4": 100, "gpt-3.5-turbo": 200}\n- model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit per model for this team. Example: {"gpt-4": 10000, "gpt-3.5-turbo": 20000}\nExample - update team TPM Limit\n- allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.\n\n\n```\ncurl --location \'http://0.0.0.0:4000/team/update\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data-raw \'{\n    "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",\n    "tpm_limit": 100\n}\'\n```\n\nExample - Update Team `max_budget` budget\n```\ncurl --location \'http://0.0.0.0:4000/team/update\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data-raw \'{\n    "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",\n    "max_budget": 10\n}\'\n```',
			inputSchema: {
				body: updateTeamTeamUpdatePostMutationRequestSchema,
				headers: updateTeamTeamUpdatePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await updateTeamTeamUpdatePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamMemberAddTeamMemberAddPost",
		{
			description:
				'Add new members (either via user_email or user_id) to a team\n\nIf user doesn\'t exist, new user row will also be added to User Table\n\nOnly proxy_admin or admin of team, allowed to access this endpoint.\n```\n\ncurl -X POST \'http://0.0.0.0:4000/team/member_add\'     -H \'Authorization: Bearer sk-1234\'     -H \'Content-Type: application/json\'     -d \'{"team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849", "member": {"role": "user", "user_id": "krrish247652@berri.ai"}}\'\n\n```',
			inputSchema: { body: teamMemberAddTeamMemberAddPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await teamMemberAddTeamMemberAddPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamMemberDeleteTeamMemberDeletePost",
		{
			description:
				"[BETA]\n\ndelete members (either via user_email or user_id) from a team\n\nIf user doesn't exist, an exception will be raised\n```\ncurl -X POST 'http://0.0.0.0:8000/team/member_delete' \n-H 'Authorization: Bearer sk-1234' \n-H 'Content-Type: application/json' \n-d '{\n    \"team_id\": \"45e3e396-ee08-4a61-a88e-16b3ce7e0849\",\n    \"user_id\": \"krrish247652@berri.ai\"\n}'\n```",
			inputSchema: { body: teamMemberDeleteTeamMemberDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await teamMemberDeleteTeamMemberDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamMemberUpdateTeamMemberUpdatePost",
		{
			description: "[BETA]\n\nUpdate team member budgets and team member role",
			inputSchema: { body: teamMemberUpdateTeamMemberUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await teamMemberUpdateTeamMemberUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"bulkTeamMemberAddTeamBulkMemberAddPost",
		{
			description:
				'Bulk add multiple members to a team at once.\n\nThis endpoint reuses the same logic as /team/member_add but provides a bulk-friendly response format.\n\nParameters:\n- team_id: str - The ID of the team to add members to\n- members: List[Member] - List of members to add to the team\n- all_users: Optional[bool] - Flag to add all users on Proxy to the team\n- max_budget_in_team: Optional[float] - Maximum budget allocated to each user within the team\n\nReturns:\n- results: List of individual member addition results\n- total_requested: Total number of members requested for addition\n- successful_additions: Number of successful additions  \n- failed_additions: Number of failed additions\n- updated_team: The updated team object\n\nExample request:\n```bash\ncurl --location \'http://0.0.0.0:4000/team/bulk_member_add\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "team_id": "team-1234",\n    "members": [\n        {\n            "user_id": "user1",\n            "role": "user"\n        },\n        {\n            "user_email": "user2@example.com",\n            "role": "admin"\n        }\n    ],\n    "max_budget_in_team": 100.0\n}\'\n```',
			inputSchema: { body: bulkTeamMemberAddTeamBulkMemberAddPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await bulkTeamMemberAddTeamBulkMemberAddPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteTeamTeamDeletePost",
		{
			description:
				"delete team and associated team keys\n\nParameters:\n- team_ids: List[str] - Required. List of team IDs to delete. Example: [\"team-1234\", \"team-5678\"]\n\n```\ncurl --location 'http://0.0.0.0:4000/team/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{\n    \"team_ids\": [\"8d916b1c-510d-4894-a334-1c16a93344f5\"]\n}'\n```",
			inputSchema: {
				body: deleteTeamTeamDeletePostMutationRequestSchema,
				headers: deleteTeamTeamDeletePostHeaderParamsSchema,
			},
		},
		async ({ body, headers }) => {
			try {
				return await deleteTeamTeamDeletePost({ body, headers, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamInfoTeamInfoGet",
		{
			description:
				"get info on team + related keys\n\nParameters:\n- team_id: str - Required. The unique identifier of the team to get info on.\n\n```\ncurl --location 'http://localhost:4000/team/info?team_id=your_team_id_here'     --header 'Authorization: Bearer your_api_key_here'\n```",
			inputSchema: { queryParams: teamInfoTeamInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await teamInfoTeamInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"blockTeamTeamBlockPost",
		{
			description:
				"Blocks all calls from keys with this team id.\n\nParameters:\n- team_id: str - Required. The unique identifier of the team to block.\n\nExample:\n```\ncurl --location 'http://0.0.0.0:4000/team/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{\n    \"team_id\": \"team-1234\"\n}'\n```\n\nReturns:\n- The updated team record with blocked=True",
			inputSchema: { body: blockTeamTeamBlockPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await blockTeamTeamBlockPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"unblockTeamTeamUnblockPost",
		{
			description:
				"Blocks all calls from keys with this team id.\n\nParameters:\n- team_id: str - Required. The unique identifier of the team to unblock.\n\nExample:\n```\ncurl --location 'http://0.0.0.0:4000/team/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{\n    \"team_id\": \"team-1234\"\n}'\n```",
			inputSchema: { body: unblockTeamTeamUnblockPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await unblockTeamTeamUnblockPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listAvailableTeamsTeamAvailableGet",
		{
			description: "Make a GET request to /team/available",
			inputSchema: { queryParams: listAvailableTeamsTeamAvailableGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listAvailableTeamsTeamAvailableGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listTeamV2V2TeamListGet",
		{
			description:
				"Get a paginated list of teams with filtering and sorting options.\n\nParameters:\n    user_id: Optional[str]\n        Only return teams which this user belongs to\n    organization_id: Optional[str]\n        Only return teams which belong to this organization\n    team_id: Optional[str]\n        Filter teams by exact team_id match\n    team_alias: Optional[str]\n        Filter teams by partial team_alias match\n    page: int\n        The page number to return\n    page_size: int\n        The number of items per page\n    sort_by: Optional[str]\n        Column to sort by (e.g. 'team_id', 'team_alias', 'created_at')\n    sort_order: str\n        Sort order ('asc' or 'desc')",
			inputSchema: { queryParams: listTeamV2V2TeamListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listTeamV2V2TeamListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listTeamTeamListGet",
		{
			description:
				"```\ncurl --location --request GET 'http://0.0.0.0:4000/team/list'         --header 'Authorization: Bearer sk-1234'\n```\n\nParameters:\n- user_id: str - Optional. If passed will only return teams that the user_id is a member of.\n- organization_id: str - Optional. If passed will only return teams that belong to the organization_id. Pass 'default_organization' to get all teams without organization_id.",
			inputSchema: { queryParams: listTeamTeamListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listTeamTeamListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamModelAddTeamModelAddPost",
		{
			description:
				'Add models to a team\'s allowed model list. Only proxy admin or team admin can add models.\n\nParameters:\n- team_id: str - Required. The team to add models to\n- models: List[str] - Required. List of models to add to the team\n\nExample Request:\n```\ncurl --location \'http://0.0.0.0:4000/team/model/add\'     --header \'Authorization: Bearer sk-1234\'     --header \'Content-Type: application/json\'     --data \'{\n    "team_id": "team-1234",\n    "models": ["gpt-4", "claude-2"]\n}\'\n```',
			inputSchema: { body: teamModelAddTeamModelAddPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await teamModelAddTeamModelAddPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamModelDeleteTeamModelDeletePost",
		{
			description:
				"Remove models from a team's allowed model list. Only proxy admin or team admin can remove models.\n\nParameters:\n- team_id: str - Required. The team to remove models from\n- models: List[str] - Required. List of models to remove from the team\n\nExample Request:\n```\ncurl --location 'http://0.0.0.0:4000/team/model/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{\n    \"team_id\": \"team-1234\",\n    \"models\": [\"gpt-4\"]\n}'\n```",
			inputSchema: { body: teamModelDeleteTeamModelDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await teamModelDeleteTeamModelDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"teamMemberPermissionsTeamPermissionsListGet",
		{
			description: "Get the team member permissions for a team",
			inputSchema: { queryParams: teamMemberPermissionsTeamPermissionsListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await teamMemberPermissionsTeamPermissionsListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateTeamMemberPermissionsTeamPermissionsUpdatePost",
		{
			description: "Update the team member permissions for a team",
			inputSchema: {
				body: updateTeamMemberPermissionsTeamPermissionsUpdatePostMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await updateTeamMemberPermissionsTeamPermissionsUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getTeamDailyActivityTeamDailyActivityGet",
		{
			description:
				"Get daily activity for specific teams or all teams.\n\nArgs:\n    team_ids (Optional[str]): Comma-separated list of team IDs to filter by. If not provided, returns data for all teams.\n    start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).\n    end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).\n    model (Optional[str]): Filter by model name.\n    api_key (Optional[str]): Filter by API key.\n    page (int): Page number for pagination.\n    page_size (int): Number of items per page.\n    exclude_team_ids (Optional[str]): Comma-separated list of team IDs to exclude.\nReturns:\n    SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.",
			inputSchema: { queryParams: getTeamDailyActivityTeamDailyActivityGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getTeamDailyActivityTeamDailyActivityGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getServiceProviderConfigScimV2ServiceProviderConfigGet",
		{
			description: "Return SCIM Service Provider Configuration.",
			inputSchema: {
				queryParams: getServiceProviderConfigScimV2ServiceProviderConfigGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await getServiceProviderConfigScimV2ServiceProviderConfigGet({
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUsersScimV2UsersGet",
		{
			description: "Get a list of users according to SCIM v2 protocol",
			inputSchema: { queryParams: getUsersScimV2UsersGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getUsersScimV2UsersGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createUserScimV2UsersPost",
		{
			description: "Create a user according to SCIM v2 protocol",
			inputSchema: {
				body: createUserScimV2UsersPostMutationRequestSchema,
				queryParams: createUserScimV2UsersPostQueryParamsSchema,
			},
		},
		async ({ body, queryParams }) => {
			try {
				return await createUserScimV2UsersPost({ body, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUserScimV2UsersUserIdGet",
		{
			description: "Get a single user by ID according to SCIM v2 protocol",
			inputSchema: {
				userId: getUserScimV2UsersUserIdGetPathParamsSchema.shape["user_id"],
				queryParams: getUserScimV2UsersUserIdGetQueryParamsSchema,
			},
		},
		async ({ userId, queryParams }) => {
			try {
				return await getUserScimV2UsersUserIdGet({ pathParams: { userId }, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateUserScimV2UsersUserIdPut",
		{
			description: "Update a user according to SCIM v2 protocol (full replacement)",
			inputSchema: {
				userId: updateUserScimV2UsersUserIdPutPathParamsSchema.shape["user_id"],
				body: updateUserScimV2UsersUserIdPutMutationRequestSchema,
				queryParams: updateUserScimV2UsersUserIdPutQueryParamsSchema,
			},
		},
		async ({ userId, body, queryParams }) => {
			try {
				return await updateUserScimV2UsersUserIdPut({
					pathParams: { userId },
					body,
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteUserScimV2UsersUserIdDelete",
		{
			description: "Delete a user according to SCIM v2 protocol",
			inputSchema: {
				userId: deleteUserScimV2UsersUserIdDeletePathParamsSchema.shape["user_id"],
				queryParams: deleteUserScimV2UsersUserIdDeleteQueryParamsSchema,
			},
		},
		async ({ userId, queryParams }) => {
			try {
				return await deleteUserScimV2UsersUserIdDelete({
					pathParams: { userId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"patchUserScimV2UsersUserIdPatch",
		{
			description: "Patch a user according to SCIM v2 protocol",
			inputSchema: {
				userId: patchUserScimV2UsersUserIdPatchPathParamsSchema.shape["user_id"],
				body: patchUserScimV2UsersUserIdPatchMutationRequestSchema,
				queryParams: patchUserScimV2UsersUserIdPatchQueryParamsSchema,
			},
		},
		async ({ userId, body, queryParams }) => {
			try {
				return await patchUserScimV2UsersUserIdPatch({
					pathParams: { userId },
					body,
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getGroupsScimV2GroupsGet",
		{
			description: "Get a list of groups according to SCIM v2 protocol",
			inputSchema: { queryParams: getGroupsScimV2GroupsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getGroupsScimV2GroupsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createGroupScimV2GroupsPost",
		{
			description: "Create a group according to SCIM v2 protocol",
			inputSchema: {
				body: createGroupScimV2GroupsPostMutationRequestSchema,
				queryParams: createGroupScimV2GroupsPostQueryParamsSchema,
			},
		},
		async ({ body, queryParams }) => {
			try {
				return await createGroupScimV2GroupsPost({ body, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getGroupScimV2GroupsGroupIdGet",
		{
			description: "Get a single group by ID according to SCIM v2 protocol",
			inputSchema: {
				groupId: getGroupScimV2GroupsGroupIdGetPathParamsSchema.shape["group_id"],
				queryParams: getGroupScimV2GroupsGroupIdGetQueryParamsSchema,
			},
		},
		async ({ groupId, queryParams }) => {
			try {
				return await getGroupScimV2GroupsGroupIdGet({
					pathParams: { groupId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateGroupScimV2GroupsGroupIdPut",
		{
			description: "Update a group according to SCIM v2 protocol",
			inputSchema: {
				groupId: updateGroupScimV2GroupsGroupIdPutPathParamsSchema.shape["group_id"],
				body: updateGroupScimV2GroupsGroupIdPutMutationRequestSchema,
				queryParams: updateGroupScimV2GroupsGroupIdPutQueryParamsSchema,
			},
		},
		async ({ groupId, body, queryParams }) => {
			try {
				return await updateGroupScimV2GroupsGroupIdPut({
					pathParams: { groupId },
					body,
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteGroupScimV2GroupsGroupIdDelete",
		{
			description: "Delete a group according to SCIM v2 protocol",
			inputSchema: {
				groupId: deleteGroupScimV2GroupsGroupIdDeletePathParamsSchema.shape["group_id"],
				queryParams: deleteGroupScimV2GroupsGroupIdDeleteQueryParamsSchema,
			},
		},
		async ({ groupId, queryParams }) => {
			try {
				return await deleteGroupScimV2GroupsGroupIdDelete({
					pathParams: { groupId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"patchGroupScimV2GroupsGroupIdPatch",
		{
			description: "Patch a group according to SCIM v2 protocol",
			inputSchema: {
				groupId: patchGroupScimV2GroupsGroupIdPatchPathParamsSchema.shape["group_id"],
				body: patchGroupScimV2GroupsGroupIdPatchMutationRequestSchema,
				queryParams: patchGroupScimV2GroupsGroupIdPatchQueryParamsSchema,
			},
		},
		async ({ groupId, body, queryParams }) => {
			try {
				return await patchGroupScimV2GroupsGroupIdPatch({
					pathParams: { groupId },
					body,
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newOrganizationOrganizationNewPost",
		{
			description:
				'Allow orgs to own teams\n\nSet org level budgets + model access.\n\nOnly admins can create orgs.\n\n# Parameters\n\n- organization_alias: *str* - The name of the organization.\n- models: *List* - The models the organization has access to.\n- budget_id: *Optional[str]* - The id for a budget (tpm/rpm/max budget) for the organization.\n### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###\n- max_budget: *Optional[float]* - Max budget for org\n- tpm_limit: *Optional[int]* - Max tpm limit for org\n- rpm_limit: *Optional[int]* - Max rpm limit for org\n- model_rpm_limit: *Optional[Dict[str, int]]* - The RPM (Requests Per Minute) limit per model for this organization.\n- model_tpm_limit: *Optional[Dict[str, int]]* - The TPM (Tokens Per Minute) limit per model for this organization.\n- max_parallel_requests: *Optional[int]* - [Not Implemented Yet] Max parallel requests for org\n- soft_budget: *Optional[float]* - [Not Implemented Yet] Get a slack alert when this soft budget is reached. Don\'t block requests.\n- model_max_budget: *Optional[dict]* - Max budget for a specific model\n- budget_duration: *Optional[str]* - Frequency of reseting org budget\n- metadata: *Optional[dict]* - Metadata for organization, store information for organization. Example metadata - {"extra_info": "some info"}\n- blocked: *bool* - Flag indicating if the org is blocked or not - will stop all calls from keys with this org_id.\n- tags: *Optional[List[str]]* - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).\n- organization_id: *Optional[str]* - The organization id of the team. Default is None. Create via `/organization/new`.\n- model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)\n- object_permission: Optional[LiteLLM_ObjectPermissionBase] - organization-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.\nCase 1: Create new org **without** a budget_id\n\n```bash\ncurl --location \'http://0.0.0.0:4000/organization/new\' \n--header \'Authorization: Bearer sk-1234\' \n--header \'Content-Type: application/json\' \n--data \'{\n    "organization_alias": "my-secret-org",\n    "models": ["model1", "model2"],\n    "max_budget": 100\n}\'\n\n\n```\n\nCase 2: Create new org **with** a budget_id\n\n```bash\ncurl --location \'http://0.0.0.0:4000/organization/new\' \n--header \'Authorization: Bearer sk-1234\' \n--header \'Content-Type: application/json\' \n--data \'{\n    "organization_alias": "my-secret-org",\n    "models": ["model1", "model2"],\n    "budget_id": "428eeaa8-f3ac-4e85-a8fb-7dc8d7aa8689"\n}\'\n```',
			inputSchema: { body: newOrganizationOrganizationNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await newOrganizationOrganizationNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateOrganizationOrganizationUpdatePatch",
		{ description: "Update an organization" },
		async () => {
			try {
				return await updateOrganizationOrganizationUpdatePatch({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteOrganizationOrganizationDeleteDelete",
		{
			description:
				"Delete an organization\n\n# Parameters:\n\n- organization_ids: List[str] - The organization ids to delete.",
			inputSchema: { body: deleteOrganizationOrganizationDeleteDeleteMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteOrganizationOrganizationDeleteDelete({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listOrganizationOrganizationListGet",
		{
			description:
				"```\ncurl --location --request GET 'http://0.0.0.0:4000/organization/list'         --header 'Authorization: Bearer sk-1234'\n```",
		},
		async () => {
			try {
				return await listOrganizationOrganizationListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"infoOrganizationOrganizationInfoGet",
		{
			description: "Get the org specific information",
			inputSchema: { queryParams: infoOrganizationOrganizationInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await infoOrganizationOrganizationInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deprecatedInfoOrganizationOrganizationInfoPost",
		{
			description: "DEPRECATED: Use GET /organization/info instead",
			inputSchema: { body: deprecatedInfoOrganizationOrganizationInfoPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deprecatedInfoOrganizationOrganizationInfoPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"organizationMemberAddOrganizationMemberAddPost",
		{
			description:
				'[BETA]\n\nAdd new members (either via user_email or user_id) to an organization\n\nIf user doesn\'t exist, new user row will also be added to User Table\n\nOnly proxy_admin or org_admin of organization, allowed to access this endpoint.\n\n# Parameters:\n\n- organization_id: str (required)\n- member: Union[List[Member], Member] (required)\n    - role: Literal[LitellmUserRoles] (required)\n    - user_id: Optional[str]\n    - user_email: Optional[str]\n\nNote: Either user_id or user_email must be provided for each member.\n\nExample:\n```\ncurl -X POST \'http://0.0.0.0:4000/organization/member_add\'     -H \'Authorization: Bearer sk-1234\'     -H \'Content-Type: application/json\'     -d \'{\n    "organization_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",\n    "member": {\n        "role": "internal_user",\n        "user_id": "krrish247652@berri.ai"\n    },\n    "max_budget_in_organization": 100.0\n}\'\n```\n\nThe following is executed in this function:\n\n1. Check if organization exists\n2. Creates a new Internal User if the user_id or user_email is not found in LiteLLM_UserTable\n3. Add Internal User to the `LiteLLM_OrganizationMembership` table',
			inputSchema: { body: organizationMemberAddOrganizationMemberAddPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await organizationMemberAddOrganizationMemberAddPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"organizationMemberUpdateOrganizationMemberUpdatePatch",
		{
			description: "Update a member's role in an organization",
			inputSchema: {
				body: organizationMemberUpdateOrganizationMemberUpdatePatchMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await organizationMemberUpdateOrganizationMemberUpdatePatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"organizationMemberDeleteOrganizationMemberDeleteDelete",
		{
			description: "Delete a member from an organization",
			inputSchema: {
				body: organizationMemberDeleteOrganizationMemberDeleteDeleteMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await organizationMemberDeleteOrganizationMemberDeleteDelete({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"blockUserCustomerBlockPost",
		{
			description:
				'[BETA] Reject calls with this end-user id\n\nParameters:\n- user_ids (List[str], required): The unique `user_id`s for the users to block\n\n    (any /chat/completion call with this user={end-user-id} param, will be rejected.)\n\n    ```\n    curl -X POST "http://0.0.0.0:8000/user/block"\n    -H "Authorization: Bearer sk-1234"\n    -d \'{\n    "user_ids": [<user_id>, ...]\n    }\'\n    ```',
			inputSchema: { body: blockUserCustomerBlockPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await blockUserCustomerBlockPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"unblockUserCustomerUnblockPost",
		{
			description:
				'[BETA] Unblock calls with this user id\n\nExample\n```\ncurl -X POST "http://0.0.0.0:8000/user/unblock"\n-H "Authorization: Bearer sk-1234"\n-d \'{\n"user_ids": [<user_id>, ...]\n}\'\n```',
			inputSchema: { body: unblockUserCustomerUnblockPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await unblockUserCustomerUnblockPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newEndUserCustomerNewPost",
		{
			description:
				'Allow creating a new Customer \n\n\nParameters:\n- user_id: str - The unique identifier for the user.\n- alias: Optional[str] - A human-friendly alias for the user.\n- blocked: bool - Flag to allow or disallow requests for this end-user. Default is False.\n- max_budget: Optional[float] - The maximum budget allocated to the user. Either \'max_budget\' or \'budget_id\' should be provided, not both.\n- budget_id: Optional[str] - The identifier for an existing budget allocated to the user. Either \'max_budget\' or \'budget_id\' should be provided, not both.\n- allowed_model_region: Optional[Union[Literal["eu"], Literal["us"]]] - Require all user requests to use models in this specific region.\n- default_model: Optional[str] - If no equivalent model in the allowed region, default all requests to this model.\n- metadata: Optional[dict] = Metadata for customer, store information for customer. Example metadata = {"data_training_opt_out": True}\n- budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").\n- tpm_limit: Optional[int] - [Not Implemented Yet] Specify tpm limit for a given customer (Tokens per minute)\n- rpm_limit: Optional[int] - [Not Implemented Yet] Specify rpm limit for a given customer (Requests per minute)\n- model_max_budget: Optional[dict] - [Not Implemented Yet] Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d"}}\n- max_parallel_requests: Optional[int] - [Not Implemented Yet] Specify max parallel requests for a given customer.\n- soft_budget: Optional[float] - [Not Implemented Yet] Get alerts when customer crosses given budget, doesn\'t block requests.\n- spend: Optional[float] - Specify initial spend for a given customer.\n- budget_reset_at: Optional[str] - Specify the date and time when the budget should be reset.\n\n\n- Allow specifying allowed regions \n- Allow specifying default model\n\nExample curl:\n```\ncurl --location \'http://0.0.0.0:4000/customer/new\'         --header \'Authorization: Bearer sk-1234\'         --header \'Content-Type: application/json\'         --data \'{\n        "user_id" : "ishaan-jaff-3",\n        "allowed_region": "eu",\n        "budget_id": "free_tier",\n        "default_model": "azure/gpt-3.5-turbo-eu" <- all calls from this user, use this model? \n    }\'\n\n    # return end-user object\n```\n\nNOTE: This used to be called `/end_user/new`, we will still be maintaining compatibility for /end_user/XXX for these endpoints',
			inputSchema: { body: newEndUserCustomerNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await newEndUserCustomerNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"endUserInfoCustomerInfoGet",
		{
			description:
				"Get information about an end-user. An `end_user` is a customer (external user) of the proxy.\n\nParameters:\n- end_user_id (str, required): The unique identifier for the end-user\n\nExample curl:\n```\ncurl -X GET 'http://localhost:4000/customer/info?end_user_id=test-litellm-user-4'         -H 'Authorization: Bearer sk-1234'\n```",
			inputSchema: { queryParams: endUserInfoCustomerInfoGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await endUserInfoCustomerInfoGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateEndUserCustomerUpdatePost",
		{
			description:
				"Example curl \n\nParameters:\n- user_id: str\n- alias: Optional[str] = None  # human-friendly alias\n- blocked: bool = False  # allow/disallow requests for this end-user\n- max_budget: Optional[float] = None\n- budget_id: Optional[str] = None  # give either a budget_id or max_budget\n- allowed_model_region: Optional[AllowedModelRegion] = (\n    None  # require all user requests to use models in this specific region\n)\n- default_model: Optional[str] = (\n    None  # if no equivalent model in allowed region - default all requests to this model\n)\n\nExample curl:\n```\ncurl --location 'http://0.0.0.0:4000/customer/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{\n    \"user_id\": \"test-litellm-user-4\",\n    \"budget_id\": \"paid_tier\"\n}'\n\nSee below for all params \n```",
			inputSchema: { body: updateEndUserCustomerUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateEndUserCustomerUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteEndUserCustomerDeletePost",
		{
			description:
				"Delete multiple end-users.\n\nParameters:\n- user_ids (List[str], required): The unique `user_id`s for the users to delete\n\nExample curl:\n```\ncurl --location 'http://0.0.0.0:4000/customer/delete'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{\n        \"user_ids\" :[\"ishaan-jaff-5\"]\n}'\n\nSee below for all params \n```",
			inputSchema: { body: deleteEndUserCustomerDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteEndUserCustomerDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listEndUserCustomerListGet",
		{
			description:
				"[Admin-only] List all available customers\n\nExample curl:\n```\ncurl --location --request GET 'http://0.0.0.0:4000/customer/list'         --header 'Authorization: Bearer sk-1234'\n```",
		},
		async () => {
			try {
				return await listEndUserCustomerListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"viewSpendTagsSpendTagsGet",
		{
			description:
				'LiteLLM Enterprise - View Spend Per Request Tag\n\nExample Request:\n```\ncurl -X GET "http://0.0.0.0:8000/spend/tags" -H "Authorization: Bearer sk-1234"\n```\n\nSpend with Start Date and End Date\n```\ncurl -X GET "http://0.0.0.0:8000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: { queryParams: viewSpendTagsSpendTagsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await viewSpendTagsSpendTagsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getGlobalSpendReportGlobalSpendReportGet",
		{
			description:
				'Get Daily Spend per Team, based on specific startTime and endTime. Per team, view usage by each key, model\n[\n    {\n        "group-by-day": "2024-05-10",\n        "teams": [\n            {\n                "team_name": "team-1"\n                "spend": 10,\n                "keys": [\n                    "key": "1213",\n                    "usage": {\n                        "model-1": {\n                                "cost": 12.50,\n                                "input_tokens": 1000,\n                                "output_tokens": 5000,\n                                "requests": 100\n                            },\n                            "audio-modelname1": {\n                            "cost": 25.50,\n                            "seconds": 25,\n                            "requests": 50\n                    },\n                    }\n                }\n        ]\n    ]\n}',
			inputSchema: { queryParams: getGlobalSpendReportGlobalSpendReportGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getGlobalSpendReportGlobalSpendReportGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"globalViewSpendTagsGlobalSpendTagsGet",
		{
			description:
				'LiteLLM Enterprise - View Spend Per Request Tag. Used by LiteLLM UI\n\nExample Request:\n```\ncurl -X GET "http://0.0.0.0:4000/spend/tags" -H "Authorization: Bearer sk-1234"\n```\n\nSpend with Start Date and End Date\n```\ncurl -X GET "http://0.0.0.0:4000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: { queryParams: globalViewSpendTagsGlobalSpendTagsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await globalViewSpendTagsGlobalSpendTagsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"calculateSpendSpendCalculatePost",
		{
			description:
				'Accepts all the params of completion_cost.\n\nCalculate spend **before** making call:\n\nNote: If you see a spend of $0.0 you need to set custom_pricing for your model: https://docs.litellm.ai/docs/proxy/custom_pricing\n\n```\ncurl --location \'http://localhost:4000/spend/calculate\'\n--header \'Authorization: Bearer sk-1234\'\n--header \'Content-Type: application/json\'\n--data \'{\n    "model": "anthropic.claude-v2",\n    "messages": [{"role": "user", "content": "Hey, how\'\'\'s it going?"}]\n}\'\n```\n\nCalculate spend **after** making call:\n\n```\ncurl --location \'http://localhost:4000/spend/calculate\'\n--header \'Authorization: Bearer sk-1234\'\n--header \'Content-Type: application/json\'\n--data \'{\n    "completion_response": {\n        "id": "chatcmpl-123",\n        "object": "chat.completion",\n        "created": 1677652288,\n        "model": "gpt-3.5-turbo-0125",\n        "system_fingerprint": "fp_44709d6fcb",\n        "choices": [{\n            "index": 0,\n            "message": {\n                "role": "assistant",\n                "content": "Hello there, how may I assist you today?"\n            },\n            "logprobs": null,\n            "finish_reason": "stop"\n        }]\n        "usage": {\n            "prompt_tokens": 9,\n            "completion_tokens": 12,\n            "total_tokens": 21\n        }\n    }\n}\'\n```',
			inputSchema: { body: calculateSpendSpendCalculatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await calculateSpendSpendCalculatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"viewSpendLogsSpendLogsGet",
		{
			description:
				'View all spend logs, if request_id is provided, only logs for that request_id will be returned\n\nWhen start_date and end_date are provided:\n- summarize=true (default): Returns aggregated spend data grouped by date (maintains backward compatibility)\n- summarize=false: Returns filtered individual log entries within the date range\n\nExample Request for all logs\n```\ncurl -X GET "http://0.0.0.0:8000/spend/logs" -H "Authorization: Bearer sk-1234"\n```\n\nExample Request for specific request_id\n```\ncurl -X GET "http://0.0.0.0:8000/spend/logs?request_id=chatcmpl-6dcb2540-d3d7-4e49-bb27-291f863f112e" -H "Authorization: Bearer sk-1234"\n```\n\nExample Request for specific api_key\n```\ncurl -X GET "http://0.0.0.0:8000/spend/logs?api_key=sk-Fn8Ej39NkBQmUagFEoUWPQ" -H "Authorization: Bearer sk-1234"\n```\n\nExample Request for specific user_id\n```\ncurl -X GET "http://0.0.0.0:8000/spend/logs?user_id=ishaan@berri.ai" -H "Authorization: Bearer sk-1234"\n```\n\nExample Request for date range with individual logs (unsummarized)\n```\ncurl -X GET "http://0.0.0.0:8000/spend/logs?start_date=2024-01-01&end_date=2024-01-02&summarize=false" -H "Authorization: Bearer sk-1234"\n```',
			inputSchema: { queryParams: viewSpendLogsSpendLogsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await viewSpendLogsSpendLogsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"globalSpendResetGlobalSpendResetPost",
		{
			description:
				"ADMIN ONLY / MASTER KEY Only Endpoint\n\nGlobally reset spend for All API Keys and Teams, maintain LiteLLM_SpendLogs\n\n1. LiteLLM_SpendLogs will maintain the logs on spend, no data gets deleted from there\n2. LiteLLM_VerificationTokens spend will be set = 0\n3. LiteLLM_TeamTable spend will be set = 0",
		},
		async () => {
			try {
				return await globalSpendResetGlobalSpendResetPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"providerBudgetsProviderBudgetsGet",
		{
			description:
				'Provider Budget Routing - Get Budget, Spend Details https://docs.litellm.ai/docs/proxy/provider_budget_routing\n\nUse this endpoint to check current budget, spend and budget reset time for a provider\n\nExample Request\n\n```bash\ncurl -X GET http://localhost:4000/provider/budgets     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"\n```\n\nExample Response\n\n```json\n{\n    "providers": {\n        "openai": {\n            "budget_limit": 1e-12,\n            "time_period": "1d",\n            "spend": 0.0,\n            "budget_reset_at": null\n        },\n        "azure": {\n            "budget_limit": 100.0,\n            "time_period": "1d",\n            "spend": 0.0,\n            "budget_reset_at": null\n        },\n        "anthropic": {\n            "budget_limit": 100.0,\n            "time_period": "10d",\n            "spend": 0.0,\n            "budget_reset_at": null\n        },\n        "vertex_ai": {\n            "budget_limit": 100.0,\n            "time_period": "12d",\n            "spend": 0.0,\n            "budget_reset_at": null\n        }\n    }\n}\n```',
		},
		async () => {
			try {
				return await providerBudgetsProviderBudgetsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getCloudzeroSettingsCloudzeroSettingsGet",
		{
			description:
				"View current CloudZero settings.\n\nReturns the current CloudZero configuration with the API key masked for security.\nOnly the first 4 and last 4 characters of the API key are shown.\n\nOnly admin users can view CloudZero settings.",
		},
		async () => {
			try {
				return await getCloudzeroSettingsCloudzeroSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateCloudzeroSettingsCloudzeroSettingsPut",
		{
			description:
				"Update existing CloudZero settings.\n\nAllows updating individual CloudZero configuration fields without requiring all fields.\nOnly provided fields will be updated; others will remain unchanged.\n\nParameters:\n- api_key: (Optional) New CloudZero API key for authentication\n- connection_id: (Optional) New CloudZero connection ID for data submission\n- timezone: (Optional) New timezone for date handling\n\nOnly admin users can update CloudZero settings.",
			inputSchema: { body: updateCloudzeroSettingsCloudzeroSettingsPutMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateCloudzeroSettingsCloudzeroSettingsPut({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"initCloudzeroSettingsCloudzeroInitPost",
		{
			description:
				"Initialize CloudZero settings and store in the database.\n\nThis endpoint stores the CloudZero API key, connection ID, and timezone configuration\nin the proxy database for use by the CloudZero logger.\n\nParameters:\n- api_key: CloudZero API key for authentication\n- connection_id: CloudZero connection ID for data submission\n- timezone: Timezone for date handling (default: UTC)\n\nOnly admin users can configure CloudZero settings.",
			inputSchema: { body: initCloudzeroSettingsCloudzeroInitPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await initCloudzeroSettingsCloudzeroInitPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cloudzeroDryRunExportCloudzeroDryRunPost",
		{
			description:
				"Perform a dry run export using the CloudZero logger.\n\nThis endpoint uses the CloudZero logger to perform a dry run export,\nwhich returns the data that would be exported without actually sending it to CloudZero.\n\nParameters:\n- limit: Optional limit on number of records to process (default: 10000)\n\nReturns:\n- usage_data: Sample of the raw usage data (first 50 records)\n- cbf_data: CloudZero CBF formatted data ready for export\n- summary: Statistics including total cost, tokens, and record counts\n\nOnly admin users can perform CloudZero exports.",
			inputSchema: { body: cloudzeroDryRunExportCloudzeroDryRunPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await cloudzeroDryRunExportCloudzeroDryRunPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cloudzeroExportCloudzeroExportPost",
		{
			description:
				'Perform an actual export using the CloudZero logger.\n\nThis endpoint uses the CloudZero logger to export usage data to CloudZero AnyCost API.\n\nParameters:\n- limit: Optional limit on number of records to export\n- operation: CloudZero operation type ("replace_hourly" or "sum", default: "replace_hourly")\n\nOnly admin users can perform CloudZero exports.',
			inputSchema: { body: cloudzeroExportCloudzeroExportPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await cloudzeroExportCloudzeroExportPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cachePingCachePingGet",
		{ description: "Endpoint for checking if cache can be pinged" },
		async () => {
			try {
				return await cachePingCachePingGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cacheDeleteCacheDeletePost",
		{
			description:
				'Endpoint for deleting a key from the cache. All responses from litellm proxy have `x-litellm-cache-key` in the headers\n\nParameters:\n- **keys**: *Optional[List[str]]* - A list of keys to delete from the cache. Example {"keys": ["key1", "key2"]}\n\n```shell\ncurl -X POST "http://0.0.0.0:4000/cache/delete"     -H "Authorization: Bearer sk-1234"     -d \'{"keys": ["key1", "key2"]}\'\n```',
		},
		async () => {
			try {
				return await cacheDeleteCacheDeletePost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cacheRedisInfoCacheRedisInfoGet",
		{ description: "Endpoint for getting /redis/info" },
		async () => {
			try {
				return await cacheRedisInfoCacheRedisInfoGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"cacheFlushallCacheFlushallPost",
		{
			description:
				'A function to flush all items from the cache. (All items will be deleted from the cache with this)\nRaises HTTPException if the cache is not initialized or if the cache type does not support flushing.\nReturns a dictionary with the status of the operation.\n\nUsage:\n```\ncurl -X POST http://0.0.0.0:4000/cache/flushall -H "Authorization: Bearer sk-1234"\n```',
		},
		async () => {
			try {
				return await cacheFlushallCacheFlushallPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listGuardrailsGuardrailsListGet",
		{
			description:
				'List the guardrails that are available on the proxy server\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/guardrails/list" -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "guardrails": [\n        {\n        "guardrail_name": "bedrock-pre-guard",\n        "guardrail_info": {\n            "params": [\n            {\n                "name": "toxicity_score",\n                "type": "float",\n                "description": "Score between 0-1 indicating content toxicity level"\n            },\n            {\n                "name": "pii_detection",\n                "type": "boolean"\n            }\n            ]\n        }\n        }\n    ]\n}\n```',
		},
		async () => {
			try {
				return await listGuardrailsGuardrailsListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listGuardrailsV2V2GuardrailsListGet",
		{
			description:
				'List the guardrails that are available in the database using GuardrailRegistry\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/v2/guardrails/list" -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "guardrails": [\n        {\n            "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",\n            "guardrail_name": "my-bedrock-guard",\n            "litellm_params": {\n                "guardrail": "bedrock",\n                "mode": "pre_call",\n                "guardrailIdentifier": "ff6ujrregl1q",\n                "guardrailVersion": "DRAFT",\n                "default_on": true\n            },\n            "guardrail_info": {\n                "description": "Bedrock content moderation guardrail"\n            }\n        }\n    ]\n}\n```',
		},
		async () => {
			try {
				return await listGuardrailsV2V2GuardrailsListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createGuardrailGuardrailsPost",
		{
			description:
				'Create a new guardrail\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X POST "http://localhost:4000/guardrails" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "guardrail": {\n            "guardrail_name": "my-bedrock-guard",\n            "litellm_params": {\n                "guardrail": "bedrock",\n                "mode": "pre_call",\n                "guardrailIdentifier": "ff6ujrregl1q",\n                "guardrailVersion": "DRAFT",\n                "default_on": true\n            },\n            "guardrail_info": {\n                "description": "Bedrock content moderation guardrail"\n            }\n        }\n    }\'\n```\n\nExample Response:\n```json\n{\n    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",\n    "guardrail_name": "my-bedrock-guard",\n    "litellm_params": {\n        "guardrail": "bedrock",\n        "mode": "pre_call",\n        "guardrailIdentifier": "ff6ujrregl1q",\n        "guardrailVersion": "DRAFT",\n        "default_on": true\n    },\n    "guardrail_info": {\n        "description": "Bedrock content moderation guardrail"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T12:34:56.789Z"\n}\n```',
			inputSchema: { body: createGuardrailGuardrailsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await createGuardrailGuardrailsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateGuardrailGuardrailsGuardrailIdPut",
		{
			description:
				'Update an existing guardrail\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X PUT "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "guardrail": {\n            "guardrail_name": "updated-bedrock-guard",\n            "litellm_params": {\n                "guardrail": "bedrock",\n                "mode": "pre_call",\n                "guardrailIdentifier": "ff6ujrregl1q",\n                "guardrailVersion": "1.0",\n                "default_on": true\n            },\n            "guardrail_info": {\n                "description": "Updated Bedrock content moderation guardrail"\n            }\n        }\n    }\'\n```\n\nExample Response:\n```json\n{\n    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",\n    "guardrail_name": "updated-bedrock-guard",\n    "litellm_params": {\n        "guardrail": "bedrock",\n        "mode": "pre_call",\n        "guardrailIdentifier": "ff6ujrregl1q",\n        "guardrailVersion": "1.0",\n        "default_on": true\n    },\n    "guardrail_info": {\n        "description": "Updated Bedrock content moderation guardrail"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T13:45:12.345Z"\n}\n```',
			inputSchema: {
				guardrailId: updateGuardrailGuardrailsGuardrailIdPutPathParamsSchema.shape["guardrail_id"],
				body: updateGuardrailGuardrailsGuardrailIdPutMutationRequestSchema,
			},
		},
		async ({ guardrailId, body }) => {
			try {
				return await updateGuardrailGuardrailsGuardrailIdPut({
					pathParams: { guardrailId },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteGuardrailGuardrailsGuardrailIdDelete",
		{
			description:
				'Delete a guardrail\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X DELETE "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "message": "Guardrail 123e4567-e89b-12d3-a456-426614174000 deleted successfully"\n}\n```',
			inputSchema: {
				guardrailId:
					deleteGuardrailGuardrailsGuardrailIdDeletePathParamsSchema.shape["guardrail_id"],
			},
		},
		async ({ guardrailId }) => {
			try {
				return await deleteGuardrailGuardrailsGuardrailIdDelete({
					pathParams: { guardrailId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"patchGuardrailGuardrailsGuardrailIdPatch",
		{
			description:
				'Partially update an existing guardrail\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nThis endpoint allows updating specific fields of a guardrail without sending the entire object.\nOnly the following fields can be updated:\n- guardrail_name: The name of the guardrail\n- default_on: Whether the guardrail is enabled by default\n- guardrail_info: Additional information about the guardrail\n\nExample Request:\n```bash\ncurl -X PATCH "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "guardrail_name": "updated-name",\n        "default_on": true,\n        "guardrail_info": {\n            "description": "Updated description"\n        }\n    }\'\n```\n\nExample Response:\n```json\n{\n    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",\n    "guardrail_name": "updated-name",\n    "litellm_params": {\n        "guardrail": "bedrock",\n        "mode": "pre_call",\n        "guardrailIdentifier": "ff6ujrregl1q",\n        "guardrailVersion": "DRAFT",\n        "default_on": true\n    },\n    "guardrail_info": {\n        "description": "Updated description"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T14:22:33.456Z"\n}\n```',
			inputSchema: {
				guardrailId: patchGuardrailGuardrailsGuardrailIdPatchPathParamsSchema.shape["guardrail_id"],
				body: patchGuardrailGuardrailsGuardrailIdPatchMutationRequestSchema,
			},
		},
		async ({ guardrailId, body }) => {
			try {
				return await patchGuardrailGuardrailsGuardrailIdPatch({
					pathParams: { guardrailId },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getGuardrailInfoGuardrailsGuardrailIdGet",
		{
			description:
				'Get detailed information about a specific guardrail by ID\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",\n    "guardrail_name": "my-bedrock-guard",\n    "litellm_params": {\n        "guardrail": "bedrock",\n        "mode": "pre_call",\n        "guardrailIdentifier": "ff6ujrregl1q",\n        "guardrailVersion": "DRAFT",\n        "default_on": true\n    },\n    "guardrail_info": {\n        "description": "Bedrock content moderation guardrail"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T12:34:56.789Z"\n}\n```',
			inputSchema: {
				guardrailId: getGuardrailInfoGuardrailsGuardrailIdGetPathParamsSchema.shape["guardrail_id"],
			},
		},
		async ({ guardrailId }) => {
			try {
				return await getGuardrailInfoGuardrailsGuardrailIdGet({
					pathParams: { guardrailId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getGuardrailInfoGuardrailsGuardrailIdInfoGet",
		{
			description:
				'Get detailed information about a specific guardrail by ID\n\n [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",\n    "guardrail_name": "my-bedrock-guard",\n    "litellm_params": {\n        "guardrail": "bedrock",\n        "mode": "pre_call",\n        "guardrailIdentifier": "ff6ujrregl1q",\n        "guardrailVersion": "DRAFT",\n        "default_on": true\n    },\n    "guardrail_info": {\n        "description": "Bedrock content moderation guardrail"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T12:34:56.789Z"\n}\n```',
			inputSchema: {
				guardrailId:
					getGuardrailInfoGuardrailsGuardrailIdInfoGetPathParamsSchema.shape["guardrail_id"],
			},
		},
		async ({ guardrailId }) => {
			try {
				return await getGuardrailInfoGuardrailsGuardrailIdInfoGet({
					pathParams: { guardrailId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet",
		{
			description:
				"Get the UI settings for the guardrails\n\nReturns:\n- Supported entities for guardrails\n- Supported modes for guardrails\n- PII entity categories for UI organization\n- Content filter settings (patterns and categories)",
		},
		async () => {
			try {
				return await getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost",
		{
			description:
				'Validate a blocked_words YAML file content.\n\nArgs:\n    request: Dictionary with \'file_content\' key containing the YAML string\n\nReturns:\n    Dictionary with \'valid\' boolean and either \'message\'/\'errors\' depending on result\n\nExample Request:\n```json\n{\n    "file_content": "blocked_words:\\n  - keyword: \\"test\\"\\n    action: \\"BLOCK\\""\n}\n```\n\nExample Success Response:\n```json\n{\n    "valid": true,\n    "message": "Valid YAML file with 2 blocked words"\n}\n```\n\nExample Error Response:\n```json\n{\n    "valid": false,\n    "errors": ["Entry 0: missing \'action\' field"]\n}\n```',
			inputSchema: {
				body: validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost({
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet",
		{
			description:
				'Get provider-specific parameters for different guardrail types.\n\nReturns a dictionary mapping guardrail providers to their specific parameters,\nincluding parameter names, descriptions, and whether they are required.\n\nExample Response:\n```json\n{\n    "bedrock": {\n        "guardrailIdentifier": {\n            "description": "The ID of your guardrail on Bedrock",\n            "required": true,\n            "type": null\n        },\n        "guardrailVersion": {\n            "description": "The version of your Bedrock guardrail (e.g., DRAFT or version number)",\n            "required": true,\n            "type": null\n        }\n    },\n    "azure_content_safety_text_moderation": {\n        "api_key": {\n            "description": "API key for the Azure Content Safety Text Moderation guardrail",\n            "required": false,\n            "type": null\n        },\n        "optional_params": {\n            "description": "Optional parameters for the Azure Content Safety Text Moderation guardrail",\n            "required": true,\n            "type": "nested",\n            "fields": {\n                "severity_threshold": {\n                    "description": "Severity threshold for the Azure Content Safety Text Moderation guardrail across all categories",\n                    "required": false,\n                    "type": null\n                },\n                "categories": {\n                    "description": "Categories to scan for the Azure Content Safety Text Moderation guardrail",\n                    "required": false,\n                    "type": "multiselect",\n                    "options": ["Hate", "SelfHarm", "Sexual", "Violence"],\n                    "default_value": None\n                }\n            }\n        }\n    }\n}\n```',
		},
		async () => {
			try {
				return await getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"applyGuardrailApplyGuardrailPost",
		{
			description:
				"Apply a guardrail to text input and return the processed result.\n\nThis endpoint allows testing guardrails by applying them to custom text inputs.",
			inputSchema: { body: applyGuardrailApplyGuardrailPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await applyGuardrailApplyGuardrailPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"applyGuardrailGuardrailsApplyGuardrailPost",
		{
			description: "Mask PII from a given text, requires a guardrail to be added to litellm.",
			inputSchema: { body: applyGuardrailGuardrailsApplyGuardrailPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await applyGuardrailGuardrailsApplyGuardrailPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listSearchToolsSearchToolsListGet",
		{
			description:
				'List all search tools that are available in the database.\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/search_tools/list" -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "search_tools": [\n        {\n            "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",\n            "search_tool_name": "litellm-search",\n            "litellm_params": {\n                "search_provider": "perplexity",\n                "api_key": "sk-***",\n                "api_base": "https://api.perplexity.ai"\n            },\n            "search_tool_info": {\n                "description": "Perplexity search tool"\n            },\n            "created_at": "2023-11-09T12:34:56.789Z",\n            "updated_at": "2023-11-09T12:34:56.789Z"\n        }\n    ]\n}\n```',
		},
		async () => {
			try {
				return await listSearchToolsSearchToolsListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createSearchToolSearchToolsPost",
		{
			description:
				'Create a new search tool.\n\nExample Request:\n```bash\ncurl -X POST "http://localhost:4000/search_tools" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "search_tool": {\n            "search_tool_name": "litellm-search",\n            "litellm_params": {\n                "search_provider": "perplexity",\n                "api_key": "sk-..."\n            },\n            "search_tool_info": {\n                "description": "Perplexity search tool"\n            }\n        }\n    }\'\n```\n\nExample Response:\n```json\n{\n    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",\n    "search_tool_name": "litellm-search",\n    "litellm_params": {\n        "search_provider": "perplexity",\n        "api_key": "sk-..."\n    },\n    "search_tool_info": {\n        "description": "Perplexity search tool"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T12:34:56.789Z"\n}\n```',
			inputSchema: { body: createSearchToolSearchToolsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await createSearchToolSearchToolsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateSearchToolSearchToolsSearchToolIdPut",
		{
			description:
				'Update an existing search tool.\n\nExample Request:\n```bash\ncurl -X PUT "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "search_tool": {\n            "search_tool_name": "updated-search",\n            "litellm_params": {\n                "search_provider": "perplexity",\n                "api_key": "sk-new-key"\n            },\n            "search_tool_info": {\n                "description": "Updated search tool"\n            }\n        }\n    }\'\n```\n\nExample Response:\n```json\n{\n    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",\n    "search_tool_name": "updated-search",\n    "litellm_params": {\n        "search_provider": "perplexity",\n        "api_key": "sk-new-key"\n    },\n    "search_tool_info": {\n        "description": "Updated search tool"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T13:45:12.345Z"\n}\n```',
			inputSchema: {
				searchToolId:
					updateSearchToolSearchToolsSearchToolIdPutPathParamsSchema.shape["search_tool_id"],
				body: updateSearchToolSearchToolsSearchToolIdPutMutationRequestSchema,
			},
		},
		async ({ searchToolId, body }) => {
			try {
				return await updateSearchToolSearchToolsSearchToolIdPut({
					pathParams: { searchToolId },
					body,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteSearchToolSearchToolsSearchToolIdDelete",
		{
			description:
				'Delete a search tool.\n\nExample Request:\n```bash\ncurl -X DELETE "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "message": "Search tool 123e4567-e89b-12d3-a456-426614174000 deleted successfully",\n    "search_tool_name": "litellm-search"\n}\n```',
			inputSchema: {
				searchToolId:
					deleteSearchToolSearchToolsSearchToolIdDeletePathParamsSchema.shape["search_tool_id"],
			},
		},
		async ({ searchToolId }) => {
			try {
				return await deleteSearchToolSearchToolsSearchToolIdDelete({
					pathParams: { searchToolId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getSearchToolInfoSearchToolsSearchToolIdGet",
		{
			description:
				'Get detailed information about a specific search tool by ID.\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",\n    "search_tool_name": "litellm-search",\n    "litellm_params": {\n        "search_provider": "perplexity",\n        "api_key": "sk-***"\n    },\n    "search_tool_info": {\n        "description": "Perplexity search tool"\n    },\n    "created_at": "2023-11-09T12:34:56.789Z",\n    "updated_at": "2023-11-09T12:34:56.789Z"\n}\n```',
			inputSchema: {
				searchToolId:
					getSearchToolInfoSearchToolsSearchToolIdGetPathParamsSchema.shape["search_tool_id"],
			},
		},
		async ({ searchToolId }) => {
			try {
				return await getSearchToolInfoSearchToolsSearchToolIdGet({
					pathParams: { searchToolId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"testSearchToolConnectionSearchToolsTestConnectionPost",
		{
			description:
				'Test connection to a search provider with the given configuration.\n\nMakes a simple test search query to verify the API key and configuration are valid.\n\nExample Request:\n```bash\ncurl -X POST "http://localhost:4000/search_tools/test_connection" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "litellm_params": {\n            "search_provider": "perplexity",\n            "api_key": "sk-..."\n        }\n    }\'\n```\n\nExample Response (Success):\n```json\n{\n    "status": "success",\n    "message": "Successfully connected to perplexity search provider",\n    "test_query": "test",\n    "results_count": 5\n}\n```\n\nExample Response (Failure):\n```json\n{\n    "status": "error",\n    "message": "Authentication failed: Invalid API key",\n    "error_type": "AuthenticationError"\n}\n```',
			inputSchema: {
				body: testSearchToolConnectionSearchToolsTestConnectionPostMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await testSearchToolConnectionSearchToolsTestConnectionPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet",
		{
			description:
				'Get the list of available search providers with their configuration fields.\n\nAuto-discovers search providers and their UI-friendly names from transformation configs.\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/search_tools/ui/available_providers" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "providers": [\n        {\n            "provider_name": "perplexity",\n            "ui_friendly_name": "Perplexity"\n        },\n        {\n            "provider_name": "tavily",\n            "ui_friendly_name": "Tavily"\n        }\n    ]\n}\n```',
		},
		async () => {
			try {
				return await getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listPromptsPromptsListGet",
		{
			description:
				'List the prompts that are available on the proxy server\n\n [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\nExample Request:\n```bash\ncurl -X GET "http://localhost:4000/prompts/list" -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "prompts": [\n        {\n            "prompt_id": "my_prompt_id",\n            "litellm_params": {\n                "prompt_id": "my_prompt_id",\n                "prompt_integration": "dotprompt",\n                "prompt_directory": "/path/to/prompts"\n            },\n            "prompt_info": {\n                "prompt_type": "config"\n            },\n            "created_at": "2023-11-09T12:34:56.789Z",\n            "updated_at": "2023-11-09T12:34:56.789Z"\n        }\n    ]\n}\n```',
		},
		async () => {
			try {
				return await listPromptsPromptsListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getPromptInfoPromptsPromptIdInfoGet",
		{
			description:
				'Get detailed information about a specific prompt by ID, including prompt content\n\n     [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\n    Example Request:\n    ```bash\n    curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \\\n        -H "Authorization: Bearer <your_api_key>"\n    ```\n\n    Example Response:\n    ```json\n    {\n        "prompt_id": "my_prompt_id",\n        "litellm_params": {\n            "prompt_id": "my_prompt_id",\n            "prompt_integration": "dotprompt",\n            "prompt_directory": "/path/to/prompts"\n        },\n        "prompt_info": {\n            "prompt_type": "config"\n        },\n        "created_at": "2023-11-09T12:34:56.789Z",\n        "updated_at": "2023-11-09T12:34:56.789Z",\n        "content": "System: You are a helpful assistant.\n\nUser: {{user_message}}"\n    }\n    ```',
			inputSchema: {
				promptId: getPromptInfoPromptsPromptIdInfoGetPathParamsSchema.shape["prompt_id"],
			},
		},
		async ({ promptId }) => {
			try {
				return await getPromptInfoPromptsPromptIdInfoGet({ pathParams: { promptId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getPromptInfoPromptsPromptIdGet",
		{
			description:
				'Get detailed information about a specific prompt by ID, including prompt content\n\n     [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\n    Example Request:\n    ```bash\n    curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \\\n        -H "Authorization: Bearer <your_api_key>"\n    ```\n\n    Example Response:\n    ```json\n    {\n        "prompt_id": "my_prompt_id",\n        "litellm_params": {\n            "prompt_id": "my_prompt_id",\n            "prompt_integration": "dotprompt",\n            "prompt_directory": "/path/to/prompts"\n        },\n        "prompt_info": {\n            "prompt_type": "config"\n        },\n        "created_at": "2023-11-09T12:34:56.789Z",\n        "updated_at": "2023-11-09T12:34:56.789Z",\n        "content": "System: You are a helpful assistant.\n\nUser: {{user_message}}"\n    }\n    ```',
			inputSchema: { promptId: getPromptInfoPromptsPromptIdGetPathParamsSchema.shape["prompt_id"] },
		},
		async ({ promptId }) => {
			try {
				return await getPromptInfoPromptsPromptIdGet({ pathParams: { promptId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updatePromptPromptsPromptIdPut",
		{
			description:
				'Update an existing prompt\n\n [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\nExample Request:\n```bash\ncurl -X PUT "http://localhost:4000/prompts/my_prompt_id" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "prompt_id": "my_prompt",\n        "litellm_params": {\n            "prompt_id": "my_prompt",\n                "prompt_integration": "dotprompt",\n                "prompt_directory": "/path/to/prompts"\n            },\n            "prompt_info": {\n                "prompt_type": "config"\n            }\n        }\n    }\'\n```',
			inputSchema: {
				promptId: updatePromptPromptsPromptIdPutPathParamsSchema.shape["prompt_id"],
				body: updatePromptPromptsPromptIdPutMutationRequestSchema,
			},
		},
		async ({ promptId, body }) => {
			try {
				return await updatePromptPromptsPromptIdPut({ pathParams: { promptId }, body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deletePromptPromptsPromptIdDelete",
		{
			description:
				'Delete a prompt\n\n [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\nExample Request:\n```bash\ncurl -X DELETE "http://localhost:4000/prompts/my_prompt_id" \\\n    -H "Authorization: Bearer <your_api_key>"\n```\n\nExample Response:\n```json\n{\n    "message": "Prompt my_prompt_id deleted successfully"\n}\n```',
			inputSchema: {
				promptId: deletePromptPromptsPromptIdDeletePathParamsSchema.shape["prompt_id"],
			},
		},
		async ({ promptId }) => {
			try {
				return await deletePromptPromptsPromptIdDelete({ pathParams: { promptId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"patchPromptPromptsPromptIdPatch",
		{
			description:
				'Partially update an existing prompt\n\n [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\nThis endpoint allows updating specific fields of a prompt without sending the entire object.\nOnly the following fields can be updated:\n- litellm_params: LiteLLM parameters for the prompt\n- prompt_info: Additional information about the prompt\n\nExample Request:\n```bash\ncurl -X PATCH "http://localhost:4000/prompts/my_prompt_id" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "prompt_info": {\n            "prompt_type": "db"\n        }\n    }\'\n```',
			inputSchema: {
				promptId: patchPromptPromptsPromptIdPatchPathParamsSchema.shape["prompt_id"],
				body: patchPromptPromptsPromptIdPatchMutationRequestSchema,
			},
		},
		async ({ promptId, body }) => {
			try {
				return await patchPromptPromptsPromptIdPatch({ pathParams: { promptId }, body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createPromptPromptsPost",
		{
			description:
				'Create a new prompt\n\n [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)\n\nExample Request:\n```bash\ncurl -X POST "http://localhost:4000/prompts" \\\n    -H "Authorization: Bearer <your_api_key>" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "prompt_id": "my_prompt",\n        "litellm_params": {\n            "prompt_id": "json_prompt",\n            "prompt_integration": "dotprompt",\n            ### EITHER prompt_directory OR prompt_data MUST BE PROVIDED\n            "prompt_directory": "/path/to/dotprompt/folder",\n            "prompt_data": {"json_prompt": {"content": "This is a prompt", "metadata": {"model": "gpt-4"}}}\n        },\n        "prompt_info": {\n            "prompt_type": "config"\n        }\n    }\'\n```',
			inputSchema: { body: createPromptPromptsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await createPromptPromptsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"convertPromptFileToJsonUtilsDotpromptJsonConverterPost",
		{
			description:
				"Convert a .prompt file to JSON format.\n\nThis endpoint accepts a .prompt file upload and returns the equivalent JSON representation\nthat can be stored in a database or used programmatically.\n\nReturns the JSON structure with 'content' and 'metadata' fields.",
		},
		async () => {
			try {
				return await convertPromptFileToJsonUtilsDotpromptJsonConverterPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listCallbacksCallbacksListGet",
		{ description: "View List of Active Logging Callbacks" },
		async () => {
			try {
				return await listCallbacksCallbacksListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getActiveTasksStatsDebugAsyncioTasksGet",
		{ description: "Returns:\n  total_active_tasks: int\n  by_name: { coroutine_name: count }" },
		async () => {
			try {
				return await getActiveTasksStatsDebugAsyncioTasksGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"addAllowedIpAddAllowedIpPost",
		{
			description: "Make a POST request to /add/allowed_ip",
			inputSchema: { body: addAllowedIpAddAllowedIpPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await addAllowedIpAddAllowedIpPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteAllowedIpDeleteAllowedIpPost",
		{
			description: "Make a POST request to /delete/allowed_ip",
			inputSchema: { body: deleteAllowedIpDeleteAllowedIpPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteAllowedIpDeleteAllowedIpPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getInternalUserSettingsGetInternalUserSettingsGet",
		{
			description:
				"Get all SSO settings from the litellm_settings configuration.\nReturns a structured object with values and descriptions for UI display.",
		},
		async () => {
			try {
				return await getInternalUserSettingsGetInternalUserSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getDefaultTeamSettingsGetDefaultTeamSettingsGet",
		{
			description:
				"Get all SSO settings from the litellm_settings configuration.\nReturns a structured object with values and descriptions for UI display.",
		},
		async () => {
			try {
				return await getDefaultTeamSettingsGetDefaultTeamSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateInternalUserSettingsUpdateInternalUserSettingsPatch",
		{
			description:
				"Update the default internal user parameters for SSO users.\nThese settings will be applied to new users who sign in via SSO.",
			inputSchema: {
				body: updateInternalUserSettingsUpdateInternalUserSettingsPatchMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await updateInternalUserSettingsUpdateInternalUserSettingsPatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch",
		{
			description:
				"Update the default team parameters for SSO users.\nThese settings will be applied to new teams created from SSO.",
			inputSchema: {
				body: updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getSsoSettingsGetSsoSettingsGet",
		{
			description:
				"Get all SSO configuration settings from the dedicated SSO table.\nReturns a structured object with values and descriptions for UI display.",
		},
		async () => {
			try {
				return await getSsoSettingsGetSsoSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateSsoSettingsUpdateSsoSettingsPatch",
		{
			description: "Update SSO configuration by saving to the dedicated SSO table.",
			inputSchema: { body: updateSsoSettingsUpdateSsoSettingsPatchMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateSsoSettingsUpdateSsoSettingsPatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUiThemeSettingsGetUiThemeSettingsGet",
		{
			description:
				"Get UI theme configuration from the litellm_settings.\nReturns current logo settings for UI customization.\n\nNote: This endpoint is public (no authentication required) so all users can see custom branding.\nOnly the /update/ui_theme_settings endpoint requires authentication for admins to change settings.",
		},
		async () => {
			try {
				return await getUiThemeSettingsGetUiThemeSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateUiThemeSettingsUpdateUiThemeSettingsPatch",
		{
			description: "Update UI theme configuration.\nUpdates logo settings for the admin UI.",
			inputSchema: { body: updateUiThemeSettingsUpdateUiThemeSettingsPatchMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateUiThemeSettingsUpdateUiThemeSettingsPatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"uploadLogoUploadLogoPost",
		{
			description:
				"Upload a custom logo for the admin UI.\nAccepts image files (PNG, JPG, JPEG, SVG) and stores them for use in the UI.",
		},
		async () => {
			try {
				return await uploadLogoUploadLogoPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createFileFilesPost",
		{
			description:
				'Upload a file that can be used across - Assistants API, Batch API \nThis is the equivalent of POST https://api.openai.com/v1/files\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/create\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"\n\n```',
			inputSchema: { queryParams: createFileFilesPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await createFileFilesPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listFilesFilesGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/list\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: { queryParams: listFilesFilesGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listFilesFilesGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createFileV1FilesPost",
		{
			description:
				'Upload a file that can be used across - Assistants API, Batch API \nThis is the equivalent of POST https://api.openai.com/v1/files\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/create\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"\n\n```',
			inputSchema: { queryParams: createFileV1FilesPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await createFileV1FilesPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listFilesV1FilesGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/list\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: { queryParams: listFilesV1FilesGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listFilesV1FilesGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"createFileProviderV1FilesPost",
		{
			description:
				'Upload a file that can be used across - Assistants API, Batch API \nThis is the equivalent of POST https://api.openai.com/v1/files\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/create\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"\n\n```',
			inputSchema: { provider: createFileProviderV1FilesPostPathParamsSchema.shape["provider"] },
		},
		async ({ provider }) => {
			try {
				return await createFileProviderV1FilesPost({ pathParams: { provider }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listFilesProviderV1FilesGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/list\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				provider: listFilesProviderV1FilesGetPathParamsSchema.shape["provider"],
				queryParams: listFilesProviderV1FilesGetQueryParamsSchema,
			},
		},
		async ({ provider, queryParams }) => {
			try {
				return await listFilesProviderV1FilesGet({ pathParams: { provider }, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getFileContentFilesFileIdContentGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				fileId: getFileContentFilesFileIdContentGetPathParamsSchema.shape["file_id"],
				queryParams: getFileContentFilesFileIdContentGetQueryParamsSchema,
			},
		},
		async ({ fileId, queryParams }) => {
			try {
				return await getFileContentFilesFileIdContentGet({
					pathParams: { fileId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getFileContentV1FilesFileIdContentGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				fileId: getFileContentV1FilesFileIdContentGetPathParamsSchema.shape["file_id"],
				queryParams: getFileContentV1FilesFileIdContentGetQueryParamsSchema,
			},
		},
		async ({ fileId, queryParams }) => {
			try {
				return await getFileContentV1FilesFileIdContentGet({
					pathParams: { fileId },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getFileContentProviderV1FilesFileIdContentGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				fileId: getFileContentProviderV1FilesFileIdContentGetPathParamsSchema.shape["file_id"],
				provider: getFileContentProviderV1FilesFileIdContentGetPathParamsSchema.shape["provider"],
			},
		},
		async ({ fileId, provider }) => {
			try {
				return await getFileContentProviderV1FilesFileIdContentGet({
					pathParams: { fileId, provider },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getFileFilesFileIdGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/{file_id}\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				fileId: getFileFilesFileIdGetPathParamsSchema.shape["file_id"],
				queryParams: getFileFilesFileIdGetQueryParamsSchema,
			},
		},
		async ({ fileId, queryParams }) => {
			try {
				return await getFileFilesFileIdGet({ pathParams: { fileId }, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteFileFilesFileIdDelete",
		{
			description:
				'Deletes a specified file. that can be used across - Assistants API, Batch API \nThis is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"\n\n```',
			inputSchema: {
				fileId: deleteFileFilesFileIdDeletePathParamsSchema.shape["file_id"],
				queryParams: deleteFileFilesFileIdDeleteQueryParamsSchema,
			},
		},
		async ({ fileId, queryParams }) => {
			try {
				return await deleteFileFilesFileIdDelete({ pathParams: { fileId }, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getFileV1FilesFileIdGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/{file_id}\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				fileId: getFileV1FilesFileIdGetPathParamsSchema.shape["file_id"],
				queryParams: getFileV1FilesFileIdGetQueryParamsSchema,
			},
		},
		async ({ fileId, queryParams }) => {
			try {
				return await getFileV1FilesFileIdGet({ pathParams: { fileId }, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteFileV1FilesFileIdDelete",
		{
			description:
				'Deletes a specified file. that can be used across - Assistants API, Batch API \nThis is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"\n\n```',
			inputSchema: {
				fileId: deleteFileV1FilesFileIdDeletePathParamsSchema.shape["file_id"],
				queryParams: deleteFileV1FilesFileIdDeleteQueryParamsSchema,
			},
		},
		async ({ fileId, queryParams }) => {
			try {
				return await deleteFileV1FilesFileIdDelete({ pathParams: { fileId }, queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getFileProviderV1FilesFileIdGet",
		{
			description:
				'Returns information about a specific file. that can be used across - Assistants API, Batch API \nThis is the equivalent of GET https://api.openai.com/v1/files/{file_id}\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"\n\n```',
			inputSchema: {
				fileId: getFileProviderV1FilesFileIdGetPathParamsSchema.shape["file_id"],
				provider: getFileProviderV1FilesFileIdGetPathParamsSchema.shape["provider"],
			},
		},
		async ({ fileId, provider }) => {
			try {
				return await getFileProviderV1FilesFileIdGet({ pathParams: { fileId, provider }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteFileProviderV1FilesFileIdDelete",
		{
			description:
				'Deletes a specified file. that can be used across - Assistants API, Batch API \nThis is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}\n\nSupports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete\n\nExample Curl\n```\ncurl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"\n\n```',
			inputSchema: {
				fileId: deleteFileProviderV1FilesFileIdDeletePathParamsSchema.shape["file_id"],
				provider: deleteFileProviderV1FilesFileIdDeletePathParamsSchema.shape["provider"],
			},
		},
		async ({ fileId, provider }) => {
			try {
				return await deleteFileProviderV1FilesFileIdDelete({
					pathParams: { fileId, provider },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"addTeamCallbacksTeamTeamIdCallbackPost",
		{
			description:
				'Add a success/failure callback to a team\n\nUse this if if you want different teams to have different success/failure callbacks\n\nParameters:\n- callback_name (Literal["langfuse", "langsmith", "gcs"], required): The name of the callback to add\n- callback_type (Literal["success", "failure", "success_and_failure"], required): The type of callback to add. One of:\n    - "success": Callback for successful LLM calls\n    - "failure": Callback for failed LLM calls\n    - "success_and_failure": Callback for both successful and failed LLM calls\n- callback_vars (StandardCallbackDynamicParams, required): A dictionary of variables to pass to the callback\n    - langfuse_public_key: The public key for the Langfuse callback\n    - langfuse_secret_key: The secret key for the Langfuse callback\n    - langfuse_secret: The secret for the Langfuse callback\n    - langfuse_host: The host for the Langfuse callback\n    - gcs_bucket_name: The name of the GCS bucket\n    - gcs_path_service_account: The path to the GCS service account\n    - langsmith_api_key: The API key for the Langsmith callback\n    - langsmith_project: The project for the Langsmith callback\n    - langsmith_base_url: The base URL for the Langsmith callback\n\nExample curl:\n```\ncurl -X POST \'http:/localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback\'         -H \'Content-Type: application/json\'         -H \'Authorization: Bearer sk-1234\'         -d \'{\n    "callback_name": "langfuse",\n    "callback_type": "success",\n    "callback_vars": {"langfuse_public_key": "pk-lf-xxxx1", "langfuse_secret_key": "sk-xxxxx"}\n    \n}\'\n```\n\nThis means for the team where team_id = dbe2f686-a686-4896-864a-4c3924458709, all LLM calls will be logged to langfuse using the public key pk-lf-xxxx1 and the secret key sk-xxxxx',
			inputSchema: {
				teamId: addTeamCallbacksTeamTeamIdCallbackPostPathParamsSchema.shape["team_id"],
				body: addTeamCallbacksTeamTeamIdCallbackPostMutationRequestSchema,
				headers: addTeamCallbacksTeamTeamIdCallbackPostHeaderParamsSchema,
			},
		},
		async ({ teamId, body, headers }) => {
			try {
				return await addTeamCallbacksTeamTeamIdCallbackPost({
					pathParams: { teamId },
					body,
					headers,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getTeamCallbacksTeamTeamIdCallbackGet",
		{
			description:
				'Get the success/failure callbacks and variables for a team\n\nParameters:\n- team_id (str, required): The unique identifier for the team\n\nExample curl:\n```\ncurl -X GET \'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback\'         -H \'Authorization: Bearer sk-1234\'\n```\n\nThis will return the callback settings for the team with id dbe2f686-a686-4896-864a-4c3924458709\n\nReturns {\n        "status": "success",\n        "data": {\n            "team_id": team_id,\n            "success_callbacks": team_callback_settings_obj.success_callback,\n            "failure_callbacks": team_callback_settings_obj.failure_callback,\n            "callback_vars": team_callback_settings_obj.callback_vars,\n        },\n    }',
			inputSchema: {
				teamId: getTeamCallbacksTeamTeamIdCallbackGetPathParamsSchema.shape["team_id"],
			},
		},
		async ({ teamId }) => {
			try {
				return await getTeamCallbacksTeamTeamIdCallbackGet({ pathParams: { teamId }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"disableTeamLoggingTeamTeamIdDisableLoggingPost",
		{
			description:
				"Disable all logging callbacks for a team\n\nParameters:\n- team_id (str, required): The unique identifier for the team\n\nExample curl:\n```\ncurl -X POST 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/disable_logging'         -H 'Authorization: Bearer sk-1234'\n```",
			inputSchema: {
				teamId: disableTeamLoggingTeamTeamIdDisableLoggingPostPathParamsSchema.shape["team_id"],
			},
		},
		async ({ teamId }) => {
			try {
				return await disableTeamLoggingTeamTeamIdDisableLoggingPost({
					pathParams: { teamId },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newBudgetBudgetNewPost",
		{
			description:
				'Create a new budget object. Can apply this to teams, orgs, end-users, keys.\n\nParameters:\n- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)\n- budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.\n- max_budget: Optional[float] - The max budget for the budget.\n- soft_budget: Optional[float] - The soft budget for the budget.\n- max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.\n- tpm_limit: Optional[int] - The tokens per minute limit for the budget.\n- rpm_limit: Optional[int] - The requests per minute limit for the budget.\n- model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}\n- budget_reset_at: Optional[datetime] - Datetime when the initial budget is reset. Default is now.',
			inputSchema: { body: newBudgetBudgetNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await newBudgetBudgetNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateBudgetBudgetUpdatePost",
		{
			description:
				'Update an existing budget object.\n\nParameters:\n- budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)\n- budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.\n- max_budget: Optional[float] - The max budget for the budget.\n- soft_budget: Optional[float] - The soft budget for the budget.\n- max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.\n- tpm_limit: Optional[int] - The tokens per minute limit for the budget.\n- rpm_limit: Optional[int] - The requests per minute limit for the budget.\n- model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}\n- budget_reset_at: Optional[datetime] - Update the Datetime when the budget was last reset.',
			inputSchema: { body: updateBudgetBudgetUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateBudgetBudgetUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"infoBudgetBudgetInfoPost",
		{
			description:
				"Get the budget id specific information\n\nParameters:\n- budgets: List[str] - The list of budget ids to get information for",
			inputSchema: { body: infoBudgetBudgetInfoPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await infoBudgetBudgetInfoPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"budgetSettingsBudgetSettingsGet",
		{
			description:
				"Get list of configurable params + current value for a budget item + description of each field\n\nUsed on Admin UI.\n\nQuery Parameters:\n- budget_id: str - The budget id to get information for",
			inputSchema: { queryParams: budgetSettingsBudgetSettingsGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await budgetSettingsBudgetSettingsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listBudgetBudgetListGet",
		{ description: "List all the created budgets in proxy db. Used on Admin UI." },
		async () => {
			try {
				return await listBudgetBudgetListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteBudgetBudgetDeletePost",
		{
			description: "Delete budget\n\nParameters:\n- id: str - The budget id to delete",
			inputSchema: { body: deleteBudgetBudgetDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteBudgetBudgetDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"patchModelModelModelIdUpdatePatch",
		{
			description:
				"PATCH Endpoint for partial model updates.\n\nOnly updates the fields specified in the request while preserving other existing values.\nFollows proper PATCH semantics by only modifying provided fields.\n\nArgs:\n    model_id: The ID of the model to update\n    patch_data: The fields to update and their new values\n    user_api_key_dict: User authentication information\n\nReturns:\n    Updated model information\n\nRaises:\n    ProxyException: For various error conditions including authentication and database errors",
			inputSchema: {
				modelId: patchModelModelModelIdUpdatePatchPathParamsSchema.shape["model_id"],
				body: patchModelModelModelIdUpdatePatchMutationRequestSchema,
			},
		},
		async ({ modelId, body }) => {
			try {
				return await patchModelModelModelIdUpdatePatch({ pathParams: { modelId }, body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteModelModelDeletePost",
		{
			description: "Allows deleting models in the model list in the config.yaml",
			inputSchema: { body: deleteModelModelDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteModelModelDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"addNewModelModelNewPost",
		{
			description: "Allows adding new models to the model list in the config.yaml",
			inputSchema: { body: addNewModelModelNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await addNewModelModelNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateModelModelUpdatePost",
		{
			description: "Edit existing model params",
			inputSchema: { body: updateModelModelUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateModelModelUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updatePublicModelGroupsModelGroupMakePublicPost",
		{
			description: "Update which model groups are public",
			inputSchema: { body: updatePublicModelGroupsModelGroupMakePublicPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updatePublicModelGroupsModelGroupMakePublicPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateUsefulLinksModelHubUpdateUsefulLinksPost",
		{
			description: "Update useful links",
			inputSchema: { body: updateUsefulLinksModelHubUpdateUsefulLinksPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateUsefulLinksModelHubUpdateUsefulLinksPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newTagTagNewPost",
		{
			description:
				"Create a new tag.\n\nParameters:\n- name: str - The name of the tag\n- description: Optional[str] - Description of what this tag represents\n- models: List[str] - List of either 'model_id' or 'model_name' allowed for this tag\n- budget_id: Optional[str] - The id for a budget (tpm/rpm/max budget) for the tag\n\n### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###\n- max_budget: Optional[float] - Max budget for tag\n- tpm_limit: Optional[int] - Max tpm limit for tag\n- rpm_limit: Optional[int] - Max rpm limit for tag\n- max_parallel_requests: Optional[int] - Max parallel requests for tag\n- soft_budget: Optional[float] - Get a slack alert when this soft budget is reached\n- model_max_budget: Optional[dict] - Max budget for a specific model\n- budget_duration: Optional[str] - Frequency of resetting tag budget",
			inputSchema: { body: newTagTagNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await newTagTagNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateTagTagUpdatePost",
		{
			description:
				"Update an existing tag.\n\nParameters:\n- name: str - The name of the tag to update\n- description: Optional[str] - Updated description\n- models: List[str] - Updated list of allowed LLM models\n- budget_id: Optional[str] - The id for a budget to associate with the tag\n\n### BUDGET UPDATE PARAMS ###\n- max_budget: Optional[float] - Max budget for tag\n- tpm_limit: Optional[int] - Max tpm limit for tag\n- rpm_limit: Optional[int] - Max rpm limit for tag\n- max_parallel_requests: Optional[int] - Max parallel requests for tag\n- soft_budget: Optional[float] - Get a slack alert when this soft budget is reached\n- model_max_budget: Optional[dict] - Max budget for a specific model\n- budget_duration: Optional[str] - Frequency of resetting tag budget",
			inputSchema: { body: updateTagTagUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateTagTagUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"infoTagTagInfoPost",
		{
			description:
				"Get information about specific tags.\n\nParameters:\n- names: List[str] - List of tag names to get information for",
			inputSchema: { body: infoTagTagInfoPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await infoTagTagInfoPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listTagsTagListGet",
		{ description: "List all available tags with their budget information." },
		async () => {
			try {
				return await listTagsTagListGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteTagTagDeletePost",
		{
			description: "Delete a tag.\n\nParameters:\n- name: str - The name of the tag to delete",
			inputSchema: { body: deleteTagTagDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteTagTagDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getTagDailyActivityTagDailyActivityGet",
		{
			description:
				"Get daily activity for specific tags or all tags.\n\nArgs:\n    tags (Optional[str]): Comma-separated list of tags to filter by. If not provided, returns data for all tags.\n    start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).\n    end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).\n    model (Optional[str]): Filter by model name.\n    api_key (Optional[str]): Filter by API key.\n    page (int): Page number for pagination.\n    page_size (int): Number of items per page.\n\nReturns:\n    SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.",
			inputSchema: { queryParams: getTagDailyActivityTagDailyActivityGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getTagDailyActivityTagDailyActivityGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getCostDiscountConfigConfigCostDiscountConfigGet",
		{
			description:
				"Get current cost discount configuration.\n\nReturns the cost_discount_config from litellm_settings.",
		},
		async () => {
			try {
				return await getCostDiscountConfigConfigCostDiscountConfigGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateCostDiscountConfigConfigCostDiscountConfigPatch",
		{
			description:
				'Update cost discount configuration.\n\nUpdates the cost_discount_config in litellm_settings.\nDiscounts should be between 0 and 1 (e.g., 0.05 = 5% discount).\n\nExample:\n```json\n{\n    "vertex_ai": 0.05,\n    "gemini": 0.05,\n    "openai": 0.01\n}\n```',
			inputSchema: {
				body: updateCostDiscountConfigConfigCostDiscountConfigPatchMutationRequestSchema,
			},
		},
		async ({ body }) => {
			try {
				return await updateCostDiscountConfigConfigCostDiscountConfigPatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getRouterSettingsRouterSettingsGet",
		{
			description:
				"Get router configuration and available settings.\n\nReturns:\n- fields: List of all configurable router settings with their metadata (type, description, default, options)\n          The routing_strategy field includes available options extracted from the Router class\n- current_values: Current values of router settings from config",
		},
		async () => {
			try {
				return await getRouterSettingsRouterSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getCacheSettingsCacheSettingsGet",
		{
			description:
				"Get cache configuration and available settings.\n\nReturns:\n- fields: List of all configurable cache settings with their metadata (type, description, default, options)\n- current_values: Current values of cache settings from database",
		},
		async () => {
			try {
				return await getCacheSettingsCacheSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateCacheSettingsCacheSettingsPost",
		{
			description:
				"Save cache settings to database and initialize cache.\n\nThis endpoint:\n1. Encrypts sensitive fields (passwords, etc.)\n2. Saves to LiteLLM_CacheConfig table\n3. Reinitializes cache with new settings",
			inputSchema: { body: updateCacheSettingsCacheSettingsPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateCacheSettingsCacheSettingsPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"testCacheConnectionCacheSettingsTestPost",
		{
			description:
				"Test cache connection with provided credentials.\n\nCreates a temporary cache instance and uses its test_connection method\nto verify the credentials work without affecting global state.",
			inputSchema: { body: testCacheConnectionCacheSettingsTestPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await testCacheConnectionCacheSettingsTestPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getDistinctUserAgentTagsTagDistinctGet",
		{
			description:
				"Get all distinct user agent tags up to a maximum of {MAX_TAGS} tags.\n\nThis endpoint returns all unique user agent tags found in the database,\nsorted by frequency of usage.\n\nReturns:\n    DistinctTagsResponse: List of distinct user agent tags",
		},
		async () => {
			try {
				return await getDistinctUserAgentTagsTagDistinctGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getDailyActiveUsersTagDauGet",
		{
			description:
				"Get Daily Active Users (DAU) by tags for the last {MAX_DAYS} days ending on UTC today + 1 day.\n\nThis endpoint efficiently calculates unique users per tag for each of the last {MAX_DAYS} days\nusing a single optimized SQL query, perfect for dashboard time series visualization.\n\nArgs:\n    tag_filter: Optional filter to specific tag (legacy)\n    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)\n    \nReturns:\n    ActiveUsersAnalyticsResponse: DAU data by tag for each of the last {MAX_DAYS} days",
			inputSchema: { queryParams: getDailyActiveUsersTagDauGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getDailyActiveUsersTagDauGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getWeeklyActiveUsersTagWauGet",
		{
			description:
				'Get Weekly Active Users (WAU) by tags for the last {MAX_WEEKS} weeks ending on UTC today + 1 day.\n\nShows week-by-week breakdown:\n- Week 1 (Jan 1): Earliest week (7 weeks ago)\n- Week 2 (Jan 8): Next week (6 weeks ago)\n- Week 3 (Jan 15): Next week (5 weeks ago)\n- ... and so on for {MAX_WEEKS} weeks total\n- Week 7: Most recent week ending on UTC today + 1 day\n\nArgs:\n    tag_filter: Optional filter to specific tag (legacy)\n    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)\n    \nReturns:\n    ActiveUsersAnalyticsResponse: WAU data by tag for each of the last {MAX_WEEKS} weeks with descriptive week labels (e.g., "Week 1 (Jan 1)")',
			inputSchema: { queryParams: getWeeklyActiveUsersTagWauGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getWeeklyActiveUsersTagWauGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getMonthlyActiveUsersTagMauGet",
		{
			description:
				'Get Monthly Active Users (MAU) by tags for the last {MAX_MONTHS} months ending on UTC today + 1 day.\n\nShows month-by-month breakdown:\n- Month 1 (Nov): Earliest month (7 months ago, 30-day period)\n- Month 2 (Dec): Next month (6 months ago)\n- Month 3 (Jan): Next month (5 months ago)\n- ... and so on for {MAX_MONTHS} months total\n- Month 7: Most recent month ending on UTC today + 1 day\n\nArgs:\n    tag_filter: Optional filter to specific tag (legacy)\n    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)\n    \nReturns:\n    ActiveUsersAnalyticsResponse: MAU data by tag for each of the last {MAX_MONTHS} months with descriptive month labels (e.g., "Month 1 (Nov)")',
			inputSchema: { queryParams: getMonthlyActiveUsersTagMauGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getMonthlyActiveUsersTagMauGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getTagSummaryTagSummaryGet",
		{
			description:
				"Get summary analytics for tags including unique users, requests, tokens, and spend.\n\nArgs:\n    start_date: Start date for the analytics period (YYYY-MM-DD)\n    end_date: End date for the analytics period (YYYY-MM-DD)\n    tag_filter: Optional filter to specific tag (legacy)\n    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)\n    \nReturns:\n    TagSummaryResponse: Summary analytics data by tag",
			inputSchema: { queryParams: getTagSummaryTagSummaryGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getTagSummaryTagSummaryGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet",
		{
			description:
				"Get per-user analytics including successful requests, tokens, and spend by individual users.\n\nThis endpoint provides usage metrics broken down by individual users based on their\ntag activity during the last 30 days ending on UTC today + 1 day.\n\nArgs:\n    tag_filter: Optional filter to specific tag (legacy)\n    tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)\n    page: Page number for pagination\n    page_size: Number of items per page\n    \nReturns:\n    PerUserAnalyticsResponse: Analytics data broken down by individual users for the last 30 days",
			inputSchema: {
				queryParams: getPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"newVectorStoreVectorStoreNewPost",
		{
			description:
				"Create a new vector store.\n\nParameters:\n- vector_store_id: str - Unique identifier for the vector store\n- custom_llm_provider: str - Provider of the vector store\n- vector_store_name: Optional[str] - Name of the vector store\n- vector_store_description: Optional[str] - Description of the vector store\n- vector_store_metadata: Optional[Dict] - Additional metadata for the vector store",
			inputSchema: { body: newVectorStoreVectorStoreNewPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await newVectorStoreVectorStoreNewPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listVectorStoresVectorStoreListGet",
		{
			description:
				"List all available vector stores with optional filtering and pagination.\nCombines both in-memory vector stores and those stored in the database.\n\nParameters:\n- page: int - Page number for pagination (default: 1)\n- page_size: int - Number of items per page (default: 100)",
			inputSchema: { queryParams: listVectorStoresVectorStoreListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listVectorStoresVectorStoreListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"deleteVectorStoreVectorStoreDeletePost",
		{
			description:
				"Delete a vector store.\n\nParameters:\n- vector_store_id: str - ID of the vector store to delete",
			inputSchema: { body: deleteVectorStoreVectorStoreDeletePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await deleteVectorStoreVectorStoreDeletePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getVectorStoreInfoVectorStoreInfoPost",
		{
			description: "Return a single vector store's details",
			inputSchema: { body: getVectorStoreInfoVectorStoreInfoPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await getVectorStoreInfoVectorStoreInfoPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateVectorStoreVectorStoreUpdatePost",
		{
			description: "Update vector store details",
			inputSchema: { body: updateVectorStoreVectorStoreUpdatePostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateVectorStoreVectorStoreUpdatePost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getEmailEventSettingsEmailEventSettingsGet",
		{ description: "Get all email event settings" },
		async () => {
			try {
				return await getEmailEventSettingsEmailEventSettingsGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"updateEventSettingsEmailEventSettingsPatch",
		{
			description: "Update the settings for email events",
			inputSchema: { body: updateEventSettingsEmailEventSettingsPatchMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await updateEventSettingsEmailEventSettingsPatch({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"resetEventSettingsEmailEventSettingsResetPost",
		{
			description:
				"Reset all email event settings to default (new user invitations on, virtual key creation off)",
		},
		async () => {
			try {
				return await resetEventSettingsEmailEventSettingsResetPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getAuditLogsAuditGet",
		{
			description:
				"Get all audit logs with filtering and pagination.\n\nReturns a paginated response of audit logs matching the specified filters.",
			inputSchema: { queryParams: getAuditLogsAuditGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await getAuditLogsAuditGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getAuditLogByIdAuditIdGet",
		{
			description:
				"Get detailed information about a specific audit log entry by its ID.\n\nArgs:\n    id (str): The unique identifier of the audit log entry\n\nReturns:\n    AuditLogResponse: Detailed information about the audit log entry\n\nRaises:\n    HTTPException: If the audit log is not found or if there's a database connection error",
			inputSchema: { id: getAuditLogByIdAuditIdGetPathParamsSchema.shape["id"] },
		},
		async ({ id }) => {
			try {
				return await getAuditLogByIdAuditIdGet({ pathParams: { id }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"availableEnterpriseUsersUserAvailableUsersGet",
		{
			description:
				"For keys with `max_users` set, return the list of users that are allowed to use the key.",
		},
		async () => {
			try {
				return await availableEnterpriseUsersUserAvailableUsersGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getRobotsRobotsTxtGet",
		{
			description:
				"Block all web crawlers from indexing the proxy server endpoints\nThis is useful for ensuring that the API endpoints aren't indexed by search engines",
		},
		async () => {
			try {
				return await getRobotsRobotsTxtGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUiConfigLitellmWellKnownLitellmUiConfigGet",
		{ description: "Make a GET request to /litellm/.well-known/litellm-ui-config" },
		async () => {
			try {
				return await getUiConfigLitellmWellKnownLitellmUiConfigGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"getUiConfigWellKnownLitellmUiConfigGet",
		{ description: "Make a GET request to /.well-known/litellm-ui-config" },
		async () => {
			try {
				return await getUiConfigWellKnownLitellmUiConfigGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamicMcpRouteMcpServerNameMcpPatch4",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatch4PathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch4({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamicMcpRouteMcpServerNameMcpPatch2",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatch2PathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch2({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamic_mcp_route__mcp_server_name__mcp_patch",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatchPathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamicMcpRouteMcpServerNameMcpPatch3",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatch3PathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch3({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamicMcpRouteMcpServerNameMcpPatch",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatchPathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamic_mcp_route__mcp_server_name__mcp_patch",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatchPathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"dynamicMcpRouteMcpServerNameMcpPatch5",
		{
			description: "Handle dynamic MCP server routes like /github_mcp/mcp",
			inputSchema: {
				mcpServerName:
					dynamicMcpRouteMcpServerNameMcpPatch5PathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await dynamicMcpRouteMcpServerNameMcpPatch5({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"listToolRestApiMcpRestToolsListGet",
		{
			description:
				'List all available tools with information about the server they belong to.\n\nExample response:\n{\n    "tools": [\n        {\n            "name": "create_zap",\n            "description": "Create a new zap",\n            "inputSchema": "tool_input_schema",\n            "mcp_info": {\n                "server_name": "zapier",\n                "logo_url": "https://www.zapier.com/logo.png",\n            }\n        }\n    ],\n    "error": null,\n    "message": "Successfully retrieved tools"\n}',
			inputSchema: { queryParams: listToolRestApiMcpRestToolsListGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await listToolRestApiMcpRestToolsListGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"callToolRestApiMcpRestToolsCallPost",
		{ description: "REST API to call a specific MCP tool with the provided arguments" },
		async () => {
			try {
				return await callToolRestApiMcpRestToolsCallPost({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"testConnectionMcpRestTestConnectionPost",
		{
			description: "Test if we can connect to the provided MCP server before adding it",
			inputSchema: { body: testConnectionMcpRestTestConnectionPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await testConnectionMcpRestTestConnectionPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"testToolsListMcpRestTestToolsListPost",
		{
			description: "Preview tools available from MCP server before adding it",
			inputSchema: { body: testToolsListMcpRestTestToolsListPostMutationRequestSchema },
		},
		async ({ body }) => {
			try {
				return await testToolsListMcpRestTestToolsListPost({ body, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"authorizeAuthorizeGet",
		{
			description: "Make a GET request to /authorize",
			inputSchema: { queryParams: authorizeAuthorizeGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await authorizeAuthorizeGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"authorizeMcpServerNameAuthorizeGet",
		{
			description: "Make a GET request to /{mcp_server_name}/authorize",
			inputSchema: {
				mcpServerName: authorizeMcpServerNameAuthorizeGetPathParamsSchema.shape["mcp_server_name"],
				queryParams: authorizeMcpServerNameAuthorizeGetQueryParamsSchema,
			},
		},
		async ({ mcpServerName, queryParams }) => {
			try {
				return await authorizeMcpServerNameAuthorizeGet({
					pathParams: { mcpServerName },
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"tokenEndpointTokenPost",
		{
			description:
				"Accept the authorization code from client and exchange it for OAuth token.\nSupports PKCE flow by forwarding code_verifier to upstream provider.\n\n1. Call the token endpoint with PKCE parameters\n2. Store the user's token in the db - and generate a LiteLLM virtual key\n3. Return the token\n4. Return a virtual key in this response",
			inputSchema: { queryParams: tokenEndpointTokenPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await tokenEndpointTokenPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"tokenEndpointMcpServerNameTokenPost",
		{
			description:
				"Accept the authorization code from client and exchange it for OAuth token.\nSupports PKCE flow by forwarding code_verifier to upstream provider.\n\n1. Call the token endpoint with PKCE parameters\n2. Store the user's token in the db - and generate a LiteLLM virtual key\n3. Return the token\n4. Return a virtual key in this response",
			inputSchema: {
				mcpServerName: tokenEndpointMcpServerNameTokenPostPathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await tokenEndpointMcpServerNameTokenPost({ pathParams: { mcpServerName }, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"callbackCallbackGet",
		{
			description: "Make a GET request to /callback",
			inputSchema: { queryParams: callbackCallbackGetQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await callbackCallbackGet({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet",
		{
			description: "Make a GET request to /.well-known/oauth-protected-resource",
			inputSchema: {
				queryParams: oauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet({
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet",
		{
			description:
				"Make a GET request to /.well-known/oauth-protected-resource/{mcp_server_name}/mcp",
			inputSchema: {
				mcpServerName:
					oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParamsSchema
						.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet",
		{
			description: "Make a GET request to /.well-known/oauth-authorization-server",
			inputSchema: {
				queryParams:
					oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParamsSchema,
			},
		},
		async ({ queryParams }) => {
			try {
				return await oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet({
					queryParams,
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet",
		{
			description:
				"Make a GET request to /.well-known/oauth-authorization-server/{mcp_server_name}",
			inputSchema: {
				mcpServerName:
					oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParamsSchema
						.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"openidConfigurationWellKnownOpenidConfigurationGet",
		{ description: "Make a GET request to /.well-known/openid-configuration" },
		async () => {
			try {
				return await openidConfigurationWellKnownOpenidConfigurationGet({ config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet",
		{
			description:
				"Make a GET request to /.well-known/oauth-authorization-server/{mcp_server_name}/mcp",
			inputSchema: {
				mcpServerName:
					oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParamsSchema
						.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet(
					{ pathParams: { mcpServerName }, config },
				);
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"registerClientRegisterPost",
		{
			description: "Make a POST request to /register",
			inputSchema: { queryParams: registerClientRegisterPostQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await registerClientRegisterPost({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"registerClientMcpServerNameRegisterPost",
		{
			description: "Make a POST request to /{mcp_server_name}/register",
			inputSchema: {
				mcpServerName:
					registerClientMcpServerNameRegisterPostPathParamsSchema.shape["mcp_server_name"],
			},
		},
		async ({ mcpServerName }) => {
			try {
				return await registerClientMcpServerNameRegisterPost({
					pathParams: { mcpServerName },
					config,
				});
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"websocketVertexAiLivePassthroughEndpoint",
		{
			description: "WebSocket connection endpoint",
			inputSchema: { queryParams: websocketVertexAiLivePassthroughEndpointQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await websocketVertexAiLivePassthroughEndpoint({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"websocketWebsocketEndpoint",
		{
			description: "WebSocket connection endpoint",
			inputSchema: { queryParams: websocketWebsocketEndpointQueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await websocketWebsocketEndpoint({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);

	server.registerTool(
		"websocketWebsocketEndpoint2",
		{
			description: "WebSocket connection endpoint",
			inputSchema: { queryParams: websocketWebsocketEndpoint2QueryParamsSchema },
		},
		async ({ queryParams }) => {
			try {
				return await websocketWebsocketEndpoint2({ queryParams, config });
			} catch (error) {
				return { isError: true, content: [{ type: "text", text: JSON.stringify(error) }] };
			}
		},
	);
}
