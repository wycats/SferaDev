/**
 * Generated by @openapi-codegen
 *
 * @version 1.79.3
 */
import type * as Fetcher from "./fetcher";
import { type FetcherExtraProps, fetch } from "./fetcher";
import type * as Schemas from "./schemas";

export type ModelListModelsGetQueryParams = {
	/**
	 * @default false
	 */
	return_wildcard_routes?: boolean | null;
	team_id?: string | null;
	/**
	 * @default false
	 */
	include_model_access_groups?: boolean | null;
	/**
	 * @default false
	 */
	only_model_access_groups?: boolean | null;
	/**
	 * @default false
	 */
	include_metadata?: boolean | null;
	fallback_type?: string | null;
};

export type ModelListModelsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelListModelsGetResponse = {
	[key: string]: any;
};

export type ModelListModelsGetVariables = {
	queryParams?: ModelListModelsGetQueryParams;
} & FetcherExtraProps;

/**
 * Use `/model/info` - to get detailed model information, example - pricing, mode, etc.
 *
 * This is just for compatibility with openai projects like aider.
 *
 * Query Parameters:
 * - include_metadata: Include additional metadata in the response with fallback information
 * - fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")
 *                 Defaults to "general" when include_metadata=true
 */
export const modelListModelsGet = (variables: ModelListModelsGetVariables, signal?: AbortSignal) =>
	fetch<
		ModelListModelsGetResponse,
		ModelListModelsGetError,
		undefined,
		{},
		ModelListModelsGetQueryParams,
		{}
	>({ url: "/models", method: "get", ...variables, signal });

export type ModelListV1ModelsGetQueryParams = {
	/**
	 * @default false
	 */
	return_wildcard_routes?: boolean | null;
	team_id?: string | null;
	/**
	 * @default false
	 */
	include_model_access_groups?: boolean | null;
	/**
	 * @default false
	 */
	only_model_access_groups?: boolean | null;
	/**
	 * @default false
	 */
	include_metadata?: boolean | null;
	fallback_type?: string | null;
};

export type ModelListV1ModelsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelListV1ModelsGetResponse = {
	[key: string]: any;
};

export type ModelListV1ModelsGetVariables = {
	queryParams?: ModelListV1ModelsGetQueryParams;
} & FetcherExtraProps;

/**
 * Use `/model/info` - to get detailed model information, example - pricing, mode, etc.
 *
 * This is just for compatibility with openai projects like aider.
 *
 * Query Parameters:
 * - include_metadata: Include additional metadata in the response with fallback information
 * - fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")
 *                 Defaults to "general" when include_metadata=true
 */
export const modelListV1ModelsGet = (
	variables: ModelListV1ModelsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModelListV1ModelsGetResponse,
		ModelListV1ModelsGetError,
		undefined,
		{},
		ModelListV1ModelsGetQueryParams,
		{}
	>({ url: "/v1/models", method: "get", ...variables, signal });

export type ModelInfoModelsModelIdGetPathParams = {
	modelId: string;
};

export type ModelInfoModelsModelIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelInfoModelsModelIdGetResponse = {
	[key: string]: any;
};

export type ModelInfoModelsModelIdGetVariables = {
	pathParams: ModelInfoModelsModelIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieve information about a specific model accessible to your API key.
 *
 * Returns model details only if the model is available to your API key/team.
 * Returns 404 if the model doesn't exist or is not accessible.
 *
 * Follows OpenAI API specification for individual model retrieval.
 * https://platform.openai.com/docs/api-reference/models/retrieve
 */
export const modelInfoModelsModelIdGet = (
	variables: ModelInfoModelsModelIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModelInfoModelsModelIdGetResponse,
		ModelInfoModelsModelIdGetError,
		undefined,
		{},
		{},
		ModelInfoModelsModelIdGetPathParams
	>({ url: "/models/{modelId}", method: "get", ...variables, signal });

export type ModelInfoV1ModelsModelIdGetPathParams = {
	modelId: string;
};

export type ModelInfoV1ModelsModelIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelInfoV1ModelsModelIdGetResponse = {
	[key: string]: any;
};

export type ModelInfoV1ModelsModelIdGetVariables = {
	pathParams: ModelInfoV1ModelsModelIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieve information about a specific model accessible to your API key.
 *
 * Returns model details only if the model is available to your API key/team.
 * Returns 404 if the model doesn't exist or is not accessible.
 *
 * Follows OpenAI API specification for individual model retrieval.
 * https://platform.openai.com/docs/api-reference/models/retrieve
 */
export const modelInfoV1ModelsModelIdGet = (
	variables: ModelInfoV1ModelsModelIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModelInfoV1ModelsModelIdGetResponse,
		ModelInfoV1ModelsModelIdGetError,
		undefined,
		{},
		{},
		ModelInfoV1ModelsModelIdGetPathParams
	>({ url: "/v1/models/{modelId}", method: "get", ...variables, signal });

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams = {
	model: string | null;
};

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostError = Fetcher.ErrorWrapper<
	| {
			status: 400;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 401;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 403;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 404;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 408;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 422;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 429;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 500;
			payload: Schemas.ErrorResponse;
	  }
	| {
			status: 503;
			payload: Schemas.ErrorResponse;
	  }
>;

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostResponse = {
	[key: string]: any;
};

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostRequestBody = {
	model: string;
	/**
	 * @example {"role":"user","content":"Hello, how are you?"}
	 */
	messages: (
		| Schemas.ChatCompletionUserMessage
		| Schemas.ChatCompletionAssistantMessage
		| Schemas.ChatCompletionToolMessage
		| Schemas.ChatCompletionSystemMessage
		| Schemas.ChatCompletionFunctionMessage
		| Schemas.ChatCompletionDeveloperMessage
	)[];
	/**
	 * @default null
	 */
	frequency_penalty?: number | null;
	/**
	 * @default null
	 */
	logit_bias?: {
		[key: string]: number;
	} | null;
	/**
	 * @default null
	 */
	logprobs?: boolean | null;
	/**
	 * @default null
	 */
	top_logprobs?: number | null;
	/**
	 * @default null
	 */
	max_tokens?: number | null;
	/**
	 * @default null
	 */
	n?: number | null;
	/**
	 * @default null
	 */
	presence_penalty?: number | null;
	/**
	 * @default null
	 */
	response_format?: Record<string, any> | null;
	/**
	 * @default null
	 */
	seed?: number | null;
	/**
	 * @default null
	 */
	service_tier?: string | null;
	/**
	 * @default null
	 */
	stop?: string | string[] | null;
	/**
	 * @default null
	 */
	stream_options?: Record<string, any> | null;
	/**
	 * @default null
	 */
	temperature?: number | null;
	/**
	 * @default null
	 */
	top_p?: number | null;
	/**
	 * @default null
	 */
	tools?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	tool_choice?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	parallel_tool_calls?: boolean | null;
	/**
	 * @default null
	 */
	function_call?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	functions?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	stream?: boolean | null;
	/**
	 * @default null
	 */
	metadata?: Record<string, any> | null;
	/**
	 * @default null
	 */
	guardrails?: string[] | null;
	/**
	 * @default null
	 */
	caching?: boolean | null;
	/**
	 * @default null
	 */
	num_retries?: number | null;
	/**
	 * @default null
	 */
	context_window_fallback_dict?: {
		[key: string]: string;
	} | null;
	/**
	 * @default null
	 */
	fallbacks?: string[] | null;
};

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostVariables = {
	body: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostRequestBody;
	pathParams: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionOpenaiDeploymentsModelChatCompletionsPost = (
	variables: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostResponse,
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostError,
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostRequestBody,
		{},
		{},
		ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams
	>({
		url: "/openai/deployments/{model}/chat/completions",
		method: "post",
		...variables,
		signal,
	});

export type ChatCompletionEnginesModelChatCompletionsPostPathParams = {
	model: string | null;
};

export type ChatCompletionEnginesModelChatCompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ChatCompletionEnginesModelChatCompletionsPostResponse = {
	[key: string]: any;
};

export type ChatCompletionEnginesModelChatCompletionsPostRequestBody = {
	model: string;
	/**
	 * @example {"role":"user","content":"Hello, how are you?"}
	 */
	messages: (
		| Schemas.ChatCompletionUserMessage
		| Schemas.ChatCompletionAssistantMessage
		| Schemas.ChatCompletionToolMessage
		| Schemas.ChatCompletionSystemMessage
		| Schemas.ChatCompletionFunctionMessage
		| Schemas.ChatCompletionDeveloperMessage
	)[];
	/**
	 * @default null
	 */
	frequency_penalty?: number | null;
	/**
	 * @default null
	 */
	logit_bias?: {
		[key: string]: number;
	} | null;
	/**
	 * @default null
	 */
	logprobs?: boolean | null;
	/**
	 * @default null
	 */
	top_logprobs?: number | null;
	/**
	 * @default null
	 */
	max_tokens?: number | null;
	/**
	 * @default null
	 */
	n?: number | null;
	/**
	 * @default null
	 */
	presence_penalty?: number | null;
	/**
	 * @default null
	 */
	response_format?: Record<string, any> | null;
	/**
	 * @default null
	 */
	seed?: number | null;
	/**
	 * @default null
	 */
	service_tier?: string | null;
	/**
	 * @default null
	 */
	stop?: string | string[] | null;
	/**
	 * @default null
	 */
	stream_options?: Record<string, any> | null;
	/**
	 * @default null
	 */
	temperature?: number | null;
	/**
	 * @default null
	 */
	top_p?: number | null;
	/**
	 * @default null
	 */
	tools?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	tool_choice?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	parallel_tool_calls?: boolean | null;
	/**
	 * @default null
	 */
	function_call?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	functions?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	stream?: boolean | null;
	/**
	 * @default null
	 */
	metadata?: Record<string, any> | null;
	/**
	 * @default null
	 */
	guardrails?: string[] | null;
	/**
	 * @default null
	 */
	caching?: boolean | null;
	/**
	 * @default null
	 */
	num_retries?: number | null;
	/**
	 * @default null
	 */
	context_window_fallback_dict?: {
		[key: string]: string;
	} | null;
	/**
	 * @default null
	 */
	fallbacks?: string[] | null;
};

export type ChatCompletionEnginesModelChatCompletionsPostVariables = {
	body: ChatCompletionEnginesModelChatCompletionsPostRequestBody;
	pathParams: ChatCompletionEnginesModelChatCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionEnginesModelChatCompletionsPost = (
	variables: ChatCompletionEnginesModelChatCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ChatCompletionEnginesModelChatCompletionsPostResponse,
		ChatCompletionEnginesModelChatCompletionsPostError,
		ChatCompletionEnginesModelChatCompletionsPostRequestBody,
		{},
		{},
		ChatCompletionEnginesModelChatCompletionsPostPathParams
	>({
		url: "/engines/{model}/chat/completions",
		method: "post",
		...variables,
		signal,
	});

export type ChatCompletionChatCompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ChatCompletionChatCompletionsPostResponse = {
	[key: string]: any;
};

export type ChatCompletionChatCompletionsPostRequestBody = {
	model: string;
	/**
	 * @example {"role":"user","content":"Hello, how are you?"}
	 */
	messages: (
		| Schemas.ChatCompletionUserMessage
		| Schemas.ChatCompletionAssistantMessage
		| Schemas.ChatCompletionToolMessage
		| Schemas.ChatCompletionSystemMessage
		| Schemas.ChatCompletionFunctionMessage
		| Schemas.ChatCompletionDeveloperMessage
	)[];
	/**
	 * @default null
	 */
	frequency_penalty?: number | null;
	/**
	 * @default null
	 */
	logit_bias?: {
		[key: string]: number;
	} | null;
	/**
	 * @default null
	 */
	logprobs?: boolean | null;
	/**
	 * @default null
	 */
	top_logprobs?: number | null;
	/**
	 * @default null
	 */
	max_tokens?: number | null;
	/**
	 * @default null
	 */
	n?: number | null;
	/**
	 * @default null
	 */
	presence_penalty?: number | null;
	/**
	 * @default null
	 */
	response_format?: Record<string, any> | null;
	/**
	 * @default null
	 */
	seed?: number | null;
	/**
	 * @default null
	 */
	service_tier?: string | null;
	/**
	 * @default null
	 */
	stop?: string | string[] | null;
	/**
	 * @default null
	 */
	stream_options?: Record<string, any> | null;
	/**
	 * @default null
	 */
	temperature?: number | null;
	/**
	 * @default null
	 */
	top_p?: number | null;
	/**
	 * @default null
	 */
	tools?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	tool_choice?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	parallel_tool_calls?: boolean | null;
	/**
	 * @default null
	 */
	function_call?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	functions?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	stream?: boolean | null;
	/**
	 * @default null
	 */
	metadata?: Record<string, any> | null;
	/**
	 * @default null
	 */
	guardrails?: string[] | null;
	/**
	 * @default null
	 */
	caching?: boolean | null;
	/**
	 * @default null
	 */
	num_retries?: number | null;
	/**
	 * @default null
	 */
	context_window_fallback_dict?: {
		[key: string]: string;
	} | null;
	/**
	 * @default null
	 */
	fallbacks?: string[] | null;
};

export type ChatCompletionChatCompletionsPostVariables = {
	body: ChatCompletionChatCompletionsPostRequestBody;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionChatCompletionsPost = (
	variables: ChatCompletionChatCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ChatCompletionChatCompletionsPostResponse,
		ChatCompletionChatCompletionsPostError,
		ChatCompletionChatCompletionsPostRequestBody,
		{},
		{},
		{}
	>({ url: "/chat/completions", method: "post", ...variables, signal });

export type ChatCompletionV1ChatCompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ChatCompletionV1ChatCompletionsPostResponse = {
	[key: string]: any;
};

export type ChatCompletionV1ChatCompletionsPostRequestBody = {
	model: string;
	/**
	 * @example {"role":"user","content":"Hello, how are you?"}
	 */
	messages: (
		| Schemas.ChatCompletionUserMessage
		| Schemas.ChatCompletionAssistantMessage
		| Schemas.ChatCompletionToolMessage
		| Schemas.ChatCompletionSystemMessage
		| Schemas.ChatCompletionFunctionMessage
		| Schemas.ChatCompletionDeveloperMessage
	)[];
	/**
	 * @default null
	 */
	frequency_penalty?: number | null;
	/**
	 * @default null
	 */
	logit_bias?: {
		[key: string]: number;
	} | null;
	/**
	 * @default null
	 */
	logprobs?: boolean | null;
	/**
	 * @default null
	 */
	top_logprobs?: number | null;
	/**
	 * @default null
	 */
	max_tokens?: number | null;
	/**
	 * @default null
	 */
	n?: number | null;
	/**
	 * @default null
	 */
	presence_penalty?: number | null;
	/**
	 * @default null
	 */
	response_format?: Record<string, any> | null;
	/**
	 * @default null
	 */
	seed?: number | null;
	/**
	 * @default null
	 */
	service_tier?: string | null;
	/**
	 * @default null
	 */
	stop?: string | string[] | null;
	/**
	 * @default null
	 */
	stream_options?: Record<string, any> | null;
	/**
	 * @default null
	 */
	temperature?: number | null;
	/**
	 * @default null
	 */
	top_p?: number | null;
	/**
	 * @default null
	 */
	tools?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	tool_choice?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	parallel_tool_calls?: boolean | null;
	/**
	 * @default null
	 */
	function_call?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	functions?: Record<string, any>[] | null;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	stream?: boolean | null;
	/**
	 * @default null
	 */
	metadata?: Record<string, any> | null;
	/**
	 * @default null
	 */
	guardrails?: string[] | null;
	/**
	 * @default null
	 */
	caching?: boolean | null;
	/**
	 * @default null
	 */
	num_retries?: number | null;
	/**
	 * @default null
	 */
	context_window_fallback_dict?: {
		[key: string]: string;
	} | null;
	/**
	 * @default null
	 */
	fallbacks?: string[] | null;
};

export type ChatCompletionV1ChatCompletionsPostVariables = {
	body: ChatCompletionV1ChatCompletionsPostRequestBody;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionV1ChatCompletionsPost = (
	variables: ChatCompletionV1ChatCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ChatCompletionV1ChatCompletionsPostResponse,
		ChatCompletionV1ChatCompletionsPostError,
		ChatCompletionV1ChatCompletionsPostRequestBody,
		{},
		{},
		{}
	>({ url: "/v1/chat/completions", method: "post", ...variables, signal });

export type CompletionOpenaiDeploymentsModelCompletionsPostPathParams = {
	model: string | null;
};

export type CompletionOpenaiDeploymentsModelCompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CompletionOpenaiDeploymentsModelCompletionsPostResponse = {
	[key: string]: any;
};

export type CompletionOpenaiDeploymentsModelCompletionsPostVariables = {
	pathParams: CompletionOpenaiDeploymentsModelCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionOpenaiDeploymentsModelCompletionsPost = (
	variables: CompletionOpenaiDeploymentsModelCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CompletionOpenaiDeploymentsModelCompletionsPostResponse,
		CompletionOpenaiDeploymentsModelCompletionsPostError,
		undefined,
		{},
		{},
		CompletionOpenaiDeploymentsModelCompletionsPostPathParams
	>({
		url: "/openai/deployments/{model}/completions",
		method: "post",
		...variables,
		signal,
	});

export type CompletionEnginesModelCompletionsPostPathParams = {
	model: string | null;
};

export type CompletionEnginesModelCompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CompletionEnginesModelCompletionsPostResponse = {
	[key: string]: any;
};

export type CompletionEnginesModelCompletionsPostVariables = {
	pathParams: CompletionEnginesModelCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionEnginesModelCompletionsPost = (
	variables: CompletionEnginesModelCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CompletionEnginesModelCompletionsPostResponse,
		CompletionEnginesModelCompletionsPostError,
		undefined,
		{},
		{},
		CompletionEnginesModelCompletionsPostPathParams
	>({
		url: "/engines/{model}/completions",
		method: "post",
		...variables,
		signal,
	});

export type CompletionCompletionsPostQueryParams = {
	model?: string | null;
};

export type CompletionCompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CompletionCompletionsPostResponse = {
	[key: string]: any;
};

export type CompletionCompletionsPostVariables = {
	queryParams?: CompletionCompletionsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionCompletionsPost = (
	variables: CompletionCompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CompletionCompletionsPostResponse,
		CompletionCompletionsPostError,
		undefined,
		{},
		CompletionCompletionsPostQueryParams,
		{}
	>({ url: "/completions", method: "post", ...variables, signal });

export type CompletionV1CompletionsPostQueryParams = {
	model?: string | null;
};

export type CompletionV1CompletionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CompletionV1CompletionsPostResponse = {
	[key: string]: any;
};

export type CompletionV1CompletionsPostVariables = {
	queryParams?: CompletionV1CompletionsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionV1CompletionsPost = (
	variables: CompletionV1CompletionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CompletionV1CompletionsPostResponse,
		CompletionV1CompletionsPostError,
		undefined,
		{},
		CompletionV1CompletionsPostQueryParams,
		{}
	>({ url: "/v1/completions", method: "post", ...variables, signal });

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams = {
	model: string | null;
};

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostResponse = {
	[key: string]: any;
};

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostRequestBody = {
	model: string;
	input?: string[];
	/**
	 * @default 600
	 */
	timeout?: number;
	/**
	 * @default null
	 */
	api_base?: string | null;
	/**
	 * @default null
	 */
	api_version?: string | null;
	/**
	 * @default null
	 */
	api_key?: string | null;
	/**
	 * @default null
	 */
	api_type?: string | null;
	/**
	 * @default false
	 */
	caching?: boolean;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	custom_llm_provider?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	litellm_call_id?: string | null;
	/**
	 * @default null
	 */
	litellm_logging_obj?: Record<string, any> | null;
	/**
	 * @default null
	 */
	logger_fn?: string | null;
};

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostVariables = {
	body: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostRequestBody;
	pathParams: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsOpenaiDeploymentsModelEmbeddingsPost = (
	variables: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostResponse,
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostError,
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostRequestBody,
		{},
		{},
		EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams
	>({
		url: "/openai/deployments/{model}/embeddings",
		method: "post",
		...variables,
		signal,
	});

export type EmbeddingsEnginesModelEmbeddingsPostPathParams = {
	model: string | null;
};

export type EmbeddingsEnginesModelEmbeddingsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsEnginesModelEmbeddingsPostResponse = {
	[key: string]: any;
};

export type EmbeddingsEnginesModelEmbeddingsPostRequestBody = {
	model: string;
	input?: string[];
	/**
	 * @default 600
	 */
	timeout?: number;
	/**
	 * @default null
	 */
	api_base?: string | null;
	/**
	 * @default null
	 */
	api_version?: string | null;
	/**
	 * @default null
	 */
	api_key?: string | null;
	/**
	 * @default null
	 */
	api_type?: string | null;
	/**
	 * @default false
	 */
	caching?: boolean;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	custom_llm_provider?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	litellm_call_id?: string | null;
	/**
	 * @default null
	 */
	litellm_logging_obj?: Record<string, any> | null;
	/**
	 * @default null
	 */
	logger_fn?: string | null;
};

export type EmbeddingsEnginesModelEmbeddingsPostVariables = {
	body: EmbeddingsEnginesModelEmbeddingsPostRequestBody;
	pathParams: EmbeddingsEnginesModelEmbeddingsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsEnginesModelEmbeddingsPost = (
	variables: EmbeddingsEnginesModelEmbeddingsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		EmbeddingsEnginesModelEmbeddingsPostResponse,
		EmbeddingsEnginesModelEmbeddingsPostError,
		EmbeddingsEnginesModelEmbeddingsPostRequestBody,
		{},
		{},
		EmbeddingsEnginesModelEmbeddingsPostPathParams
	>({
		url: "/engines/{model}/embeddings",
		method: "post",
		...variables,
		signal,
	});

export type EmbeddingsEmbeddingsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsEmbeddingsPostResponse = {
	[key: string]: any;
};

export type EmbeddingsEmbeddingsPostRequestBody = {
	model: string;
	input?: string[];
	/**
	 * @default 600
	 */
	timeout?: number;
	/**
	 * @default null
	 */
	api_base?: string | null;
	/**
	 * @default null
	 */
	api_version?: string | null;
	/**
	 * @default null
	 */
	api_key?: string | null;
	/**
	 * @default null
	 */
	api_type?: string | null;
	/**
	 * @default false
	 */
	caching?: boolean;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	custom_llm_provider?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	litellm_call_id?: string | null;
	/**
	 * @default null
	 */
	litellm_logging_obj?: Record<string, any> | null;
	/**
	 * @default null
	 */
	logger_fn?: string | null;
};

export type EmbeddingsEmbeddingsPostVariables = {
	body: EmbeddingsEmbeddingsPostRequestBody;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsEmbeddingsPost = (
	variables: EmbeddingsEmbeddingsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		EmbeddingsEmbeddingsPostResponse,
		EmbeddingsEmbeddingsPostError,
		EmbeddingsEmbeddingsPostRequestBody,
		{},
		{},
		{}
	>({ url: "/embeddings", method: "post", ...variables, signal });

export type EmbeddingsV1EmbeddingsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsV1EmbeddingsPostResponse = {
	[key: string]: any;
};

export type EmbeddingsV1EmbeddingsPostRequestBody = {
	model: string;
	input?: string[];
	/**
	 * @default 600
	 */
	timeout?: number;
	/**
	 * @default null
	 */
	api_base?: string | null;
	/**
	 * @default null
	 */
	api_version?: string | null;
	/**
	 * @default null
	 */
	api_key?: string | null;
	/**
	 * @default null
	 */
	api_type?: string | null;
	/**
	 * @default false
	 */
	caching?: boolean;
	/**
	 * @default null
	 */
	user?: string | null;
	/**
	 * @default null
	 */
	custom_llm_provider?: string | Record<string, any> | null;
	/**
	 * @default null
	 */
	litellm_call_id?: string | null;
	/**
	 * @default null
	 */
	litellm_logging_obj?: Record<string, any> | null;
	/**
	 * @default null
	 */
	logger_fn?: string | null;
};

export type EmbeddingsV1EmbeddingsPostVariables = {
	body: EmbeddingsV1EmbeddingsPostRequestBody;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsV1EmbeddingsPost = (
	variables: EmbeddingsV1EmbeddingsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		EmbeddingsV1EmbeddingsPostResponse,
		EmbeddingsV1EmbeddingsPostError,
		EmbeddingsV1EmbeddingsPostRequestBody,
		{},
		{},
		{}
	>({ url: "/v1/embeddings", method: "post", ...variables, signal });

export type ModerationsModerationsPostError = Fetcher.ErrorWrapper<undefined>;

export type ModerationsModerationsPostResponse = {
	[key: string]: any;
};

export type ModerationsModerationsPostVariables = FetcherExtraProps;

/**
 * The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.
 * Quick Start
 * ```
 * curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'
 * ```
 */
export const moderationsModerationsPost = (
	variables: ModerationsModerationsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<ModerationsModerationsPostResponse, ModerationsModerationsPostError, undefined, {}, {}, {}>(
		{ url: "/moderations", method: "post", ...variables, signal },
	);

export type ModerationsV1ModerationsPostError = Fetcher.ErrorWrapper<undefined>;

export type ModerationsV1ModerationsPostResponse = {
	[key: string]: any;
};

export type ModerationsV1ModerationsPostVariables = FetcherExtraProps;

/**
 * The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.
 * Quick Start
 * ```
 * curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'
 * ```
 */
export const moderationsV1ModerationsPost = (
	variables: ModerationsV1ModerationsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModerationsV1ModerationsPostResponse,
		ModerationsV1ModerationsPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/moderations", method: "post", ...variables, signal });

export type AudioSpeechAudioSpeechPostError = Fetcher.ErrorWrapper<undefined>;

export type AudioSpeechAudioSpeechPostResponse = {
	[key: string]: any;
};

export type AudioSpeechAudioSpeechPostVariables = FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createSpeech
 */
export const audioSpeechAudioSpeechPost = (
	variables: AudioSpeechAudioSpeechPostVariables,
	signal?: AbortSignal,
) =>
	fetch<AudioSpeechAudioSpeechPostResponse, AudioSpeechAudioSpeechPostError, undefined, {}, {}, {}>(
		{ url: "/audio/speech", method: "post", ...variables, signal },
	);

export type AudioSpeechV1AudioSpeechPostError = Fetcher.ErrorWrapper<undefined>;

export type AudioSpeechV1AudioSpeechPostResponse = {
	[key: string]: any;
};

export type AudioSpeechV1AudioSpeechPostVariables = FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createSpeech
 */
export const audioSpeechV1AudioSpeechPost = (
	variables: AudioSpeechV1AudioSpeechPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AudioSpeechV1AudioSpeechPostResponse,
		AudioSpeechV1AudioSpeechPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/audio/speech", method: "post", ...variables, signal });

export type AudioTranscriptionsAudioTranscriptionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AudioTranscriptionsAudioTranscriptionsPostResponse = {
	[key: string]: any;
};

export type AudioTranscriptionsAudioTranscriptionsPostVariables = {
	body: Schemas.BodyAudioTranscriptionsAudioTranscriptionsPost;
} & FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 */
export const audioTranscriptionsAudioTranscriptionsPost = (
	variables: AudioTranscriptionsAudioTranscriptionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AudioTranscriptionsAudioTranscriptionsPostResponse,
		AudioTranscriptionsAudioTranscriptionsPostError,
		Schemas.BodyAudioTranscriptionsAudioTranscriptionsPost,
		{},
		{},
		{}
	>({ url: "/audio/transcriptions", method: "post", ...variables, signal });

export type AudioTranscriptionsV1AudioTranscriptionsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AudioTranscriptionsV1AudioTranscriptionsPostResponse = {
	[key: string]: any;
};

export type AudioTranscriptionsV1AudioTranscriptionsPostVariables = {
	body: Schemas.BodyAudioTranscriptionsV1AudioTranscriptionsPost;
} & FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 */
export const audioTranscriptionsV1AudioTranscriptionsPost = (
	variables: AudioTranscriptionsV1AudioTranscriptionsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AudioTranscriptionsV1AudioTranscriptionsPostResponse,
		AudioTranscriptionsV1AudioTranscriptionsPostError,
		Schemas.BodyAudioTranscriptionsV1AudioTranscriptionsPost,
		{},
		{},
		{}
	>({ url: "/v1/audio/transcriptions", method: "post", ...variables, signal });

export type GetAssistantsAssistantsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetAssistantsAssistantsGetResponse = {
	[key: string]: any;
};

export type GetAssistantsAssistantsGetVariables = FetcherExtraProps;

/**
 * Returns a list of assistants.
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 */
export const getAssistantsAssistantsGet = (
	variables: GetAssistantsAssistantsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<GetAssistantsAssistantsGetResponse, GetAssistantsAssistantsGetError, undefined, {}, {}, {}>(
		{ url: "/assistants", method: "get", ...variables, signal },
	);

export type CreateAssistantAssistantsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateAssistantAssistantsPostResponse = {
	[key: string]: any;
};

export type CreateAssistantAssistantsPostVariables = FetcherExtraProps;

/**
 * Create assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const createAssistantAssistantsPost = (
	variables: CreateAssistantAssistantsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateAssistantAssistantsPostResponse,
		CreateAssistantAssistantsPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/assistants", method: "post", ...variables, signal });

export type GetAssistantsV1AssistantsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetAssistantsV1AssistantsGetResponse = {
	[key: string]: any;
};

export type GetAssistantsV1AssistantsGetVariables = FetcherExtraProps;

/**
 * Returns a list of assistants.
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 */
export const getAssistantsV1AssistantsGet = (
	variables: GetAssistantsV1AssistantsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetAssistantsV1AssistantsGetResponse,
		GetAssistantsV1AssistantsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/assistants", method: "get", ...variables, signal });

export type CreateAssistantV1AssistantsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateAssistantV1AssistantsPostResponse = {
	[key: string]: any;
};

export type CreateAssistantV1AssistantsPostVariables = FetcherExtraProps;

/**
 * Create assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const createAssistantV1AssistantsPost = (
	variables: CreateAssistantV1AssistantsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateAssistantV1AssistantsPostResponse,
		CreateAssistantV1AssistantsPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/assistants", method: "post", ...variables, signal });

export type DeleteAssistantAssistantsAssistantIdDeletePathParams = {
	assistantId: string;
};

export type DeleteAssistantAssistantsAssistantIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteAssistantAssistantsAssistantIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteAssistantAssistantsAssistantIdDeleteVariables = {
	pathParams: DeleteAssistantAssistantsAssistantIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const deleteAssistantAssistantsAssistantIdDelete = (
	variables: DeleteAssistantAssistantsAssistantIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteAssistantAssistantsAssistantIdDeleteResponse,
		DeleteAssistantAssistantsAssistantIdDeleteError,
		undefined,
		{},
		{},
		DeleteAssistantAssistantsAssistantIdDeletePathParams
	>({
		url: "/assistants/{assistantId}",
		method: "delete",
		...variables,
		signal,
	});

export type DeleteAssistantV1AssistantsAssistantIdDeletePathParams = {
	assistantId: string;
};

export type DeleteAssistantV1AssistantsAssistantIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteAssistantV1AssistantsAssistantIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteAssistantV1AssistantsAssistantIdDeleteVariables = {
	pathParams: DeleteAssistantV1AssistantsAssistantIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const deleteAssistantV1AssistantsAssistantIdDelete = (
	variables: DeleteAssistantV1AssistantsAssistantIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteAssistantV1AssistantsAssistantIdDeleteResponse,
		DeleteAssistantV1AssistantsAssistantIdDeleteError,
		undefined,
		{},
		{},
		DeleteAssistantV1AssistantsAssistantIdDeletePathParams
	>({
		url: "/v1/assistants/{assistantId}",
		method: "delete",
		...variables,
		signal,
	});

export type CreateThreadsThreadsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateThreadsThreadsPostResponse = {
	[key: string]: any;
};

export type CreateThreadsThreadsPostVariables = FetcherExtraProps;

/**
 * Create a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 */
export const createThreadsThreadsPost = (
	variables: CreateThreadsThreadsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<CreateThreadsThreadsPostResponse, CreateThreadsThreadsPostError, undefined, {}, {}, {}>({
		url: "/threads",
		method: "post",
		...variables,
		signal,
	});

export type CreateThreadsV1ThreadsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateThreadsV1ThreadsPostResponse = {
	[key: string]: any;
};

export type CreateThreadsV1ThreadsPostVariables = FetcherExtraProps;

/**
 * Create a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 */
export const createThreadsV1ThreadsPost = (
	variables: CreateThreadsV1ThreadsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<CreateThreadsV1ThreadsPostResponse, CreateThreadsV1ThreadsPostError, undefined, {}, {}, {}>(
		{ url: "/v1/threads", method: "post", ...variables, signal },
	);

export type GetThreadThreadsThreadIdGetPathParams = {
	threadId: string;
};

export type GetThreadThreadsThreadIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetThreadThreadsThreadIdGetResponse = {
	[key: string]: any;
};

export type GetThreadThreadsThreadIdGetVariables = {
	pathParams: GetThreadThreadsThreadIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieves a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 */
export const getThreadThreadsThreadIdGet = (
	variables: GetThreadThreadsThreadIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetThreadThreadsThreadIdGetResponse,
		GetThreadThreadsThreadIdGetError,
		undefined,
		{},
		{},
		GetThreadThreadsThreadIdGetPathParams
	>({ url: "/threads/{threadId}", method: "get", ...variables, signal });

export type GetThreadV1ThreadsThreadIdGetPathParams = {
	threadId: string;
};

export type GetThreadV1ThreadsThreadIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetThreadV1ThreadsThreadIdGetResponse = {
	[key: string]: any;
};

export type GetThreadV1ThreadsThreadIdGetVariables = {
	pathParams: GetThreadV1ThreadsThreadIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieves a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 */
export const getThreadV1ThreadsThreadIdGet = (
	variables: GetThreadV1ThreadsThreadIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetThreadV1ThreadsThreadIdGetResponse,
		GetThreadV1ThreadsThreadIdGetError,
		undefined,
		{},
		{},
		GetThreadV1ThreadsThreadIdGetPathParams
	>({ url: "/v1/threads/{threadId}", method: "get", ...variables, signal });

export type AddMessagesThreadsThreadIdMessagesPostPathParams = {
	threadId: string;
};

export type AddMessagesThreadsThreadIdMessagesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AddMessagesThreadsThreadIdMessagesPostResponse = {
	[key: string]: any;
};

export type AddMessagesThreadsThreadIdMessagesPostVariables = {
	pathParams: AddMessagesThreadsThreadIdMessagesPostPathParams;
} & FetcherExtraProps;

/**
 * Create a message.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 */
export const addMessagesThreadsThreadIdMessagesPost = (
	variables: AddMessagesThreadsThreadIdMessagesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AddMessagesThreadsThreadIdMessagesPostResponse,
		AddMessagesThreadsThreadIdMessagesPostError,
		undefined,
		{},
		{},
		AddMessagesThreadsThreadIdMessagesPostPathParams
	>({
		url: "/threads/{threadId}/messages",
		method: "post",
		...variables,
		signal,
	});

export type GetMessagesThreadsThreadIdMessagesGetPathParams = {
	threadId: string;
};

export type GetMessagesThreadsThreadIdMessagesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetMessagesThreadsThreadIdMessagesGetResponse = {
	[key: string]: any;
};

export type GetMessagesThreadsThreadIdMessagesGetVariables = {
	pathParams: GetMessagesThreadsThreadIdMessagesGetPathParams;
} & FetcherExtraProps;

/**
 * Returns a list of messages for a given thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 */
export const getMessagesThreadsThreadIdMessagesGet = (
	variables: GetMessagesThreadsThreadIdMessagesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetMessagesThreadsThreadIdMessagesGetResponse,
		GetMessagesThreadsThreadIdMessagesGetError,
		undefined,
		{},
		{},
		GetMessagesThreadsThreadIdMessagesGetPathParams
	>({
		url: "/threads/{threadId}/messages",
		method: "get",
		...variables,
		signal,
	});

export type AddMessagesV1ThreadsThreadIdMessagesPostPathParams = {
	threadId: string;
};

export type AddMessagesV1ThreadsThreadIdMessagesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AddMessagesV1ThreadsThreadIdMessagesPostResponse = {
	[key: string]: any;
};

export type AddMessagesV1ThreadsThreadIdMessagesPostVariables = {
	pathParams: AddMessagesV1ThreadsThreadIdMessagesPostPathParams;
} & FetcherExtraProps;

/**
 * Create a message.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 */
export const addMessagesV1ThreadsThreadIdMessagesPost = (
	variables: AddMessagesV1ThreadsThreadIdMessagesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AddMessagesV1ThreadsThreadIdMessagesPostResponse,
		AddMessagesV1ThreadsThreadIdMessagesPostError,
		undefined,
		{},
		{},
		AddMessagesV1ThreadsThreadIdMessagesPostPathParams
	>({
		url: "/v1/threads/{threadId}/messages",
		method: "post",
		...variables,
		signal,
	});

export type GetMessagesV1ThreadsThreadIdMessagesGetPathParams = {
	threadId: string;
};

export type GetMessagesV1ThreadsThreadIdMessagesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetMessagesV1ThreadsThreadIdMessagesGetResponse = {
	[key: string]: any;
};

export type GetMessagesV1ThreadsThreadIdMessagesGetVariables = {
	pathParams: GetMessagesV1ThreadsThreadIdMessagesGetPathParams;
} & FetcherExtraProps;

/**
 * Returns a list of messages for a given thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 */
export const getMessagesV1ThreadsThreadIdMessagesGet = (
	variables: GetMessagesV1ThreadsThreadIdMessagesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetMessagesV1ThreadsThreadIdMessagesGetResponse,
		GetMessagesV1ThreadsThreadIdMessagesGetError,
		undefined,
		{},
		{},
		GetMessagesV1ThreadsThreadIdMessagesGetPathParams
	>({
		url: "/v1/threads/{threadId}/messages",
		method: "get",
		...variables,
		signal,
	});

export type RunThreadThreadsThreadIdRunsPostPathParams = {
	threadId: string;
};

export type RunThreadThreadsThreadIdRunsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RunThreadThreadsThreadIdRunsPostResponse = {
	[key: string]: any;
};

export type RunThreadThreadsThreadIdRunsPostVariables = {
	pathParams: RunThreadThreadsThreadIdRunsPostPathParams;
} & FetcherExtraProps;

/**
 * Create a run.
 *
 * API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 */
export const runThreadThreadsThreadIdRunsPost = (
	variables: RunThreadThreadsThreadIdRunsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RunThreadThreadsThreadIdRunsPostResponse,
		RunThreadThreadsThreadIdRunsPostError,
		undefined,
		{},
		{},
		RunThreadThreadsThreadIdRunsPostPathParams
	>({ url: "/threads/{threadId}/runs", method: "post", ...variables, signal });

export type RunThreadV1ThreadsThreadIdRunsPostPathParams = {
	threadId: string;
};

export type RunThreadV1ThreadsThreadIdRunsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RunThreadV1ThreadsThreadIdRunsPostResponse = {
	[key: string]: any;
};

export type RunThreadV1ThreadsThreadIdRunsPostVariables = {
	pathParams: RunThreadV1ThreadsThreadIdRunsPostPathParams;
} & FetcherExtraProps;

/**
 * Create a run.
 *
 * API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 */
export const runThreadV1ThreadsThreadIdRunsPost = (
	variables: RunThreadV1ThreadsThreadIdRunsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RunThreadV1ThreadsThreadIdRunsPostResponse,
		RunThreadV1ThreadsThreadIdRunsPostError,
		undefined,
		{},
		{},
		RunThreadV1ThreadsThreadIdRunsPostPathParams
	>({
		url: "/v1/threads/{threadId}/runs",
		method: "post",
		...variables,
		signal,
	});

export type TokenCounterUtilsTokenCounterPostQueryParams = {
	/**
	 * @default false
	 */
	call_endpoint?: boolean;
};

export type TokenCounterUtilsTokenCounterPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TokenCounterUtilsTokenCounterPostVariables = {
	body: Schemas.TokenCountRequest;
	queryParams?: TokenCounterUtilsTokenCounterPostQueryParams;
} & FetcherExtraProps;

/**
 * Args:
 *     request: TokenCountRequest
 *     call_endpoint: bool - When set to "True" it will call the token counting endpoint - e.g Anthropic or Google AI Studio Token Counting APIs.
 *
 * Returns:
 *     TokenCountResponse
 */
export const tokenCounterUtilsTokenCounterPost = (
	variables: TokenCounterUtilsTokenCounterPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TokenCountResponse,
		TokenCounterUtilsTokenCounterPostError,
		Schemas.TokenCountRequest,
		{},
		TokenCounterUtilsTokenCounterPostQueryParams,
		{}
	>({ url: "/utils/token_counter", method: "post", ...variables, signal });

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams = {
	model: string;
};

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetResponse = {
	[key: string]: any;
};

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetVariables = {
	queryParams: SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns supported openai params for a given litellm model name
 *
 * e.g. `gpt-4` vs `gpt-3.5-turbo`
 *
 * Example curl:
 * ```
 * curl -X GET --location 'http://localhost:4000/utils/supported_openai_params?model=gpt-3.5-turbo-16k'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const supportedOpenaiParamsUtilsSupportedOpenaiParamsGet = (
	variables: SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetResponse,
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetError,
		undefined,
		{},
		SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams,
		{}
	>({
		url: "/utils/supported_openai_params",
		method: "get",
		...variables,
		signal,
	});

export type TransformRequestUtilsTransformRequestPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TransformRequestUtilsTransformRequestPostVariables = {
	body: Schemas.TransformRequestBody;
} & FetcherExtraProps;

export const transformRequestUtilsTransformRequestPost = (
	variables: TransformRequestUtilsTransformRequestPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.RawRequestTypedDict,
		TransformRequestUtilsTransformRequestPostError,
		Schemas.TransformRequestBody,
		{},
		{},
		{}
	>({ url: "/utils/transform_request", method: "post", ...variables, signal });

export type ModelInfoV1V1ModelInfoGetQueryParams = {
	litellm_model_id?: string | null;
};

export type ModelInfoV1V1ModelInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelInfoV1V1ModelInfoGetResponse = {
	data?: Schemas.Deployment[];
} & {
	[key: string]: any;
};

export type ModelInfoV1V1ModelInfoGetVariables = {
	queryParams?: ModelInfoV1V1ModelInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)
 *
 * Parameters:
 *     litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)
 *
 *     - When litellm_model_id is passed, it will return the info for that specific model
 *     - When litellm_model_id is not passed, it will return the info for all models
 *
 * Returns:
 *     Returns a dictionary containing information about each model.
 *
 * Example Response:
 * ```json
 * {
 *     "data": [
 *                 {
 *                     "model_name": "fake-openai-endpoint",
 *                     "litellm_params": {
 *                         "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",
 *                         "model": "openai/fake"
 *                     },
 *                     "model_info": {
 *                         "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",
 *                         "db_model": false
 *                     }
 *                 }
 *             ]
 * }
 *
 * ```
 */
export const modelInfoV1V1ModelInfoGet = (
	variables: ModelInfoV1V1ModelInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModelInfoV1V1ModelInfoGetResponse,
		ModelInfoV1V1ModelInfoGetError,
		undefined,
		{},
		ModelInfoV1V1ModelInfoGetQueryParams,
		{}
	>({ url: "/v1/model/info", method: "get", ...variables, signal });

export type ModelInfoV1ModelInfoGetQueryParams = {
	litellm_model_id?: string | null;
};

export type ModelInfoV1ModelInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelInfoV1ModelInfoGetResponse = {
	[key: string]: any;
};

export type ModelInfoV1ModelInfoGetVariables = {
	queryParams?: ModelInfoV1ModelInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)
 *
 * Parameters:
 *     litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)
 *
 *     - When litellm_model_id is passed, it will return the info for that specific model
 *     - When litellm_model_id is not passed, it will return the info for all models
 *
 * Returns:
 *     Returns a dictionary containing information about each model.
 *
 * Example Response:
 * ```json
 * {
 *     "data": [
 *                 {
 *                     "model_name": "fake-openai-endpoint",
 *                     "litellm_params": {
 *                         "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",
 *                         "model": "openai/fake"
 *                     },
 *                     "model_info": {
 *                         "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",
 *                         "db_model": false
 *                     }
 *                 }
 *             ]
 * }
 *
 * ```
 */
export const modelInfoV1ModelInfoGet = (
	variables: ModelInfoV1ModelInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModelInfoV1ModelInfoGetResponse,
		ModelInfoV1ModelInfoGetError,
		undefined,
		{},
		ModelInfoV1ModelInfoGetQueryParams,
		{}
	>({ url: "/model/info", method: "get", ...variables, signal });

export type ModelGroupInfoModelGroupInfoGetQueryParams = {
	model_group?: string | null;
};

export type ModelGroupInfoModelGroupInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ModelGroupInfoModelGroupInfoGetResponse = {
	[key: string]: any;
};

export type ModelGroupInfoModelGroupInfoGetVariables = {
	queryParams?: ModelGroupInfoModelGroupInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Get information about all the deployments on litellm proxy, including config.yaml descriptions (except api key and api base)
 *
 * - /model_group/info returns all model groups. End users of proxy should use /model_group/info since those models will be used for /chat/completions, /embeddings, etc.
 * - /model_group/info?model_group=rerank-english-v3.0 returns all model groups for a specific model group (`model_name` in config.yaml)
 *
 *
 *
 * Example Request (All Models):
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info'     -H 'accept: application/json'     -H 'x-api-key: sk-1234'
 * ```
 *
 * Example Request (Specific Model Group):
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info?model_group=rerank-english-v3.0'     -H 'accept: application/json'     -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * Example Request (Specific Wildcard Model Group): (e.g. `model_name: openai/*` on config.yaml)
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info?model_group=openai/tts-1'
 * -H 'accept: application/json'     -H 'Authorization: Bearersk-1234'
 * ```
 *
 * Learn how to use and set wildcard models [here](https://docs.litellm.ai/docs/wildcard_routing)
 *
 * Example Response:
 * ```json
 *     {
 *         "data": [
 *             {
 *             "model_group": "rerank-english-v3.0",
 *             "providers": [
 *                 "cohere"
 *             ],
 *             "max_input_tokens": null,
 *             "max_output_tokens": null,
 *             "input_cost_per_token": 0.0,
 *             "output_cost_per_token": 0.0,
 *             "mode": null,
 *             "tpm": null,
 *             "rpm": null,
 *             "supports_parallel_function_calling": false,
 *             "supports_vision": false,
 *             "supports_function_calling": false,
 *             "supported_openai_params": [
 *                 "stream",
 *                 "temperature",
 *                 "max_tokens",
 *                 "logit_bias",
 *                 "top_p",
 *                 "frequency_penalty",
 *                 "presence_penalty",
 *                 "stop",
 *                 "n",
 *                 "extra_headers"
 *             ]
 *             },
 *             {
 *             "model_group": "gpt-3.5-turbo",
 *             "providers": [
 *                 "openai"
 *             ],
 *             "max_input_tokens": 16385.0,
 *             "max_output_tokens": 4096.0,
 *             "input_cost_per_token": 1.5e-06,
 *             "output_cost_per_token": 2e-06,
 *             "mode": "chat",
 *             "tpm": null,
 *             "rpm": null,
 *             "supports_parallel_function_calling": false,
 *             "supports_vision": false,
 *             "supports_function_calling": true,
 *             "supported_openai_params": [
 *                 "frequency_penalty",
 *                 "logit_bias",
 *                 "logprobs",
 *                 "top_logprobs",
 *                 "max_tokens",
 *                 "max_completion_tokens",
 *                 "n",
 *                 "presence_penalty",
 *                 "seed",
 *                 "stop",
 *                 "stream",
 *                 "stream_options",
 *                 "temperature",
 *                 "top_p",
 *                 "tools",
 *                 "tool_choice",
 *                 "function_call",
 *                 "functions",
 *                 "max_retries",
 *                 "extra_headers",
 *                 "parallel_tool_calls",
 *                 "response_format"
 *             ]
 *             },
 *             {
 *             "model_group": "llava-hf",
 *             "providers": [
 *                 "openai"
 *             ],
 *             "max_input_tokens": null,
 *             "max_output_tokens": null,
 *             "input_cost_per_token": 0.0,
 *             "output_cost_per_token": 0.0,
 *             "mode": null,
 *             "tpm": null,
 *             "rpm": null,
 *             "supports_parallel_function_calling": false,
 *             "supports_vision": true,
 *             "supports_function_calling": false,
 *             "supported_openai_params": [
 *                 "frequency_penalty",
 *                 "logit_bias",
 *                 "logprobs",
 *                 "top_logprobs",
 *                 "max_tokens",
 *                 "max_completion_tokens",
 *                 "n",
 *                 "presence_penalty",
 *                 "seed",
 *                 "stop",
 *                 "stream",
 *                 "stream_options",
 *                 "temperature",
 *                 "top_p",
 *                 "tools",
 *                 "tool_choice",
 *                 "function_call",
 *                 "functions",
 *                 "max_retries",
 *                 "extra_headers",
 *                 "parallel_tool_calls",
 *                 "response_format"
 *             ]
 *             }
 *         ]
 *         }
 * ```
 */
export const modelGroupInfoModelGroupInfoGet = (
	variables: ModelGroupInfoModelGroupInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ModelGroupInfoModelGroupInfoGetResponse,
		ModelGroupInfoModelGroupInfoGetError,
		undefined,
		{},
		ModelGroupInfoModelGroupInfoGetQueryParams,
		{}
	>({ url: "/model_group/info", method: "get", ...variables, signal });

export type HomeGetError = Fetcher.ErrorWrapper<undefined>;

export type HomeGetResponse = {
	[key: string]: any;
};

export type HomeGetVariables = FetcherExtraProps;

export const homeGet = (variables: HomeGetVariables, signal?: AbortSignal) =>
	fetch<HomeGetResponse, HomeGetError, undefined, {}, {}, {}>({
		url: "/",
		method: "get",
		...variables,
		signal,
	});

export type GetRoutesRoutesGetError = Fetcher.ErrorWrapper<undefined>;

export type GetRoutesRoutesGetResponse = {
	[key: string]: any;
};

export type GetRoutesRoutesGetVariables = FetcherExtraProps;

/**
 * Get a list of available routes in the FastAPI application.
 */
export const getRoutesRoutesGet = (variables: GetRoutesRoutesGetVariables, signal?: AbortSignal) =>
	fetch<GetRoutesRoutesGetResponse, GetRoutesRoutesGetError, undefined, {}, {}, {}>({
		url: "/routes",
		method: "get",
		...variables,
		signal,
	});

export type ResponsesApiOpenaiV1ResponsesPostError = Fetcher.ErrorWrapper<undefined>;

export type ResponsesApiOpenaiV1ResponsesPostResponse = {
	[key: string]: any;
};

export type ResponsesApiOpenaiV1ResponsesPostVariables = FetcherExtraProps;

/**
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 *     "model": "gpt-4o",
 *     "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiOpenaiV1ResponsesPost = (
	variables: ResponsesApiOpenaiV1ResponsesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ResponsesApiOpenaiV1ResponsesPostResponse,
		ResponsesApiOpenaiV1ResponsesPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/openai/v1/responses", method: "post", ...variables, signal });

export type ResponsesApiResponsesPostError = Fetcher.ErrorWrapper<undefined>;

export type ResponsesApiResponsesPostResponse = {
	[key: string]: any;
};

export type ResponsesApiResponsesPostVariables = FetcherExtraProps;

/**
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 *     "model": "gpt-4o",
 *     "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiResponsesPost = (
	variables: ResponsesApiResponsesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<ResponsesApiResponsesPostResponse, ResponsesApiResponsesPostError, undefined, {}, {}, {}>({
		url: "/responses",
		method: "post",
		...variables,
		signal,
	});

export type ResponsesApiV1ResponsesPostError = Fetcher.ErrorWrapper<undefined>;

export type ResponsesApiV1ResponsesPostResponse = {
	[key: string]: any;
};

export type ResponsesApiV1ResponsesPostVariables = FetcherExtraProps;

/**
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 *     "model": "gpt-4o",
 *     "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiV1ResponsesPost = (
	variables: ResponsesApiV1ResponsesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ResponsesApiV1ResponsesPostResponse,
		ResponsesApiV1ResponsesPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/responses", method: "post", ...variables, signal });

export type GetResponseOpenaiV1ResponsesResponseIdGetPathParams = {
	responseId: string;
};

export type GetResponseOpenaiV1ResponsesResponseIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetResponseOpenaiV1ResponsesResponseIdGetResponse = {
	[key: string]: any;
};

export type GetResponseOpenaiV1ResponsesResponseIdGetVariables = {
	pathParams: GetResponseOpenaiV1ResponsesResponseIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseOpenaiV1ResponsesResponseIdGet = (
	variables: GetResponseOpenaiV1ResponsesResponseIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetResponseOpenaiV1ResponsesResponseIdGetResponse,
		GetResponseOpenaiV1ResponsesResponseIdGetError,
		undefined,
		{},
		{},
		GetResponseOpenaiV1ResponsesResponseIdGetPathParams
	>({
		url: "/openai/v1/responses/{responseId}",
		method: "get",
		...variables,
		signal,
	});

export type DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams = {
	responseId: string;
};

export type DeleteResponseOpenaiV1ResponsesResponseIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteResponseOpenaiV1ResponsesResponseIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteResponseOpenaiV1ResponsesResponseIdDeleteVariables = {
	pathParams: DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseOpenaiV1ResponsesResponseIdDelete = (
	variables: DeleteResponseOpenaiV1ResponsesResponseIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteResponseOpenaiV1ResponsesResponseIdDeleteResponse,
		DeleteResponseOpenaiV1ResponsesResponseIdDeleteError,
		undefined,
		{},
		{},
		DeleteResponseOpenaiV1ResponsesResponseIdDeletePathParams
	>({
		url: "/openai/v1/responses/{responseId}",
		method: "delete",
		...variables,
		signal,
	});

export type GetResponseResponsesResponseIdGetPathParams = {
	responseId: string;
};

export type GetResponseResponsesResponseIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetResponseResponsesResponseIdGetResponse = {
	[key: string]: any;
};

export type GetResponseResponsesResponseIdGetVariables = {
	pathParams: GetResponseResponsesResponseIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseResponsesResponseIdGet = (
	variables: GetResponseResponsesResponseIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetResponseResponsesResponseIdGetResponse,
		GetResponseResponsesResponseIdGetError,
		undefined,
		{},
		{},
		GetResponseResponsesResponseIdGetPathParams
	>({ url: "/responses/{responseId}", method: "get", ...variables, signal });

export type DeleteResponseResponsesResponseIdDeletePathParams = {
	responseId: string;
};

export type DeleteResponseResponsesResponseIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteResponseResponsesResponseIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteResponseResponsesResponseIdDeleteVariables = {
	pathParams: DeleteResponseResponsesResponseIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseResponsesResponseIdDelete = (
	variables: DeleteResponseResponsesResponseIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteResponseResponsesResponseIdDeleteResponse,
		DeleteResponseResponsesResponseIdDeleteError,
		undefined,
		{},
		{},
		DeleteResponseResponsesResponseIdDeletePathParams
	>({ url: "/responses/{responseId}", method: "delete", ...variables, signal });

export type GetResponseV1ResponsesResponseIdGetPathParams = {
	responseId: string;
};

export type GetResponseV1ResponsesResponseIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetResponseV1ResponsesResponseIdGetResponse = {
	[key: string]: any;
};

export type GetResponseV1ResponsesResponseIdGetVariables = {
	pathParams: GetResponseV1ResponsesResponseIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseV1ResponsesResponseIdGet = (
	variables: GetResponseV1ResponsesResponseIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetResponseV1ResponsesResponseIdGetResponse,
		GetResponseV1ResponsesResponseIdGetError,
		undefined,
		{},
		{},
		GetResponseV1ResponsesResponseIdGetPathParams
	>({ url: "/v1/responses/{responseId}", method: "get", ...variables, signal });

export type DeleteResponseV1ResponsesResponseIdDeletePathParams = {
	responseId: string;
};

export type DeleteResponseV1ResponsesResponseIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteResponseV1ResponsesResponseIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteResponseV1ResponsesResponseIdDeleteVariables = {
	pathParams: DeleteResponseV1ResponsesResponseIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseV1ResponsesResponseIdDelete = (
	variables: DeleteResponseV1ResponsesResponseIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteResponseV1ResponsesResponseIdDeleteResponse,
		DeleteResponseV1ResponsesResponseIdDeleteError,
		undefined,
		{},
		{},
		DeleteResponseV1ResponsesResponseIdDeletePathParams
	>({
		url: "/v1/responses/{responseId}",
		method: "delete",
		...variables,
		signal,
	});

export type GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams = {
	responseId: string;
};

export type GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetResponse = {
	[key: string]: any;
};

export type GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetVariables = {
	pathParams: GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams;
} & FetcherExtraProps;

/**
 * List input items for a response.
 */
export const getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet = (
	variables: GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetResponse,
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetError,
		undefined,
		{},
		{},
		GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetPathParams
	>({
		url: "/openai/v1/responses/{responseId}/input_items",
		method: "get",
		...variables,
		signal,
	});

export type GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams = {
	responseId: string;
};

export type GetResponseInputItemsResponsesResponseIdInputItemsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetResponseInputItemsResponsesResponseIdInputItemsGetResponse = {
	[key: string]: any;
};

export type GetResponseInputItemsResponsesResponseIdInputItemsGetVariables = {
	pathParams: GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams;
} & FetcherExtraProps;

/**
 * List input items for a response.
 */
export const getResponseInputItemsResponsesResponseIdInputItemsGet = (
	variables: GetResponseInputItemsResponsesResponseIdInputItemsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetResponseInputItemsResponsesResponseIdInputItemsGetResponse,
		GetResponseInputItemsResponsesResponseIdInputItemsGetError,
		undefined,
		{},
		{},
		GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams
	>({
		url: "/responses/{responseId}/input_items",
		method: "get",
		...variables,
		signal,
	});

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams = {
	responseId: string;
};

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetResponse = {
	[key: string]: any;
};

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetVariables = {
	pathParams: GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams;
} & FetcherExtraProps;

/**
 * List input items for a response.
 */
export const getResponseInputItemsV1ResponsesResponseIdInputItemsGet = (
	variables: GetResponseInputItemsV1ResponsesResponseIdInputItemsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetResponse,
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetError,
		undefined,
		{},
		{},
		GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams
	>({
		url: "/v1/responses/{responseId}/input_items",
		method: "get",
		...variables,
		signal,
	});

export type CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams = {
	responseId: string;
};

export type CancelResponseOpenaiV1ResponsesResponseIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelResponseOpenaiV1ResponsesResponseIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelResponseOpenaiV1ResponsesResponseIdCancelPostVariables = {
	pathParams: CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cancelResponseOpenaiV1ResponsesResponseIdCancelPost = (
	variables: CancelResponseOpenaiV1ResponsesResponseIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostResponse,
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostError,
		undefined,
		{},
		{},
		CancelResponseOpenaiV1ResponsesResponseIdCancelPostPathParams
	>({
		url: "/openai/v1/responses/{responseId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type CancelResponseResponsesResponseIdCancelPostPathParams = {
	responseId: string;
};

export type CancelResponseResponsesResponseIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelResponseResponsesResponseIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelResponseResponsesResponseIdCancelPostVariables = {
	pathParams: CancelResponseResponsesResponseIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cancelResponseResponsesResponseIdCancelPost = (
	variables: CancelResponseResponsesResponseIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelResponseResponsesResponseIdCancelPostResponse,
		CancelResponseResponsesResponseIdCancelPostError,
		undefined,
		{},
		{},
		CancelResponseResponsesResponseIdCancelPostPathParams
	>({
		url: "/responses/{responseId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type CancelResponseV1ResponsesResponseIdCancelPostPathParams = {
	responseId: string;
};

export type CancelResponseV1ResponsesResponseIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelResponseV1ResponsesResponseIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelResponseV1ResponsesResponseIdCancelPostVariables = {
	pathParams: CancelResponseV1ResponsesResponseIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cancelResponseV1ResponsesResponseIdCancelPost = (
	variables: CancelResponseV1ResponsesResponseIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelResponseV1ResponsesResponseIdCancelPostResponse,
		CancelResponseV1ResponsesResponseIdCancelPostError,
		undefined,
		{},
		{},
		CancelResponseV1ResponsesResponseIdCancelPostPathParams
	>({
		url: "/v1/responses/{responseId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type CreateBatchBatchesPostQueryParams = {
	provider?: string | null;
};

export type CreateBatchBatchesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateBatchBatchesPostResponse = {
	[key: string]: any;
};

export type CreateBatchBatchesPostVariables = {
	queryParams?: CreateBatchBatchesPostQueryParams;
} & FetcherExtraProps;

/**
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "input_file_id": "file-abc123",
 *         "endpoint": "/v1/chat/completions",
 *         "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchBatchesPost = (
	variables: CreateBatchBatchesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateBatchBatchesPostResponse,
		CreateBatchBatchesPostError,
		undefined,
		{},
		CreateBatchBatchesPostQueryParams,
		{}
	>({ url: "/batches", method: "post", ...variables, signal });

export type ListBatchesBatchesGetQueryParams = {
	provider?: string | null;
	limit?: number | null;
	after?: string | null;
	target_model_names?: string | null;
};

export type ListBatchesBatchesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListBatchesBatchesGetResponse = {
	[key: string]: any;
};

export type ListBatchesBatchesGetVariables = {
	queryParams?: ListBatchesBatchesGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesBatchesGet = (
	variables: ListBatchesBatchesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListBatchesBatchesGetResponse,
		ListBatchesBatchesGetError,
		undefined,
		{},
		ListBatchesBatchesGetQueryParams,
		{}
	>({ url: "/batches", method: "get", ...variables, signal });

export type CreateBatchV1BatchesPostQueryParams = {
	provider?: string | null;
};

export type CreateBatchV1BatchesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateBatchV1BatchesPostResponse = {
	[key: string]: any;
};

export type CreateBatchV1BatchesPostVariables = {
	queryParams?: CreateBatchV1BatchesPostQueryParams;
} & FetcherExtraProps;

/**
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "input_file_id": "file-abc123",
 *         "endpoint": "/v1/chat/completions",
 *         "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchV1BatchesPost = (
	variables: CreateBatchV1BatchesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateBatchV1BatchesPostResponse,
		CreateBatchV1BatchesPostError,
		undefined,
		{},
		CreateBatchV1BatchesPostQueryParams,
		{}
	>({ url: "/v1/batches", method: "post", ...variables, signal });

export type ListBatchesV1BatchesGetQueryParams = {
	provider?: string | null;
	limit?: number | null;
	after?: string | null;
	target_model_names?: string | null;
};

export type ListBatchesV1BatchesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListBatchesV1BatchesGetResponse = {
	[key: string]: any;
};

export type ListBatchesV1BatchesGetVariables = {
	queryParams?: ListBatchesV1BatchesGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesV1BatchesGet = (
	variables: ListBatchesV1BatchesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListBatchesV1BatchesGetResponse,
		ListBatchesV1BatchesGetError,
		undefined,
		{},
		ListBatchesV1BatchesGetQueryParams,
		{}
	>({ url: "/v1/batches", method: "get", ...variables, signal });

export type CreateBatchProviderV1BatchesPostPathParams = {
	provider: string | null;
};

export type CreateBatchProviderV1BatchesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateBatchProviderV1BatchesPostResponse = {
	[key: string]: any;
};

export type CreateBatchProviderV1BatchesPostVariables = {
	pathParams: CreateBatchProviderV1BatchesPostPathParams;
} & FetcherExtraProps;

/**
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "input_file_id": "file-abc123",
 *         "endpoint": "/v1/chat/completions",
 *         "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchProviderV1BatchesPost = (
	variables: CreateBatchProviderV1BatchesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateBatchProviderV1BatchesPostResponse,
		CreateBatchProviderV1BatchesPostError,
		undefined,
		{},
		{},
		CreateBatchProviderV1BatchesPostPathParams
	>({ url: "/{provider}/v1/batches", method: "post", ...variables, signal });

export type ListBatchesProviderV1BatchesGetPathParams = {
	provider: string | null;
};

export type ListBatchesProviderV1BatchesGetQueryParams = {
	limit?: number | null;
	after?: string | null;
	target_model_names?: string | null;
};

export type ListBatchesProviderV1BatchesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListBatchesProviderV1BatchesGetResponse = {
	[key: string]: any;
};

export type ListBatchesProviderV1BatchesGetVariables = {
	pathParams: ListBatchesProviderV1BatchesGetPathParams;
	queryParams?: ListBatchesProviderV1BatchesGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesProviderV1BatchesGet = (
	variables: ListBatchesProviderV1BatchesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListBatchesProviderV1BatchesGetResponse,
		ListBatchesProviderV1BatchesGetError,
		undefined,
		{},
		ListBatchesProviderV1BatchesGetQueryParams,
		ListBatchesProviderV1BatchesGetPathParams
	>({ url: "/{provider}/v1/batches", method: "get", ...variables, signal });

export type RetrieveBatchBatchesBatchIdGetPathParams = {
	/**
	 * The ID of the batch to retrieve
	 */
	batchId: string;
};

export type RetrieveBatchBatchesBatchIdGetQueryParams = {
	provider?: string | null;
};

export type RetrieveBatchBatchesBatchIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveBatchBatchesBatchIdGetResponse = {
	[key: string]: any;
};

export type RetrieveBatchBatchesBatchIdGetVariables = {
	pathParams: RetrieveBatchBatchesBatchIdGetPathParams;
	queryParams?: RetrieveBatchBatchesBatchIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchBatchesBatchIdGet = (
	variables: RetrieveBatchBatchesBatchIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveBatchBatchesBatchIdGetResponse,
		RetrieveBatchBatchesBatchIdGetError,
		undefined,
		{},
		RetrieveBatchBatchesBatchIdGetQueryParams,
		RetrieveBatchBatchesBatchIdGetPathParams
	>({ url: "/batches/{batchId}", method: "get", ...variables, signal });

export type RetrieveBatchV1BatchesBatchIdGetPathParams = {
	/**
	 * The ID of the batch to retrieve
	 */
	batchId: string;
};

export type RetrieveBatchV1BatchesBatchIdGetQueryParams = {
	provider?: string | null;
};

export type RetrieveBatchV1BatchesBatchIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveBatchV1BatchesBatchIdGetResponse = {
	[key: string]: any;
};

export type RetrieveBatchV1BatchesBatchIdGetVariables = {
	pathParams: RetrieveBatchV1BatchesBatchIdGetPathParams;
	queryParams?: RetrieveBatchV1BatchesBatchIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchV1BatchesBatchIdGet = (
	variables: RetrieveBatchV1BatchesBatchIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveBatchV1BatchesBatchIdGetResponse,
		RetrieveBatchV1BatchesBatchIdGetError,
		undefined,
		{},
		RetrieveBatchV1BatchesBatchIdGetQueryParams,
		RetrieveBatchV1BatchesBatchIdGetPathParams
	>({ url: "/v1/batches/{batchId}", method: "get", ...variables, signal });

export type RetrieveBatchProviderV1BatchesBatchIdGetPathParams = {
	provider: string | null;
	/**
	 * The ID of the batch to retrieve
	 */
	batchId: string;
};

export type RetrieveBatchProviderV1BatchesBatchIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveBatchProviderV1BatchesBatchIdGetResponse = {
	[key: string]: any;
};

export type RetrieveBatchProviderV1BatchesBatchIdGetVariables = {
	pathParams: RetrieveBatchProviderV1BatchesBatchIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchProviderV1BatchesBatchIdGet = (
	variables: RetrieveBatchProviderV1BatchesBatchIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveBatchProviderV1BatchesBatchIdGetResponse,
		RetrieveBatchProviderV1BatchesBatchIdGetError,
		undefined,
		{},
		{},
		RetrieveBatchProviderV1BatchesBatchIdGetPathParams
	>({
		url: "/{provider}/v1/batches/{batchId}",
		method: "get",
		...variables,
		signal,
	});

export type CancelBatchBatchesBatchIdCancelPostPathParams = {
	batchId: string;
};

export type CancelBatchBatchesBatchIdCancelPostQueryParams = {
	provider?: string | null;
};

export type CancelBatchBatchesBatchIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelBatchBatchesBatchIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelBatchBatchesBatchIdCancelPostVariables = {
	pathParams: CancelBatchBatchesBatchIdCancelPostPathParams;
	queryParams?: CancelBatchBatchesBatchIdCancelPostQueryParams;
} & FetcherExtraProps;

/**
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchBatchesBatchIdCancelPost = (
	variables: CancelBatchBatchesBatchIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelBatchBatchesBatchIdCancelPostResponse,
		CancelBatchBatchesBatchIdCancelPostError,
		undefined,
		{},
		CancelBatchBatchesBatchIdCancelPostQueryParams,
		CancelBatchBatchesBatchIdCancelPostPathParams
	>({ url: "/batches/{batchId}/cancel", method: "post", ...variables, signal });

export type CancelBatchV1BatchesBatchIdCancelPostPathParams = {
	batchId: string;
};

export type CancelBatchV1BatchesBatchIdCancelPostQueryParams = {
	provider?: string | null;
};

export type CancelBatchV1BatchesBatchIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelBatchV1BatchesBatchIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelBatchV1BatchesBatchIdCancelPostVariables = {
	pathParams: CancelBatchV1BatchesBatchIdCancelPostPathParams;
	queryParams?: CancelBatchV1BatchesBatchIdCancelPostQueryParams;
} & FetcherExtraProps;

/**
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchV1BatchesBatchIdCancelPost = (
	variables: CancelBatchV1BatchesBatchIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelBatchV1BatchesBatchIdCancelPostResponse,
		CancelBatchV1BatchesBatchIdCancelPostError,
		undefined,
		{},
		CancelBatchV1BatchesBatchIdCancelPostQueryParams,
		CancelBatchV1BatchesBatchIdCancelPostPathParams
	>({
		url: "/v1/batches/{batchId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type CancelBatchProviderV1BatchesBatchIdCancelPostPathParams = {
	batchId: string;
	provider: string | null;
};

export type CancelBatchProviderV1BatchesBatchIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelBatchProviderV1BatchesBatchIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelBatchProviderV1BatchesBatchIdCancelPostVariables = {
	pathParams: CancelBatchProviderV1BatchesBatchIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchProviderV1BatchesBatchIdCancelPost = (
	variables: CancelBatchProviderV1BatchesBatchIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelBatchProviderV1BatchesBatchIdCancelPostResponse,
		CancelBatchProviderV1BatchesBatchIdCancelPostError,
		undefined,
		{},
		{},
		CancelBatchProviderV1BatchesBatchIdCancelPostPathParams
	>({
		url: "/{provider}/v1/batches/{batchId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type PublicModelHubPublicModelHubGetError = Fetcher.ErrorWrapper<undefined>;

export type PublicModelHubPublicModelHubGetResponse = Schemas.ModelGroupInfoProxy[];

export type PublicModelHubPublicModelHubGetVariables = FetcherExtraProps;

export const publicModelHubPublicModelHubGet = (
	variables: PublicModelHubPublicModelHubGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		PublicModelHubPublicModelHubGetResponse,
		PublicModelHubPublicModelHubGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/public/model_hub", method: "get", ...variables, signal });

export type PublicModelHubInfoPublicModelHubInfoGetError = Fetcher.ErrorWrapper<undefined>;

export type PublicModelHubInfoPublicModelHubInfoGetVariables = FetcherExtraProps;

export const publicModelHubInfoPublicModelHubInfoGet = (
	variables: PublicModelHubInfoPublicModelHubInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PublicModelHubInfo,
		PublicModelHubInfoPublicModelHubInfoGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/public/model_hub/info", method: "get", ...variables, signal });

export type RerankRerankPostError = Fetcher.ErrorWrapper<undefined>;

export type RerankRerankPostResponse = {
	[key: string]: any;
};

export type RerankRerankPostVariables = FetcherExtraProps;

export const rerankRerankPost = (variables: RerankRerankPostVariables, signal?: AbortSignal) =>
	fetch<RerankRerankPostResponse, RerankRerankPostError, undefined, {}, {}, {}>({
		url: "/rerank",
		method: "post",
		...variables,
		signal,
	});

export type RerankV1RerankPostError = Fetcher.ErrorWrapper<undefined>;

export type RerankV1RerankPostResponse = {
	[key: string]: any;
};

export type RerankV1RerankPostVariables = FetcherExtraProps;

export const rerankV1RerankPost = (variables: RerankV1RerankPostVariables, signal?: AbortSignal) =>
	fetch<RerankV1RerankPostResponse, RerankV1RerankPostError, undefined, {}, {}, {}>({
		url: "/v1/rerank",
		method: "post",
		...variables,
		signal,
	});

export type RerankV2RerankPostError = Fetcher.ErrorWrapper<undefined>;

export type RerankV2RerankPostResponse = {
	[key: string]: any;
};

export type RerankV2RerankPostVariables = FetcherExtraProps;

export const rerankV2RerankPost = (variables: RerankV2RerankPostVariables, signal?: AbortSignal) =>
	fetch<RerankV2RerankPostResponse, RerankV2RerankPostError, undefined, {}, {}, {}>({
		url: "/v2/rerank",
		method: "post",
		...variables,
		signal,
	});

export type OcrOcrPostError = Fetcher.ErrorWrapper<undefined>;

export type OcrOcrPostResponse = {
	[key: string]: any;
};

export type OcrOcrPostVariables = FetcherExtraProps;

/**
 * OCR endpoint for extracting text from documents and images.
 *
 * Follows the Mistral OCR API spec:
 * https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocr
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "model": "mistral/mistral-ocr-latest",
 *         "document": {
 *             "type": "document_url",
 *             "document_url": "https://arxiv.org/pdf/2201.04234"
 *         }
 *     }'
 * ```
 */
export const ocrOcrPost = (variables: OcrOcrPostVariables, signal?: AbortSignal) =>
	fetch<OcrOcrPostResponse, OcrOcrPostError, undefined, {}, {}, {}>({
		url: "/ocr",
		method: "post",
		...variables,
		signal,
	});

export type OcrV1OcrPostError = Fetcher.ErrorWrapper<undefined>;

export type OcrV1OcrPostResponse = {
	[key: string]: any;
};

export type OcrV1OcrPostVariables = FetcherExtraProps;

/**
 * OCR endpoint for extracting text from documents and images.
 *
 * Follows the Mistral OCR API spec:
 * https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocr
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "model": "mistral/mistral-ocr-latest",
 *         "document": {
 *             "type": "document_url",
 *             "document_url": "https://arxiv.org/pdf/2201.04234"
 *         }
 *     }'
 * ```
 */
export const ocrV1OcrPost = (variables: OcrV1OcrPostVariables, signal?: AbortSignal) =>
	fetch<OcrV1OcrPostResponse, OcrV1OcrPostError, undefined, {}, {}, {}>({
		url: "/v1/ocr",
		method: "post",
		...variables,
		signal,
	});

export type VideoListVideosGetError = Fetcher.ErrorWrapper<undefined>;

export type VideoListVideosGetResponse = {
	[key: string]: any;
};

export type VideoListVideosGetVariables = FetcherExtraProps;

/**
 * Video list endpoint for retrieving a list of videos.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoListVideosGet = (variables: VideoListVideosGetVariables, signal?: AbortSignal) =>
	fetch<VideoListVideosGetResponse, VideoListVideosGetError, undefined, {}, {}, {}>({
		url: "/videos",
		method: "get",
		...variables,
		signal,
	});

export type VideoGenerationVideosPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoGenerationVideosPostResponse = {
	[key: string]: any;
};

export type VideoGenerationVideosPostVariables = {
	body?: Schemas.BodyVideoGenerationVideosPost;
} & FetcherExtraProps;

/**
 * Video generation endpoint for creating videos from text prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "model": "sora-2",
 *         "prompt": "A beautiful sunset over the ocean"
 *     }'
 * ```
 */
export const videoGenerationVideosPost = (
	variables: VideoGenerationVideosPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VideoGenerationVideosPostResponse,
		VideoGenerationVideosPostError,
		Schemas.BodyVideoGenerationVideosPost,
		{},
		{},
		{}
	>({ url: "/videos", method: "post", ...variables, signal });

export type VideoListV1VideosGetError = Fetcher.ErrorWrapper<undefined>;

export type VideoListV1VideosGetResponse = {
	[key: string]: any;
};

export type VideoListV1VideosGetVariables = FetcherExtraProps;

/**
 * Video list endpoint for retrieving a list of videos.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoListV1VideosGet = (
	variables: VideoListV1VideosGetVariables,
	signal?: AbortSignal,
) =>
	fetch<VideoListV1VideosGetResponse, VideoListV1VideosGetError, undefined, {}, {}, {}>({
		url: "/v1/videos",
		method: "get",
		...variables,
		signal,
	});

export type VideoGenerationV1VideosPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoGenerationV1VideosPostResponse = {
	[key: string]: any;
};

export type VideoGenerationV1VideosPostVariables = {
	body?: Schemas.BodyVideoGenerationV1VideosPost;
} & FetcherExtraProps;

/**
 * Video generation endpoint for creating videos from text prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "model": "sora-2",
 *         "prompt": "A beautiful sunset over the ocean"
 *     }'
 * ```
 */
export const videoGenerationV1VideosPost = (
	variables: VideoGenerationV1VideosPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VideoGenerationV1VideosPostResponse,
		VideoGenerationV1VideosPostError,
		Schemas.BodyVideoGenerationV1VideosPost,
		{},
		{},
		{}
	>({ url: "/v1/videos", method: "post", ...variables, signal });

export type VideoStatusVideosVideoIdGetPathParams = {
	videoId: string;
};

export type VideoStatusVideosVideoIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoStatusVideosVideoIdGetResponse = {
	[key: string]: any;
};

export type VideoStatusVideosVideoIdGetVariables = {
	pathParams: VideoStatusVideosVideoIdGetPathParams;
} & FetcherExtraProps;

/**
 * Video status endpoint for retrieving video status and metadata.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoStatusVideosVideoIdGet = (
	variables: VideoStatusVideosVideoIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VideoStatusVideosVideoIdGetResponse,
		VideoStatusVideosVideoIdGetError,
		undefined,
		{},
		{},
		VideoStatusVideosVideoIdGetPathParams
	>({ url: "/videos/{videoId}", method: "get", ...variables, signal });

export type VideoStatusV1VideosVideoIdGetPathParams = {
	videoId: string;
};

export type VideoStatusV1VideosVideoIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoStatusV1VideosVideoIdGetResponse = {
	[key: string]: any;
};

export type VideoStatusV1VideosVideoIdGetVariables = {
	pathParams: VideoStatusV1VideosVideoIdGetPathParams;
} & FetcherExtraProps;

/**
 * Video status endpoint for retrieving video status and metadata.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoStatusV1VideosVideoIdGet = (
	variables: VideoStatusV1VideosVideoIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VideoStatusV1VideosVideoIdGetResponse,
		VideoStatusV1VideosVideoIdGetError,
		undefined,
		{},
		{},
		VideoStatusV1VideosVideoIdGetPathParams
	>({ url: "/v1/videos/{videoId}", method: "get", ...variables, signal });

export type VideoContentVideosVideoIdContentGetPathParams = {
	videoId: string;
};

export type VideoContentVideosVideoIdContentGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoContentVideosVideoIdContentGetVariables = {
	pathParams: VideoContentVideosVideoIdContentGetPathParams;
} & FetcherExtraProps;

/**
 * Video content endpoint for downloading video content.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4
 * ```
 */
export const videoContentVideosVideoIdContentGet = (
	variables: VideoContentVideosVideoIdContentGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		VideoContentVideosVideoIdContentGetError,
		undefined,
		{},
		{},
		VideoContentVideosVideoIdContentGetPathParams
	>({ url: "/videos/{videoId}/content", method: "get", ...variables, signal });

export type VideoContentV1VideosVideoIdContentGetPathParams = {
	videoId: string;
};

export type VideoContentV1VideosVideoIdContentGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoContentV1VideosVideoIdContentGetVariables = {
	pathParams: VideoContentV1VideosVideoIdContentGetPathParams;
} & FetcherExtraProps;

/**
 * Video content endpoint for downloading video content.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4
 * ```
 */
export const videoContentV1VideosVideoIdContentGet = (
	variables: VideoContentV1VideosVideoIdContentGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		VideoContentV1VideosVideoIdContentGetError,
		undefined,
		{},
		{},
		VideoContentV1VideosVideoIdContentGetPathParams
	>({
		url: "/v1/videos/{videoId}/content",
		method: "get",
		...variables,
		signal,
	});

export type VideoRemixVideosVideoIdRemixPostPathParams = {
	videoId: string;
};

export type VideoRemixVideosVideoIdRemixPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoRemixVideosVideoIdRemixPostResponse = {
	[key: string]: any;
};

export type VideoRemixVideosVideoIdRemixPostVariables = {
	pathParams: VideoRemixVideosVideoIdRemixPostPathParams;
} & FetcherExtraProps;

/**
 * Video remix endpoint for remixing existing videos with new prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "prompt": "A new version with different colors"
 *     }'
 * ```
 */
export const videoRemixVideosVideoIdRemixPost = (
	variables: VideoRemixVideosVideoIdRemixPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VideoRemixVideosVideoIdRemixPostResponse,
		VideoRemixVideosVideoIdRemixPostError,
		undefined,
		{},
		{},
		VideoRemixVideosVideoIdRemixPostPathParams
	>({ url: "/videos/{videoId}/remix", method: "post", ...variables, signal });

export type VideoRemixV1VideosVideoIdRemixPostPathParams = {
	videoId: string;
};

export type VideoRemixV1VideosVideoIdRemixPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VideoRemixV1VideosVideoIdRemixPostResponse = {
	[key: string]: any;
};

export type VideoRemixV1VideosVideoIdRemixPostVariables = {
	pathParams: VideoRemixV1VideosVideoIdRemixPostPathParams;
} & FetcherExtraProps;

/**
 * Video remix endpoint for remixing existing videos with new prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "prompt": "A new version with different colors"
 *     }'
 * ```
 */
export const videoRemixV1VideosVideoIdRemixPost = (
	variables: VideoRemixV1VideosVideoIdRemixPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VideoRemixV1VideosVideoIdRemixPostResponse,
		VideoRemixV1VideosVideoIdRemixPostError,
		undefined,
		{},
		{},
		VideoRemixV1VideosVideoIdRemixPostPathParams
	>({
		url: "/v1/videos/{videoId}/remix",
		method: "post",
		...variables,
		signal,
	});

export type ListContainersContainersGetError = Fetcher.ErrorWrapper<undefined>;

export type ListContainersContainersGetResponse = {
	[key: string]: any;
};

export type ListContainersContainersGetVariables = FetcherExtraProps;

/**
 * Container list endpoint for retrieving a list of containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header or query param:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const listContainersContainersGet = (
	variables: ListContainersContainersGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListContainersContainersGetResponse,
		ListContainersContainersGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/containers", method: "get", ...variables, signal });

export type CreateContainerContainersPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateContainerContainersPostResponse = {
	[key: string]: any;
};

export type CreateContainerContainersPostVariables = FetcherExtraProps;

/**
 * Container creation endpoint for creating new containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "name": "My Container",
 *         "expires_after": {
 *             "anchor": "last_active_at",
 *             "minutes": 20
 *         }
 *     }'
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{
 *         "name": "My Container"
 *     }'
 * ```
 */
export const createContainerContainersPost = (
	variables: CreateContainerContainersPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateContainerContainersPostResponse,
		CreateContainerContainersPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/containers", method: "post", ...variables, signal });

export type ListContainersV1ContainersGetError = Fetcher.ErrorWrapper<undefined>;

export type ListContainersV1ContainersGetResponse = {
	[key: string]: any;
};

export type ListContainersV1ContainersGetVariables = FetcherExtraProps;

/**
 * Container list endpoint for retrieving a list of containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header or query param:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const listContainersV1ContainersGet = (
	variables: ListContainersV1ContainersGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListContainersV1ContainersGetResponse,
		ListContainersV1ContainersGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/containers", method: "get", ...variables, signal });

export type CreateContainerV1ContainersPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateContainerV1ContainersPostResponse = {
	[key: string]: any;
};

export type CreateContainerV1ContainersPostVariables = FetcherExtraProps;

/**
 * Container creation endpoint for creating new containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "name": "My Container",
 *         "expires_after": {
 *             "anchor": "last_active_at",
 *             "minutes": 20
 *         }
 *     }'
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{
 *         "name": "My Container"
 *     }'
 * ```
 */
export const createContainerV1ContainersPost = (
	variables: CreateContainerV1ContainersPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateContainerV1ContainersPostResponse,
		CreateContainerV1ContainersPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/containers", method: "post", ...variables, signal });

export type RetrieveContainerContainersContainerIdGetPathParams = {
	containerId: string;
};

export type RetrieveContainerContainersContainerIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveContainerContainersContainerIdGetResponse = {
	[key: string]: any;
};

export type RetrieveContainerContainersContainerIdGetVariables = {
	pathParams: RetrieveContainerContainersContainerIdGetPathParams;
} & FetcherExtraProps;

/**
 * Container retrieve endpoint for getting details of a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const retrieveContainerContainersContainerIdGet = (
	variables: RetrieveContainerContainersContainerIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveContainerContainersContainerIdGetResponse,
		RetrieveContainerContainersContainerIdGetError,
		undefined,
		{},
		{},
		RetrieveContainerContainersContainerIdGetPathParams
	>({ url: "/containers/{containerId}", method: "get", ...variables, signal });

export type DeleteContainerContainersContainerIdDeletePathParams = {
	containerId: string;
};

export type DeleteContainerContainersContainerIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteContainerContainersContainerIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteContainerContainersContainerIdDeleteVariables = {
	pathParams: DeleteContainerContainersContainerIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Container delete endpoint for deleting a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const deleteContainerContainersContainerIdDelete = (
	variables: DeleteContainerContainersContainerIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteContainerContainersContainerIdDeleteResponse,
		DeleteContainerContainersContainerIdDeleteError,
		undefined,
		{},
		{},
		DeleteContainerContainersContainerIdDeletePathParams
	>({
		url: "/containers/{containerId}",
		method: "delete",
		...variables,
		signal,
	});

export type RetrieveContainerV1ContainersContainerIdGetPathParams = {
	containerId: string;
};

export type RetrieveContainerV1ContainersContainerIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveContainerV1ContainersContainerIdGetResponse = {
	[key: string]: any;
};

export type RetrieveContainerV1ContainersContainerIdGetVariables = {
	pathParams: RetrieveContainerV1ContainersContainerIdGetPathParams;
} & FetcherExtraProps;

/**
 * Container retrieve endpoint for getting details of a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const retrieveContainerV1ContainersContainerIdGet = (
	variables: RetrieveContainerV1ContainersContainerIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveContainerV1ContainersContainerIdGetResponse,
		RetrieveContainerV1ContainersContainerIdGetError,
		undefined,
		{},
		{},
		RetrieveContainerV1ContainersContainerIdGetPathParams
	>({
		url: "/v1/containers/{containerId}",
		method: "get",
		...variables,
		signal,
	});

export type DeleteContainerV1ContainersContainerIdDeletePathParams = {
	containerId: string;
};

export type DeleteContainerV1ContainersContainerIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteContainerV1ContainersContainerIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteContainerV1ContainersContainerIdDeleteVariables = {
	pathParams: DeleteContainerV1ContainersContainerIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Container delete endpoint for deleting a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const deleteContainerV1ContainersContainerIdDelete = (
	variables: DeleteContainerV1ContainersContainerIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteContainerV1ContainersContainerIdDeleteResponse,
		DeleteContainerV1ContainersContainerIdDeleteError,
		undefined,
		{},
		{},
		DeleteContainerV1ContainersContainerIdDeletePathParams
	>({
		url: "/v1/containers/{containerId}",
		method: "delete",
		...variables,
		signal,
	});

export type SearchSearchPostQueryParams = {
	search_tool_name?: string | null;
};

export type SearchSearchPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type SearchSearchPostResponse = {
	[key: string]: any;
};

export type SearchSearchPostVariables = {
	queryParams?: SearchSearchPostQueryParams;
} & FetcherExtraProps;

/**
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "search_tool_name": "litellm-search",
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 *     "object": "search",
 *     "results": [
 *         {
 *             "title": "Result title",
 *             "url": "https://example.com",
 *             "snippet": "Result snippet...",
 *             "date": "2024-01-01",
 *             "last_updated": "2024-01-01"
 *         }
 *     ]
 * }
 * ```
 */
export const searchSearchPost = (variables: SearchSearchPostVariables, signal?: AbortSignal) =>
	fetch<
		SearchSearchPostResponse,
		SearchSearchPostError,
		undefined,
		{},
		SearchSearchPostQueryParams,
		{}
	>({ url: "/search", method: "post", ...variables, signal });

export type SearchV1SearchPostQueryParams = {
	search_tool_name?: string | null;
};

export type SearchV1SearchPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type SearchV1SearchPostResponse = {
	[key: string]: any;
};

export type SearchV1SearchPostVariables = {
	queryParams?: SearchV1SearchPostQueryParams;
} & FetcherExtraProps;

/**
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "search_tool_name": "litellm-search",
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 *     "object": "search",
 *     "results": [
 *         {
 *             "title": "Result title",
 *             "url": "https://example.com",
 *             "snippet": "Result snippet...",
 *             "date": "2024-01-01",
 *             "last_updated": "2024-01-01"
 *         }
 *     ]
 * }
 * ```
 */
export const searchV1SearchPost = (variables: SearchV1SearchPostVariables, signal?: AbortSignal) =>
	fetch<
		SearchV1SearchPostResponse,
		SearchV1SearchPostError,
		undefined,
		{},
		SearchV1SearchPostQueryParams,
		{}
	>({ url: "/v1/search", method: "post", ...variables, signal });

export type SearchSearchSearchToolNamePostPathParams = {
	searchToolName: string | null;
};

export type SearchSearchSearchToolNamePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type SearchSearchSearchToolNamePostResponse = {
	[key: string]: any;
};

export type SearchSearchSearchToolNamePostVariables = {
	pathParams: SearchSearchSearchToolNamePostPathParams;
} & FetcherExtraProps;

/**
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "search_tool_name": "litellm-search",
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 *     "object": "search",
 *     "results": [
 *         {
 *             "title": "Result title",
 *             "url": "https://example.com",
 *             "snippet": "Result snippet...",
 *             "date": "2024-01-01",
 *             "last_updated": "2024-01-01"
 *         }
 *     ]
 * }
 * ```
 */
export const searchSearchSearchToolNamePost = (
	variables: SearchSearchSearchToolNamePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		SearchSearchSearchToolNamePostResponse,
		SearchSearchSearchToolNamePostError,
		undefined,
		{},
		{},
		SearchSearchSearchToolNamePostPathParams
	>({ url: "/search/{searchToolName}", method: "post", ...variables, signal });

export type SearchV1SearchSearchToolNamePostPathParams = {
	searchToolName: string | null;
};

export type SearchV1SearchSearchToolNamePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type SearchV1SearchSearchToolNamePostResponse = {
	[key: string]: any;
};

export type SearchV1SearchSearchToolNamePostVariables = {
	pathParams: SearchV1SearchSearchToolNamePostPathParams;
} & FetcherExtraProps;

/**
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "search_tool_name": "litellm-search",
 *         "query": "latest AI developments 2024",
 *         "max_results": 5,
 *         "search_domain_filter": ["arxiv.org", "nature.com"],
 *         "country": "US"
 *     }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 *     "object": "search",
 *     "results": [
 *         {
 *             "title": "Result title",
 *             "url": "https://example.com",
 *             "snippet": "Result snippet...",
 *             "date": "2024-01-01",
 *             "last_updated": "2024-01-01"
 *         }
 *     ]
 * }
 * ```
 */
export const searchV1SearchSearchToolNamePost = (
	variables: SearchV1SearchSearchToolNamePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		SearchV1SearchSearchToolNamePostResponse,
		SearchV1SearchSearchToolNamePostError,
		undefined,
		{},
		{},
		SearchV1SearchSearchToolNamePostPathParams
	>({
		url: "/v1/search/{searchToolName}",
		method: "post",
		...variables,
		signal,
	});

export type ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams = {
	model: string | null;
};

export type ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostResponse = {
	[key: string]: any;
};

export type ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostVariables = {
	pathParams: ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams;
} & FetcherExtraProps;

export const imageGenerationOpenaiDeploymentsModelImagesGenerationsPost = (
	variables: ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostResponse,
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostError,
		undefined,
		{},
		{},
		ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostPathParams
	>({
		url: "/openai/deployments/{model}/images/generations",
		method: "post",
		...variables,
		signal,
	});

export type ImageGenerationImagesGenerationsPostQueryParams = {
	model?: string | null;
};

export type ImageGenerationImagesGenerationsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ImageGenerationImagesGenerationsPostResponse = {
	[key: string]: any;
};

export type ImageGenerationImagesGenerationsPostVariables = {
	queryParams?: ImageGenerationImagesGenerationsPostQueryParams;
} & FetcherExtraProps;

export const imageGenerationImagesGenerationsPost = (
	variables: ImageGenerationImagesGenerationsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ImageGenerationImagesGenerationsPostResponse,
		ImageGenerationImagesGenerationsPostError,
		undefined,
		{},
		ImageGenerationImagesGenerationsPostQueryParams,
		{}
	>({ url: "/images/generations", method: "post", ...variables, signal });

export type ImageGenerationV1ImagesGenerationsPostQueryParams = {
	model?: string | null;
};

export type ImageGenerationV1ImagesGenerationsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ImageGenerationV1ImagesGenerationsPostResponse = {
	[key: string]: any;
};

export type ImageGenerationV1ImagesGenerationsPostVariables = {
	queryParams?: ImageGenerationV1ImagesGenerationsPostQueryParams;
} & FetcherExtraProps;

export const imageGenerationV1ImagesGenerationsPost = (
	variables: ImageGenerationV1ImagesGenerationsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ImageGenerationV1ImagesGenerationsPostResponse,
		ImageGenerationV1ImagesGenerationsPostError,
		undefined,
		{},
		ImageGenerationV1ImagesGenerationsPostQueryParams,
		{}
	>({ url: "/v1/images/generations", method: "post", ...variables, signal });

export type ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams = {
	model: string | null;
};

export type ImageEditApiOpenaiDeploymentsModelImagesEditsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ImageEditApiOpenaiDeploymentsModelImagesEditsPostResponse = {
	[key: string]: any;
};

export type ImageEditApiOpenaiDeploymentsModelImagesEditsPostVariables = {
	body: Schemas.BodyImageEditApiOpenaiDeploymentsModelImagesEditsPost;
	pathParams: ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create
 *
 * ```bash
 * curl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'
 * ```
 */
export const imageEditApiOpenaiDeploymentsModelImagesEditsPost = (
	variables: ImageEditApiOpenaiDeploymentsModelImagesEditsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostResponse,
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostError,
		Schemas.BodyImageEditApiOpenaiDeploymentsModelImagesEditsPost,
		{},
		{},
		ImageEditApiOpenaiDeploymentsModelImagesEditsPostPathParams
	>({
		url: "/openai/deployments/{model}/images/edits",
		method: "post",
		...variables,
		signal,
	});

export type ImageEditApiImagesEditsPostQueryParams = {
	model?: string | null;
};

export type ImageEditApiImagesEditsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ImageEditApiImagesEditsPostResponse = {
	[key: string]: any;
};

export type ImageEditApiImagesEditsPostVariables = {
	body: Schemas.BodyImageEditApiImagesEditsPost;
	queryParams?: ImageEditApiImagesEditsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create
 *
 * ```bash
 * curl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'
 * ```
 */
export const imageEditApiImagesEditsPost = (
	variables: ImageEditApiImagesEditsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ImageEditApiImagesEditsPostResponse,
		ImageEditApiImagesEditsPostError,
		Schemas.BodyImageEditApiImagesEditsPost,
		{},
		ImageEditApiImagesEditsPostQueryParams,
		{}
	>({ url: "/images/edits", method: "post", ...variables, signal });

export type ImageEditApiV1ImagesEditsPostQueryParams = {
	model?: string | null;
};

export type ImageEditApiV1ImagesEditsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ImageEditApiV1ImagesEditsPostResponse = {
	[key: string]: any;
};

export type ImageEditApiV1ImagesEditsPostVariables = {
	body: Schemas.BodyImageEditApiV1ImagesEditsPost;
	queryParams?: ImageEditApiV1ImagesEditsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create
 *
 * ```bash
 * curl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'
 * ```
 */
export const imageEditApiV1ImagesEditsPost = (
	variables: ImageEditApiV1ImagesEditsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ImageEditApiV1ImagesEditsPostResponse,
		ImageEditApiV1ImagesEditsPostError,
		Schemas.BodyImageEditApiV1ImagesEditsPost,
		{},
		ImageEditApiV1ImagesEditsPostQueryParams,
		{}
	>({ url: "/v1/images/edits", method: "post", ...variables, signal });

export type CreateFineTuningJobFineTuningJobsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateFineTuningJobFineTuningJobsPostResponse = {
	[key: string]: any;
};

export type CreateFineTuningJobFineTuningJobsPostVariables = {
	body: Schemas.LiteLLMFineTuningJobCreate;
} & FetcherExtraProps;

/**
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create
 *
 * Example Curl:
 * ```
 * curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{
 *     "model": "gpt-3.5-turbo",
 *     "training_file": "file-abc123",
 *     "hyperparameters": {
 *       "n_epochs": 4
 *     }
 *   }'
 * ```
 */
export const createFineTuningJobFineTuningJobsPost = (
	variables: CreateFineTuningJobFineTuningJobsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateFineTuningJobFineTuningJobsPostResponse,
		CreateFineTuningJobFineTuningJobsPostError,
		Schemas.LiteLLMFineTuningJobCreate,
		{},
		{},
		{}
	>({ url: "/fine_tuning/jobs", method: "post", ...variables, signal });

export type ListFineTuningJobsFineTuningJobsGetQueryParams = {
	custom_llm_provider?: ("openai" | "azure") | null;
	/**
	 * Comma separated list of model names to filter by. Example: 'gpt-4o,gpt-4o-mini'
	 */
	target_model_names?: string | null;
	after?: string | null;
	limit?: number | null;
};

export type ListFineTuningJobsFineTuningJobsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListFineTuningJobsFineTuningJobsGetResponse = {
	[key: string]: any;
};

export type ListFineTuningJobsFineTuningJobsGetVariables = {
	queryParams?: ListFineTuningJobsFineTuningJobsGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists fine-tuning jobs for the organization.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `after`: Identifier for the last job from the previous pagination request.
 * - `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 */
export const listFineTuningJobsFineTuningJobsGet = (
	variables: ListFineTuningJobsFineTuningJobsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListFineTuningJobsFineTuningJobsGetResponse,
		ListFineTuningJobsFineTuningJobsGetError,
		undefined,
		{},
		ListFineTuningJobsFineTuningJobsGetQueryParams,
		{}
	>({ url: "/fine_tuning/jobs", method: "get", ...variables, signal });

export type CreateFineTuningJobV1FineTuningJobsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateFineTuningJobV1FineTuningJobsPostResponse = {
	[key: string]: any;
};

export type CreateFineTuningJobV1FineTuningJobsPostVariables = {
	body: Schemas.LiteLLMFineTuningJobCreate;
} & FetcherExtraProps;

/**
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create
 *
 * Example Curl:
 * ```
 * curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{
 *     "model": "gpt-3.5-turbo",
 *     "training_file": "file-abc123",
 *     "hyperparameters": {
 *       "n_epochs": 4
 *     }
 *   }'
 * ```
 */
export const createFineTuningJobV1FineTuningJobsPost = (
	variables: CreateFineTuningJobV1FineTuningJobsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateFineTuningJobV1FineTuningJobsPostResponse,
		CreateFineTuningJobV1FineTuningJobsPostError,
		Schemas.LiteLLMFineTuningJobCreate,
		{},
		{},
		{}
	>({ url: "/v1/fine_tuning/jobs", method: "post", ...variables, signal });

export type ListFineTuningJobsV1FineTuningJobsGetQueryParams = {
	custom_llm_provider?: ("openai" | "azure") | null;
	/**
	 * Comma separated list of model names to filter by. Example: 'gpt-4o,gpt-4o-mini'
	 */
	target_model_names?: string | null;
	after?: string | null;
	limit?: number | null;
};

export type ListFineTuningJobsV1FineTuningJobsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListFineTuningJobsV1FineTuningJobsGetResponse = {
	[key: string]: any;
};

export type ListFineTuningJobsV1FineTuningJobsGetVariables = {
	queryParams?: ListFineTuningJobsV1FineTuningJobsGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists fine-tuning jobs for the organization.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `after`: Identifier for the last job from the previous pagination request.
 * - `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 */
export const listFineTuningJobsV1FineTuningJobsGet = (
	variables: ListFineTuningJobsV1FineTuningJobsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListFineTuningJobsV1FineTuningJobsGetResponse,
		ListFineTuningJobsV1FineTuningJobsGetError,
		undefined,
		{},
		ListFineTuningJobsV1FineTuningJobsGetQueryParams,
		{}
	>({ url: "/v1/fine_tuning/jobs", method: "get", ...variables, signal });

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams = {
	fineTuningJobId: string;
};

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams = {
	custom_llm_provider?: ("openai" | "azure") | null;
};

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetResponse = {
	[key: string]: any;
};

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetVariables = {
	pathParams: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams;
	queryParams?: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a fine-tuning job.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 */
export const retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet = (
	variables: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetResponse,
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetError,
		undefined,
		{},
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams,
		RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams
	>({
		url: "/fine_tuning/jobs/{fineTuningJobId}",
		method: "get",
		...variables,
		signal,
	});

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams = {
	fineTuningJobId: string;
};

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams = {
	custom_llm_provider?: ("openai" | "azure") | null;
};

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetResponse = {
	[key: string]: any;
};

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetVariables = {
	pathParams: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams;
	queryParams?: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a fine-tuning job.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 */
export const retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet = (
	variables: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetResponse,
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetError,
		undefined,
		{},
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams,
		RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams
	>({
		url: "/v1/fine_tuning/jobs/{fineTuningJobId}",
		method: "get",
		...variables,
		signal,
	});

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams = {
	fineTuningJobId: string;
};

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostVariables = {
	pathParams: CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a fine-tuning job.
 *
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 */
export const cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost = (
	variables: CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostResponse,
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostError,
		undefined,
		{},
		{},
		CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams
	>({
		url: "/fine_tuning/jobs/{fineTuningJobId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams = {
	fineTuningJobId: string;
};

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostResponse = {
	[key: string]: any;
};

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostVariables = {
	pathParams: CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a fine-tuning job.
 *
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 */
export const cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost = (
	variables: CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostResponse,
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostError,
		undefined,
		{},
		{},
		CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams
	>({
		url: "/v1/fine_tuning/jobs/{fineTuningJobId}/cancel",
		method: "post",
		...variables,
		signal,
	});

export type VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams = {
	vectorStoreId: string;
};

export type VectorStoreSearchVectorStoresVectorStoreIdSearchPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VectorStoreSearchVectorStoresVectorStoreIdSearchPostResponse = {
	[key: string]: any;
};

export type VectorStoreSearchVectorStoresVectorStoreIdSearchPostVariables = {
	pathParams: VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams;
} & FetcherExtraProps;

/**
 * Search a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/search
 */
export const vectorStoreSearchVectorStoresVectorStoreIdSearchPost = (
	variables: VectorStoreSearchVectorStoresVectorStoreIdSearchPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostResponse,
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostError,
		undefined,
		{},
		{},
		VectorStoreSearchVectorStoresVectorStoreIdSearchPostPathParams
	>({
		url: "/vector_stores/{vectorStoreId}/search",
		method: "post",
		...variables,
		signal,
	});

export type VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams = {
	vectorStoreId: string;
};

export type VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostResponse = {
	[key: string]: any;
};

export type VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostVariables = {
	pathParams: VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams;
} & FetcherExtraProps;

/**
 * Search a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/search
 */
export const vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost = (
	variables: VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostResponse,
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostError,
		undefined,
		{},
		{},
		VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostPathParams
	>({
		url: "/v1/vector_stores/{vectorStoreId}/search",
		method: "post",
		...variables,
		signal,
	});

export type VectorStoreCreateVectorStoresPostError = Fetcher.ErrorWrapper<undefined>;

export type VectorStoreCreateVectorStoresPostResponse = {
	[key: string]: any;
};

export type VectorStoreCreateVectorStoresPostVariables = FetcherExtraProps;

/**
 * Create a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/create
 */
export const vectorStoreCreateVectorStoresPost = (
	variables: VectorStoreCreateVectorStoresPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VectorStoreCreateVectorStoresPostResponse,
		VectorStoreCreateVectorStoresPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/vector_stores", method: "post", ...variables, signal });

export type VectorStoreCreateV1VectorStoresPostError = Fetcher.ErrorWrapper<undefined>;

export type VectorStoreCreateV1VectorStoresPostResponse = {
	[key: string]: any;
};

export type VectorStoreCreateV1VectorStoresPostVariables = FetcherExtraProps;

/**
 * Create a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/create
 */
export const vectorStoreCreateV1VectorStoresPost = (
	variables: VectorStoreCreateV1VectorStoresPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		VectorStoreCreateV1VectorStoresPostResponse,
		VectorStoreCreateV1VectorStoresPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/vector_stores", method: "post", ...variables, signal });

export type IndexCreateV1IndexesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type IndexCreateV1IndexesPostResponse = {
	[key: string]: any;
};

export type IndexCreateV1IndexesPostVariables = {
	body: Schemas.IndexCreateRequest;
} & FetcherExtraProps;

/**
 * Create an index. Just writes the index to the database.
 *
 * ```bash
 * curl -L -X POST 'http://0.0.0.0:4000/indexes/create'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -H 'LiteLLM-Beta: indexes_beta=v1'         -d '{
 *         "index_name": "dall-e-3",
 *         "vector_store_index": "real-index-name",
 *         "vector_store_name": "azure-ai-search"
 *     }'
 * ```
 */
export const indexCreateV1IndexesPost = (
	variables: IndexCreateV1IndexesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		IndexCreateV1IndexesPostResponse,
		IndexCreateV1IndexesPostError,
		Schemas.IndexCreateRequest,
		{},
		{},
		{}
	>({ url: "/v1/indexes", method: "post", ...variables, signal });

export type GetCredentialsCredentialsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetCredentialsCredentialsGetResponse = {
	[key: string]: any;
};

export type GetCredentialsCredentialsGetVariables = FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialsCredentialsGet = (
	variables: GetCredentialsCredentialsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetCredentialsCredentialsGetResponse,
		GetCredentialsCredentialsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/credentials", method: "get", ...variables, signal });

export type CreateCredentialCredentialsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateCredentialCredentialsPostResponse = {
	[key: string]: any;
};

export type CreateCredentialCredentialsPostVariables = {
	body: Schemas.CreateCredentialItem;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 * Stores credential in DB.
 * Reloads credentials in memory.
 */
export const createCredentialCredentialsPost = (
	variables: CreateCredentialCredentialsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateCredentialCredentialsPostResponse,
		CreateCredentialCredentialsPostError,
		Schemas.CreateCredentialItem,
		{},
		{},
		{}
	>({ url: "/credentials", method: "post", ...variables, signal });

export type GetCredentialCredentialsByModelModelIdGetPathParams = {
	/**
	 * The credential name, percent-decoded; may contain slashes
	 */
	credentialName: string;
	modelId: string | null;
};

export type GetCredentialCredentialsByModelModelIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetCredentialCredentialsByModelModelIdGetVariables = {
	pathParams: GetCredentialCredentialsByModelModelIdGetPathParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialCredentialsByModelModelIdGet = (
	variables: GetCredentialCredentialsByModelModelIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CredentialItem,
		GetCredentialCredentialsByModelModelIdGetError,
		undefined,
		{},
		{},
		GetCredentialCredentialsByModelModelIdGetPathParams
	>({
		url: "/credentials/by_model/{modelId}",
		method: "get",
		...variables,
		signal,
	});

export type GetCredentialCredentialsByNameCredentialNameGetPathParams = {
	/**
	 * The credential name, percent-decoded; may contain slashes
	 */
	credentialName: string;
};

export type GetCredentialCredentialsByNameCredentialNameGetQueryParams = {
	model_id?: string | null;
};

export type GetCredentialCredentialsByNameCredentialNameGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetCredentialCredentialsByNameCredentialNameGetVariables = {
	pathParams: GetCredentialCredentialsByNameCredentialNameGetPathParams;
	queryParams?: GetCredentialCredentialsByNameCredentialNameGetQueryParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialCredentialsByNameCredentialNameGet = (
	variables: GetCredentialCredentialsByNameCredentialNameGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CredentialItem,
		GetCredentialCredentialsByNameCredentialNameGetError,
		undefined,
		{},
		GetCredentialCredentialsByNameCredentialNameGetQueryParams,
		GetCredentialCredentialsByNameCredentialNameGetPathParams
	>({
		url: "/credentials/by_name/{credentialName}",
		method: "get",
		...variables,
		signal,
	});

export type DeleteCredentialCredentialsCredentialNameDeletePathParams = {
	/**
	 * The credential name, percent-decoded; may contain slashes
	 */
	credentialName: string;
};

export type DeleteCredentialCredentialsCredentialNameDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteCredentialCredentialsCredentialNameDeleteResponse = {
	[key: string]: any;
};

export type DeleteCredentialCredentialsCredentialNameDeleteVariables = {
	pathParams: DeleteCredentialCredentialsCredentialNameDeletePathParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const deleteCredentialCredentialsCredentialNameDelete = (
	variables: DeleteCredentialCredentialsCredentialNameDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteCredentialCredentialsCredentialNameDeleteResponse,
		DeleteCredentialCredentialsCredentialNameDeleteError,
		undefined,
		{},
		{},
		DeleteCredentialCredentialsCredentialNameDeletePathParams
	>({
		url: "/credentials/{credentialName}",
		method: "delete",
		...variables,
		signal,
	});

export type UpdateCredentialCredentialsCredentialNamePatchPathParams = {
	/**
	 * The credential name, percent-decoded; may contain slashes
	 */
	credentialName: string;
};

export type UpdateCredentialCredentialsCredentialNamePatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateCredentialCredentialsCredentialNamePatchVariables = {
	body: Schemas.CredentialItem;
	pathParams: UpdateCredentialCredentialsCredentialNamePatchPathParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const updateCredentialCredentialsCredentialNamePatch = (
	variables: UpdateCredentialCredentialsCredentialNamePatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		UpdateCredentialCredentialsCredentialNamePatchError,
		Schemas.CredentialItem,
		{},
		{},
		UpdateCredentialCredentialsCredentialNamePatchPathParams
	>({
		url: "/credentials/{credentialName}",
		method: "patch",
		...variables,
		signal,
	});

export type GetMcpToolsV1McpToolsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetMcpToolsV1McpToolsGetResponse = {
	[key: string]: any;
};

export type GetMcpToolsV1McpToolsGetVariables = FetcherExtraProps;

/**
 * Get all MCP tools available for the current key, including those from access groups
 */
export const getMcpToolsV1McpToolsGet = (
	variables: GetMcpToolsV1McpToolsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<GetMcpToolsV1McpToolsGetResponse, GetMcpToolsV1McpToolsGetError, undefined, {}, {}, {}>({
		url: "/v1/mcp/tools",
		method: "get",
		...variables,
		signal,
	});

export type GetMcpAccessGroupsV1McpAccessGroupsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetMcpAccessGroupsV1McpAccessGroupsGetResponse = {
	[key: string]: any;
};

export type GetMcpAccessGroupsV1McpAccessGroupsGetVariables = FetcherExtraProps;

/**
 * Get all available MCP access groups from the database AND config
 */
export const getMcpAccessGroupsV1McpAccessGroupsGet = (
	variables: GetMcpAccessGroupsV1McpAccessGroupsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetMcpAccessGroupsV1McpAccessGroupsGetResponse,
		GetMcpAccessGroupsV1McpAccessGroupsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/mcp/access_groups", method: "get", ...variables, signal });

export type HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams = {
	serverId: string;
};

export type HealthCheckMcpServerV1McpServerServerIdHealthGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type HealthCheckMcpServerV1McpServerServerIdHealthGetResponse = {
	[key: string]: any;
};

export type HealthCheckMcpServerV1McpServerServerIdHealthGetVariables = {
	pathParams: HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams;
} & FetcherExtraProps;

/**
 * Perform health check on a specific MCP server
 */
export const healthCheckMcpServerV1McpServerServerIdHealthGet = (
	variables: HealthCheckMcpServerV1McpServerServerIdHealthGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthCheckMcpServerV1McpServerServerIdHealthGetResponse,
		HealthCheckMcpServerV1McpServerServerIdHealthGetError,
		undefined,
		{},
		{},
		HealthCheckMcpServerV1McpServerServerIdHealthGetPathParams
	>({
		url: "/v1/mcp/server/{serverId}/health",
		method: "get",
		...variables,
		signal,
	});

export type HealthCheckAllMcpServersV1McpServerHealthGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthCheckAllMcpServersV1McpServerHealthGetResponse = {
	[key: string]: any;
};

export type HealthCheckAllMcpServersV1McpServerHealthGetVariables = FetcherExtraProps;

/**
 * Perform health check on all accessible MCP servers
 */
export const healthCheckAllMcpServersV1McpServerHealthGet = (
	variables: HealthCheckAllMcpServersV1McpServerHealthGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthCheckAllMcpServersV1McpServerHealthGetResponse,
		HealthCheckAllMcpServersV1McpServerHealthGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/mcp/server/health", method: "get", ...variables, signal });

export type FetchAllMcpServersV1McpServerGetError = Fetcher.ErrorWrapper<undefined>;

export type FetchAllMcpServersV1McpServerGetResponse = Schemas.LiteLLMMCPServerTable[];

export type FetchAllMcpServersV1McpServerGetVariables = FetcherExtraProps;

/**
 * Returns the mcp server list with associated teams
 */
export const fetchAllMcpServersV1McpServerGet = (
	variables: FetchAllMcpServersV1McpServerGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		FetchAllMcpServersV1McpServerGetResponse,
		FetchAllMcpServersV1McpServerGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/mcp/server", method: "get", ...variables, signal });

export type AddMcpServerV1McpServerPostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type AddMcpServerV1McpServerPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AddMcpServerV1McpServerPostVariables = {
	body?: Schemas.NewMCPServerRequest;
	headers?: AddMcpServerV1McpServerPostHeaders;
} & FetcherExtraProps;

/**
 * Allows creation of mcp servers
 */
export const addMcpServerV1McpServerPost = (
	variables: AddMcpServerV1McpServerPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMMCPServerTable,
		AddMcpServerV1McpServerPostError,
		Schemas.NewMCPServerRequest,
		AddMcpServerV1McpServerPostHeaders,
		{},
		{}
	>({ url: "/v1/mcp/server", method: "post", ...variables, signal });

export type EditMcpServerV1McpServerPutHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type EditMcpServerV1McpServerPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type EditMcpServerV1McpServerPutVariables = {
	body: Schemas.UpdateMCPServerRequest;
	headers?: EditMcpServerV1McpServerPutHeaders;
} & FetcherExtraProps;

/**
 * Allows deleting mcp serves in the db
 */
export const editMcpServerV1McpServerPut = (
	variables: EditMcpServerV1McpServerPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMMCPServerTable,
		EditMcpServerV1McpServerPutError,
		Schemas.UpdateMCPServerRequest,
		EditMcpServerV1McpServerPutHeaders,
		{},
		{}
	>({ url: "/v1/mcp/server", method: "put", ...variables, signal });

export type FetchMcpServerV1McpServerServerIdGetPathParams = {
	serverId: string;
};

export type FetchMcpServerV1McpServerServerIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type FetchMcpServerV1McpServerServerIdGetVariables = {
	pathParams: FetchMcpServerV1McpServerServerIdGetPathParams;
} & FetcherExtraProps;

/**
 * Returns the mcp server info
 */
export const fetchMcpServerV1McpServerServerIdGet = (
	variables: FetchMcpServerV1McpServerServerIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMMCPServerTable,
		FetchMcpServerV1McpServerServerIdGetError,
		undefined,
		{},
		{},
		FetchMcpServerV1McpServerServerIdGetPathParams
	>({ url: "/v1/mcp/server/{serverId}", method: "get", ...variables, signal });

export type RemoveMcpServerV1McpServerServerIdDeletePathParams = {
	serverId: string;
};

export type RemoveMcpServerV1McpServerServerIdDeleteHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type RemoveMcpServerV1McpServerServerIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RemoveMcpServerV1McpServerServerIdDeleteResponse = {
	[key: string]: any;
};

export type RemoveMcpServerV1McpServerServerIdDeleteVariables = {
	headers?: RemoveMcpServerV1McpServerServerIdDeleteHeaders;
	pathParams: RemoveMcpServerV1McpServerServerIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Allows deleting mcp serves in the db
 */
export const removeMcpServerV1McpServerServerIdDelete = (
	variables: RemoveMcpServerV1McpServerServerIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RemoveMcpServerV1McpServerServerIdDeleteResponse,
		RemoveMcpServerV1McpServerServerIdDeleteError,
		undefined,
		RemoveMcpServerV1McpServerServerIdDeleteHeaders,
		{},
		RemoveMcpServerV1McpServerServerIdDeletePathParams
	>({
		url: "/v1/mcp/server/{serverId}",
		method: "delete",
		...variables,
		signal,
	});

export type AnthropicResponseV1MessagesPostError = Fetcher.ErrorWrapper<undefined>;

export type AnthropicResponseV1MessagesPostResponse = {
	[key: string]: any;
};

export type AnthropicResponseV1MessagesPostVariables = FetcherExtraProps;

/**
 * Use `{PROXY_BASE_URL}/anthropic/v1/messages` instead - [Docs](https://docs.litellm.ai/docs/anthropic_completion).
 *
 * This was a BETA endpoint that calls 100+ LLMs in the anthropic format.
 */
export const anthropicResponseV1MessagesPost = (
	variables: AnthropicResponseV1MessagesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AnthropicResponseV1MessagesPostResponse,
		AnthropicResponseV1MessagesPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/messages", method: "post", ...variables, signal });

export type CountTokensV1MessagesCountTokensPostError = Fetcher.ErrorWrapper<undefined>;

export type CountTokensV1MessagesCountTokensPostResponse = {
	[key: string]: any;
};

export type CountTokensV1MessagesCountTokensPostVariables = FetcherExtraProps;

/**
 * Count tokens for Anthropic Messages API format.
 *
 * This endpoint follows the Anthropic Messages API token counting specification.
 * It accepts the same parameters as the /v1/messages endpoint but returns
 * token counts instead of generating a response.
 *
 * Example usage:
 * ```
 * curl -X POST "http://localhost:4000/v1/messages/count_tokens?beta=true"       -H "Content-Type: application/json"       -H "Authorization: Bearer your-key"       -d '{
 *     "model": "claude-3-sonnet-20240229",
 *     "messages": [{"role": "user", "content": "Hello Claude!"}]
 *   }'
 * ```
 *
 * Returns: {"input_tokens": <number>}
 */
export const countTokensV1MessagesCountTokensPost = (
	variables: CountTokensV1MessagesCountTokensPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CountTokensV1MessagesCountTokensPostResponse,
		CountTokensV1MessagesCountTokensPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v1/messages/count_tokens", method: "post", ...variables, signal });

export type GoogleGenerateContentModelsModelNameGenerateContentPostPathParams = {
	modelName: string;
};

export type GoogleGenerateContentModelsModelNameGenerateContentPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GoogleGenerateContentModelsModelNameGenerateContentPostResponse = {
	[key: string]: any;
};

export type GoogleGenerateContentModelsModelNameGenerateContentPostVariables = {
	pathParams: GoogleGenerateContentModelsModelNameGenerateContentPostPathParams;
} & FetcherExtraProps;

export const googleGenerateContentModelsModelNameGenerateContentPost = (
	variables: GoogleGenerateContentModelsModelNameGenerateContentPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GoogleGenerateContentModelsModelNameGenerateContentPostResponse,
		GoogleGenerateContentModelsModelNameGenerateContentPostError,
		undefined,
		{},
		{},
		GoogleGenerateContentModelsModelNameGenerateContentPostPathParams
	>({
		url: "/models/{modelName}:generateContent",
		method: "post",
		...variables,
		signal,
	});

export type GoogleGenerateContentV1betaModelsModelNameGenerateContentPostPathParams = {
	modelName: string;
};

export type GoogleGenerateContentV1betaModelsModelNameGenerateContentPostError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type GoogleGenerateContentV1betaModelsModelNameGenerateContentPostResponse = {
	[key: string]: any;
};

export type GoogleGenerateContentV1betaModelsModelNameGenerateContentPostVariables = {
	pathParams: GoogleGenerateContentV1betaModelsModelNameGenerateContentPostPathParams;
} & FetcherExtraProps;

export const googleGenerateContentV1betaModelsModelNameGenerateContentPost = (
	variables: GoogleGenerateContentV1betaModelsModelNameGenerateContentPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GoogleGenerateContentV1betaModelsModelNameGenerateContentPostResponse,
		GoogleGenerateContentV1betaModelsModelNameGenerateContentPostError,
		undefined,
		{},
		{},
		GoogleGenerateContentV1betaModelsModelNameGenerateContentPostPathParams
	>({
		url: "/v1beta/models/{modelName}:generateContent",
		method: "post",
		...variables,
		signal,
	});

export type GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams = {
	modelName: string;
};

export type GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostResponse = {
	[key: string]: any;
};

export type GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostVariables = {
	pathParams: GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams;
} & FetcherExtraProps;

export const googleStreamGenerateContentModelsModelNameStreamGenerateContentPost = (
	variables: GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostResponse,
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostError,
		undefined,
		{},
		{},
		GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostPathParams
	>({
		url: "/models/{modelName}:streamGenerateContent",
		method: "post",
		...variables,
		signal,
	});

export type GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostPathParams = {
	modelName: string;
};

export type GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostResponse = {
	[key: string]: any;
};

export type GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostVariables = {
	pathParams: GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostPathParams;
} & FetcherExtraProps;

export const googleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPost = (
	variables: GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostResponse,
		GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostError,
		undefined,
		{},
		{},
		GoogleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPostPathParams
	>({
		url: "/v1beta/models/{modelName}:streamGenerateContent",
		method: "post",
		...variables,
		signal,
	});

export type GoogleCountTokensModelsModelNameCountTokensPostPathParams = {
	modelName: string;
};

export type GoogleCountTokensModelsModelNameCountTokensPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GoogleCountTokensModelsModelNameCountTokensPostVariables = {
	pathParams: GoogleCountTokensModelsModelNameCountTokensPostPathParams;
} & FetcherExtraProps;

/**
 * ```json
 * return {
 *     "totalTokens": 31,
 *     "totalBillableCharacters": 96,
 *     "promptTokensDetails": [
 *         {
 *         "modality": "TEXT",
 *         "tokenCount": 31
 *         }
 *     ]
 * }
 * ```
 */
export const googleCountTokensModelsModelNameCountTokensPost = (
	variables: GoogleCountTokensModelsModelNameCountTokensPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TokenCountDetailsResponse,
		GoogleCountTokensModelsModelNameCountTokensPostError,
		undefined,
		{},
		{},
		GoogleCountTokensModelsModelNameCountTokensPostPathParams
	>({
		url: "/models/{modelName}:countTokens",
		method: "post",
		...variables,
		signal,
	});

export type GoogleCountTokensV1betaModelsModelNameCountTokensPostPathParams = {
	modelName: string;
};

export type GoogleCountTokensV1betaModelsModelNameCountTokensPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GoogleCountTokensV1betaModelsModelNameCountTokensPostVariables = {
	pathParams: GoogleCountTokensV1betaModelsModelNameCountTokensPostPathParams;
} & FetcherExtraProps;

/**
 * ```json
 * return {
 *     "totalTokens": 31,
 *     "totalBillableCharacters": 96,
 *     "promptTokensDetails": [
 *         {
 *         "modality": "TEXT",
 *         "tokenCount": 31
 *         }
 *     ]
 * }
 * ```
 */
export const googleCountTokensV1betaModelsModelNameCountTokensPost = (
	variables: GoogleCountTokensV1betaModelsModelNameCountTokensPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TokenCountDetailsResponse,
		GoogleCountTokensV1betaModelsModelNameCountTokensPostError,
		undefined,
		{},
		{},
		GoogleCountTokensV1betaModelsModelNameCountTokensPostPathParams
	>({
		url: "/v1beta/models/{modelName}:countTokens",
		method: "post",
		...variables,
		signal,
	});

export type GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams = {
	teamId: string | null;
};

export type GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams = {
	endpoint_id?: string | null;
};

export type GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetVariables = {
	pathParams: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams;
	queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams;
} & FetcherExtraProps;

/**
 * GET configured pass through endpoint.
 *
 * If no endpoint_id given, return all configured endpoints.
 */
export const getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet = (
	variables: GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PassThroughEndpointResponse,
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetError,
		undefined,
		{},
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetQueryParams,
		GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetPathParams
	>({
		url: "/config/pass_through_endpoint/team/{teamId}",
		method: "get",
		...variables,
		signal,
	});

export type GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams = {
	endpoint_id?: string | null;
	team_id?: string | null;
};

export type GetPassThroughEndpointsConfigPassThroughEndpointGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetPassThroughEndpointsConfigPassThroughEndpointGetVariables = {
	queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams;
} & FetcherExtraProps;

/**
 * GET configured pass through endpoint.
 *
 * If no endpoint_id given, return all configured endpoints.
 */
export const getPassThroughEndpointsConfigPassThroughEndpointGet = (
	variables: GetPassThroughEndpointsConfigPassThroughEndpointGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PassThroughEndpointResponse,
		GetPassThroughEndpointsConfigPassThroughEndpointGetError,
		undefined,
		{},
		GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams,
		{}
	>({
		url: "/config/pass_through_endpoint",
		method: "get",
		...variables,
		signal,
	});

export type CreatePassThroughEndpointsConfigPassThroughEndpointPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreatePassThroughEndpointsConfigPassThroughEndpointPostResponse = {
	[key: string]: any;
};

export type CreatePassThroughEndpointsConfigPassThroughEndpointPostVariables = {
	body: Schemas.PassThroughGenericEndpoint;
} & FetcherExtraProps;

/**
 * Create new pass-through endpoint
 */
export const createPassThroughEndpointsConfigPassThroughEndpointPost = (
	variables: CreatePassThroughEndpointsConfigPassThroughEndpointPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreatePassThroughEndpointsConfigPassThroughEndpointPostResponse,
		CreatePassThroughEndpointsConfigPassThroughEndpointPostError,
		Schemas.PassThroughGenericEndpoint,
		{},
		{},
		{}
	>({
		url: "/config/pass_through_endpoint",
		method: "post",
		...variables,
		signal,
	});

export type DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams = {
	endpoint_id: string;
};

export type DeletePassThroughEndpointsConfigPassThroughEndpointDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeletePassThroughEndpointsConfigPassThroughEndpointDeleteVariables = {
	queryParams: DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Delete a pass-through endpoint by ID.
 *
 * Returns - the deleted endpoint
 */
export const deletePassThroughEndpointsConfigPassThroughEndpointDelete = (
	variables: DeletePassThroughEndpointsConfigPassThroughEndpointDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PassThroughEndpointResponse,
		DeletePassThroughEndpointsConfigPassThroughEndpointDeleteError,
		undefined,
		{},
		DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams,
		{}
	>({
		url: "/config/pass_through_endpoint",
		method: "delete",
		...variables,
		signal,
	});

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams = {
	endpointId: string;
};

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostResponse = {
	[key: string]: any;
};

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostVariables = {
	body: Schemas.PassThroughGenericEndpoint;
	pathParams: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams;
} & FetcherExtraProps;

/**
 * Update a pass-through endpoint by ID.
 */
export const updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost = (
	variables: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostResponse,
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostError,
		Schemas.PassThroughGenericEndpoint,
		{},
		{},
		UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams
	>({
		url: "/config/pass_through_endpoint/{endpointId}",
		method: "post",
		...variables,
		signal,
	});

export type TestEndpointTestGetError = Fetcher.ErrorWrapper<undefined>;

export type TestEndpointTestGetResponse = {
	[key: string]: any;
};

export type TestEndpointTestGetVariables = FetcherExtraProps;

/**
 * [DEPRECATED] use `/health/liveliness` instead.
 *
 * A test endpoint that pings the proxy server to check if it's healthy.
 *
 * Parameters:
 *     request (Request): The incoming request.
 *
 * Returns:
 *     dict: A dictionary containing the route of the request URL.
 */
export const testEndpointTestGet = (
	variables: TestEndpointTestGetVariables,
	signal?: AbortSignal,
) =>
	fetch<TestEndpointTestGetResponse, TestEndpointTestGetError, undefined, {}, {}, {}>({
		url: "/test",
		method: "get",
		...variables,
		signal,
	});

export type HealthServicesEndpointHealthServicesGetQueryParams = {
	/**
	 * Specify the service being hit.
	 */
	service:
		| (
				| "slack_budget_alerts"
				| "langfuse"
				| "slack"
				| "openmeter"
				| "webhook"
				| "email"
				| "braintrust"
				| "datadog"
				| "generic_api"
				| "arize"
		  )
		| string;
};

export type HealthServicesEndpointHealthServicesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type HealthServicesEndpointHealthServicesGetResponse = {
	[key: string]: any;
};

export type HealthServicesEndpointHealthServicesGetVariables = {
	queryParams: HealthServicesEndpointHealthServicesGetQueryParams;
} & FetcherExtraProps;

/**
 * Use this admin-only endpoint to check if the service is healthy.
 *
 * Example:
 * ```
 * curl -L -X GET 'http://0.0.0.0:4000/health/services?service=datadog'     -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const healthServicesEndpointHealthServicesGet = (
	variables: HealthServicesEndpointHealthServicesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthServicesEndpointHealthServicesGetResponse,
		HealthServicesEndpointHealthServicesGetError,
		undefined,
		{},
		HealthServicesEndpointHealthServicesGetQueryParams,
		{}
	>({ url: "/health/services", method: "get", ...variables, signal });

export type HealthEndpointHealthGetQueryParams = {
	/**
	 * Specify the model name (optional)
	 */
	model?: string | null;
	/**
	 * Specify the model ID (optional)
	 */
	model_id?: string | null;
};

export type HealthEndpointHealthGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type HealthEndpointHealthGetResponse = {
	[key: string]: any;
};

export type HealthEndpointHealthGetVariables = {
	queryParams?: HealthEndpointHealthGetQueryParams;
} & FetcherExtraProps;

/**
 *  USE `/health/liveliness` to health check the proxy 
 *
 * See more  https://docs.litellm.ai/docs/proxy/health
 *
 *
 * Check the health of all the endpoints in config.yaml
 *
 * To run health checks in the background, add this to config.yaml:
 * ```
 * general_settings:
 *     # ... other settings
 *     background_health_checks: True
 * ```
 * else, the health checks will be run on models when /health is called.
 */
export const healthEndpointHealthGet = (
	variables: HealthEndpointHealthGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthEndpointHealthGetResponse,
		HealthEndpointHealthGetError,
		undefined,
		{},
		HealthEndpointHealthGetQueryParams,
		{}
	>({ url: "/health", method: "get", ...variables, signal });

export type HealthCheckHistoryEndpointHealthHistoryGetQueryParams = {
	/**
	 * Filter by specific model name
	 */
	model?: string | null;
	/**
	 * Filter by status (healthy/unhealthy)
	 */
	status_filter?: string | null;
	/**
	 * Number of records to return
	 *
	 * @maximum 1000
	 * @minimum 1
	 * @default 100
	 */
	limit?: number;
	/**
	 * Number of records to skip
	 *
	 * @minimum 0
	 * @default 0
	 */
	offset?: number;
};

export type HealthCheckHistoryEndpointHealthHistoryGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type HealthCheckHistoryEndpointHealthHistoryGetResponse = {
	[key: string]: any;
};

export type HealthCheckHistoryEndpointHealthHistoryGetVariables = {
	queryParams?: HealthCheckHistoryEndpointHealthHistoryGetQueryParams;
} & FetcherExtraProps;

/**
 * Get health check history for models
 *
 * Returns historical health check data with optional filtering.
 */
export const healthCheckHistoryEndpointHealthHistoryGet = (
	variables: HealthCheckHistoryEndpointHealthHistoryGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthCheckHistoryEndpointHealthHistoryGetResponse,
		HealthCheckHistoryEndpointHealthHistoryGetError,
		undefined,
		{},
		HealthCheckHistoryEndpointHealthHistoryGetQueryParams,
		{}
	>({ url: "/health/history", method: "get", ...variables, signal });

export type LatestHealthChecksEndpointHealthLatestGetError = Fetcher.ErrorWrapper<undefined>;

export type LatestHealthChecksEndpointHealthLatestGetResponse = {
	[key: string]: any;
};

export type LatestHealthChecksEndpointHealthLatestGetVariables = FetcherExtraProps;

/**
 * Get the latest health check status for all models
 *
 * Returns the most recent health check result for each model.
 */
export const latestHealthChecksEndpointHealthLatestGet = (
	variables: LatestHealthChecksEndpointHealthLatestGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		LatestHealthChecksEndpointHealthLatestGetResponse,
		LatestHealthChecksEndpointHealthLatestGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/health/latest", method: "get", ...variables, signal });

export type SharedHealthCheckStatusEndpointHealthSharedStatusGetError =
	Fetcher.ErrorWrapper<undefined>;

export type SharedHealthCheckStatusEndpointHealthSharedStatusGetResponse = {
	[key: string]: any;
};

export type SharedHealthCheckStatusEndpointHealthSharedStatusGetVariables = FetcherExtraProps;

/**
 * Get the status of shared health check coordination across pods.
 *
 * Returns information about Redis connectivity, lock status, and cache status.
 */
export const sharedHealthCheckStatusEndpointHealthSharedStatusGet = (
	variables: SharedHealthCheckStatusEndpointHealthSharedStatusGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		SharedHealthCheckStatusEndpointHealthSharedStatusGetResponse,
		SharedHealthCheckStatusEndpointHealthSharedStatusGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/health/shared-status", method: "get", ...variables, signal });

export type ActiveCallbacksActiveCallbacksGetError = Fetcher.ErrorWrapper<undefined>;

export type ActiveCallbacksActiveCallbacksGetResponse = {
	[key: string]: any;
};

export type ActiveCallbacksActiveCallbacksGetVariables = FetcherExtraProps;

/**
 * Returns a list of litellm level settings
 *
 * This is useful for debugging and ensuring the proxy server is configured correctly.
 *
 * Response schema:
 * ```
 * {
 *     "alerting": _alerting,
 *     "litellm.callbacks": litellm_callbacks,
 *     "litellm.input_callback": litellm_input_callbacks,
 *     "litellm.failure_callback": litellm_failure_callbacks,
 *     "litellm.success_callback": litellm_success_callbacks,
 *     "litellm._async_success_callback": litellm_async_success_callbacks,
 *     "litellm._async_failure_callback": litellm_async_failure_callbacks,
 *     "litellm._async_input_callback": litellm_async_input_callbacks,
 *     "all_litellm_callbacks": all_litellm_callbacks,
 *     "num_callbacks": len(all_litellm_callbacks),
 *     "num_alerting": _num_alerting,
 *     "litellm.request_timeout": litellm.request_timeout,
 * }
 * ```
 */
export const activeCallbacksActiveCallbacksGet = (
	variables: ActiveCallbacksActiveCallbacksGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ActiveCallbacksActiveCallbacksGetResponse,
		ActiveCallbacksActiveCallbacksGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/active/callbacks", method: "get", ...variables, signal });

export type ActiveCallbacksSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type ActiveCallbacksSettingsGetResponse = {
	[key: string]: any;
};

export type ActiveCallbacksSettingsGetVariables = FetcherExtraProps;

/**
 * Returns a list of litellm level settings
 *
 * This is useful for debugging and ensuring the proxy server is configured correctly.
 *
 * Response schema:
 * ```
 * {
 *     "alerting": _alerting,
 *     "litellm.callbacks": litellm_callbacks,
 *     "litellm.input_callback": litellm_input_callbacks,
 *     "litellm.failure_callback": litellm_failure_callbacks,
 *     "litellm.success_callback": litellm_success_callbacks,
 *     "litellm._async_success_callback": litellm_async_success_callbacks,
 *     "litellm._async_failure_callback": litellm_async_failure_callbacks,
 *     "litellm._async_input_callback": litellm_async_input_callbacks,
 *     "all_litellm_callbacks": all_litellm_callbacks,
 *     "num_callbacks": len(all_litellm_callbacks),
 *     "num_alerting": _num_alerting,
 *     "litellm.request_timeout": litellm.request_timeout,
 * }
 * ```
 */
export const activeCallbacksSettingsGet = (
	variables: ActiveCallbacksSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<ActiveCallbacksSettingsGetResponse, ActiveCallbacksSettingsGetError, undefined, {}, {}, {}>(
		{ url: "/settings", method: "get", ...variables, signal },
	);

export type HealthReadinessHealthReadinessGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthReadinessHealthReadinessGetResponse = {
	[key: string]: any;
};

export type HealthReadinessHealthReadinessGetVariables = FetcherExtraProps;

/**
 * Unprotected endpoint for checking if worker can receive requests
 */
export const healthReadinessHealthReadinessGet = (
	variables: HealthReadinessHealthReadinessGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthReadinessHealthReadinessGetResponse,
		HealthReadinessHealthReadinessGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/health/readiness", method: "get", ...variables, signal });

export type HealthLivelinessHealthLivenessGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthLivelinessHealthLivenessGetResponse = {
	[key: string]: any;
};

export type HealthLivelinessHealthLivenessGetVariables = FetcherExtraProps;

/**
 * Unprotected endpoint for checking if worker is alive
 */
export const healthLivelinessHealthLivenessGet = (
	variables: HealthLivelinessHealthLivenessGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthLivelinessHealthLivenessGetResponse,
		HealthLivelinessHealthLivenessGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/health/liveness", method: "get", ...variables, signal });

export type HealthLivelinessHealthLivelinessGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthLivelinessHealthLivelinessGetResponse = {
	[key: string]: any;
};

export type HealthLivelinessHealthLivelinessGetVariables = FetcherExtraProps;

/**
 * Unprotected endpoint for checking if worker is alive
 */
export const healthLivelinessHealthLivelinessGet = (
	variables: HealthLivelinessHealthLivelinessGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		HealthLivelinessHealthLivelinessGetResponse,
		HealthLivelinessHealthLivelinessGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/health/liveliness", method: "get", ...variables, signal });

export type TestModelConnectionHealthTestConnectionPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TestModelConnectionHealthTestConnectionPostResponse = {
	[key: string]: any;
};

export type TestModelConnectionHealthTestConnectionPostVariables = {
	body?: Schemas.BodyTestModelConnectionHealthTestConnectionPost;
} & FetcherExtraProps;

/**
 * Test a direct connection to a specific model.
 *
 * This endpoint allows you to verify if your proxy can successfully connect to a specific model.
 * It's useful for troubleshooting model connectivity issues without going through the full proxy routing.
 *
 * Example:
 * ```bash
 * curl -X POST 'http://localhost:4000/health/test_connection' \
 *   -H 'Authorization: Bearer sk-1234' \
 *   -H 'Content-Type: application/json' \
 *   -d '{
 *     "litellm_params": {
 *         "model": "gpt-4",
 *         "custom_llm_provider": "azure_ai",
 *         "litellm_credential_name": null,
 *         "api_key": "6xxxxxxx",
 *         "api_base": "https://litellm8397336933.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21",
 *     },
 *     "mode": "chat"
 *   }'
 * ```
 *
 * Returns:
 *     dict: A dictionary containing the health check result with either success information or error details.
 */
export const testModelConnectionHealthTestConnectionPost = (
	variables: TestModelConnectionHealthTestConnectionPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TestModelConnectionHealthTestConnectionPostResponse,
		TestModelConnectionHealthTestConnectionPostError,
		Schemas.BodyTestModelConnectionHealthTestConnectionPost,
		{},
		{},
		{}
	>({ url: "/health/test_connection", method: "post", ...variables, signal });

export type GenerateKeyFnKeyGeneratePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type GenerateKeyFnKeyGeneratePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GenerateKeyFnKeyGeneratePostVariables = {
	body?: Schemas.GenerateKeyRequest;
	headers?: GenerateKeyFnKeyGeneratePostHeaders;
} & FetcherExtraProps;

/**
 * Generate an API key based on the provided data.
 *
 * Docs: https://docs.litellm.ai/docs/proxy/virtual_keys
 *
 * Parameters:
 * - duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - key_alias: Optional[str] - User defined key alias
 * - key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.
 * - team_id: Optional[str] - The team id of the key
 * - user_id: Optional[str] - The user id of the key
 * - organization_id: Optional[str] - The organization id of the key. If not set, and team_id is set, the organization id will be the same as the team id. If conflict, an error will be raised.
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 * - aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models
 * - config: Optional[dict] - any key-specific configs, overrides config in config.yaml
 * - spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend
 * - send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key
 * - max_budget: Optional[float] - Specify max budget for a given key.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.
 * - model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.
 * - model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.
 * - tpm_limit_type: Optional[str] - Type of tpm limit. Options: "best_effort_throughput" (no error if we're overallocating tpm), "guaranteed_throughput" (raise an error if we're overallocating tpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".
 * - rpm_limit_type: Optional[str] - Type of rpm limit. Options: "best_effort_throughput" (no error if we're overallocating rpm), "guaranteed_throughput" (raise an error if we're overallocating rpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request
 * - blocked: Optional[bool] - Whether the key is blocked.
 * - rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)
 * - tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)
 * - soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]
 * - allowed_passthrough_routes: Optional[list] - List of allowed pass through endpoints for the key. Store the actual endpoint or store a wildcard pattern for a set of endpoints. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through endpoints the key can access, without specifying the routes. If allowed_routes is specified, allowed_pass_through_endpoints is ignored.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - key_type: Optional[str] - Type of key that determines default allowed routes. Options: "llm_api" (can call LLM API routes), "management" (can call management routes), "read_only" (can only call info/read routes), "default" (uses default allowed routes). Defaults to "default".
 * - prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.
 * - auto_rotate: Optional[bool] - Whether this key should be automatically rotated (regenerated)
 * - rotation_interval: Optional[str] - How often to auto-rotate this key (e.g., '30s', '30m', '30h', '30d'). Required if auto_rotate=True.
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 * Examples:
 *
 * 1. Allow users to turn on/off pii masking
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "permissions": {"allow_pii_controls": true}
 * }'
 * ```
 *
 * Returns:
 * - key: (str) The generated api key
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 */
export const generateKeyFnKeyGeneratePost = (
	variables: GenerateKeyFnKeyGeneratePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.GenerateKeyResponse,
		GenerateKeyFnKeyGeneratePostError,
		Schemas.GenerateKeyRequest,
		GenerateKeyFnKeyGeneratePostHeaders,
		{},
		{}
	>({ url: "/key/generate", method: "post", ...variables, signal });

export type GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostResponse = {
	[key: string]: any;
};

export type GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostVariables = {
	body?: Schemas.GenerateKeyRequest;
	headers?: GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaders;
} & FetcherExtraProps;

/**
 * Generate a Service Account API key based on the provided data. This key does not belong to any user. It belongs to the team.
 *
 * Why use a service account key?
 * - Prevent key from being deleted when user is deleted.
 * - Apply team limits, not team member limits to key.
 *
 * Docs: https://docs.litellm.ai/docs/proxy/virtual_keys
 *
 * Parameters:
 * - duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - key_alias: Optional[str] - User defined key alias
 * - key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.
 * - team_id: Optional[str] - The team id of the key
 * - user_id: Optional[str] - [NON-FUNCTIONAL] THIS WILL BE IGNORED. The user id of the key
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 * - aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models
 * - config: Optional[dict] - any key-specific configs, overrides config in config.yaml
 * - spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend
 * - send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key
 * - max_budget: Optional[float] - Specify max budget for a given key.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.
 * - model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.
 * - model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.
 * - tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request
 * - blocked: Optional[bool] - Whether the key is blocked.
 * - rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)
 * - tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)
 * - soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * Examples:
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 * 1. Allow users to turn on/off pii masking
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "permissions": {"allow_pii_controls": true}
 * }'
 * ```
 *
 * Returns:
 * - key: (str) The generated api key
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 */
export const generateServiceAccountKeyFnKeyServiceAccountGeneratePost = (
	variables: GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostResponse,
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostError,
		Schemas.GenerateKeyRequest,
		GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostHeaders,
		{},
		{}
	>({
		url: "/key/service-account/generate",
		method: "post",
		...variables,
		signal,
	});

export type UpdateKeyFnKeyUpdatePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type UpdateKeyFnKeyUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateKeyFnKeyUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateKeyFnKeyUpdatePostVariables = {
	body: Schemas.UpdateKeyRequest;
	headers?: UpdateKeyFnKeyUpdatePostHeaders;
} & FetcherExtraProps;

/**
 * Update an existing API key's parameters.
 *
 * Parameters:
 * - key: str - The key to update
 * - key_alias: Optional[str] - User-friendly key alias
 * - user_id: Optional[str] - User ID associated with key
 * - team_id: Optional[str] - Team ID associated with key
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call
 * - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - spend: Optional[float] - Amount spent by key
 * - max_budget: Optional[float] - Max budget for key
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - soft_budget: Optional[float] - [TODO] Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 * - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 * - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 * - tpm_limit: Optional[int] - Tokens per minute limit
 * - rpm_limit: Optional[int] - Requests per minute limit
 * - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 * - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 * - tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values
 * - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 * - permissions: Optional[dict] - Key-specific permissions
 * - send_invite_email: Optional[bool] - Send invite email to user_id
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - blocked: Optional[bool] - Whether the key is blocked
 * - aliases: Optional[dict] - Model aliases for the key - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] Key-specific config.
 * - temp_budget_increase: Optional[float] - Temporary budget increase for the key (Enterprise only).
 * - temp_budget_expiry: Optional[str] - Expiry time for the temporary budget increase (Enterprise only).
 * - allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys/*"]
 * - allowed_passthrough_routes: Optional[list] - List of allowed pass through routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through routes the key can access, without specifying the routes. If allowed_routes is specified, allowed_passthrough_routes is ignored.
 * - prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - auto_rotate: Optional[bool] - Whether this key should be automatically rotated
 * - rotation_interval: Optional[str] - How often to rotate this key (e.g., '30d', '90d'). Required if auto_rotate=True
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "key": "sk-1234",
 *     "key_alias": "my-key",
 *     "user_id": "user-1234",
 *     "team_id": "team-1234",
 *     "max_budget": 100,
 *     "metadata": {"any_key": "any-val"},
 * }'
 * ```
 */
export const updateKeyFnKeyUpdatePost = (
	variables: UpdateKeyFnKeyUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateKeyFnKeyUpdatePostResponse,
		UpdateKeyFnKeyUpdatePostError,
		Schemas.UpdateKeyRequest,
		UpdateKeyFnKeyUpdatePostHeaders,
		{},
		{}
	>({ url: "/key/update", method: "post", ...variables, signal });

export type DeleteKeyFnKeyDeletePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type DeleteKeyFnKeyDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteKeyFnKeyDeletePostResponse = {
	[key: string]: any;
};

export type DeleteKeyFnKeyDeletePostVariables = {
	body?: Schemas.KeyRequest;
	headers?: DeleteKeyFnKeyDeletePostHeaders;
} & FetcherExtraProps;

/**
 * Delete a key from the key management system.
 *
 * Parameters::
 * - keys (List[str]): A list of keys or hashed keys to delete. Example {"keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}
 * - key_aliases (List[str]): A list of key aliases to delete. Can be passed instead of `keys`.Example {"key_aliases": ["alias1", "alias2"]}
 *
 * Returns:
 * - deleted_keys (List[str]): A list of deleted keys. Example {"deleted_keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "keys": ["sk-QWrxEynunsNpV1zT48HIrw"]
 * }'
 * ```
 *
 * Raises:
 *     HTTPException: If an error occurs during key deletion.
 */
export const deleteKeyFnKeyDeletePost = (
	variables: DeleteKeyFnKeyDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteKeyFnKeyDeletePostResponse,
		DeleteKeyFnKeyDeletePostError,
		Schemas.KeyRequest,
		DeleteKeyFnKeyDeletePostHeaders,
		{},
		{}
	>({ url: "/key/delete", method: "post", ...variables, signal });

export type InfoKeyFnKeyInfoGetQueryParams = {
	/**
	 * Key in the request parameters
	 */
	key?: string | null;
};

export type InfoKeyFnKeyInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type InfoKeyFnKeyInfoGetResponse = {
	[key: string]: any;
};

export type InfoKeyFnKeyInfoGetVariables = {
	queryParams?: InfoKeyFnKeyInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieve information about a key.
 * Parameters:
 *     key: Optional[str] = Query parameter representing the key in the request
 *     user_api_key_dict: UserAPIKeyAuth = Dependency representing the user's API key
 * Returns:
 *     Dict containing the key and its associated information
 *
 * Example Curl:
 * ```
 * curl -X GET "http://0.0.0.0:4000/key/info?key=sk-02Wr4IAlN3NvPXvL5JVvDA" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Curl - if no key is passed, it will use the Key Passed in Authorization Header
 * ```
 * curl -X GET "http://0.0.0.0:4000/key/info" -H "Authorization: Bearer sk-02Wr4IAlN3NvPXvL5JVvDA"
 * ```
 */
export const infoKeyFnKeyInfoGet = (
	variables: InfoKeyFnKeyInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		InfoKeyFnKeyInfoGetResponse,
		InfoKeyFnKeyInfoGetError,
		undefined,
		{},
		InfoKeyFnKeyInfoGetQueryParams,
		{}
	>({ url: "/key/info", method: "get", ...variables, signal });

export type RegenerateKeyFnKeyRegeneratePostQueryParams = {
	key?: string | null;
};

export type RegenerateKeyFnKeyRegeneratePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type RegenerateKeyFnKeyRegeneratePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RegenerateKeyFnKeyRegeneratePostResponse = Schemas.GenerateKeyResponse | null;

export type RegenerateKeyFnKeyRegeneratePostRequestBody = Schemas.RegenerateKeyRequest | null;

export type RegenerateKeyFnKeyRegeneratePostVariables = {
	body?: RegenerateKeyFnKeyRegeneratePostRequestBody;
	headers?: RegenerateKeyFnKeyRegeneratePostHeaders;
	queryParams?: RegenerateKeyFnKeyRegeneratePostQueryParams;
} & FetcherExtraProps;

/**
 * Regenerate an existing API key while optionally updating its parameters.
 *
 * Parameters:
 * - key: str (path parameter) - The key to regenerate
 * - data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update
 *     - key: Optional[str] - The key to regenerate.
 *     - new_master_key: Optional[str] - The new master key to use, if key is the master key.
 *     - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.
 *     - key_alias: Optional[str] - User-friendly key alias
 *     - user_id: Optional[str] - User ID associated with key
 *     - team_id: Optional[str] - Team ID associated with key
 *     - models: Optional[list] - Model_name's a user is allowed to call
 *     - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 *     - spend: Optional[float] - Amount spent by key
 *     - max_budget: Optional[float] - Max budget for key
 *     - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 *     - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 *     - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 *     - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 *     - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 *     - tpm_limit: Optional[int] - Tokens per minute limit
 *     - rpm_limit: Optional[int] - Requests per minute limit
 *     - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 *     - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 *     - allowed_cache_controls: Optional[list] - List of allowed cache control values
 *     - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 *     - permissions: Optional[dict] - Key-specific permissions
 *     - guardrails: Optional[List[str]] - List of active guardrails for the key
 *     - blocked: Optional[bool] - Whether the key is blocked
 *
 *
 * Returns:
 * - GenerateKeyResponse containing the new key and its updated parameters
 *
 * Example:
 * ```bash
 * curl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "max_budget": 100,
 *     "metadata": {"team": "core-infra"},
 *     "models": ["gpt-4", "gpt-3.5-turbo"]
 * }'
 * ```
 *
 * Note: This is an Enterprise feature. It requires a premium license to use.
 */
export const regenerateKeyFnKeyRegeneratePost = (
	variables: RegenerateKeyFnKeyRegeneratePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RegenerateKeyFnKeyRegeneratePostResponse,
		RegenerateKeyFnKeyRegeneratePostError,
		RegenerateKeyFnKeyRegeneratePostRequestBody,
		RegenerateKeyFnKeyRegeneratePostHeaders,
		RegenerateKeyFnKeyRegeneratePostQueryParams,
		{}
	>({ url: "/key/regenerate", method: "post", ...variables, signal });

export type RegenerateKeyFnKeyKeyRegeneratePostPathParams = {
	key: string | null;
};

export type RegenerateKeyFnKeyKeyRegeneratePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type RegenerateKeyFnKeyKeyRegeneratePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RegenerateKeyFnKeyKeyRegeneratePostResponse = Schemas.GenerateKeyResponse | null;

export type RegenerateKeyFnKeyKeyRegeneratePostRequestBody = Schemas.RegenerateKeyRequest | null;

export type RegenerateKeyFnKeyKeyRegeneratePostVariables = {
	body?: RegenerateKeyFnKeyKeyRegeneratePostRequestBody;
	headers?: RegenerateKeyFnKeyKeyRegeneratePostHeaders;
	pathParams: RegenerateKeyFnKeyKeyRegeneratePostPathParams;
} & FetcherExtraProps;

/**
 * Regenerate an existing API key while optionally updating its parameters.
 *
 * Parameters:
 * - key: str (path parameter) - The key to regenerate
 * - data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update
 *     - key: Optional[str] - The key to regenerate.
 *     - new_master_key: Optional[str] - The new master key to use, if key is the master key.
 *     - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.
 *     - key_alias: Optional[str] - User-friendly key alias
 *     - user_id: Optional[str] - User ID associated with key
 *     - team_id: Optional[str] - Team ID associated with key
 *     - models: Optional[list] - Model_name's a user is allowed to call
 *     - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 *     - spend: Optional[float] - Amount spent by key
 *     - max_budget: Optional[float] - Max budget for key
 *     - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 *     - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 *     - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 *     - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 *     - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 *     - tpm_limit: Optional[int] - Tokens per minute limit
 *     - rpm_limit: Optional[int] - Requests per minute limit
 *     - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 *     - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 *     - allowed_cache_controls: Optional[list] - List of allowed cache control values
 *     - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 *     - permissions: Optional[dict] - Key-specific permissions
 *     - guardrails: Optional[List[str]] - List of active guardrails for the key
 *     - blocked: Optional[bool] - Whether the key is blocked
 *
 *
 * Returns:
 * - GenerateKeyResponse containing the new key and its updated parameters
 *
 * Example:
 * ```bash
 * curl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "max_budget": 100,
 *     "metadata": {"team": "core-infra"},
 *     "models": ["gpt-4", "gpt-3.5-turbo"]
 * }'
 * ```
 *
 * Note: This is an Enterprise feature. It requires a premium license to use.
 */
export const regenerateKeyFnKeyKeyRegeneratePost = (
	variables: RegenerateKeyFnKeyKeyRegeneratePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RegenerateKeyFnKeyKeyRegeneratePostResponse,
		RegenerateKeyFnKeyKeyRegeneratePostError,
		RegenerateKeyFnKeyKeyRegeneratePostRequestBody,
		RegenerateKeyFnKeyKeyRegeneratePostHeaders,
		{},
		RegenerateKeyFnKeyKeyRegeneratePostPathParams
	>({ url: "/key/{key}/regenerate", method: "post", ...variables, signal });

export type ListKeysKeyListGetQueryParams = {
	/**
	 * Page number
	 *
	 * @minimum 1
	 * @default 1
	 */
	page?: number;
	/**
	 * Page size
	 *
	 * @maximum 100
	 * @minimum 1
	 * @default 10
	 */
	size?: number;
	/**
	 * Filter keys by user ID
	 */
	user_id?: string | null;
	/**
	 * Filter keys by team ID
	 */
	team_id?: string | null;
	/**
	 * Filter keys by organization ID
	 */
	organization_id?: string | null;
	/**
	 * Filter keys by key hash
	 */
	key_hash?: string | null;
	/**
	 * Filter keys by key alias
	 */
	key_alias?: string | null;
	/**
	 * Return full key object
	 *
	 * @default false
	 */
	return_full_object?: boolean;
	/**
	 * Include all keys for teams that user is an admin of.
	 *
	 * @default false
	 */
	include_team_keys?: boolean;
	/**
	 * Include keys created by the user
	 *
	 * @default false
	 */
	include_created_by_keys?: boolean;
	/**
	 * Column to sort by (e.g. 'user_id', 'created_at', 'spend')
	 */
	sort_by?: string | null;
	/**
	 * Sort order ('asc' or 'desc')
	 *
	 * @default desc
	 */
	sort_order?: string;
};

export type ListKeysKeyListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListKeysKeyListGetVariables = {
	queryParams?: ListKeysKeyListGetQueryParams;
} & FetcherExtraProps;

/**
 * List all keys for a given user / team / organization.
 *
 * Returns:
 *     {
 *         "keys": List[str] or List[UserAPIKeyAuth],
 *         "total_count": int,
 *         "current_page": int,
 *         "total_pages": int,
 *     }
 */
export const listKeysKeyListGet = (variables: ListKeysKeyListGetVariables, signal?: AbortSignal) =>
	fetch<
		Schemas.KeyListResponseObject,
		ListKeysKeyListGetError,
		undefined,
		{},
		ListKeysKeyListGetQueryParams,
		{}
	>({ url: "/key/list", method: "get", ...variables, signal });

export type KeyAliasesKeyAliasesGetError = Fetcher.ErrorWrapper<undefined>;

export type KeyAliasesKeyAliasesGetResponse = {
	[key: string]: string[];
};

export type KeyAliasesKeyAliasesGetVariables = FetcherExtraProps;

/**
 * Lists all key aliases
 *
 * Returns:
 *     {
 *         "aliases": List[str]
 *     }
 */
export const keyAliasesKeyAliasesGet = (
	variables: KeyAliasesKeyAliasesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<KeyAliasesKeyAliasesGetResponse, KeyAliasesKeyAliasesGetError, undefined, {}, {}, {}>({
		url: "/key/aliases",
		method: "get",
		...variables,
		signal,
	});

export type BlockKeyKeyBlockPostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type BlockKeyKeyBlockPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type BlockKeyKeyBlockPostResponse = Schemas.LiteLLMVerificationToken | null;

export type BlockKeyKeyBlockPostVariables = {
	body: Schemas.BlockKeyRequest;
	headers?: BlockKeyKeyBlockPostHeaders;
} & FetcherExtraProps;

/**
 * Block an Virtual key from making any requests.
 *
 * Parameters:
 * - key: str - The key to block. Can be either the unhashed key (sk-...) or the hashed key value
 *
 *  Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"
 * }'
 * ```
 *
 * Note: This is an admin-only endpoint. Only proxy admins can block keys.
 */
export const blockKeyKeyBlockPost = (
	variables: BlockKeyKeyBlockPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		BlockKeyKeyBlockPostResponse,
		BlockKeyKeyBlockPostError,
		Schemas.BlockKeyRequest,
		BlockKeyKeyBlockPostHeaders,
		{},
		{}
	>({ url: "/key/block", method: "post", ...variables, signal });

export type UnblockKeyKeyUnblockPostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type UnblockKeyKeyUnblockPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UnblockKeyKeyUnblockPostResponse = {
	[key: string]: any;
};

export type UnblockKeyKeyUnblockPostVariables = {
	body: Schemas.BlockKeyRequest;
	headers?: UnblockKeyKeyUnblockPostHeaders;
} & FetcherExtraProps;

/**
 * Unblock a Virtual key to allow it to make requests again.
 *
 * Parameters:
 * - key: str - The key to unblock. Can be either the unhashed key (sk-...) or the hashed key value
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"
 * }'
 * ```
 *
 * Note: This is an admin-only endpoint. Only proxy admins can unblock keys.
 */
export const unblockKeyKeyUnblockPost = (
	variables: UnblockKeyKeyUnblockPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UnblockKeyKeyUnblockPostResponse,
		UnblockKeyKeyUnblockPostError,
		Schemas.BlockKeyRequest,
		UnblockKeyKeyUnblockPostHeaders,
		{},
		{}
	>({ url: "/key/unblock", method: "post", ...variables, signal });

export type KeyHealthKeyHealthPostError = Fetcher.ErrorWrapper<undefined>;

export type KeyHealthKeyHealthPostVariables = FetcherExtraProps;

/**
 * Check the health of the key
 *
 * Checks:
 * - If key based logging is configured correctly - sends a test log
 *
 * Usage
 *
 * Pass the key in the request header
 *
 * ```bash
 * curl -X POST "http://localhost:4000/key/health"      -H "Authorization: Bearer sk-1234"      -H "Content-Type: application/json"
 * ```
 *
 * Response when logging callbacks are setup correctly:
 *
 * ```json
 * {
 *   "key": "healthy",
 *   "logging_callbacks": {
 *     "callbacks": [
 *       "gcs_bucket"
 *     ],
 *     "status": "healthy",
 *     "details": "No logger exceptions triggered, system is healthy. Manually check if logs were sent to ['gcs_bucket']"
 *   }
 * }
 * ```
 *
 *
 * Response when logging callbacks are not setup correctly:
 * ```json
 * {
 *   "key": "unhealthy",
 *   "logging_callbacks": {
 *     "callbacks": [
 *       "gcs_bucket"
 *     ],
 *     "status": "unhealthy",
 *     "details": "Logger exceptions triggered, system is unhealthy: Failed to load vertex credentials. Check to see if credentials containing partial/invalid information."
 *   }
 * }
 * ```
 */
export const keyHealthKeyHealthPost = (
	variables: KeyHealthKeyHealthPostVariables,
	signal?: AbortSignal,
) =>
	fetch<Schemas.KeyHealthResponse, KeyHealthKeyHealthPostError, undefined, {}, {}, {}>({
		url: "/key/health",
		method: "post",
		...variables,
		signal,
	});

export type NewUserUserNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewUserUserNewPostVariables = {
	body?: Schemas.NewUserRequest;
} & FetcherExtraProps;

/**
 * Use this to create a new INTERNAL user with a budget.
 * Internal Users can access LiteLLM Admin UI to make keys, request access to models.
 * This creates a new user and generates a new api key for the new user. The new api key is returned.
 *
 * Returns user id, budget + new key.
 *
 * Parameters:
 * - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.
 * - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.
 * - teams: Optional[list] - specify a list of team id's a user belongs to.
 * - user_email: Optional[str] - Specify a user email.
 * - send_invite_email: Optional[bool] - Specify if an invite email should be sent.
 * - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`
 * - max_budget: Optional[float] - Specify max budget for a given user.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models). Set to ['no-default-models'] to block all model access. Restricting user to only team-based model access.
 * - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)
 * - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)
 * - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response
 * - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-
 * - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.
 * - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user
 * - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.
 * - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.
 * - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)
 * - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.
 * - duration: Optional[str] - Duration for the key auto-created on `/user/new`. Default is None.
 * - key_alias: Optional[str] - Alias for the key auto-created on `/user/new`. Default is None.
 * - sso_user_id: Optional[str] - The id of the user in the SSO provider.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.
 * - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.
 * - organizations: List[str] - List of organization id's the user is a member of
 * Returns:
 * - key: (str) The generated api key for the user
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * - max_budget: (float|None) Max budget for given user.
 *
 * Usage Example
 *
 * ```shell
 *  curl -X POST "http://localhost:4000/user/new"      -H "Content-Type: application/json"      -H "Authorization: Bearer sk-1234"      -d '{
 *      "username": "new_user",
 *      "email": "new_user@example.com"
 *  }'
 * ```
 */
export const newUserUserNewPost = (variables: NewUserUserNewPostVariables, signal?: AbortSignal) =>
	fetch<Schemas.NewUserResponse, NewUserUserNewPostError, Schemas.NewUserRequest, {}, {}, {}>({
		url: "/user/new",
		method: "post",
		...variables,
		signal,
	});

export type UserInfoUserInfoGetQueryParams = {
	/**
	 * User ID in the request parameters
	 */
	user_id?: string | null;
};

export type UserInfoUserInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UserInfoUserInfoGetResponse = {
	[key: string]: any;
};

export type UserInfoUserInfoGetVariables = {
	queryParams?: UserInfoUserInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * [10/07/2024]
 * Note: To get all users (+pagination), use `/user/list` endpoint.
 *
 *
 * Use this to get user information. (user row + all user key info)
 *
 * Example request
 * ```
 * curl -X GET 'http://localhost:4000/user/info?user_id=krrish7%40berri.ai'     --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const userInfoUserInfoGet = (
	variables: UserInfoUserInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UserInfoUserInfoGetResponse,
		UserInfoUserInfoGetError,
		undefined,
		{},
		UserInfoUserInfoGetQueryParams,
		{}
	>({ url: "/user/info", method: "get", ...variables, signal });

export type UserUpdateUserUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UserUpdateUserUpdatePostResponse = {
	[key: string]: any;
};

export type UserUpdateUserUpdatePostVariables = {
	body?: Schemas.UpdateUserRequest;
} & FetcherExtraProps;

/**
 * Example curl
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/user/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "user_id": "test-litellm-user-4",
 *     "user_role": "proxy_admin_viewer"
 * }'
 * ```
 *
 * Parameters:
 *     - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.
 *     - user_email: Optional[str] - Specify a user email.
 *     - password: Optional[str] - Specify a user password.
 *     - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.
 *     - teams: Optional[list] - specify a list of team id's a user belongs to.
 *     - send_invite_email: Optional[bool] - Specify if an invite email should be sent.
 *     - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`
 *     - max_budget: Optional[float] - Specify max budget for a given user.
 *     - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 *     - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 *     - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)
 *     - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)
 *     - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response
 *     - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 *     - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.
 *     - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-
 *     - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.
 *     - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user
 *     - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.
 *     - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 *     - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 *     - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.
 *     - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)
 *     - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 *     - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 *     - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 *     - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.
 *     - duration: Optional[str] - [NOT IMPLEMENTED].
 *     - key_alias: Optional[str] - [NOT IMPLEMENTED].
 *     - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.
 *     - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.
 */
export const userUpdateUserUpdatePost = (
	variables: UserUpdateUserUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UserUpdateUserUpdatePostResponse,
		UserUpdateUserUpdatePostError,
		Schemas.UpdateUserRequest,
		{},
		{},
		{}
	>({ url: "/user/update", method: "post", ...variables, signal });

export type BulkUserUpdateUserBulkUpdatePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type BulkUserUpdateUserBulkUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type BulkUserUpdateUserBulkUpdatePostVariables = {
	body?: Schemas.BulkUpdateUserRequest;
	headers?: BulkUserUpdateUserBulkUpdatePostHeaders;
} & FetcherExtraProps;

/**
 * Bulk update multiple users at once.
 *
 * This endpoint allows updating multiple users in a single request. Each user update
 * is processed independently - if some updates fail, others will still succeed.
 *
 * Parameters:
 * - users: Optional[List[UpdateUserRequest]] - List of specific user update requests
 * - all_users: Optional[bool] - Set to true to update all users in the system
 * - user_updates: Optional[UpdateUserRequest] - Updates to apply when all_users=True
 *
 * Returns:
 * - results: List of individual update results
 * - total_requested: Total number of users requested for update
 * - successful_updates: Number of successful updates
 * - failed_updates: Number of failed updates
 *
 * Example request for specific users:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "users": [
 *         {
 *             "user_id": "user1",
 *             "user_role": "internal_user",
 *             "max_budget": 100.0
 *         },
 *         {
 *             "user_email": "user2@example.com",
 *             "user_role": "internal_user_viewer",
 *             "max_budget": 50.0
 *         }
 *     ]
 * }'
 * ```
 *
 * Example request for all users:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "all_users": true,
 *     "user_updates": {
 *         "user_role": "internal_user",
 *         "max_budget": 50.0
 *     }
 * }'
 * ```
 */
export const bulkUserUpdateUserBulkUpdatePost = (
	variables: BulkUserUpdateUserBulkUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.BulkUpdateUserResponse,
		BulkUserUpdateUserBulkUpdatePostError,
		Schemas.BulkUpdateUserRequest,
		BulkUserUpdateUserBulkUpdatePostHeaders,
		{},
		{}
	>({ url: "/user/bulk_update", method: "post", ...variables, signal });

export type GetUsersUserListGetQueryParams = {
	/**
	 * Filter users by role
	 */
	role?: string | null;
	/**
	 * Get list of users by user_ids
	 */
	user_ids?: string | null;
	/**
	 * Get list of users by sso_user_id
	 */
	sso_user_ids?: string | null;
	/**
	 * Filter users by partial email match
	 */
	user_email?: string | null;
	/**
	 * Filter users by team id
	 */
	team?: string | null;
	/**
	 * Page number
	 *
	 * @minimum 1
	 * @default 1
	 */
	page?: number;
	/**
	 * Number of items per page
	 *
	 * @maximum 100
	 * @minimum 1
	 * @default 25
	 */
	page_size?: number;
	/**
	 * Column to sort by (e.g. 'user_id', 'user_email', 'created_at', 'spend')
	 */
	sort_by?: string | null;
	/**
	 * Sort order ('asc' or 'desc')
	 *
	 * @default asc
	 */
	sort_order?: string;
};

export type GetUsersUserListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetUsersUserListGetVariables = {
	queryParams?: GetUsersUserListGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a paginated list of users with filtering and sorting options.
 *
 * Parameters:
 *     role: Optional[str]
 *         Filter users by role. Can be one of:
 *         - proxy_admin
 *         - proxy_admin_viewer
 *         - internal_user
 *         - internal_user_viewer
 *     user_ids: Optional[str]
 *         Get list of users by user_ids. Comma separated list of user_ids.
 *     sso_ids: Optional[str]
 *         Get list of users by sso_ids. Comma separated list of sso_ids.
 *     user_email: Optional[str]
 *         Filter users by partial email match
 *     team: Optional[str]
 *         Filter users by team id. Will match if user has this team in their teams array.
 *     page: int
 *         The page number to return
 *     page_size: int
 *         The number of items per page
 *     sort_by: Optional[str]
 *         Column to sort by (e.g. 'user_id', 'user_email', 'created_at', 'spend')
 *     sort_order: Optional[str]
 *         Sort order ('asc' or 'desc')
 */
export const getUsersUserListGet = (
	variables: GetUsersUserListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.UserListResponse,
		GetUsersUserListGetError,
		undefined,
		{},
		GetUsersUserListGetQueryParams,
		{}
	>({ url: "/user/list", method: "get", ...variables, signal });

export type DeleteUserUserDeletePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type DeleteUserUserDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteUserUserDeletePostResponse = {
	[key: string]: any;
};

export type DeleteUserUserDeletePostVariables = {
	body: Schemas.DeleteUserRequest;
	headers?: DeleteUserUserDeletePostHeaders;
} & FetcherExtraProps;

/**
 * delete user and associated user keys
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/user/delete'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data-raw '{
 *     "user_ids": ["45e3e396-ee08-4a61-a88e-16b3ce7e0849"]
 * }'
 * ```
 *
 * Parameters:
 * - user_ids: List[str] - The list of user id's to be deleted.
 */
export const deleteUserUserDeletePost = (
	variables: DeleteUserUserDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteUserUserDeletePostResponse,
		DeleteUserUserDeletePostError,
		Schemas.DeleteUserRequest,
		DeleteUserUserDeletePostHeaders,
		{},
		{}
	>({ url: "/user/delete", method: "post", ...variables, signal });

export type GetUserDailyActivityUserDailyActivityGetQueryParams = {
	/**
	 * Start date in YYYY-MM-DD format
	 */
	start_date?: string | null;
	/**
	 * End date in YYYY-MM-DD format
	 */
	end_date?: string | null;
	/**
	 * Filter by specific model
	 */
	model?: string | null;
	/**
	 * Filter by specific API key
	 */
	api_key?: string | null;
	/**
	 * Page number for pagination
	 *
	 * @minimum 1
	 * @default 1
	 */
	page?: number;
	/**
	 * Items per page
	 *
	 * @maximum 1000
	 * @minimum 1
	 * @default 50
	 */
	page_size?: number;
};

export type GetUserDailyActivityUserDailyActivityGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetUserDailyActivityUserDailyActivityGetVariables = {
	queryParams?: GetUserDailyActivityUserDailyActivityGetQueryParams;
} & FetcherExtraProps;

/**
 * [BETA] This is a beta endpoint. It will change.
 *
 * Meant to optimize querying spend data for analytics for a user.
 *
 * Returns:
 * (by date)
 * - spend
 * - prompt_tokens
 * - completion_tokens
 * - cache_read_input_tokens
 * - cache_creation_input_tokens
 * - total_tokens
 * - api_requests
 * - breakdown by model, api_key, provider
 */
export const getUserDailyActivityUserDailyActivityGet = (
	variables: GetUserDailyActivityUserDailyActivityGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SpendAnalyticsPaginatedResponse,
		GetUserDailyActivityUserDailyActivityGetError,
		undefined,
		{},
		GetUserDailyActivityUserDailyActivityGetQueryParams,
		{}
	>({ url: "/user/daily/activity", method: "get", ...variables, signal });

export type GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams = {
	/**
	 * Start date in YYYY-MM-DD format
	 */
	start_date?: string | null;
	/**
	 * End date in YYYY-MM-DD format
	 */
	end_date?: string | null;
	/**
	 * Filter by specific model
	 */
	model?: string | null;
	/**
	 * Filter by specific API key
	 */
	api_key?: string | null;
};

export type GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetVariables = {
	queryParams?: GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams;
} & FetcherExtraProps;

/**
 * Aggregated analytics for a user's daily activity without pagination.
 * Returns the same response shape as the paginated endpoint with page metadata set to single-page.
 */
export const getUserDailyActivityAggregatedUserDailyActivityAggregatedGet = (
	variables: GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SpendAnalyticsPaginatedResponse,
		GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetError,
		undefined,
		{},
		GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetQueryParams,
		{}
	>({
		url: "/user/daily/activity/aggregated",
		method: "get",
		...variables,
		signal,
	});

export type NewTeamTeamNewPostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type NewTeamTeamNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewTeamTeamNewPostVariables = {
	body?: Schemas.NewTeamRequest;
	headers?: NewTeamTeamNewPostHeaders;
} & FetcherExtraProps;

/**
 * Allow users to create a new team. Apply user permissions to their team.
 *
 *  [Detailed Doc on setting team budgets](https://docs.litellm.ai/docs/proxy/team_budgets)
 *
 *
 * Parameters:
 * - team_alias: Optional[str] - User defined team alias
 * - team_id: Optional[str] - The team id of the user. If none passed, we'll generate it.
 * - members_with_roles: List[{"role": "admin" or "user", "user_id": "<user-id>"}] - A list of users and their roles in the team. Get user_id when making a new user via `/user/new`.
 * - team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]
 * - metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"extra_info": "some info"}
 * - model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit for this team - applied across all keys for this team.
 * - model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit for this team - applied across all keys for this team.
 * - tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit
 * - rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit
 * - rpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of RPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating RPM, or "best_effort_throughput" for best effort enforcement.
 * - tpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of TPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating TPM, or "best_effort_throughput" for best effort enforcement.
 * - max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget
 * - budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)
 * - models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.
 * - blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.
 * - members: Optional[List] - Control team members via `/team/member/add` and `/team/member/delete`.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.
 * - team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.
 * - team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.
 * - team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"
 * - prompts: Optional[List[str]] - List of allowed prompts for the team. If specified, the team will only be able to use these specific prompts.
 * - allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 *
 * Returns:
 * - team_id: (str) Unique team id - used for tracking spend across multiple keys for same team id.
 *
 * _deprecated_params:
 * - admins: list - A list of user_id's for the admin role
 * - users: list - A list of user_id's for the user role
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *   "team_alias": "my-new-team_2",
 *   "members_with_roles": [{"role": "admin", "user_id": "user-1234"},
 *     {"role": "user", "user_id": "user-2434"}]
 * }'
 *
 * ```
 *
 *  ```
 * curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *             "team_alias": "QA Prod Bot",
 *             "max_budget": 0.000000001,
 *             "budget_duration": "1d"
 *         }'
 * ```
 */
export const newTeamTeamNewPost = (variables: NewTeamTeamNewPostVariables, signal?: AbortSignal) =>
	fetch<
		Schemas.LiteLLMTeamTableOutput,
		NewTeamTeamNewPostError,
		Schemas.NewTeamRequest,
		NewTeamTeamNewPostHeaders,
		{},
		{}
	>({ url: "/team/new", method: "post", ...variables, signal });

export type UpdateTeamTeamUpdatePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type UpdateTeamTeamUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateTeamTeamUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateTeamTeamUpdatePostVariables = {
	body: Schemas.UpdateTeamRequest;
	headers?: UpdateTeamTeamUpdatePostHeaders;
} & FetcherExtraProps;

/**
 * Use `/team/member_add` AND `/team/member/delete` to add/remove new team members
 *
 * You can now update team budget / rate limits via /team/update
 *
 * Parameters:
 * - team_id: str - The team id of the user. Required param.
 * - team_alias: Optional[str] - User defined team alias
 * - team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]
 * - metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit
 * - rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit
 * - max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget
 * - budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)
 * - models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.
 * - team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.
 * - team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.
 * - team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"
 * - allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.
 * - model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit per model for this team. Example: {"gpt-4": 100, "gpt-3.5-turbo": 200}
 * - model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit per model for this team. Example: {"gpt-4": 10000, "gpt-3.5-turbo": 20000}
 * Example - update team TPM Limit
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",
 *     "tpm_limit": 100
 * }'
 * ```
 *
 * Example - Update Team `max_budget` budget
 * ```
 * curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",
 *     "max_budget": 10
 * }'
 * ```
 */
export const updateTeamTeamUpdatePost = (
	variables: UpdateTeamTeamUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateTeamTeamUpdatePostResponse,
		UpdateTeamTeamUpdatePostError,
		Schemas.UpdateTeamRequest,
		UpdateTeamTeamUpdatePostHeaders,
		{},
		{}
	>({ url: "/team/update", method: "post", ...variables, signal });

export type TeamMemberAddTeamMemberAddPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberAddTeamMemberAddPostVariables = {
	body: Schemas.TeamMemberAddRequest;
} & FetcherExtraProps;

/**
 * Add new members (either via user_email or user_id) to a team
 *
 * If user doesn't exist, new user row will also be added to User Table
 *
 * Only proxy_admin or admin of team, allowed to access this endpoint.
 * ```
 *
 * curl -X POST 'http://0.0.0.0:4000/team/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{"team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849", "member": {"role": "user", "user_id": "krrish247652@berri.ai"}}'
 *
 * ```
 */
export const teamMemberAddTeamMemberAddPost = (
	variables: TeamMemberAddTeamMemberAddPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TeamAddMemberResponse,
		TeamMemberAddTeamMemberAddPostError,
		Schemas.TeamMemberAddRequest,
		{},
		{},
		{}
	>({ url: "/team/member_add", method: "post", ...variables, signal });

export type TeamMemberDeleteTeamMemberDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberDeleteTeamMemberDeletePostResponse = {
	[key: string]: any;
};

export type TeamMemberDeleteTeamMemberDeletePostVariables = {
	body: Schemas.TeamMemberDeleteRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * delete members (either via user_email or user_id) from a team
 *
 * If user doesn't exist, an exception will be raised
 * ```
 * curl -X POST 'http://0.0.0.0:8000/team/member_delete'
 * -H 'Authorization: Bearer sk-1234'
 * -H 'Content-Type: application/json'
 * -d '{
 *     "team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",
 *     "user_id": "krrish247652@berri.ai"
 * }'
 * ```
 */
export const teamMemberDeleteTeamMemberDeletePost = (
	variables: TeamMemberDeleteTeamMemberDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TeamMemberDeleteTeamMemberDeletePostResponse,
		TeamMemberDeleteTeamMemberDeletePostError,
		Schemas.TeamMemberDeleteRequest,
		{},
		{},
		{}
	>({ url: "/team/member_delete", method: "post", ...variables, signal });

export type TeamMemberUpdateTeamMemberUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberUpdateTeamMemberUpdatePostVariables = {
	body: Schemas.TeamMemberUpdateRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * Update team member budgets and team member role
 */
export const teamMemberUpdateTeamMemberUpdatePost = (
	variables: TeamMemberUpdateTeamMemberUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TeamMemberUpdateResponse,
		TeamMemberUpdateTeamMemberUpdatePostError,
		Schemas.TeamMemberUpdateRequest,
		{},
		{},
		{}
	>({ url: "/team/member_update", method: "post", ...variables, signal });

export type BulkTeamMemberAddTeamBulkMemberAddPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type BulkTeamMemberAddTeamBulkMemberAddPostVariables = {
	body: Schemas.BulkTeamMemberAddRequest;
} & FetcherExtraProps;

/**
 * Bulk add multiple members to a team at once.
 *
 * This endpoint reuses the same logic as /team/member_add but provides a bulk-friendly response format.
 *
 * Parameters:
 * - team_id: str - The ID of the team to add members to
 * - members: List[Member] - List of members to add to the team
 * - all_users: Optional[bool] - Flag to add all users on Proxy to the team
 * - max_budget_in_team: Optional[float] - Maximum budget allocated to each user within the team
 *
 * Returns:
 * - results: List of individual member addition results
 * - total_requested: Total number of members requested for addition
 * - successful_additions: Number of successful additions
 * - failed_additions: Number of failed additions
 * - updated_team: The updated team object
 *
 * Example request:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/team/bulk_member_add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234",
 *     "members": [
 *         {
 *             "user_id": "user1",
 *             "role": "user"
 *         },
 *         {
 *             "user_email": "user2@example.com",
 *             "role": "admin"
 *         }
 *     ],
 *     "max_budget_in_team": 100.0
 * }'
 * ```
 */
export const bulkTeamMemberAddTeamBulkMemberAddPost = (
	variables: BulkTeamMemberAddTeamBulkMemberAddPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.BulkTeamMemberAddResponse,
		BulkTeamMemberAddTeamBulkMemberAddPostError,
		Schemas.BulkTeamMemberAddRequest,
		{},
		{},
		{}
	>({ url: "/team/bulk_member_add", method: "post", ...variables, signal });

export type DeleteTeamTeamDeletePostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type DeleteTeamTeamDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteTeamTeamDeletePostResponse = {
	[key: string]: any;
};

export type DeleteTeamTeamDeletePostVariables = {
	body: Schemas.DeleteTeamRequest;
	headers?: DeleteTeamTeamDeletePostHeaders;
} & FetcherExtraProps;

/**
 * delete team and associated team keys
 *
 * Parameters:
 * - team_ids: List[str] - Required. List of team IDs to delete. Example: ["team-1234", "team-5678"]
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "team_ids": ["8d916b1c-510d-4894-a334-1c16a93344f5"]
 * }'
 * ```
 */
export const deleteTeamTeamDeletePost = (
	variables: DeleteTeamTeamDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteTeamTeamDeletePostResponse,
		DeleteTeamTeamDeletePostError,
		Schemas.DeleteTeamRequest,
		DeleteTeamTeamDeletePostHeaders,
		{},
		{}
	>({ url: "/team/delete", method: "post", ...variables, signal });

export type TeamInfoTeamInfoGetQueryParams = {
	/**
	 * Team ID in the request parameters
	 */
	team_id?: string;
};

export type TeamInfoTeamInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamInfoTeamInfoGetResponse = {
	[key: string]: any;
};

export type TeamInfoTeamInfoGetVariables = {
	queryParams?: TeamInfoTeamInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * get info on team + related keys
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to get info on.
 *
 * ```
 * curl --location 'http://localhost:4000/team/info?team_id=your_team_id_here'     --header 'Authorization: Bearer your_api_key_here'
 * ```
 */
export const teamInfoTeamInfoGet = (
	variables: TeamInfoTeamInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TeamInfoTeamInfoGetResponse,
		TeamInfoTeamInfoGetError,
		undefined,
		{},
		TeamInfoTeamInfoGetQueryParams,
		{}
	>({ url: "/team/info", method: "get", ...variables, signal });

export type BlockTeamTeamBlockPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type BlockTeamTeamBlockPostResponse = {
	[key: string]: any;
};

export type BlockTeamTeamBlockPostVariables = {
	body: Schemas.BlockTeamRequest;
} & FetcherExtraProps;

/**
 * Blocks all calls from keys with this team id.
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to block.
 *
 * Example:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234"
 * }'
 * ```
 *
 * Returns:
 * - The updated team record with blocked=True
 */
export const blockTeamTeamBlockPost = (
	variables: BlockTeamTeamBlockPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		BlockTeamTeamBlockPostResponse,
		BlockTeamTeamBlockPostError,
		Schemas.BlockTeamRequest,
		{},
		{},
		{}
	>({ url: "/team/block", method: "post", ...variables, signal });

export type UnblockTeamTeamUnblockPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UnblockTeamTeamUnblockPostResponse = {
	[key: string]: any;
};

export type UnblockTeamTeamUnblockPostVariables = {
	body: Schemas.BlockTeamRequest;
} & FetcherExtraProps;

/**
 * Blocks all calls from keys with this team id.
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to unblock.
 *
 * Example:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234"
 * }'
 * ```
 */
export const unblockTeamTeamUnblockPost = (
	variables: UnblockTeamTeamUnblockPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UnblockTeamTeamUnblockPostResponse,
		UnblockTeamTeamUnblockPostError,
		Schemas.BlockTeamRequest,
		{},
		{},
		{}
	>({ url: "/team/unblock", method: "post", ...variables, signal });

export type ListAvailableTeamsTeamAvailableGetQueryParams = {
	response_model?: void;
};

export type ListAvailableTeamsTeamAvailableGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListAvailableTeamsTeamAvailableGetResponse = {
	[key: string]: any;
};

export type ListAvailableTeamsTeamAvailableGetVariables = {
	queryParams?: ListAvailableTeamsTeamAvailableGetQueryParams;
} & FetcherExtraProps;

export const listAvailableTeamsTeamAvailableGet = (
	variables: ListAvailableTeamsTeamAvailableGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListAvailableTeamsTeamAvailableGetResponse,
		ListAvailableTeamsTeamAvailableGetError,
		undefined,
		{},
		ListAvailableTeamsTeamAvailableGetQueryParams,
		{}
	>({ url: "/team/available", method: "get", ...variables, signal });

export type ListTeamV2V2TeamListGetQueryParams = {
	/**
	 * Only return teams which this 'user_id' belongs to
	 */
	user_id?: string | null;
	/**
	 * Only return teams which this 'organization_id' belongs to
	 */
	organization_id?: string | null;
	/**
	 * Only return teams which this 'team_id' belongs to
	 */
	team_id?: string | null;
	/**
	 * Only return teams which this 'team_alias' belongs to. Supports partial matching.
	 */
	team_alias?: string | null;
	/**
	 * Page number for pagination
	 *
	 * @minimum 1
	 * @default 1
	 */
	page?: number;
	/**
	 * Number of teams per page
	 *
	 * @maximum 100
	 * @minimum 1
	 * @default 10
	 */
	page_size?: number;
	/**
	 * Column to sort by (e.g. 'team_id', 'team_alias', 'created_at')
	 */
	sort_by?: string | null;
	/**
	 * Sort order ('asc' or 'desc')
	 *
	 * @default asc
	 */
	sort_order?: string;
};

export type ListTeamV2V2TeamListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListTeamV2V2TeamListGetVariables = {
	queryParams?: ListTeamV2V2TeamListGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a paginated list of teams with filtering and sorting options.
 *
 * Parameters:
 *     user_id: Optional[str]
 *         Only return teams which this user belongs to
 *     organization_id: Optional[str]
 *         Only return teams which belong to this organization
 *     team_id: Optional[str]
 *         Filter teams by exact team_id match
 *     team_alias: Optional[str]
 *         Filter teams by partial team_alias match
 *     page: int
 *         The page number to return
 *     page_size: int
 *         The number of items per page
 *     sort_by: Optional[str]
 *         Column to sort by (e.g. 'team_id', 'team_alias', 'created_at')
 *     sort_order: str
 *         Sort order ('asc' or 'desc')
 */
export const listTeamV2V2TeamListGet = (
	variables: ListTeamV2V2TeamListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TeamListResponse,
		ListTeamV2V2TeamListGetError,
		undefined,
		{},
		ListTeamV2V2TeamListGetQueryParams,
		{}
	>({ url: "/v2/team/list", method: "get", ...variables, signal });

export type ListTeamTeamListGetQueryParams = {
	/**
	 * Only return teams which this 'user_id' belongs to
	 */
	user_id?: string | null;
	organization_id?: string | null;
};

export type ListTeamTeamListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListTeamTeamListGetResponse = {
	[key: string]: any;
};

export type ListTeamTeamListGetVariables = {
	queryParams?: ListTeamTeamListGetQueryParams;
} & FetcherExtraProps;

/**
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/team/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 *
 * Parameters:
 * - user_id: str - Optional. If passed will only return teams that the user_id is a member of.
 * - organization_id: str - Optional. If passed will only return teams that belong to the organization_id. Pass 'default_organization' to get all teams without organization_id.
 */
export const listTeamTeamListGet = (
	variables: ListTeamTeamListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListTeamTeamListGetResponse,
		ListTeamTeamListGetError,
		undefined,
		{},
		ListTeamTeamListGetQueryParams,
		{}
	>({ url: "/team/list", method: "get", ...variables, signal });

export type TeamModelAddTeamModelAddPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamModelAddTeamModelAddPostResponse = {
	[key: string]: any;
};

export type TeamModelAddTeamModelAddPostVariables = {
	body: Schemas.TeamModelAddRequest;
} & FetcherExtraProps;

/**
 * Add models to a team's allowed model list. Only proxy admin or team admin can add models.
 *
 * Parameters:
 * - team_id: str - Required. The team to add models to
 * - models: List[str] - Required. List of models to add to the team
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/model/add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234",
 *     "models": ["gpt-4", "claude-2"]
 * }'
 * ```
 */
export const teamModelAddTeamModelAddPost = (
	variables: TeamModelAddTeamModelAddPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TeamModelAddTeamModelAddPostResponse,
		TeamModelAddTeamModelAddPostError,
		Schemas.TeamModelAddRequest,
		{},
		{},
		{}
	>({ url: "/team/model/add", method: "post", ...variables, signal });

export type TeamModelDeleteTeamModelDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamModelDeleteTeamModelDeletePostResponse = {
	[key: string]: any;
};

export type TeamModelDeleteTeamModelDeletePostVariables = {
	body: Schemas.TeamModelDeleteRequest;
} & FetcherExtraProps;

/**
 * Remove models from a team's allowed model list. Only proxy admin or team admin can remove models.
 *
 * Parameters:
 * - team_id: str - Required. The team to remove models from
 * - models: List[str] - Required. List of models to remove from the team
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/model/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234",
 *     "models": ["gpt-4"]
 * }'
 * ```
 */
export const teamModelDeleteTeamModelDeletePost = (
	variables: TeamModelDeleteTeamModelDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TeamModelDeleteTeamModelDeletePostResponse,
		TeamModelDeleteTeamModelDeletePostError,
		Schemas.TeamModelDeleteRequest,
		{},
		{},
		{}
	>({ url: "/team/model/delete", method: "post", ...variables, signal });

export type TeamMemberPermissionsTeamPermissionsListGetQueryParams = {
	/**
	 * Team ID in the request parameters
	 */
	team_id?: string;
};

export type TeamMemberPermissionsTeamPermissionsListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberPermissionsTeamPermissionsListGetVariables = {
	queryParams?: TeamMemberPermissionsTeamPermissionsListGetQueryParams;
} & FetcherExtraProps;

/**
 * Get the team member permissions for a team
 */
export const teamMemberPermissionsTeamPermissionsListGet = (
	variables: TeamMemberPermissionsTeamPermissionsListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.GetTeamMemberPermissionsResponse,
		TeamMemberPermissionsTeamPermissionsListGetError,
		undefined,
		{},
		TeamMemberPermissionsTeamPermissionsListGetQueryParams,
		{}
	>({ url: "/team/permissions_list", method: "get", ...variables, signal });

export type UpdateTeamMemberPermissionsTeamPermissionsUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateTeamMemberPermissionsTeamPermissionsUpdatePostVariables = {
	body: Schemas.UpdateTeamMemberPermissionsRequest;
} & FetcherExtraProps;

/**
 * Update the team member permissions for a team
 */
export const updateTeamMemberPermissionsTeamPermissionsUpdatePost = (
	variables: UpdateTeamMemberPermissionsTeamPermissionsUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMTeamTableOutput,
		UpdateTeamMemberPermissionsTeamPermissionsUpdatePostError,
		Schemas.UpdateTeamMemberPermissionsRequest,
		{},
		{},
		{}
	>({ url: "/team/permissions_update", method: "post", ...variables, signal });

export type GetTeamDailyActivityTeamDailyActivityGetQueryParams = {
	team_ids?: string | null;
	start_date?: string | null;
	end_date?: string | null;
	model?: string | null;
	api_key?: string | null;
	/**
	 * @default 1
	 */
	page?: number;
	/**
	 * @default 10
	 */
	page_size?: number;
	exclude_team_ids?: string | null;
};

export type GetTeamDailyActivityTeamDailyActivityGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetTeamDailyActivityTeamDailyActivityGetVariables = {
	queryParams?: GetTeamDailyActivityTeamDailyActivityGetQueryParams;
} & FetcherExtraProps;

/**
 * Get daily activity for specific teams or all teams.
 *
 * Args:
 *     team_ids (Optional[str]): Comma-separated list of team IDs to filter by. If not provided, returns data for all teams.
 *     start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).
 *     end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).
 *     model (Optional[str]): Filter by model name.
 *     api_key (Optional[str]): Filter by API key.
 *     page (int): Page number for pagination.
 *     page_size (int): Number of items per page.
 *     exclude_team_ids (Optional[str]): Comma-separated list of team IDs to exclude.
 * Returns:
 *     SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 */
export const getTeamDailyActivityTeamDailyActivityGet = (
	variables: GetTeamDailyActivityTeamDailyActivityGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SpendAnalyticsPaginatedResponse,
		GetTeamDailyActivityTeamDailyActivityGetError,
		undefined,
		{},
		GetTeamDailyActivityTeamDailyActivityGetQueryParams,
		{}
	>({ url: "/team/daily/activity", method: "get", ...variables, signal });

export type GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams = {
	feature?: string | null;
};

export type GetServiceProviderConfigScimV2ServiceProviderConfigGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetServiceProviderConfigScimV2ServiceProviderConfigGetVariables = {
	queryParams?: GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams;
} & FetcherExtraProps;

/**
 * Return SCIM Service Provider Configuration.
 */
export const getServiceProviderConfigScimV2ServiceProviderConfigGet = (
	variables: GetServiceProviderConfigScimV2ServiceProviderConfigGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMServiceProviderConfig,
		GetServiceProviderConfigScimV2ServiceProviderConfigGetError,
		undefined,
		{},
		GetServiceProviderConfigScimV2ServiceProviderConfigGetQueryParams,
		{}
	>({
		url: "/scim/v2/ServiceProviderConfig",
		method: "get",
		...variables,
		signal,
	});

export type GetUsersScimV2UsersGetQueryParams = {
	/**
	 * @minimum 1
	 * @default 1
	 */
	startIndex?: number;
	/**
	 * @maximum 100
	 * @minimum 1
	 * @default 10
	 */
	count?: number;
	filter?: string | null;
	feature?: string | null;
};

export type GetUsersScimV2UsersGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetUsersScimV2UsersGetVariables = {
	queryParams?: GetUsersScimV2UsersGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a list of users according to SCIM v2 protocol
 */
export const getUsersScimV2UsersGet = (
	variables: GetUsersScimV2UsersGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMListResponse,
		GetUsersScimV2UsersGetError,
		undefined,
		{},
		GetUsersScimV2UsersGetQueryParams,
		{}
	>({ url: "/scim/v2/Users", method: "get", ...variables, signal });

export type CreateUserScimV2UsersPostQueryParams = {
	feature?: string | null;
};

export type CreateUserScimV2UsersPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateUserScimV2UsersPostVariables = {
	body: Schemas.SCIMUser;
	queryParams?: CreateUserScimV2UsersPostQueryParams;
} & FetcherExtraProps;

/**
 * Create a user according to SCIM v2 protocol
 */
export const createUserScimV2UsersPost = (
	variables: CreateUserScimV2UsersPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMUser,
		CreateUserScimV2UsersPostError,
		Schemas.SCIMUser,
		{},
		CreateUserScimV2UsersPostQueryParams,
		{}
	>({ url: "/scim/v2/Users", method: "post", ...variables, signal });

export type GetUserScimV2UsersUserIdGetPathParams = {
	userId: string;
};

export type GetUserScimV2UsersUserIdGetQueryParams = {
	feature?: string | null;
};

export type GetUserScimV2UsersUserIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetUserScimV2UsersUserIdGetVariables = {
	pathParams: GetUserScimV2UsersUserIdGetPathParams;
	queryParams?: GetUserScimV2UsersUserIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a single user by ID according to SCIM v2 protocol
 */
export const getUserScimV2UsersUserIdGet = (
	variables: GetUserScimV2UsersUserIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMUser,
		GetUserScimV2UsersUserIdGetError,
		undefined,
		{},
		GetUserScimV2UsersUserIdGetQueryParams,
		GetUserScimV2UsersUserIdGetPathParams
	>({ url: "/scim/v2/Users/{userId}", method: "get", ...variables, signal });

export type UpdateUserScimV2UsersUserIdPutPathParams = {
	userId: string;
};

export type UpdateUserScimV2UsersUserIdPutQueryParams = {
	feature?: string | null;
};

export type UpdateUserScimV2UsersUserIdPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateUserScimV2UsersUserIdPutVariables = {
	body: Schemas.SCIMUser;
	pathParams: UpdateUserScimV2UsersUserIdPutPathParams;
	queryParams?: UpdateUserScimV2UsersUserIdPutQueryParams;
} & FetcherExtraProps;

/**
 * Update a user according to SCIM v2 protocol (full replacement)
 */
export const updateUserScimV2UsersUserIdPut = (
	variables: UpdateUserScimV2UsersUserIdPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMUser,
		UpdateUserScimV2UsersUserIdPutError,
		Schemas.SCIMUser,
		{},
		UpdateUserScimV2UsersUserIdPutQueryParams,
		UpdateUserScimV2UsersUserIdPutPathParams
	>({ url: "/scim/v2/Users/{userId}", method: "put", ...variables, signal });

export type DeleteUserScimV2UsersUserIdDeletePathParams = {
	userId: string;
};

export type DeleteUserScimV2UsersUserIdDeleteQueryParams = {
	feature?: string | null;
};

export type DeleteUserScimV2UsersUserIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteUserScimV2UsersUserIdDeleteVariables = {
	pathParams: DeleteUserScimV2UsersUserIdDeletePathParams;
	queryParams?: DeleteUserScimV2UsersUserIdDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Delete a user according to SCIM v2 protocol
 */
export const deleteUserScimV2UsersUserIdDelete = (
	variables: DeleteUserScimV2UsersUserIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		DeleteUserScimV2UsersUserIdDeleteError,
		undefined,
		{},
		DeleteUserScimV2UsersUserIdDeleteQueryParams,
		DeleteUserScimV2UsersUserIdDeletePathParams
	>({ url: "/scim/v2/Users/{userId}", method: "delete", ...variables, signal });

export type PatchUserScimV2UsersUserIdPatchPathParams = {
	userId: string;
};

export type PatchUserScimV2UsersUserIdPatchQueryParams = {
	feature?: string | null;
};

export type PatchUserScimV2UsersUserIdPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type PatchUserScimV2UsersUserIdPatchVariables = {
	body: Schemas.SCIMPatchOp;
	pathParams: PatchUserScimV2UsersUserIdPatchPathParams;
	queryParams?: PatchUserScimV2UsersUserIdPatchQueryParams;
} & FetcherExtraProps;

/**
 * Patch a user according to SCIM v2 protocol
 */
export const patchUserScimV2UsersUserIdPatch = (
	variables: PatchUserScimV2UsersUserIdPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMUser,
		PatchUserScimV2UsersUserIdPatchError,
		Schemas.SCIMPatchOp,
		{},
		PatchUserScimV2UsersUserIdPatchQueryParams,
		PatchUserScimV2UsersUserIdPatchPathParams
	>({ url: "/scim/v2/Users/{userId}", method: "patch", ...variables, signal });

export type GetGroupsScimV2GroupsGetQueryParams = {
	/**
	 * @minimum 1
	 * @default 1
	 */
	startIndex?: number;
	/**
	 * @maximum 100
	 * @minimum 1
	 * @default 10
	 */
	count?: number;
	filter?: string | null;
	feature?: string | null;
};

export type GetGroupsScimV2GroupsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetGroupsScimV2GroupsGetVariables = {
	queryParams?: GetGroupsScimV2GroupsGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a list of groups according to SCIM v2 protocol
 */
export const getGroupsScimV2GroupsGet = (
	variables: GetGroupsScimV2GroupsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMListResponse,
		GetGroupsScimV2GroupsGetError,
		undefined,
		{},
		GetGroupsScimV2GroupsGetQueryParams,
		{}
	>({ url: "/scim/v2/Groups", method: "get", ...variables, signal });

export type CreateGroupScimV2GroupsPostQueryParams = {
	feature?: string | null;
};

export type CreateGroupScimV2GroupsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateGroupScimV2GroupsPostVariables = {
	body: Schemas.SCIMGroup;
	queryParams?: CreateGroupScimV2GroupsPostQueryParams;
} & FetcherExtraProps;

/**
 * Create a group according to SCIM v2 protocol
 */
export const createGroupScimV2GroupsPost = (
	variables: CreateGroupScimV2GroupsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMGroup,
		CreateGroupScimV2GroupsPostError,
		Schemas.SCIMGroup,
		{},
		CreateGroupScimV2GroupsPostQueryParams,
		{}
	>({ url: "/scim/v2/Groups", method: "post", ...variables, signal });

export type GetGroupScimV2GroupsGroupIdGetPathParams = {
	groupId: string;
};

export type GetGroupScimV2GroupsGroupIdGetQueryParams = {
	feature?: string | null;
};

export type GetGroupScimV2GroupsGroupIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetGroupScimV2GroupsGroupIdGetVariables = {
	pathParams: GetGroupScimV2GroupsGroupIdGetPathParams;
	queryParams?: GetGroupScimV2GroupsGroupIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a single group by ID according to SCIM v2 protocol
 */
export const getGroupScimV2GroupsGroupIdGet = (
	variables: GetGroupScimV2GroupsGroupIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMGroup,
		GetGroupScimV2GroupsGroupIdGetError,
		undefined,
		{},
		GetGroupScimV2GroupsGroupIdGetQueryParams,
		GetGroupScimV2GroupsGroupIdGetPathParams
	>({ url: "/scim/v2/Groups/{groupId}", method: "get", ...variables, signal });

export type UpdateGroupScimV2GroupsGroupIdPutPathParams = {
	groupId: string;
};

export type UpdateGroupScimV2GroupsGroupIdPutQueryParams = {
	feature?: string | null;
};

export type UpdateGroupScimV2GroupsGroupIdPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateGroupScimV2GroupsGroupIdPutVariables = {
	body: Schemas.SCIMGroup;
	pathParams: UpdateGroupScimV2GroupsGroupIdPutPathParams;
	queryParams?: UpdateGroupScimV2GroupsGroupIdPutQueryParams;
} & FetcherExtraProps;

/**
 * Update a group according to SCIM v2 protocol
 */
export const updateGroupScimV2GroupsGroupIdPut = (
	variables: UpdateGroupScimV2GroupsGroupIdPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMGroup,
		UpdateGroupScimV2GroupsGroupIdPutError,
		Schemas.SCIMGroup,
		{},
		UpdateGroupScimV2GroupsGroupIdPutQueryParams,
		UpdateGroupScimV2GroupsGroupIdPutPathParams
	>({ url: "/scim/v2/Groups/{groupId}", method: "put", ...variables, signal });

export type DeleteGroupScimV2GroupsGroupIdDeletePathParams = {
	groupId: string;
};

export type DeleteGroupScimV2GroupsGroupIdDeleteQueryParams = {
	feature?: string | null;
};

export type DeleteGroupScimV2GroupsGroupIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteGroupScimV2GroupsGroupIdDeleteVariables = {
	pathParams: DeleteGroupScimV2GroupsGroupIdDeletePathParams;
	queryParams?: DeleteGroupScimV2GroupsGroupIdDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Delete a group according to SCIM v2 protocol
 */
export const deleteGroupScimV2GroupsGroupIdDelete = (
	variables: DeleteGroupScimV2GroupsGroupIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		DeleteGroupScimV2GroupsGroupIdDeleteError,
		undefined,
		{},
		DeleteGroupScimV2GroupsGroupIdDeleteQueryParams,
		DeleteGroupScimV2GroupsGroupIdDeletePathParams
	>({
		url: "/scim/v2/Groups/{groupId}",
		method: "delete",
		...variables,
		signal,
	});

export type PatchGroupScimV2GroupsGroupIdPatchPathParams = {
	groupId: string;
};

export type PatchGroupScimV2GroupsGroupIdPatchQueryParams = {
	feature?: string | null;
};

export type PatchGroupScimV2GroupsGroupIdPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type PatchGroupScimV2GroupsGroupIdPatchVariables = {
	body: Schemas.SCIMPatchOp;
	pathParams: PatchGroupScimV2GroupsGroupIdPatchPathParams;
	queryParams?: PatchGroupScimV2GroupsGroupIdPatchQueryParams;
} & FetcherExtraProps;

/**
 * Patch a group according to SCIM v2 protocol
 */
export const patchGroupScimV2GroupsGroupIdPatch = (
	variables: PatchGroupScimV2GroupsGroupIdPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SCIMGroup,
		PatchGroupScimV2GroupsGroupIdPatchError,
		Schemas.SCIMPatchOp,
		{},
		PatchGroupScimV2GroupsGroupIdPatchQueryParams,
		PatchGroupScimV2GroupsGroupIdPatchPathParams
	>({
		url: "/scim/v2/Groups/{groupId}",
		method: "patch",
		...variables,
		signal,
	});

export type NewOrganizationOrganizationNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewOrganizationOrganizationNewPostVariables = {
	body: Schemas.NewOrganizationRequest;
} & FetcherExtraProps;

/**
 * Allow orgs to own teams
 *
 * Set org level budgets + model access.
 *
 * Only admins can create orgs.
 *
 * # Parameters
 *
 * - organization_alias: *str* - The name of the organization.
 * - models: *List* - The models the organization has access to.
 * - budget_id: *Optional[str]* - The id for a budget (tpm/rpm/max budget) for the organization.
 * ### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###
 * - max_budget: *Optional[float]* - Max budget for org
 * - tpm_limit: *Optional[int]* - Max tpm limit for org
 * - rpm_limit: *Optional[int]* - Max rpm limit for org
 * - model_rpm_limit: *Optional[Dict[str, int]]* - The RPM (Requests Per Minute) limit per model for this organization.
 * - model_tpm_limit: *Optional[Dict[str, int]]* - The TPM (Tokens Per Minute) limit per model for this organization.
 * - max_parallel_requests: *Optional[int]* - [Not Implemented Yet] Max parallel requests for org
 * - soft_budget: *Optional[float]* - [Not Implemented Yet] Get a slack alert when this soft budget is reached. Don't block requests.
 * - model_max_budget: *Optional[dict]* - Max budget for a specific model
 * - budget_duration: *Optional[str]* - Frequency of reseting org budget
 * - metadata: *Optional[dict]* - Metadata for organization, store information for organization. Example metadata - {"extra_info": "some info"}
 * - blocked: *bool* - Flag indicating if the org is blocked or not - will stop all calls from keys with this org_id.
 * - tags: *Optional[List[str]]* - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: *Optional[str]* - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - organization-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.
 * Case 1: Create new org **without** a budget_id
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/organization/new'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "organization_alias": "my-secret-org",
 *     "models": ["model1", "model2"],
 *     "max_budget": 100
 * }'
 *
 *
 * ```
 *
 * Case 2: Create new org **with** a budget_id
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/organization/new'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "organization_alias": "my-secret-org",
 *     "models": ["model1", "model2"],
 *     "budget_id": "428eeaa8-f3ac-4e85-a8fb-7dc8d7aa8689"
 * }'
 * ```
 */
export const newOrganizationOrganizationNewPost = (
	variables: NewOrganizationOrganizationNewPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.NewOrganizationResponse,
		NewOrganizationOrganizationNewPostError,
		Schemas.NewOrganizationRequest,
		{},
		{},
		{}
	>({ url: "/organization/new", method: "post", ...variables, signal });

export type UpdateOrganizationOrganizationUpdatePatchError = Fetcher.ErrorWrapper<undefined>;

export type UpdateOrganizationOrganizationUpdatePatchVariables = FetcherExtraProps;

/**
 * Update an organization
 */
export const updateOrganizationOrganizationUpdatePatch = (
	variables: UpdateOrganizationOrganizationUpdatePatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMOrganizationTableWithMembers,
		UpdateOrganizationOrganizationUpdatePatchError,
		undefined,
		{},
		{},
		{}
	>({ url: "/organization/update", method: "patch", ...variables, signal });

export type DeleteOrganizationOrganizationDeleteDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteOrganizationOrganizationDeleteDeleteResponse =
	Schemas.LiteLLMOrganizationTableWithMembers[];

export type DeleteOrganizationOrganizationDeleteDeleteVariables = {
	body: Schemas.DeleteOrganizationRequest;
} & FetcherExtraProps;

/**
 * Delete an organization
 *
 * # Parameters:
 *
 * - organization_ids: List[str] - The organization ids to delete.
 */
export const deleteOrganizationOrganizationDeleteDelete = (
	variables: DeleteOrganizationOrganizationDeleteDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteOrganizationOrganizationDeleteDeleteResponse,
		DeleteOrganizationOrganizationDeleteDeleteError,
		Schemas.DeleteOrganizationRequest,
		{},
		{},
		{}
	>({ url: "/organization/delete", method: "delete", ...variables, signal });

export type ListOrganizationOrganizationListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListOrganizationOrganizationListGetResponse =
	Schemas.LiteLLMOrganizationTableWithMembers[];

export type ListOrganizationOrganizationListGetVariables = FetcherExtraProps;

/**
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/organization/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const listOrganizationOrganizationListGet = (
	variables: ListOrganizationOrganizationListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListOrganizationOrganizationListGetResponse,
		ListOrganizationOrganizationListGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/organization/list", method: "get", ...variables, signal });

export type InfoOrganizationOrganizationInfoGetQueryParams = {
	organization_id: string;
};

export type InfoOrganizationOrganizationInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type InfoOrganizationOrganizationInfoGetVariables = {
	queryParams: InfoOrganizationOrganizationInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Get the org specific information
 */
export const infoOrganizationOrganizationInfoGet = (
	variables: InfoOrganizationOrganizationInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMOrganizationTableWithMembers,
		InfoOrganizationOrganizationInfoGetError,
		undefined,
		{},
		InfoOrganizationOrganizationInfoGetQueryParams,
		{}
	>({ url: "/organization/info", method: "get", ...variables, signal });

export type DeprecatedInfoOrganizationOrganizationInfoPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeprecatedInfoOrganizationOrganizationInfoPostResponse = {
	[key: string]: any;
};

export type DeprecatedInfoOrganizationOrganizationInfoPostVariables = {
	body: Schemas.OrganizationRequest;
} & FetcherExtraProps;

/**
 * DEPRECATED: Use GET /organization/info instead
 */
export const deprecatedInfoOrganizationOrganizationInfoPost = (
	variables: DeprecatedInfoOrganizationOrganizationInfoPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeprecatedInfoOrganizationOrganizationInfoPostResponse,
		DeprecatedInfoOrganizationOrganizationInfoPostError,
		Schemas.OrganizationRequest,
		{},
		{},
		{}
	>({ url: "/organization/info", method: "post", ...variables, signal });

export type OrganizationMemberAddOrganizationMemberAddPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type OrganizationMemberAddOrganizationMemberAddPostVariables = {
	body: Schemas.OrganizationMemberAddRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * Add new members (either via user_email or user_id) to an organization
 *
 * If user doesn't exist, new user row will also be added to User Table
 *
 * Only proxy_admin or org_admin of organization, allowed to access this endpoint.
 *
 * # Parameters:
 *
 * - organization_id: str (required)
 * - member: Union[List[Member], Member] (required)
 *     - role: Literal[LitellmUserRoles] (required)
 *     - user_id: Optional[str]
 *     - user_email: Optional[str]
 *
 * Note: Either user_id or user_email must be provided for each member.
 *
 * Example:
 * ```
 * curl -X POST 'http://0.0.0.0:4000/organization/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{
 *     "organization_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",
 *     "member": {
 *         "role": "internal_user",
 *         "user_id": "krrish247652@berri.ai"
 *     },
 *     "max_budget_in_organization": 100.0
 * }'
 * ```
 *
 * The following is executed in this function:
 *
 * 1. Check if organization exists
 * 2. Creates a new Internal User if the user_id or user_email is not found in LiteLLM_UserTable
 * 3. Add Internal User to the `LiteLLM_OrganizationMembership` table
 */
export const organizationMemberAddOrganizationMemberAddPost = (
	variables: OrganizationMemberAddOrganizationMemberAddPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.OrganizationAddMemberResponse,
		OrganizationMemberAddOrganizationMemberAddPostError,
		Schemas.OrganizationMemberAddRequest,
		{},
		{},
		{}
	>({ url: "/organization/member_add", method: "post", ...variables, signal });

export type OrganizationMemberUpdateOrganizationMemberUpdatePatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type OrganizationMemberUpdateOrganizationMemberUpdatePatchVariables = {
	body: Schemas.OrganizationMemberUpdateRequest;
} & FetcherExtraProps;

/**
 * Update a member's role in an organization
 */
export const organizationMemberUpdateOrganizationMemberUpdatePatch = (
	variables: OrganizationMemberUpdateOrganizationMemberUpdatePatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMOrganizationMembershipTable,
		OrganizationMemberUpdateOrganizationMemberUpdatePatchError,
		Schemas.OrganizationMemberUpdateRequest,
		{},
		{},
		{}
	>({
		url: "/organization/member_update",
		method: "patch",
		...variables,
		signal,
	});

export type OrganizationMemberDeleteOrganizationMemberDeleteDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type OrganizationMemberDeleteOrganizationMemberDeleteDeleteResponse = {
	[key: string]: any;
};

export type OrganizationMemberDeleteOrganizationMemberDeleteDeleteVariables = {
	body: Schemas.OrganizationMemberDeleteRequest;
} & FetcherExtraProps;

/**
 * Delete a member from an organization
 */
export const organizationMemberDeleteOrganizationMemberDeleteDelete = (
	variables: OrganizationMemberDeleteOrganizationMemberDeleteDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OrganizationMemberDeleteOrganizationMemberDeleteDeleteResponse,
		OrganizationMemberDeleteOrganizationMemberDeleteDeleteError,
		Schemas.OrganizationMemberDeleteRequest,
		{},
		{},
		{}
	>({
		url: "/organization/member_delete",
		method: "delete",
		...variables,
		signal,
	});

export type BlockUserCustomerBlockPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type BlockUserCustomerBlockPostResponse = {
	[key: string]: any;
};

export type BlockUserCustomerBlockPostVariables = {
	body: Schemas.BlockUsers;
} & FetcherExtraProps;

/**
 * [BETA] Reject calls with this end-user id
 *
 * Parameters:
 * - user_ids (List[str], required): The unique `user_id`s for the users to block
 *
 *     (any /chat/completion call with this user={end-user-id} param, will be rejected.)
 *
 *     ```
 *     curl -X POST "http://0.0.0.0:8000/user/block"
 *     -H "Authorization: Bearer sk-1234"
 *     -d '{
 *     "user_ids": [<user_id>, ...]
 *     }'
 *     ```
 */
export const blockUserCustomerBlockPost = (
	variables: BlockUserCustomerBlockPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		BlockUserCustomerBlockPostResponse,
		BlockUserCustomerBlockPostError,
		Schemas.BlockUsers,
		{},
		{},
		{}
	>({ url: "/customer/block", method: "post", ...variables, signal });

export type UnblockUserCustomerUnblockPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UnblockUserCustomerUnblockPostResponse = {
	[key: string]: any;
};

export type UnblockUserCustomerUnblockPostVariables = {
	body: Schemas.BlockUsers;
} & FetcherExtraProps;

/**
 * [BETA] Unblock calls with this user id
 *
 * Example
 * ```
 * curl -X POST "http://0.0.0.0:8000/user/unblock"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "user_ids": [<user_id>, ...]
 * }'
 * ```
 */
export const unblockUserCustomerUnblockPost = (
	variables: UnblockUserCustomerUnblockPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UnblockUserCustomerUnblockPostResponse,
		UnblockUserCustomerUnblockPostError,
		Schemas.BlockUsers,
		{},
		{},
		{}
	>({ url: "/customer/unblock", method: "post", ...variables, signal });

export type NewEndUserCustomerNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewEndUserCustomerNewPostResponse = {
	[key: string]: any;
};

export type NewEndUserCustomerNewPostVariables = {
	body: Schemas.NewCustomerRequest;
} & FetcherExtraProps;

/**
 * Allow creating a new Customer
 *
 *
 * Parameters:
 * - user_id: str - The unique identifier for the user.
 * - alias: Optional[str] - A human-friendly alias for the user.
 * - blocked: bool - Flag to allow or disallow requests for this end-user. Default is False.
 * - max_budget: Optional[float] - The maximum budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.
 * - budget_id: Optional[str] - The identifier for an existing budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.
 * - allowed_model_region: Optional[Union[Literal["eu"], Literal["us"]]] - Require all user requests to use models in this specific region.
 * - default_model: Optional[str] - If no equivalent model in the allowed region, default all requests to this model.
 * - metadata: Optional[dict] = Metadata for customer, store information for customer. Example metadata = {"data_training_opt_out": True}
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - tpm_limit: Optional[int] - [Not Implemented Yet] Specify tpm limit for a given customer (Tokens per minute)
 * - rpm_limit: Optional[int] - [Not Implemented Yet] Specify rpm limit for a given customer (Requests per minute)
 * - model_max_budget: Optional[dict] - [Not Implemented Yet] Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d"}}
 * - max_parallel_requests: Optional[int] - [Not Implemented Yet] Specify max parallel requests for a given customer.
 * - soft_budget: Optional[float] - [Not Implemented Yet] Get alerts when customer crosses given budget, doesn't block requests.
 * - spend: Optional[float] - Specify initial spend for a given customer.
 * - budget_reset_at: Optional[str] - Specify the date and time when the budget should be reset.
 *
 *
 * - Allow specifying allowed regions
 * - Allow specifying default model
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/new'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "user_id" : "ishaan-jaff-3",
 *         "allowed_region": "eu",
 *         "budget_id": "free_tier",
 *         "default_model": "azure/gpt-3.5-turbo-eu" <- all calls from this user, use this model?
 *     }'
 *
 *     # return end-user object
 * ```
 *
 * NOTE: This used to be called `/end_user/new`, we will still be maintaining compatibility for /end_user/XXX for these endpoints
 */
export const newEndUserCustomerNewPost = (
	variables: NewEndUserCustomerNewPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		NewEndUserCustomerNewPostResponse,
		NewEndUserCustomerNewPostError,
		Schemas.NewCustomerRequest,
		{},
		{},
		{}
	>({ url: "/customer/new", method: "post", ...variables, signal });

export type EndUserInfoCustomerInfoGetQueryParams = {
	/**
	 * End User ID in the request parameters
	 */
	end_user_id: string;
};

export type EndUserInfoCustomerInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type EndUserInfoCustomerInfoGetVariables = {
	queryParams: EndUserInfoCustomerInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Get information about an end-user. An `end_user` is a customer (external user) of the proxy.
 *
 * Parameters:
 * - end_user_id (str, required): The unique identifier for the end-user
 *
 * Example curl:
 * ```
 * curl -X GET 'http://localhost:4000/customer/info?end_user_id=test-litellm-user-4'         -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const endUserInfoCustomerInfoGet = (
	variables: EndUserInfoCustomerInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMEndUserTable,
		EndUserInfoCustomerInfoGetError,
		undefined,
		{},
		EndUserInfoCustomerInfoGetQueryParams,
		{}
	>({ url: "/customer/info", method: "get", ...variables, signal });

export type UpdateEndUserCustomerUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateEndUserCustomerUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateEndUserCustomerUpdatePostVariables = {
	body: Schemas.UpdateCustomerRequest;
} & FetcherExtraProps;

/**
 * Example curl
 *
 * Parameters:
 * - user_id: str
 * - alias: Optional[str] = None  # human-friendly alias
 * - blocked: bool = False  # allow/disallow requests for this end-user
 * - max_budget: Optional[float] = None
 * - budget_id: Optional[str] = None  # give either a budget_id or max_budget
 * - allowed_model_region: Optional[AllowedModelRegion] = (
 *     None  # require all user requests to use models in this specific region
 * )
 * - default_model: Optional[str] = (
 *     None  # if no equivalent model in allowed region - default all requests to this model
 * )
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "user_id": "test-litellm-user-4",
 *     "budget_id": "paid_tier"
 * }'
 *
 * See below for all params
 * ```
 */
export const updateEndUserCustomerUpdatePost = (
	variables: UpdateEndUserCustomerUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateEndUserCustomerUpdatePostResponse,
		UpdateEndUserCustomerUpdatePostError,
		Schemas.UpdateCustomerRequest,
		{},
		{},
		{}
	>({ url: "/customer/update", method: "post", ...variables, signal });

export type DeleteEndUserCustomerDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteEndUserCustomerDeletePostResponse = {
	[key: string]: any;
};

export type DeleteEndUserCustomerDeletePostVariables = {
	body: Schemas.DeleteCustomerRequest;
} & FetcherExtraProps;

/**
 * Delete multiple end-users.
 *
 * Parameters:
 * - user_ids (List[str], required): The unique `user_id`s for the users to delete
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/delete'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "user_ids" :["ishaan-jaff-5"]
 * }'
 *
 * See below for all params
 * ```
 */
export const deleteEndUserCustomerDeletePost = (
	variables: DeleteEndUserCustomerDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteEndUserCustomerDeletePostResponse,
		DeleteEndUserCustomerDeletePostError,
		Schemas.DeleteCustomerRequest,
		{},
		{},
		{}
	>({ url: "/customer/delete", method: "post", ...variables, signal });

export type ListEndUserCustomerListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListEndUserCustomerListGetResponse = Schemas.LiteLLMEndUserTable[];

export type ListEndUserCustomerListGetVariables = FetcherExtraProps;

/**
 * [Admin-only] List all available customers
 *
 * Example curl:
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/customer/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const listEndUserCustomerListGet = (
	variables: ListEndUserCustomerListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<ListEndUserCustomerListGetResponse, ListEndUserCustomerListGetError, undefined, {}, {}, {}>(
		{ url: "/customer/list", method: "get", ...variables, signal },
	);

export type ViewSpendTagsSpendTagsGetQueryParams = {
	/**
	 * Time from which to start viewing key spend
	 */
	start_date?: string | null;
	/**
	 * Time till which to view key spend
	 */
	end_date?: string | null;
};

export type ViewSpendTagsSpendTagsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ViewSpendTagsSpendTagsGetResponse = Schemas.LiteLLMSpendLogsOutput[];

export type ViewSpendTagsSpendTagsGetVariables = {
	queryParams?: ViewSpendTagsSpendTagsGetQueryParams;
} & FetcherExtraProps;

/**
 * LiteLLM Enterprise - View Spend Per Request Tag
 *
 * Example Request:
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/tags" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Spend with Start Date and End Date
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const viewSpendTagsSpendTagsGet = (
	variables: ViewSpendTagsSpendTagsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ViewSpendTagsSpendTagsGetResponse,
		ViewSpendTagsSpendTagsGetError,
		undefined,
		{},
		ViewSpendTagsSpendTagsGetQueryParams,
		{}
	>({ url: "/spend/tags", method: "get", ...variables, signal });

export type GetGlobalSpendReportGlobalSpendReportGetQueryParams = {
	/**
	 * Time from which to start viewing spend
	 */
	start_date?: string | null;
	/**
	 * Time till which to view spend
	 */
	end_date?: string | null;
	/**
	 * Group spend by internal team or customer or api_key
	 *
	 * @default team
	 */
	group_by?: ("team" | "customer" | "api_key") | null;
	/**
	 * View spend for a specific api_key. Example api_key='sk-1234
	 */
	api_key?: string | null;
	/**
	 * View spend for a specific internal_user_id. Example internal_user_id='1234
	 */
	internal_user_id?: string | null;
	/**
	 * View spend for a specific team_id. Example team_id='1234
	 */
	team_id?: string | null;
	/**
	 * View spend for a specific customer_id. Example customer_id='1234. Can be used in conjunction with team_id as well.
	 */
	customer_id?: string | null;
};

export type GetGlobalSpendReportGlobalSpendReportGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetGlobalSpendReportGlobalSpendReportGetResponse = Schemas.LiteLLMSpendLogsOutput[];

export type GetGlobalSpendReportGlobalSpendReportGetVariables = {
	queryParams?: GetGlobalSpendReportGlobalSpendReportGetQueryParams;
} & FetcherExtraProps;

/**
 * Get Daily Spend per Team, based on specific startTime and endTime. Per team, view usage by each key, model
 * [
 *     {
 *         "group-by-day": "2024-05-10",
 *         "teams": [
 *             {
 *                 "team_name": "team-1"
 *                 "spend": 10,
 *                 "keys": [
 *                     "key": "1213",
 *                     "usage": {
 *                         "model-1": {
 *                                 "cost": 12.50,
 *                                 "input_tokens": 1000,
 *                                 "output_tokens": 5000,
 *                                 "requests": 100
 *                             },
 *                             "audio-modelname1": {
 *                             "cost": 25.50,
 *                             "seconds": 25,
 *                             "requests": 50
 *                     },
 *                     }
 *                 }
 *         ]
 *     ]
 * }
 */
export const getGlobalSpendReportGlobalSpendReportGet = (
	variables: GetGlobalSpendReportGlobalSpendReportGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetGlobalSpendReportGlobalSpendReportGetResponse,
		GetGlobalSpendReportGlobalSpendReportGetError,
		undefined,
		{},
		GetGlobalSpendReportGlobalSpendReportGetQueryParams,
		{}
	>({ url: "/global/spend/report", method: "get", ...variables, signal });

export type GlobalViewSpendTagsGlobalSpendTagsGetQueryParams = {
	/**
	 * Time from which to start viewing key spend
	 */
	start_date?: string | null;
	/**
	 * Time till which to view key spend
	 */
	end_date?: string | null;
	/**
	 * comman separated tags to filter on
	 */
	tags?: string | null;
};

export type GlobalViewSpendTagsGlobalSpendTagsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GlobalViewSpendTagsGlobalSpendTagsGetResponse = Schemas.LiteLLMSpendLogsOutput[];

export type GlobalViewSpendTagsGlobalSpendTagsGetVariables = {
	queryParams?: GlobalViewSpendTagsGlobalSpendTagsGetQueryParams;
} & FetcherExtraProps;

/**
 * LiteLLM Enterprise - View Spend Per Request Tag. Used by LiteLLM UI
 *
 * Example Request:
 * ```
 * curl -X GET "http://0.0.0.0:4000/spend/tags" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Spend with Start Date and End Date
 * ```
 * curl -X GET "http://0.0.0.0:4000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const globalViewSpendTagsGlobalSpendTagsGet = (
	variables: GlobalViewSpendTagsGlobalSpendTagsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GlobalViewSpendTagsGlobalSpendTagsGetResponse,
		GlobalViewSpendTagsGlobalSpendTagsGetError,
		undefined,
		{},
		GlobalViewSpendTagsGlobalSpendTagsGetQueryParams,
		{}
	>({ url: "/global/spend/tags", method: "get", ...variables, signal });

export type CalculateSpendSpendCalculatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CalculateSpendSpendCalculatePostResponse = {
	[key: string]: any;
};

export type CalculateSpendSpendCalculatePostVariables = {
	body?: Schemas.SpendCalculateRequest;
} & FetcherExtraProps;

/**
 * Accepts all the params of completion_cost.
 *
 * Calculate spend **before** making call:
 *
 * Note: If you see a spend of $0.0 you need to set custom_pricing for your model: https://docs.litellm.ai/docs/proxy/custom_pricing
 *
 * ```
 * curl --location 'http://localhost:4000/spend/calculate'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "model": "anthropic.claude-v2",
 *     "messages": [{"role": "user", "content": "Hey, how'''s it going?"}]
 * }'
 * ```
 *
 * Calculate spend **after** making call:
 *
 * ```
 * curl --location 'http://localhost:4000/spend/calculate'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "completion_response": {
 *         "id": "chatcmpl-123",
 *         "object": "chat.completion",
 *         "created": 1677652288,
 *         "model": "gpt-3.5-turbo-0125",
 *         "system_fingerprint": "fp_44709d6fcb",
 *         "choices": [{
 *             "index": 0,
 *             "message": {
 *                 "role": "assistant",
 *                 "content": "Hello there, how may I assist you today?"
 *             },
 *             "logprobs": null,
 *             "finish_reason": "stop"
 *         }]
 *         "usage": {
 *             "prompt_tokens": 9,
 *             "completion_tokens": 12,
 *             "total_tokens": 21
 *         }
 *     }
 * }'
 * ```
 */
export const calculateSpendSpendCalculatePost = (
	variables: CalculateSpendSpendCalculatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CalculateSpendSpendCalculatePostResponse,
		CalculateSpendSpendCalculatePostError,
		Schemas.SpendCalculateRequest,
		{},
		{},
		{}
	>({ url: "/spend/calculate", method: "post", ...variables, signal });

export type ViewSpendLogsSpendLogsGetQueryParams = {
	/**
	 * Get spend logs based on api key
	 */
	api_key?: string | null;
	/**
	 * Get spend logs based on user_id
	 */
	user_id?: string | null;
	/**
	 * request_id to get spend logs for specific request_id. If none passed then pass spend logs for all requests
	 */
	request_id?: string | null;
	/**
	 * Time from which to start viewing key spend
	 */
	start_date?: string | null;
	/**
	 * Time till which to view key spend
	 */
	end_date?: string | null;
	/**
	 * When start_date and end_date are provided, summarize=true returns aggregated data by date (legacy behavior), summarize=false returns filtered individual logs
	 *
	 * @default true
	 */
	summarize?: boolean;
};

export type ViewSpendLogsSpendLogsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ViewSpendLogsSpendLogsGetResponse = Schemas.LiteLLMSpendLogsOutput[];

export type ViewSpendLogsSpendLogsGetVariables = {
	queryParams?: ViewSpendLogsSpendLogsGetQueryParams;
} & FetcherExtraProps;

/**
 * View all spend logs, if request_id is provided, only logs for that request_id will be returned
 *
 * When start_date and end_date are provided:
 * - summarize=true (default): Returns aggregated spend data grouped by date (maintains backward compatibility)
 * - summarize=false: Returns filtered individual log entries within the date range
 *
 * Example Request for all logs
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific request_id
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?request_id=chatcmpl-6dcb2540-d3d7-4e49-bb27-291f863f112e" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific api_key
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?api_key=sk-Fn8Ej39NkBQmUagFEoUWPQ" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific user_id
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?user_id=ishaan@berri.ai" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for date range with individual logs (unsummarized)
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?start_date=2024-01-01&end_date=2024-01-02&summarize=false" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const viewSpendLogsSpendLogsGet = (
	variables: ViewSpendLogsSpendLogsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ViewSpendLogsSpendLogsGetResponse,
		ViewSpendLogsSpendLogsGetError,
		undefined,
		{},
		ViewSpendLogsSpendLogsGetQueryParams,
		{}
	>({ url: "/spend/logs", method: "get", ...variables, signal });

export type GlobalSpendResetGlobalSpendResetPostError = Fetcher.ErrorWrapper<undefined>;

export type GlobalSpendResetGlobalSpendResetPostResponse = {
	[key: string]: any;
};

export type GlobalSpendResetGlobalSpendResetPostVariables = FetcherExtraProps;

/**
 * ADMIN ONLY / MASTER KEY Only Endpoint
 *
 * Globally reset spend for All API Keys and Teams, maintain LiteLLM_SpendLogs
 *
 * 1. LiteLLM_SpendLogs will maintain the logs on spend, no data gets deleted from there
 * 2. LiteLLM_VerificationTokens spend will be set = 0
 * 3. LiteLLM_TeamTable spend will be set = 0
 */
export const globalSpendResetGlobalSpendResetPost = (
	variables: GlobalSpendResetGlobalSpendResetPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GlobalSpendResetGlobalSpendResetPostResponse,
		GlobalSpendResetGlobalSpendResetPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/global/spend/reset", method: "post", ...variables, signal });

export type ProviderBudgetsProviderBudgetsGetError = Fetcher.ErrorWrapper<undefined>;

export type ProviderBudgetsProviderBudgetsGetVariables = FetcherExtraProps;

/**
 * Provider Budget Routing - Get Budget, Spend Details https://docs.litellm.ai/docs/proxy/provider_budget_routing
 *
 * Use this endpoint to check current budget, spend and budget reset time for a provider
 *
 * Example Request
 *
 * ```bash
 * curl -X GET http://localhost:4000/provider/budgets     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Response
 *
 * ```json
 * {
 *     "providers": {
 *         "openai": {
 *             "budget_limit": 1e-12,
 *             "time_period": "1d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         },
 *         "azure": {
 *             "budget_limit": 100.0,
 *             "time_period": "1d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         },
 *         "anthropic": {
 *             "budget_limit": 100.0,
 *             "time_period": "10d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         },
 *         "vertex_ai": {
 *             "budget_limit": 100.0,
 *             "time_period": "12d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         }
 *     }
 * }
 * ```
 */
export const providerBudgetsProviderBudgetsGet = (
	variables: ProviderBudgetsProviderBudgetsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ProviderBudgetResponse,
		ProviderBudgetsProviderBudgetsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/provider/budgets", method: "get", ...variables, signal });

export type GetCloudzeroSettingsCloudzeroSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetCloudzeroSettingsCloudzeroSettingsGetVariables = FetcherExtraProps;

/**
 * View current CloudZero settings.
 *
 * Returns the current CloudZero configuration with the API key masked for security.
 * Only the first 4 and last 4 characters of the API key are shown.
 *
 * Only admin users can view CloudZero settings.
 */
export const getCloudzeroSettingsCloudzeroSettingsGet = (
	variables: GetCloudzeroSettingsCloudzeroSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CloudZeroSettingsView,
		GetCloudzeroSettingsCloudzeroSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/cloudzero/settings", method: "get", ...variables, signal });

export type UpdateCloudzeroSettingsCloudzeroSettingsPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateCloudzeroSettingsCloudzeroSettingsPutVariables = {
	body?: Schemas.CloudZeroSettingsUpdate;
} & FetcherExtraProps;

/**
 * Update existing CloudZero settings.
 *
 * Allows updating individual CloudZero configuration fields without requiring all fields.
 * Only provided fields will be updated; others will remain unchanged.
 *
 * Parameters:
 * - api_key: (Optional) New CloudZero API key for authentication
 * - connection_id: (Optional) New CloudZero connection ID for data submission
 * - timezone: (Optional) New timezone for date handling
 *
 * Only admin users can update CloudZero settings.
 */
export const updateCloudzeroSettingsCloudzeroSettingsPut = (
	variables: UpdateCloudzeroSettingsCloudzeroSettingsPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CloudZeroInitResponse,
		UpdateCloudzeroSettingsCloudzeroSettingsPutError,
		Schemas.CloudZeroSettingsUpdate,
		{},
		{},
		{}
	>({ url: "/cloudzero/settings", method: "put", ...variables, signal });

export type InitCloudzeroSettingsCloudzeroInitPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type InitCloudzeroSettingsCloudzeroInitPostVariables = {
	body: Schemas.CloudZeroInitRequest;
} & FetcherExtraProps;

/**
 * Initialize CloudZero settings and store in the database.
 *
 * This endpoint stores the CloudZero API key, connection ID, and timezone configuration
 * in the proxy database for use by the CloudZero logger.
 *
 * Parameters:
 * - api_key: CloudZero API key for authentication
 * - connection_id: CloudZero connection ID for data submission
 * - timezone: Timezone for date handling (default: UTC)
 *
 * Only admin users can configure CloudZero settings.
 */
export const initCloudzeroSettingsCloudzeroInitPost = (
	variables: InitCloudzeroSettingsCloudzeroInitPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CloudZeroInitResponse,
		InitCloudzeroSettingsCloudzeroInitPostError,
		Schemas.CloudZeroInitRequest,
		{},
		{},
		{}
	>({ url: "/cloudzero/init", method: "post", ...variables, signal });

export type CloudzeroDryRunExportCloudzeroDryRunPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CloudzeroDryRunExportCloudzeroDryRunPostVariables = {
	body?: Schemas.CloudZeroExportRequest;
} & FetcherExtraProps;

/**
 * Perform a dry run export using the CloudZero logger.
 *
 * This endpoint uses the CloudZero logger to perform a dry run export,
 * which returns the data that would be exported without actually sending it to CloudZero.
 *
 * Parameters:
 * - limit: Optional limit on number of records to process (default: 10000)
 *
 * Returns:
 * - usage_data: Sample of the raw usage data (first 50 records)
 * - cbf_data: CloudZero CBF formatted data ready for export
 * - summary: Statistics including total cost, tokens, and record counts
 *
 * Only admin users can perform CloudZero exports.
 */
export const cloudzeroDryRunExportCloudzeroDryRunPost = (
	variables: CloudzeroDryRunExportCloudzeroDryRunPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CloudZeroExportResponse,
		CloudzeroDryRunExportCloudzeroDryRunPostError,
		Schemas.CloudZeroExportRequest,
		{},
		{},
		{}
	>({ url: "/cloudzero/dry-run", method: "post", ...variables, signal });

export type CloudzeroExportCloudzeroExportPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CloudzeroExportCloudzeroExportPostVariables = {
	body?: Schemas.CloudZeroExportRequest;
} & FetcherExtraProps;

/**
 * Perform an actual export using the CloudZero logger.
 *
 * This endpoint uses the CloudZero logger to export usage data to CloudZero AnyCost API.
 *
 * Parameters:
 * - limit: Optional limit on number of records to export
 * - operation: CloudZero operation type ("replace_hourly" or "sum", default: "replace_hourly")
 *
 * Only admin users can perform CloudZero exports.
 */
export const cloudzeroExportCloudzeroExportPost = (
	variables: CloudzeroExportCloudzeroExportPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CloudZeroExportResponse,
		CloudzeroExportCloudzeroExportPostError,
		Schemas.CloudZeroExportRequest,
		{},
		{},
		{}
	>({ url: "/cloudzero/export", method: "post", ...variables, signal });

export type CachePingCachePingGetError = Fetcher.ErrorWrapper<undefined>;

export type CachePingCachePingGetVariables = FetcherExtraProps;

/**
 * Endpoint for checking if cache can be pinged
 */
export const cachePingCachePingGet = (
	variables: CachePingCachePingGetVariables,
	signal?: AbortSignal,
) =>
	fetch<Schemas.CachePingResponse, CachePingCachePingGetError, undefined, {}, {}, {}>({
		url: "/cache/ping",
		method: "get",
		...variables,
		signal,
	});

export type CacheDeleteCacheDeletePostError = Fetcher.ErrorWrapper<undefined>;

export type CacheDeleteCacheDeletePostResponse = {
	[key: string]: any;
};

export type CacheDeleteCacheDeletePostVariables = FetcherExtraProps;

/**
 * Endpoint for deleting a key from the cache. All responses from litellm proxy have `x-litellm-cache-key` in the headers
 *
 * Parameters:
 * - **keys**: *Optional[List[str]]* - A list of keys to delete from the cache. Example {"keys": ["key1", "key2"]}
 *
 * ```shell
 * curl -X POST "http://0.0.0.0:4000/cache/delete"     -H "Authorization: Bearer sk-1234"     -d '{"keys": ["key1", "key2"]}'
 * ```
 */
export const cacheDeleteCacheDeletePost = (
	variables: CacheDeleteCacheDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<CacheDeleteCacheDeletePostResponse, CacheDeleteCacheDeletePostError, undefined, {}, {}, {}>(
		{ url: "/cache/delete", method: "post", ...variables, signal },
	);

export type CacheRedisInfoCacheRedisInfoGetError = Fetcher.ErrorWrapper<undefined>;

export type CacheRedisInfoCacheRedisInfoGetResponse = {
	[key: string]: any;
};

export type CacheRedisInfoCacheRedisInfoGetVariables = FetcherExtraProps;

/**
 * Endpoint for getting /redis/info
 */
export const cacheRedisInfoCacheRedisInfoGet = (
	variables: CacheRedisInfoCacheRedisInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CacheRedisInfoCacheRedisInfoGetResponse,
		CacheRedisInfoCacheRedisInfoGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/cache/redis/info", method: "get", ...variables, signal });

export type CacheFlushallCacheFlushallPostError = Fetcher.ErrorWrapper<undefined>;

export type CacheFlushallCacheFlushallPostResponse = {
	[key: string]: any;
};

export type CacheFlushallCacheFlushallPostVariables = FetcherExtraProps;

/**
 * A function to flush all items from the cache. (All items will be deleted from the cache with this)
 * Raises HTTPException if the cache is not initialized or if the cache type does not support flushing.
 * Returns a dictionary with the status of the operation.
 *
 * Usage:
 * ```
 * curl -X POST http://0.0.0.0:4000/cache/flushall -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cacheFlushallCacheFlushallPost = (
	variables: CacheFlushallCacheFlushallPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CacheFlushallCacheFlushallPostResponse,
		CacheFlushallCacheFlushallPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/cache/flushall", method: "post", ...variables, signal });

export type ListGuardrailsGuardrailsListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListGuardrailsGuardrailsListGetVariables = FetcherExtraProps;

/**
 * List the guardrails that are available on the proxy server
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrails": [
 *         {
 *         "guardrail_name": "bedrock-pre-guard",
 *         "guardrail_info": {
 *             "params": [
 *             {
 *                 "name": "toxicity_score",
 *                 "type": "float",
 *                 "description": "Score between 0-1 indicating content toxicity level"
 *             },
 *             {
 *                 "name": "pii_detection",
 *                 "type": "boolean"
 *             }
 *             ]
 *         }
 *         }
 *     ]
 * }
 * ```
 */
export const listGuardrailsGuardrailsListGet = (
	variables: ListGuardrailsGuardrailsListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ListGuardrailsResponse,
		ListGuardrailsGuardrailsListGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/guardrails/list", method: "get", ...variables, signal });

export type ListGuardrailsV2V2GuardrailsListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListGuardrailsV2V2GuardrailsListGetVariables = FetcherExtraProps;

/**
 * List the guardrails that are available in the database using GuardrailRegistry
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/v2/guardrails/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrails": [
 *         {
 *             "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 *             "guardrail_name": "my-bedrock-guard",
 *             "litellm_params": {
 *                 "guardrail": "bedrock",
 *                 "mode": "pre_call",
 *                 "guardrailIdentifier": "ff6ujrregl1q",
 *                 "guardrailVersion": "DRAFT",
 *                 "default_on": true
 *             },
 *             "guardrail_info": {
 *                 "description": "Bedrock content moderation guardrail"
 *             }
 *         }
 *     ]
 * }
 * ```
 */
export const listGuardrailsV2V2GuardrailsListGet = (
	variables: ListGuardrailsV2V2GuardrailsListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ListGuardrailsResponse,
		ListGuardrailsV2V2GuardrailsListGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/v2/guardrails/list", method: "get", ...variables, signal });

export type CreateGuardrailGuardrailsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateGuardrailGuardrailsPostResponse = {
	[key: string]: any;
};

export type CreateGuardrailGuardrailsPostVariables = {
	body: Schemas.CreateGuardrailRequest;
} & FetcherExtraProps;

/**
 * Create a new guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/guardrails" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "guardrail": {
 *             "guardrail_name": "my-bedrock-guard",
 *             "litellm_params": {
 *                 "guardrail": "bedrock",
 *                 "mode": "pre_call",
 *                 "guardrailIdentifier": "ff6ujrregl1q",
 *                 "guardrailVersion": "DRAFT",
 *                 "default_on": true
 *             },
 *             "guardrail_info": {
 *                 "description": "Bedrock content moderation guardrail"
 *             }
 *         }
 *     }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "guardrail_name": "my-bedrock-guard",
 *     "litellm_params": {
 *         "guardrail": "bedrock",
 *         "mode": "pre_call",
 *         "guardrailIdentifier": "ff6ujrregl1q",
 *         "guardrailVersion": "DRAFT",
 *         "default_on": true
 *     },
 *     "guardrail_info": {
 *         "description": "Bedrock content moderation guardrail"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const createGuardrailGuardrailsPost = (
	variables: CreateGuardrailGuardrailsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateGuardrailGuardrailsPostResponse,
		CreateGuardrailGuardrailsPostError,
		Schemas.CreateGuardrailRequest,
		{},
		{},
		{}
	>({ url: "/guardrails", method: "post", ...variables, signal });

export type UpdateGuardrailGuardrailsGuardrailIdPutPathParams = {
	guardrailId: string;
};

export type UpdateGuardrailGuardrailsGuardrailIdPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateGuardrailGuardrailsGuardrailIdPutResponse = {
	[key: string]: any;
};

export type UpdateGuardrailGuardrailsGuardrailIdPutVariables = {
	body: Schemas.UpdateGuardrailRequest;
	pathParams: UpdateGuardrailGuardrailsGuardrailIdPutPathParams;
} & FetcherExtraProps;

/**
 * Update an existing guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "guardrail": {
 *             "guardrail_name": "updated-bedrock-guard",
 *             "litellm_params": {
 *                 "guardrail": "bedrock",
 *                 "mode": "pre_call",
 *                 "guardrailIdentifier": "ff6ujrregl1q",
 *                 "guardrailVersion": "1.0",
 *                 "default_on": true
 *             },
 *             "guardrail_info": {
 *                 "description": "Updated Bedrock content moderation guardrail"
 *             }
 *         }
 *     }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "guardrail_name": "updated-bedrock-guard",
 *     "litellm_params": {
 *         "guardrail": "bedrock",
 *         "mode": "pre_call",
 *         "guardrailIdentifier": "ff6ujrregl1q",
 *         "guardrailVersion": "1.0",
 *         "default_on": true
 *     },
 *     "guardrail_info": {
 *         "description": "Updated Bedrock content moderation guardrail"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T13:45:12.345Z"
 * }
 * ```
 */
export const updateGuardrailGuardrailsGuardrailIdPut = (
	variables: UpdateGuardrailGuardrailsGuardrailIdPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateGuardrailGuardrailsGuardrailIdPutResponse,
		UpdateGuardrailGuardrailsGuardrailIdPutError,
		Schemas.UpdateGuardrailRequest,
		{},
		{},
		UpdateGuardrailGuardrailsGuardrailIdPutPathParams
	>({ url: "/guardrails/{guardrailId}", method: "put", ...variables, signal });

export type DeleteGuardrailGuardrailsGuardrailIdDeletePathParams = {
	guardrailId: string;
};

export type DeleteGuardrailGuardrailsGuardrailIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteGuardrailGuardrailsGuardrailIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteGuardrailGuardrailsGuardrailIdDeleteVariables = {
	pathParams: DeleteGuardrailGuardrailsGuardrailIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "message": "Guardrail 123e4567-e89b-12d3-a456-426614174000 deleted successfully"
 * }
 * ```
 */
export const deleteGuardrailGuardrailsGuardrailIdDelete = (
	variables: DeleteGuardrailGuardrailsGuardrailIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteGuardrailGuardrailsGuardrailIdDeleteResponse,
		DeleteGuardrailGuardrailsGuardrailIdDeleteError,
		undefined,
		{},
		{},
		DeleteGuardrailGuardrailsGuardrailIdDeletePathParams
	>({
		url: "/guardrails/{guardrailId}",
		method: "delete",
		...variables,
		signal,
	});

export type PatchGuardrailGuardrailsGuardrailIdPatchPathParams = {
	guardrailId: string;
};

export type PatchGuardrailGuardrailsGuardrailIdPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type PatchGuardrailGuardrailsGuardrailIdPatchVariables = {
	body?: Schemas.PatchGuardrailRequest;
	pathParams: PatchGuardrailGuardrailsGuardrailIdPatchPathParams;
} & FetcherExtraProps;

/**
 * Partially update an existing guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * This endpoint allows updating specific fields of a guardrail without sending the entire object.
 * Only the following fields can be updated:
 * - guardrail_name: The name of the guardrail
 * - default_on: Whether the guardrail is enabled by default
 * - guardrail_info: Additional information about the guardrail
 *
 * Example Request:
 * ```bash
 * curl -X PATCH "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "guardrail_name": "updated-name",
 *         "default_on": true,
 *         "guardrail_info": {
 *             "description": "Updated description"
 *         }
 *     }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "guardrail_name": "updated-name",
 *     "litellm_params": {
 *         "guardrail": "bedrock",
 *         "mode": "pre_call",
 *         "guardrailIdentifier": "ff6ujrregl1q",
 *         "guardrailVersion": "DRAFT",
 *         "default_on": true
 *     },
 *     "guardrail_info": {
 *         "description": "Updated description"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T14:22:33.456Z"
 * }
 * ```
 */
export const patchGuardrailGuardrailsGuardrailIdPatch = (
	variables: PatchGuardrailGuardrailsGuardrailIdPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		PatchGuardrailGuardrailsGuardrailIdPatchError,
		Schemas.PatchGuardrailRequest,
		{},
		{},
		PatchGuardrailGuardrailsGuardrailIdPatchPathParams
	>({
		url: "/guardrails/{guardrailId}",
		method: "patch",
		...variables,
		signal,
	});

export type GetGuardrailInfoGuardrailsGuardrailIdGetPathParams = {
	guardrailId: string;
};

export type GetGuardrailInfoGuardrailsGuardrailIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetGuardrailInfoGuardrailsGuardrailIdGetResponse = {
	[key: string]: any;
};

export type GetGuardrailInfoGuardrailsGuardrailIdGetVariables = {
	pathParams: GetGuardrailInfoGuardrailsGuardrailIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get detailed information about a specific guardrail by ID
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "guardrail_name": "my-bedrock-guard",
 *     "litellm_params": {
 *         "guardrail": "bedrock",
 *         "mode": "pre_call",
 *         "guardrailIdentifier": "ff6ujrregl1q",
 *         "guardrailVersion": "DRAFT",
 *         "default_on": true
 *     },
 *     "guardrail_info": {
 *         "description": "Bedrock content moderation guardrail"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const getGuardrailInfoGuardrailsGuardrailIdGet = (
	variables: GetGuardrailInfoGuardrailsGuardrailIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetGuardrailInfoGuardrailsGuardrailIdGetResponse,
		GetGuardrailInfoGuardrailsGuardrailIdGetError,
		undefined,
		{},
		{},
		GetGuardrailInfoGuardrailsGuardrailIdGetPathParams
	>({ url: "/guardrails/{guardrailId}", method: "get", ...variables, signal });

export type GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams = {
	guardrailId: string;
};

export type GetGuardrailInfoGuardrailsGuardrailIdInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetGuardrailInfoGuardrailsGuardrailIdInfoGetResponse = {
	[key: string]: any;
};

export type GetGuardrailInfoGuardrailsGuardrailIdInfoGetVariables = {
	pathParams: GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams;
} & FetcherExtraProps;

/**
 * Get detailed information about a specific guardrail by ID
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "guardrail_name": "my-bedrock-guard",
 *     "litellm_params": {
 *         "guardrail": "bedrock",
 *         "mode": "pre_call",
 *         "guardrailIdentifier": "ff6ujrregl1q",
 *         "guardrailVersion": "DRAFT",
 *         "default_on": true
 *     },
 *     "guardrail_info": {
 *         "description": "Bedrock content moderation guardrail"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const getGuardrailInfoGuardrailsGuardrailIdInfoGet = (
	variables: GetGuardrailInfoGuardrailsGuardrailIdInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetResponse,
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetError,
		undefined,
		{},
		{},
		GetGuardrailInfoGuardrailsGuardrailIdInfoGetPathParams
	>({
		url: "/guardrails/{guardrailId}/info",
		method: "get",
		...variables,
		signal,
	});

export type GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetError =
	Fetcher.ErrorWrapper<undefined>;

export type GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetResponse = {
	[key: string]: any;
};

export type GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetVariables = FetcherExtraProps;

/**
 * Get the UI settings for the guardrails
 *
 * Returns:
 * - Supported entities for guardrails
 * - Supported modes for guardrails
 * - PII entity categories for UI organization
 * - Content filter settings (patterns and categories)
 */
export const getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet = (
	variables: GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetResponse,
		GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/guardrails/ui/add_guardrail_settings",
		method: "get",
		...variables,
		signal,
	});

export type ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostResponse = {
	[key: string]: any;
};

export type ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostRequestBody = {
	[key: string]: string;
};

export type ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostVariables = {
	body?: ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostRequestBody;
} & FetcherExtraProps;

/**
 * Validate a blocked_words YAML file content.
 *
 * Args:
 *     request: Dictionary with 'file_content' key containing the YAML string
 *
 * Returns:
 *     Dictionary with 'valid' boolean and either 'message'/'errors' depending on result
 *
 * Example Request:
 * ```json
 * {
 *     "file_content": "blocked_words:\n  - keyword: \"test\"\n    action: \"BLOCK\""
 * }
 * ```
 *
 * Example Success Response:
 * ```json
 * {
 *     "valid": true,
 *     "message": "Valid YAML file with 2 blocked words"
 * }
 * ```
 *
 * Example Error Response:
 * ```json
 * {
 *     "valid": false,
 *     "errors": ["Entry 0: missing 'action' field"]
 * }
 * ```
 */
export const validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost = (
	variables: ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostResponse,
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostError,
		ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostRequestBody,
		{},
		{},
		{}
	>({
		url: "/guardrails/validate_blocked_words_file",
		method: "post",
		...variables,
		signal,
	});

export type GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetError =
	Fetcher.ErrorWrapper<undefined>;

export type GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetResponse = {
	[key: string]: any;
};

export type GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetVariables =
	FetcherExtraProps;

/**
 * Get provider-specific parameters for different guardrail types.
 *
 * Returns a dictionary mapping guardrail providers to their specific parameters,
 * including parameter names, descriptions, and whether they are required.
 *
 * Example Response:
 * ```json
 * {
 *     "bedrock": {
 *         "guardrailIdentifier": {
 *             "description": "The ID of your guardrail on Bedrock",
 *             "required": true,
 *             "type": null
 *         },
 *         "guardrailVersion": {
 *             "description": "The version of your Bedrock guardrail (e.g., DRAFT or version number)",
 *             "required": true,
 *             "type": null
 *         }
 *     },
 *     "azure_content_safety_text_moderation": {
 *         "api_key": {
 *             "description": "API key for the Azure Content Safety Text Moderation guardrail",
 *             "required": false,
 *             "type": null
 *         },
 *         "optional_params": {
 *             "description": "Optional parameters for the Azure Content Safety Text Moderation guardrail",
 *             "required": true,
 *             "type": "nested",
 *             "fields": {
 *                 "severity_threshold": {
 *                     "description": "Severity threshold for the Azure Content Safety Text Moderation guardrail across all categories",
 *                     "required": false,
 *                     "type": null
 *                 },
 *                 "categories": {
 *                     "description": "Categories to scan for the Azure Content Safety Text Moderation guardrail",
 *                     "required": false,
 *                     "type": "multiselect",
 *                     "options": ["Hate", "SelfHarm", "Sexual", "Violence"],
 *                     "default_value": None
 *                 }
 *             }
 *         }
 *     }
 * }
 * ```
 */
export const getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet = (
	variables: GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetResponse,
		GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/guardrails/ui/provider_specific_params",
		method: "get",
		...variables,
		signal,
	});

export type ApplyGuardrailApplyGuardrailPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ApplyGuardrailApplyGuardrailPostVariables = {
	body: Schemas.ApplyGuardrailRequest;
} & FetcherExtraProps;

/**
 * Apply a guardrail to text input and return the processed result.
 *
 * This endpoint allows testing guardrails by applying them to custom text inputs.
 */
export const applyGuardrailApplyGuardrailPost = (
	variables: ApplyGuardrailApplyGuardrailPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ApplyGuardrailResponse,
		ApplyGuardrailApplyGuardrailPostError,
		Schemas.ApplyGuardrailRequest,
		{},
		{},
		{}
	>({ url: "/apply_guardrail", method: "post", ...variables, signal });

export type ApplyGuardrailGuardrailsApplyGuardrailPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ApplyGuardrailGuardrailsApplyGuardrailPostVariables = {
	body: Schemas.ApplyGuardrailRequest;
} & FetcherExtraProps;

/**
 * Mask PII from a given text, requires a guardrail to be added to litellm.
 */
export const applyGuardrailGuardrailsApplyGuardrailPost = (
	variables: ApplyGuardrailGuardrailsApplyGuardrailPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ApplyGuardrailResponse,
		ApplyGuardrailGuardrailsApplyGuardrailPostError,
		Schemas.ApplyGuardrailRequest,
		{},
		{},
		{}
	>({
		url: "/guardrails/apply_guardrail",
		method: "post",
		...variables,
		signal,
	});

export type ListSearchToolsSearchToolsListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListSearchToolsSearchToolsListGetVariables = FetcherExtraProps;

/**
 * List all search tools that are available in the database.
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/search_tools/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "search_tools": [
 *         {
 *             "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 *             "search_tool_name": "litellm-search",
 *             "litellm_params": {
 *                 "search_provider": "perplexity",
 *                 "api_key": "sk-***",
 *                 "api_base": "https://api.perplexity.ai"
 *             },
 *             "search_tool_info": {
 *                 "description": "Perplexity search tool"
 *             },
 *             "created_at": "2023-11-09T12:34:56.789Z",
 *             "updated_at": "2023-11-09T12:34:56.789Z"
 *         }
 *     ]
 * }
 * ```
 */
export const listSearchToolsSearchToolsListGet = (
	variables: ListSearchToolsSearchToolsListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ListSearchToolsResponse,
		ListSearchToolsSearchToolsListGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/search_tools/list", method: "get", ...variables, signal });

export type CreateSearchToolSearchToolsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateSearchToolSearchToolsPostResponse = {
	[key: string]: any;
};

export type CreateSearchToolSearchToolsPostVariables = {
	body: Schemas.CreateSearchToolRequest;
} & FetcherExtraProps;

/**
 * Create a new search tool.
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/search_tools" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "search_tool": {
 *             "search_tool_name": "litellm-search",
 *             "litellm_params": {
 *                 "search_provider": "perplexity",
 *                 "api_key": "sk-..."
 *             },
 *             "search_tool_info": {
 *                 "description": "Perplexity search tool"
 *             }
 *         }
 *     }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "search_tool_name": "litellm-search",
 *     "litellm_params": {
 *         "search_provider": "perplexity",
 *         "api_key": "sk-..."
 *     },
 *     "search_tool_info": {
 *         "description": "Perplexity search tool"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const createSearchToolSearchToolsPost = (
	variables: CreateSearchToolSearchToolsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateSearchToolSearchToolsPostResponse,
		CreateSearchToolSearchToolsPostError,
		Schemas.CreateSearchToolRequest,
		{},
		{},
		{}
	>({ url: "/search_tools", method: "post", ...variables, signal });

export type UpdateSearchToolSearchToolsSearchToolIdPutPathParams = {
	searchToolId: string;
};

export type UpdateSearchToolSearchToolsSearchToolIdPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateSearchToolSearchToolsSearchToolIdPutResponse = {
	[key: string]: any;
};

export type UpdateSearchToolSearchToolsSearchToolIdPutVariables = {
	body: Schemas.UpdateSearchToolRequest;
	pathParams: UpdateSearchToolSearchToolsSearchToolIdPutPathParams;
} & FetcherExtraProps;

/**
 * Update an existing search tool.
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "search_tool": {
 *             "search_tool_name": "updated-search",
 *             "litellm_params": {
 *                 "search_provider": "perplexity",
 *                 "api_key": "sk-new-key"
 *             },
 *             "search_tool_info": {
 *                 "description": "Updated search tool"
 *             }
 *         }
 *     }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "search_tool_name": "updated-search",
 *     "litellm_params": {
 *         "search_provider": "perplexity",
 *         "api_key": "sk-new-key"
 *     },
 *     "search_tool_info": {
 *         "description": "Updated search tool"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T13:45:12.345Z"
 * }
 * ```
 */
export const updateSearchToolSearchToolsSearchToolIdPut = (
	variables: UpdateSearchToolSearchToolsSearchToolIdPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateSearchToolSearchToolsSearchToolIdPutResponse,
		UpdateSearchToolSearchToolsSearchToolIdPutError,
		Schemas.UpdateSearchToolRequest,
		{},
		{},
		UpdateSearchToolSearchToolsSearchToolIdPutPathParams
	>({
		url: "/search_tools/{searchToolId}",
		method: "put",
		...variables,
		signal,
	});

export type DeleteSearchToolSearchToolsSearchToolIdDeletePathParams = {
	searchToolId: string;
};

export type DeleteSearchToolSearchToolsSearchToolIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteSearchToolSearchToolsSearchToolIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteSearchToolSearchToolsSearchToolIdDeleteVariables = {
	pathParams: DeleteSearchToolSearchToolsSearchToolIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a search tool.
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "message": "Search tool 123e4567-e89b-12d3-a456-426614174000 deleted successfully",
 *     "search_tool_name": "litellm-search"
 * }
 * ```
 */
export const deleteSearchToolSearchToolsSearchToolIdDelete = (
	variables: DeleteSearchToolSearchToolsSearchToolIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteSearchToolSearchToolsSearchToolIdDeleteResponse,
		DeleteSearchToolSearchToolsSearchToolIdDeleteError,
		undefined,
		{},
		{},
		DeleteSearchToolSearchToolsSearchToolIdDeletePathParams
	>({
		url: "/search_tools/{searchToolId}",
		method: "delete",
		...variables,
		signal,
	});

export type GetSearchToolInfoSearchToolsSearchToolIdGetPathParams = {
	searchToolId: string;
};

export type GetSearchToolInfoSearchToolsSearchToolIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetSearchToolInfoSearchToolsSearchToolIdGetResponse = {
	[key: string]: any;
};

export type GetSearchToolInfoSearchToolsSearchToolIdGetVariables = {
	pathParams: GetSearchToolInfoSearchToolsSearchToolIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get detailed information about a specific search tool by ID.
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 *     "search_tool_name": "litellm-search",
 *     "litellm_params": {
 *         "search_provider": "perplexity",
 *         "api_key": "sk-***"
 *     },
 *     "search_tool_info": {
 *         "description": "Perplexity search tool"
 *     },
 *     "created_at": "2023-11-09T12:34:56.789Z",
 *     "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const getSearchToolInfoSearchToolsSearchToolIdGet = (
	variables: GetSearchToolInfoSearchToolsSearchToolIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetSearchToolInfoSearchToolsSearchToolIdGetResponse,
		GetSearchToolInfoSearchToolsSearchToolIdGetError,
		undefined,
		{},
		{},
		GetSearchToolInfoSearchToolsSearchToolIdGetPathParams
	>({
		url: "/search_tools/{searchToolId}",
		method: "get",
		...variables,
		signal,
	});

export type TestSearchToolConnectionSearchToolsTestConnectionPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TestSearchToolConnectionSearchToolsTestConnectionPostResponse = {
	[key: string]: any;
};

export type TestSearchToolConnectionSearchToolsTestConnectionPostVariables = {
	body: Schemas.TestSearchToolConnectionRequest;
} & FetcherExtraProps;

/**
 * Test connection to a search provider with the given configuration.
 *
 * Makes a simple test search query to verify the API key and configuration are valid.
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/search_tools/test_connection" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "litellm_params": {
 *             "search_provider": "perplexity",
 *             "api_key": "sk-..."
 *         }
 *     }'
 * ```
 *
 * Example Response (Success):
 * ```json
 * {
 *     "status": "success",
 *     "message": "Successfully connected to perplexity search provider",
 *     "test_query": "test",
 *     "results_count": 5
 * }
 * ```
 *
 * Example Response (Failure):
 * ```json
 * {
 *     "status": "error",
 *     "message": "Authentication failed: Invalid API key",
 *     "error_type": "AuthenticationError"
 * }
 * ```
 */
export const testSearchToolConnectionSearchToolsTestConnectionPost = (
	variables: TestSearchToolConnectionSearchToolsTestConnectionPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TestSearchToolConnectionSearchToolsTestConnectionPostResponse,
		TestSearchToolConnectionSearchToolsTestConnectionPostError,
		Schemas.TestSearchToolConnectionRequest,
		{},
		{},
		{}
	>({
		url: "/search_tools/test_connection",
		method: "post",
		...variables,
		signal,
	});

export type GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetError =
	Fetcher.ErrorWrapper<undefined>;

export type GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetResponse = {
	[key: string]: any;
};

export type GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetVariables =
	FetcherExtraProps;

/**
 * Get the list of available search providers with their configuration fields.
 *
 * Auto-discovers search providers and their UI-friendly names from transformation configs.
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/search_tools/ui/available_providers" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "providers": [
 *         {
 *             "provider_name": "perplexity",
 *             "ui_friendly_name": "Perplexity"
 *         },
 *         {
 *             "provider_name": "tavily",
 *             "ui_friendly_name": "Tavily"
 *         }
 *     ]
 * }
 * ```
 */
export const getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet = (
	variables: GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetResponse,
		GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/search_tools/ui/available_providers",
		method: "get",
		...variables,
		signal,
	});

export type ListPromptsPromptsListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListPromptsPromptsListGetVariables = FetcherExtraProps;

/**
 * List the prompts that are available on the proxy server
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/prompts/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "prompts": [
 *         {
 *             "prompt_id": "my_prompt_id",
 *             "litellm_params": {
 *                 "prompt_id": "my_prompt_id",
 *                 "prompt_integration": "dotprompt",
 *                 "prompt_directory": "/path/to/prompts"
 *             },
 *             "prompt_info": {
 *                 "prompt_type": "config"
 *             },
 *             "created_at": "2023-11-09T12:34:56.789Z",
 *             "updated_at": "2023-11-09T12:34:56.789Z"
 *         }
 *     ]
 * }
 * ```
 */
export const listPromptsPromptsListGet = (
	variables: ListPromptsPromptsListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<Schemas.ListPromptsResponse, ListPromptsPromptsListGetError, undefined, {}, {}, {}>({
		url: "/prompts/list",
		method: "get",
		...variables,
		signal,
	});

export type GetPromptInfoPromptsPromptIdInfoGetPathParams = {
	promptId: string;
};

export type GetPromptInfoPromptsPromptIdInfoGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetPromptInfoPromptsPromptIdInfoGetVariables = {
	pathParams: GetPromptInfoPromptsPromptIdInfoGetPathParams;
} & FetcherExtraProps;

/**
 * Get detailed information about a specific prompt by ID, including prompt content
 *
 *      [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 *     Example Request:
 *     ```bash
 *     curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \
 *         -H "Authorization: Bearer <your_api_key>"
 *     ```
 *
 *     Example Response:
 *     ```json
 *     {
 *         "prompt_id": "my_prompt_id",
 *         "litellm_params": {
 *             "prompt_id": "my_prompt_id",
 *             "prompt_integration": "dotprompt",
 *             "prompt_directory": "/path/to/prompts"
 *         },
 *         "prompt_info": {
 *             "prompt_type": "config"
 *         },
 *         "created_at": "2023-11-09T12:34:56.789Z",
 *         "updated_at": "2023-11-09T12:34:56.789Z",
 *         "content": "System: You are a helpful assistant.
 *
 * User: {{user_message}}"
 *     }
 *     ```
 */
export const getPromptInfoPromptsPromptIdInfoGet = (
	variables: GetPromptInfoPromptsPromptIdInfoGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PromptInfoResponse,
		GetPromptInfoPromptsPromptIdInfoGetError,
		undefined,
		{},
		{},
		GetPromptInfoPromptsPromptIdInfoGetPathParams
	>({ url: "/prompts/{promptId}/info", method: "get", ...variables, signal });

export type GetPromptInfoPromptsPromptIdGetPathParams = {
	promptId: string;
};

export type GetPromptInfoPromptsPromptIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetPromptInfoPromptsPromptIdGetVariables = {
	pathParams: GetPromptInfoPromptsPromptIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get detailed information about a specific prompt by ID, including prompt content
 *
 *      [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 *     Example Request:
 *     ```bash
 *     curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \
 *         -H "Authorization: Bearer <your_api_key>"
 *     ```
 *
 *     Example Response:
 *     ```json
 *     {
 *         "prompt_id": "my_prompt_id",
 *         "litellm_params": {
 *             "prompt_id": "my_prompt_id",
 *             "prompt_integration": "dotprompt",
 *             "prompt_directory": "/path/to/prompts"
 *         },
 *         "prompt_info": {
 *             "prompt_type": "config"
 *         },
 *         "created_at": "2023-11-09T12:34:56.789Z",
 *         "updated_at": "2023-11-09T12:34:56.789Z",
 *         "content": "System: You are a helpful assistant.
 *
 * User: {{user_message}}"
 *     }
 *     ```
 */
export const getPromptInfoPromptsPromptIdGet = (
	variables: GetPromptInfoPromptsPromptIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PromptInfoResponse,
		GetPromptInfoPromptsPromptIdGetError,
		undefined,
		{},
		{},
		GetPromptInfoPromptsPromptIdGetPathParams
	>({ url: "/prompts/{promptId}", method: "get", ...variables, signal });

export type UpdatePromptPromptsPromptIdPutPathParams = {
	promptId: string;
};

export type UpdatePromptPromptsPromptIdPutError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdatePromptPromptsPromptIdPutResponse = {
	[key: string]: any;
};

export type UpdatePromptPromptsPromptIdPutVariables = {
	body: Schemas.Prompt;
	pathParams: UpdatePromptPromptsPromptIdPutPathParams;
} & FetcherExtraProps;

/**
 * Update an existing prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/prompts/my_prompt_id" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "prompt_id": "my_prompt",
 *         "litellm_params": {
 *             "prompt_id": "my_prompt",
 *                 "prompt_integration": "dotprompt",
 *                 "prompt_directory": "/path/to/prompts"
 *             },
 *             "prompt_info": {
 *                 "prompt_type": "config"
 *             }
 *         }
 *     }'
 * ```
 */
export const updatePromptPromptsPromptIdPut = (
	variables: UpdatePromptPromptsPromptIdPutVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdatePromptPromptsPromptIdPutResponse,
		UpdatePromptPromptsPromptIdPutError,
		Schemas.Prompt,
		{},
		{},
		UpdatePromptPromptsPromptIdPutPathParams
	>({ url: "/prompts/{promptId}", method: "put", ...variables, signal });

export type DeletePromptPromptsPromptIdDeletePathParams = {
	promptId: string;
};

export type DeletePromptPromptsPromptIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeletePromptPromptsPromptIdDeleteResponse = {
	[key: string]: any;
};

export type DeletePromptPromptsPromptIdDeleteVariables = {
	pathParams: DeletePromptPromptsPromptIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/prompts/my_prompt_id" \
 *     -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "message": "Prompt my_prompt_id deleted successfully"
 * }
 * ```
 */
export const deletePromptPromptsPromptIdDelete = (
	variables: DeletePromptPromptsPromptIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeletePromptPromptsPromptIdDeleteResponse,
		DeletePromptPromptsPromptIdDeleteError,
		undefined,
		{},
		{},
		DeletePromptPromptsPromptIdDeletePathParams
	>({ url: "/prompts/{promptId}", method: "delete", ...variables, signal });

export type PatchPromptPromptsPromptIdPatchPathParams = {
	promptId: string;
};

export type PatchPromptPromptsPromptIdPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type PatchPromptPromptsPromptIdPatchVariables = {
	body?: Schemas.PatchPromptRequest;
	pathParams: PatchPromptPromptsPromptIdPatchPathParams;
} & FetcherExtraProps;

/**
 * Partially update an existing prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * This endpoint allows updating specific fields of a prompt without sending the entire object.
 * Only the following fields can be updated:
 * - litellm_params: LiteLLM parameters for the prompt
 * - prompt_info: Additional information about the prompt
 *
 * Example Request:
 * ```bash
 * curl -X PATCH "http://localhost:4000/prompts/my_prompt_id" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "prompt_info": {
 *             "prompt_type": "db"
 *         }
 *     }'
 * ```
 */
export const patchPromptPromptsPromptIdPatch = (
	variables: PatchPromptPromptsPromptIdPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		PatchPromptPromptsPromptIdPatchError,
		Schemas.PatchPromptRequest,
		{},
		{},
		PatchPromptPromptsPromptIdPatchPathParams
	>({ url: "/prompts/{promptId}", method: "patch", ...variables, signal });

export type CreatePromptPromptsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreatePromptPromptsPostResponse = {
	[key: string]: any;
};

export type CreatePromptPromptsPostVariables = {
	body: Schemas.Prompt;
} & FetcherExtraProps;

/**
 * Create a new prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/prompts" \
 *     -H "Authorization: Bearer <your_api_key>" \
 *     -H "Content-Type: application/json" \
 *     -d '{
 *         "prompt_id": "my_prompt",
 *         "litellm_params": {
 *             "prompt_id": "json_prompt",
 *             "prompt_integration": "dotprompt",
 *             ### EITHER prompt_directory OR prompt_data MUST BE PROVIDED
 *             "prompt_directory": "/path/to/dotprompt/folder",
 *             "prompt_data": {"json_prompt": {"content": "This is a prompt", "metadata": {"model": "gpt-4"}}}
 *         },
 *         "prompt_info": {
 *             "prompt_type": "config"
 *         }
 *     }'
 * ```
 */
export const createPromptPromptsPost = (
	variables: CreatePromptPromptsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<CreatePromptPromptsPostResponse, CreatePromptPromptsPostError, Schemas.Prompt, {}, {}, {}>({
		url: "/prompts",
		method: "post",
		...variables,
		signal,
	});

export type ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostVariables = {
	body: Schemas.BodyConvertPromptFileToJsonUtilsDotpromptJsonConverterPost;
} & FetcherExtraProps;

/**
 * Convert a .prompt file to JSON format.
 *
 * This endpoint accepts a .prompt file upload and returns the equivalent JSON representation
 * that can be stored in a database or used programmatically.
 *
 * Returns the JSON structure with 'content' and 'metadata' fields.
 */
export const convertPromptFileToJsonUtilsDotpromptJsonConverterPost = (
	variables: ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Record<string, any>,
		ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostError,
		Schemas.BodyConvertPromptFileToJsonUtilsDotpromptJsonConverterPost,
		{},
		{},
		{}
	>({
		url: "/utils/dotprompt_json_converter",
		method: "post",
		...variables,
		signal,
	});

export type ListCallbacksCallbacksListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListCallbacksCallbacksListGetVariables = FetcherExtraProps;

/**
 * View List of Active Logging Callbacks
 */
export const listCallbacksCallbacksListGet = (
	variables: ListCallbacksCallbacksListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<Schemas.CallbacksByType, ListCallbacksCallbacksListGetError, undefined, {}, {}, {}>({
		url: "/callbacks/list",
		method: "get",
		...variables,
		signal,
	});

export type GetActiveTasksStatsDebugAsyncioTasksGetError = Fetcher.ErrorWrapper<undefined>;

export type GetActiveTasksStatsDebugAsyncioTasksGetResponse = {
	[key: string]: any;
};

export type GetActiveTasksStatsDebugAsyncioTasksGetVariables = FetcherExtraProps;

/**
 * Returns:
 *   total_active_tasks: int
 *   by_name: { coroutine_name: count }
 */
export const getActiveTasksStatsDebugAsyncioTasksGet = (
	variables: GetActiveTasksStatsDebugAsyncioTasksGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetActiveTasksStatsDebugAsyncioTasksGetResponse,
		GetActiveTasksStatsDebugAsyncioTasksGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/debug/asyncio-tasks", method: "get", ...variables, signal });

export type AddAllowedIpAddAllowedIpPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AddAllowedIpAddAllowedIpPostResponse = {
	[key: string]: any;
};

export type AddAllowedIpAddAllowedIpPostVariables = {
	body: Schemas.IPAddress;
} & FetcherExtraProps;

export const addAllowedIpAddAllowedIpPost = (
	variables: AddAllowedIpAddAllowedIpPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AddAllowedIpAddAllowedIpPostResponse,
		AddAllowedIpAddAllowedIpPostError,
		Schemas.IPAddress,
		{},
		{},
		{}
	>({ url: "/add/allowed_ip", method: "post", ...variables, signal });

export type DeleteAllowedIpDeleteAllowedIpPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteAllowedIpDeleteAllowedIpPostResponse = {
	[key: string]: any;
};

export type DeleteAllowedIpDeleteAllowedIpPostVariables = {
	body: Schemas.IPAddress;
} & FetcherExtraProps;

export const deleteAllowedIpDeleteAllowedIpPost = (
	variables: DeleteAllowedIpDeleteAllowedIpPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteAllowedIpDeleteAllowedIpPostResponse,
		DeleteAllowedIpDeleteAllowedIpPostError,
		Schemas.IPAddress,
		{},
		{},
		{}
	>({ url: "/delete/allowed_ip", method: "post", ...variables, signal });

export type GetInternalUserSettingsGetInternalUserSettingsGetError =
	Fetcher.ErrorWrapper<undefined>;

export type GetInternalUserSettingsGetInternalUserSettingsGetVariables = FetcherExtraProps;

/**
 * Get all SSO settings from the litellm_settings configuration.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getInternalUserSettingsGetInternalUserSettingsGet = (
	variables: GetInternalUserSettingsGetInternalUserSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.InternalUserSettingsResponse,
		GetInternalUserSettingsGetInternalUserSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/get/internal_user_settings",
		method: "get",
		...variables,
		signal,
	});

export type GetDefaultTeamSettingsGetDefaultTeamSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetDefaultTeamSettingsGetDefaultTeamSettingsGetVariables = FetcherExtraProps;

/**
 * Get all SSO settings from the litellm_settings configuration.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getDefaultTeamSettingsGetDefaultTeamSettingsGet = (
	variables: GetDefaultTeamSettingsGetDefaultTeamSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.DefaultTeamSettingsResponse,
		GetDefaultTeamSettingsGetDefaultTeamSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/get/default_team_settings", method: "get", ...variables, signal });

export type UpdateInternalUserSettingsUpdateInternalUserSettingsPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateInternalUserSettingsUpdateInternalUserSettingsPatchVariables = {
	body?: Schemas.DefaultInternalUserParams;
} & FetcherExtraProps;

/**
 * Update the default internal user parameters for SSO users.
 * These settings will be applied to new users who sign in via SSO.
 */
export const updateInternalUserSettingsUpdateInternalUserSettingsPatch = (
	variables: UpdateInternalUserSettingsUpdateInternalUserSettingsPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		UpdateInternalUserSettingsUpdateInternalUserSettingsPatchError,
		Schemas.DefaultInternalUserParams,
		{},
		{},
		{}
	>({
		url: "/update/internal_user_settings",
		method: "patch",
		...variables,
		signal,
	});

export type UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchVariables = {
	body?: Schemas.DefaultTeamSSOParams;
} & FetcherExtraProps;

/**
 * Update the default team parameters for SSO users.
 * These settings will be applied to new teams created from SSO.
 */
export const updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch = (
	variables: UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchError,
		Schemas.DefaultTeamSSOParams,
		{},
		{},
		{}
	>({
		url: "/update/default_team_settings",
		method: "patch",
		...variables,
		signal,
	});

export type GetSsoSettingsGetSsoSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetSsoSettingsGetSsoSettingsGetVariables = FetcherExtraProps;

/**
 * Get all SSO configuration settings from the dedicated SSO table.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getSsoSettingsGetSsoSettingsGet = (
	variables: GetSsoSettingsGetSsoSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<Schemas.SSOSettingsResponse, GetSsoSettingsGetSsoSettingsGetError, undefined, {}, {}, {}>({
		url: "/get/sso_settings",
		method: "get",
		...variables,
		signal,
	});

export type UpdateSsoSettingsUpdateSsoSettingsPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateSsoSettingsUpdateSsoSettingsPatchVariables = {
	body?: Schemas.SSOConfig;
} & FetcherExtraProps;

/**
 * Update SSO configuration by saving to the dedicated SSO table.
 */
export const updateSsoSettingsUpdateSsoSettingsPatch = (
	variables: UpdateSsoSettingsUpdateSsoSettingsPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<void, UpdateSsoSettingsUpdateSsoSettingsPatchError, Schemas.SSOConfig, {}, {}, {}>({
		url: "/update/sso_settings",
		method: "patch",
		...variables,
		signal,
	});

export type GetUiThemeSettingsGetUiThemeSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetUiThemeSettingsGetUiThemeSettingsGetVariables = FetcherExtraProps;

/**
 * Get UI theme configuration from the litellm_settings.
 * Returns current logo settings for UI customization.
 *
 * Note: This endpoint is public (no authentication required) so all users can see custom branding.
 * Only the /update/ui_theme_settings endpoint requires authentication for admins to change settings.
 */
export const getUiThemeSettingsGetUiThemeSettingsGet = (
	variables: GetUiThemeSettingsGetUiThemeSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.UIThemeSettingsResponse,
		GetUiThemeSettingsGetUiThemeSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/get/ui_theme_settings", method: "get", ...variables, signal });

export type UpdateUiThemeSettingsUpdateUiThemeSettingsPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateUiThemeSettingsUpdateUiThemeSettingsPatchVariables = {
	body?: Schemas.UIThemeConfig;
} & FetcherExtraProps;

/**
 * Update UI theme configuration.
 * Updates logo settings for the admin UI.
 */
export const updateUiThemeSettingsUpdateUiThemeSettingsPatch = (
	variables: UpdateUiThemeSettingsUpdateUiThemeSettingsPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		UpdateUiThemeSettingsUpdateUiThemeSettingsPatchError,
		Schemas.UIThemeConfig,
		{},
		{},
		{}
	>({
		url: "/update/ui_theme_settings",
		method: "patch",
		...variables,
		signal,
	});

export type UploadLogoUploadLogoPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UploadLogoUploadLogoPostResponse = {
	[key: string]: any;
};

export type UploadLogoUploadLogoPostVariables = {
	body: Schemas.BodyUploadLogoUploadLogoPost;
} & FetcherExtraProps;

/**
 * Upload a custom logo for the admin UI.
 * Accepts image files (PNG, JPG, JPEG, SVG) and stores them for use in the UI.
 */
export const uploadLogoUploadLogoPost = (
	variables: UploadLogoUploadLogoPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UploadLogoUploadLogoPostResponse,
		UploadLogoUploadLogoPostError,
		Schemas.BodyUploadLogoUploadLogoPost,
		{},
		{},
		{}
	>({ url: "/upload/logo", method: "post", ...variables, signal });

export type CreateFileFilesPostQueryParams = {
	provider?: string | null;
};

export type CreateFileFilesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateFileFilesPostResponse = {
	[key: string]: any;
};

export type CreateFileFilesPostVariables = {
	body: Schemas.BodyCreateFileFilesPost;
	queryParams?: CreateFileFilesPostQueryParams;
} & FetcherExtraProps;

/**
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileFilesPost = (
	variables: CreateFileFilesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateFileFilesPostResponse,
		CreateFileFilesPostError,
		Schemas.BodyCreateFileFilesPost,
		{},
		CreateFileFilesPostQueryParams,
		{}
	>({ url: "/files", method: "post", ...variables, signal });

export type ListFilesFilesGetQueryParams = {
	provider?: string | null;
	target_model_names?: string | null;
	purpose?: string | null;
};

export type ListFilesFilesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListFilesFilesGetResponse = {
	[key: string]: any;
};

export type ListFilesFilesGetVariables = {
	queryParams?: ListFilesFilesGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesFilesGet = (variables: ListFilesFilesGetVariables, signal?: AbortSignal) =>
	fetch<
		ListFilesFilesGetResponse,
		ListFilesFilesGetError,
		undefined,
		{},
		ListFilesFilesGetQueryParams,
		{}
	>({ url: "/files", method: "get", ...variables, signal });

export type CreateFileV1FilesPostQueryParams = {
	provider?: string | null;
};

export type CreateFileV1FilesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateFileV1FilesPostResponse = {
	[key: string]: any;
};

export type CreateFileV1FilesPostVariables = {
	body: Schemas.BodyCreateFileV1FilesPost;
	queryParams?: CreateFileV1FilesPostQueryParams;
} & FetcherExtraProps;

/**
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileV1FilesPost = (
	variables: CreateFileV1FilesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateFileV1FilesPostResponse,
		CreateFileV1FilesPostError,
		Schemas.BodyCreateFileV1FilesPost,
		{},
		CreateFileV1FilesPostQueryParams,
		{}
	>({ url: "/v1/files", method: "post", ...variables, signal });

export type ListFilesV1FilesGetQueryParams = {
	provider?: string | null;
	target_model_names?: string | null;
	purpose?: string | null;
};

export type ListFilesV1FilesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListFilesV1FilesGetResponse = {
	[key: string]: any;
};

export type ListFilesV1FilesGetVariables = {
	queryParams?: ListFilesV1FilesGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesV1FilesGet = (
	variables: ListFilesV1FilesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListFilesV1FilesGetResponse,
		ListFilesV1FilesGetError,
		undefined,
		{},
		ListFilesV1FilesGetQueryParams,
		{}
	>({ url: "/v1/files", method: "get", ...variables, signal });

export type CreateFileProviderV1FilesPostPathParams = {
	provider: string | null;
};

export type CreateFileProviderV1FilesPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CreateFileProviderV1FilesPostResponse = {
	[key: string]: any;
};

export type CreateFileProviderV1FilesPostVariables = {
	body: Schemas.BodyCreateFileProviderV1FilesPost;
	pathParams: CreateFileProviderV1FilesPostPathParams;
} & FetcherExtraProps;

/**
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileProviderV1FilesPost = (
	variables: CreateFileProviderV1FilesPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CreateFileProviderV1FilesPostResponse,
		CreateFileProviderV1FilesPostError,
		Schemas.BodyCreateFileProviderV1FilesPost,
		{},
		{},
		CreateFileProviderV1FilesPostPathParams
	>({ url: "/{provider}/v1/files", method: "post", ...variables, signal });

export type ListFilesProviderV1FilesGetPathParams = {
	provider: string | null;
};

export type ListFilesProviderV1FilesGetQueryParams = {
	target_model_names?: string | null;
	purpose?: string | null;
};

export type ListFilesProviderV1FilesGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListFilesProviderV1FilesGetResponse = {
	[key: string]: any;
};

export type ListFilesProviderV1FilesGetVariables = {
	pathParams: ListFilesProviderV1FilesGetPathParams;
	queryParams?: ListFilesProviderV1FilesGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesProviderV1FilesGet = (
	variables: ListFilesProviderV1FilesGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ListFilesProviderV1FilesGetResponse,
		ListFilesProviderV1FilesGetError,
		undefined,
		{},
		ListFilesProviderV1FilesGetQueryParams,
		ListFilesProviderV1FilesGetPathParams
	>({ url: "/{provider}/v1/files", method: "get", ...variables, signal });

export type GetFileContentFilesFileIdContentGetPathParams = {
	fileId: string;
};

export type GetFileContentFilesFileIdContentGetQueryParams = {
	provider?: string | null;
};

export type GetFileContentFilesFileIdContentGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetFileContentFilesFileIdContentGetResponse = {
	[key: string]: any;
};

export type GetFileContentFilesFileIdContentGetVariables = {
	pathParams: GetFileContentFilesFileIdContentGetPathParams;
	queryParams?: GetFileContentFilesFileIdContentGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentFilesFileIdContentGet = (
	variables: GetFileContentFilesFileIdContentGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetFileContentFilesFileIdContentGetResponse,
		GetFileContentFilesFileIdContentGetError,
		undefined,
		{},
		GetFileContentFilesFileIdContentGetQueryParams,
		GetFileContentFilesFileIdContentGetPathParams
	>({ url: "/files/{fileId}/content", method: "get", ...variables, signal });

export type GetFileContentV1FilesFileIdContentGetPathParams = {
	fileId: string;
};

export type GetFileContentV1FilesFileIdContentGetQueryParams = {
	provider?: string | null;
};

export type GetFileContentV1FilesFileIdContentGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetFileContentV1FilesFileIdContentGetResponse = {
	[key: string]: any;
};

export type GetFileContentV1FilesFileIdContentGetVariables = {
	pathParams: GetFileContentV1FilesFileIdContentGetPathParams;
	queryParams?: GetFileContentV1FilesFileIdContentGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentV1FilesFileIdContentGet = (
	variables: GetFileContentV1FilesFileIdContentGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetFileContentV1FilesFileIdContentGetResponse,
		GetFileContentV1FilesFileIdContentGetError,
		undefined,
		{},
		GetFileContentV1FilesFileIdContentGetQueryParams,
		GetFileContentV1FilesFileIdContentGetPathParams
	>({ url: "/v1/files/{fileId}/content", method: "get", ...variables, signal });

export type GetFileContentProviderV1FilesFileIdContentGetPathParams = {
	fileId: string;
	provider: string | null;
};

export type GetFileContentProviderV1FilesFileIdContentGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetFileContentProviderV1FilesFileIdContentGetResponse = {
	[key: string]: any;
};

export type GetFileContentProviderV1FilesFileIdContentGetVariables = {
	pathParams: GetFileContentProviderV1FilesFileIdContentGetPathParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentProviderV1FilesFileIdContentGet = (
	variables: GetFileContentProviderV1FilesFileIdContentGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetFileContentProviderV1FilesFileIdContentGetResponse,
		GetFileContentProviderV1FilesFileIdContentGetError,
		undefined,
		{},
		{},
		GetFileContentProviderV1FilesFileIdContentGetPathParams
	>({
		url: "/{provider}/v1/files/{fileId}/content",
		method: "get",
		...variables,
		signal,
	});

export type GetFileFilesFileIdGetPathParams = {
	fileId: string;
};

export type GetFileFilesFileIdGetQueryParams = {
	provider?: string | null;
};

export type GetFileFilesFileIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetFileFilesFileIdGetResponse = {
	[key: string]: any;
};

export type GetFileFilesFileIdGetVariables = {
	pathParams: GetFileFilesFileIdGetPathParams;
	queryParams?: GetFileFilesFileIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileFilesFileIdGet = (
	variables: GetFileFilesFileIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetFileFilesFileIdGetResponse,
		GetFileFilesFileIdGetError,
		undefined,
		{},
		GetFileFilesFileIdGetQueryParams,
		GetFileFilesFileIdGetPathParams
	>({ url: "/files/{fileId}", method: "get", ...variables, signal });

export type DeleteFileFilesFileIdDeletePathParams = {
	fileId: string;
};

export type DeleteFileFilesFileIdDeleteQueryParams = {
	provider?: string | null;
};

export type DeleteFileFilesFileIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteFileFilesFileIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteFileFilesFileIdDeleteVariables = {
	pathParams: DeleteFileFilesFileIdDeletePathParams;
	queryParams?: DeleteFileFilesFileIdDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileFilesFileIdDelete = (
	variables: DeleteFileFilesFileIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteFileFilesFileIdDeleteResponse,
		DeleteFileFilesFileIdDeleteError,
		undefined,
		{},
		DeleteFileFilesFileIdDeleteQueryParams,
		DeleteFileFilesFileIdDeletePathParams
	>({ url: "/files/{fileId}", method: "delete", ...variables, signal });

export type GetFileV1FilesFileIdGetPathParams = {
	fileId: string;
};

export type GetFileV1FilesFileIdGetQueryParams = {
	provider?: string | null;
};

export type GetFileV1FilesFileIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetFileV1FilesFileIdGetResponse = {
	[key: string]: any;
};

export type GetFileV1FilesFileIdGetVariables = {
	pathParams: GetFileV1FilesFileIdGetPathParams;
	queryParams?: GetFileV1FilesFileIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileV1FilesFileIdGet = (
	variables: GetFileV1FilesFileIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetFileV1FilesFileIdGetResponse,
		GetFileV1FilesFileIdGetError,
		undefined,
		{},
		GetFileV1FilesFileIdGetQueryParams,
		GetFileV1FilesFileIdGetPathParams
	>({ url: "/v1/files/{fileId}", method: "get", ...variables, signal });

export type DeleteFileV1FilesFileIdDeletePathParams = {
	fileId: string;
};

export type DeleteFileV1FilesFileIdDeleteQueryParams = {
	provider?: string | null;
};

export type DeleteFileV1FilesFileIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteFileV1FilesFileIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteFileV1FilesFileIdDeleteVariables = {
	pathParams: DeleteFileV1FilesFileIdDeletePathParams;
	queryParams?: DeleteFileV1FilesFileIdDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileV1FilesFileIdDelete = (
	variables: DeleteFileV1FilesFileIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteFileV1FilesFileIdDeleteResponse,
		DeleteFileV1FilesFileIdDeleteError,
		undefined,
		{},
		DeleteFileV1FilesFileIdDeleteQueryParams,
		DeleteFileV1FilesFileIdDeletePathParams
	>({ url: "/v1/files/{fileId}", method: "delete", ...variables, signal });

export type GetFileProviderV1FilesFileIdGetPathParams = {
	fileId: string;
	provider: string | null;
};

export type GetFileProviderV1FilesFileIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetFileProviderV1FilesFileIdGetResponse = {
	[key: string]: any;
};

export type GetFileProviderV1FilesFileIdGetVariables = {
	pathParams: GetFileProviderV1FilesFileIdGetPathParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileProviderV1FilesFileIdGet = (
	variables: GetFileProviderV1FilesFileIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetFileProviderV1FilesFileIdGetResponse,
		GetFileProviderV1FilesFileIdGetError,
		undefined,
		{},
		{},
		GetFileProviderV1FilesFileIdGetPathParams
	>({
		url: "/{provider}/v1/files/{fileId}",
		method: "get",
		...variables,
		signal,
	});

export type DeleteFileProviderV1FilesFileIdDeletePathParams = {
	fileId: string;
	provider: string | null;
};

export type DeleteFileProviderV1FilesFileIdDeleteError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteFileProviderV1FilesFileIdDeleteResponse = {
	[key: string]: any;
};

export type DeleteFileProviderV1FilesFileIdDeleteVariables = {
	pathParams: DeleteFileProviderV1FilesFileIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileProviderV1FilesFileIdDelete = (
	variables: DeleteFileProviderV1FilesFileIdDeleteVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteFileProviderV1FilesFileIdDeleteResponse,
		DeleteFileProviderV1FilesFileIdDeleteError,
		undefined,
		{},
		{},
		DeleteFileProviderV1FilesFileIdDeletePathParams
	>({
		url: "/{provider}/v1/files/{fileId}",
		method: "delete",
		...variables,
		signal,
	});

export type AddTeamCallbacksTeamTeamIdCallbackPostPathParams = {
	teamId: string;
};

export type AddTeamCallbacksTeamTeamIdCallbackPostHeaders = {
	/**
	 * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
	 */
	["litellm-changed-by"]?: string | null;
};

export type AddTeamCallbacksTeamTeamIdCallbackPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AddTeamCallbacksTeamTeamIdCallbackPostResponse = {
	[key: string]: any;
};

export type AddTeamCallbacksTeamTeamIdCallbackPostVariables = {
	body: Schemas.AddTeamCallback;
	headers?: AddTeamCallbacksTeamTeamIdCallbackPostHeaders;
	pathParams: AddTeamCallbacksTeamTeamIdCallbackPostPathParams;
} & FetcherExtraProps;

/**
 * Add a success/failure callback to a team
 *
 * Use this if if you want different teams to have different success/failure callbacks
 *
 * Parameters:
 * - callback_name (Literal["langfuse", "langsmith", "gcs"], required): The name of the callback to add
 * - callback_type (Literal["success", "failure", "success_and_failure"], required): The type of callback to add. One of:
 *     - "success": Callback for successful LLM calls
 *     - "failure": Callback for failed LLM calls
 *     - "success_and_failure": Callback for both successful and failed LLM calls
 * - callback_vars (StandardCallbackDynamicParams, required): A dictionary of variables to pass to the callback
 *     - langfuse_public_key: The public key for the Langfuse callback
 *     - langfuse_secret_key: The secret key for the Langfuse callback
 *     - langfuse_secret: The secret for the Langfuse callback
 *     - langfuse_host: The host for the Langfuse callback
 *     - gcs_bucket_name: The name of the GCS bucket
 *     - gcs_path_service_account: The path to the GCS service account
 *     - langsmith_api_key: The API key for the Langsmith callback
 *     - langsmith_project: The project for the Langsmith callback
 *     - langsmith_base_url: The base URL for the Langsmith callback
 *
 * Example curl:
 * ```
 * curl -X POST 'http:/localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -d '{
 *     "callback_name": "langfuse",
 *     "callback_type": "success",
 *     "callback_vars": {"langfuse_public_key": "pk-lf-xxxx1", "langfuse_secret_key": "sk-xxxxx"}
 *
 * }'
 * ```
 *
 * This means for the team where team_id = dbe2f686-a686-4896-864a-4c3924458709, all LLM calls will be logged to langfuse using the public key pk-lf-xxxx1 and the secret key sk-xxxxx
 */
export const addTeamCallbacksTeamTeamIdCallbackPost = (
	variables: AddTeamCallbacksTeamTeamIdCallbackPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AddTeamCallbacksTeamTeamIdCallbackPostResponse,
		AddTeamCallbacksTeamTeamIdCallbackPostError,
		Schemas.AddTeamCallback,
		AddTeamCallbacksTeamTeamIdCallbackPostHeaders,
		{},
		AddTeamCallbacksTeamTeamIdCallbackPostPathParams
	>({ url: "/team/{teamId}/callback", method: "post", ...variables, signal });

export type GetTeamCallbacksTeamTeamIdCallbackGetPathParams = {
	teamId: string;
};

export type GetTeamCallbacksTeamTeamIdCallbackGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetTeamCallbacksTeamTeamIdCallbackGetResponse = {
	[key: string]: any;
};

export type GetTeamCallbacksTeamTeamIdCallbackGetVariables = {
	pathParams: GetTeamCallbacksTeamTeamIdCallbackGetPathParams;
} & FetcherExtraProps;

/**
 * Get the success/failure callbacks and variables for a team
 *
 * Parameters:
 * - team_id (str, required): The unique identifier for the team
 *
 * Example curl:
 * ```
 * curl -X GET 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * This will return the callback settings for the team with id dbe2f686-a686-4896-864a-4c3924458709
 *
 * Returns {
 *         "status": "success",
 *         "data": {
 *             "team_id": team_id,
 *             "success_callbacks": team_callback_settings_obj.success_callback,
 *             "failure_callbacks": team_callback_settings_obj.failure_callback,
 *             "callback_vars": team_callback_settings_obj.callback_vars,
 *         },
 *     }
 */
export const getTeamCallbacksTeamTeamIdCallbackGet = (
	variables: GetTeamCallbacksTeamTeamIdCallbackGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetTeamCallbacksTeamTeamIdCallbackGetResponse,
		GetTeamCallbacksTeamTeamIdCallbackGetError,
		undefined,
		{},
		{},
		GetTeamCallbacksTeamTeamIdCallbackGetPathParams
	>({ url: "/team/{teamId}/callback", method: "get", ...variables, signal });

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams = {
	teamId: string;
};

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostResponse = {
	[key: string]: any;
};

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostVariables = {
	pathParams: DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams;
} & FetcherExtraProps;

/**
 * Disable all logging callbacks for a team
 *
 * Parameters:
 * - team_id (str, required): The unique identifier for the team
 *
 * Example curl:
 * ```
 * curl -X POST 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/disable_logging'         -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const disableTeamLoggingTeamTeamIdDisableLoggingPost = (
	variables: DisableTeamLoggingTeamTeamIdDisableLoggingPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DisableTeamLoggingTeamTeamIdDisableLoggingPostResponse,
		DisableTeamLoggingTeamTeamIdDisableLoggingPostError,
		undefined,
		{},
		{},
		DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams
	>({
		url: "/team/{teamId}/disable_logging",
		method: "post",
		...variables,
		signal,
	});

export type NewBudgetBudgetNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewBudgetBudgetNewPostResponse = {
	[key: string]: any;
};

export type NewBudgetBudgetNewPostVariables = {
	body?: Schemas.BudgetNewRequest;
} & FetcherExtraProps;

/**
 * Create a new budget object. Can apply this to teams, orgs, end-users, keys.
 *
 * Parameters:
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.
 * - max_budget: Optional[float] - The max budget for the budget.
 * - soft_budget: Optional[float] - The soft budget for the budget.
 * - max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.
 * - tpm_limit: Optional[int] - The tokens per minute limit for the budget.
 * - rpm_limit: Optional[int] - The requests per minute limit for the budget.
 * - model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}
 * - budget_reset_at: Optional[datetime] - Datetime when the initial budget is reset. Default is now.
 */
export const newBudgetBudgetNewPost = (
	variables: NewBudgetBudgetNewPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		NewBudgetBudgetNewPostResponse,
		NewBudgetBudgetNewPostError,
		Schemas.BudgetNewRequest,
		{},
		{},
		{}
	>({ url: "/budget/new", method: "post", ...variables, signal });

export type UpdateBudgetBudgetUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateBudgetBudgetUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateBudgetBudgetUpdatePostVariables = {
	body?: Schemas.BudgetNewRequest;
} & FetcherExtraProps;

/**
 * Update an existing budget object.
 *
 * Parameters:
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.
 * - max_budget: Optional[float] - The max budget for the budget.
 * - soft_budget: Optional[float] - The soft budget for the budget.
 * - max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.
 * - tpm_limit: Optional[int] - The tokens per minute limit for the budget.
 * - rpm_limit: Optional[int] - The requests per minute limit for the budget.
 * - model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}
 * - budget_reset_at: Optional[datetime] - Update the Datetime when the budget was last reset.
 */
export const updateBudgetBudgetUpdatePost = (
	variables: UpdateBudgetBudgetUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateBudgetBudgetUpdatePostResponse,
		UpdateBudgetBudgetUpdatePostError,
		Schemas.BudgetNewRequest,
		{},
		{},
		{}
	>({ url: "/budget/update", method: "post", ...variables, signal });

export type InfoBudgetBudgetInfoPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type InfoBudgetBudgetInfoPostResponse = {
	[key: string]: any;
};

export type InfoBudgetBudgetInfoPostVariables = {
	body: Schemas.BudgetRequest;
} & FetcherExtraProps;

/**
 * Get the budget id specific information
 *
 * Parameters:
 * - budgets: List[str] - The list of budget ids to get information for
 */
export const infoBudgetBudgetInfoPost = (
	variables: InfoBudgetBudgetInfoPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		InfoBudgetBudgetInfoPostResponse,
		InfoBudgetBudgetInfoPostError,
		Schemas.BudgetRequest,
		{},
		{},
		{}
	>({ url: "/budget/info", method: "post", ...variables, signal });

export type BudgetSettingsBudgetSettingsGetQueryParams = {
	budget_id: string;
};

export type BudgetSettingsBudgetSettingsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type BudgetSettingsBudgetSettingsGetResponse = {
	[key: string]: any;
};

export type BudgetSettingsBudgetSettingsGetVariables = {
	queryParams: BudgetSettingsBudgetSettingsGetQueryParams;
} & FetcherExtraProps;

/**
 * Get list of configurable params + current value for a budget item + description of each field
 *
 * Used on Admin UI.
 *
 * Query Parameters:
 * - budget_id: str - The budget id to get information for
 */
export const budgetSettingsBudgetSettingsGet = (
	variables: BudgetSettingsBudgetSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		BudgetSettingsBudgetSettingsGetResponse,
		BudgetSettingsBudgetSettingsGetError,
		undefined,
		{},
		BudgetSettingsBudgetSettingsGetQueryParams,
		{}
	>({ url: "/budget/settings", method: "get", ...variables, signal });

export type ListBudgetBudgetListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListBudgetBudgetListGetResponse = {
	[key: string]: any;
};

export type ListBudgetBudgetListGetVariables = FetcherExtraProps;

/**
 * List all the created budgets in proxy db. Used on Admin UI.
 */
export const listBudgetBudgetListGet = (
	variables: ListBudgetBudgetListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<ListBudgetBudgetListGetResponse, ListBudgetBudgetListGetError, undefined, {}, {}, {}>({
		url: "/budget/list",
		method: "get",
		...variables,
		signal,
	});

export type DeleteBudgetBudgetDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteBudgetBudgetDeletePostResponse = {
	[key: string]: any;
};

export type DeleteBudgetBudgetDeletePostVariables = {
	body: Schemas.BudgetDeleteRequest;
} & FetcherExtraProps;

/**
 * Delete budget
 *
 * Parameters:
 * - id: str - The budget id to delete
 */
export const deleteBudgetBudgetDeletePost = (
	variables: DeleteBudgetBudgetDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteBudgetBudgetDeletePostResponse,
		DeleteBudgetBudgetDeletePostError,
		Schemas.BudgetDeleteRequest,
		{},
		{},
		{}
	>({ url: "/budget/delete", method: "post", ...variables, signal });

export type PatchModelModelModelIdUpdatePatchPathParams = {
	modelId: string;
};

export type PatchModelModelModelIdUpdatePatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type PatchModelModelModelIdUpdatePatchVariables = {
	body?: Schemas.UpdateDeployment;
	pathParams: PatchModelModelModelIdUpdatePatchPathParams;
} & FetcherExtraProps;

/**
 * PATCH Endpoint for partial model updates.
 *
 * Only updates the fields specified in the request while preserving other existing values.
 * Follows proper PATCH semantics by only modifying provided fields.
 *
 * Args:
 *     model_id: The ID of the model to update
 *     patch_data: The fields to update and their new values
 *     user_api_key_dict: User authentication information
 *
 * Returns:
 *     Updated model information
 *
 * Raises:
 *     ProxyException: For various error conditions including authentication and database errors
 */
export const patchModelModelModelIdUpdatePatch = (
	variables: PatchModelModelModelIdUpdatePatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		PatchModelModelModelIdUpdatePatchError,
		Schemas.UpdateDeployment,
		{},
		{},
		PatchModelModelModelIdUpdatePatchPathParams
	>({ url: "/model/{modelId}/update", method: "patch", ...variables, signal });

export type DeleteModelModelDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteModelModelDeletePostResponse = {
	[key: string]: any;
};

export type DeleteModelModelDeletePostVariables = {
	body: Schemas.ModelInfoDelete;
} & FetcherExtraProps;

/**
 * Allows deleting models in the model list in the config.yaml
 */
export const deleteModelModelDeletePost = (
	variables: DeleteModelModelDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteModelModelDeletePostResponse,
		DeleteModelModelDeletePostError,
		Schemas.ModelInfoDelete,
		{},
		{},
		{}
	>({ url: "/model/delete", method: "post", ...variables, signal });

export type AddNewModelModelNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AddNewModelModelNewPostResponse = {
	[key: string]: any;
};

export type AddNewModelModelNewPostVariables = {
	body: Schemas.Deployment;
} & FetcherExtraProps;

/**
 * Allows adding new models to the model list in the config.yaml
 */
export const addNewModelModelNewPost = (
	variables: AddNewModelModelNewPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AddNewModelModelNewPostResponse,
		AddNewModelModelNewPostError,
		Schemas.Deployment,
		{},
		{},
		{}
	>({ url: "/model/new", method: "post", ...variables, signal });

export type UpdateModelModelUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateModelModelUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateModelModelUpdatePostVariables = {
	body?: Schemas.UpdateDeployment;
} & FetcherExtraProps;

/**
 * Edit existing model params
 */
export const updateModelModelUpdatePost = (
	variables: UpdateModelModelUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateModelModelUpdatePostResponse,
		UpdateModelModelUpdatePostError,
		Schemas.UpdateDeployment,
		{},
		{},
		{}
	>({ url: "/model/update", method: "post", ...variables, signal });

export type UpdatePublicModelGroupsModelGroupMakePublicPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdatePublicModelGroupsModelGroupMakePublicPostResponse = {
	[key: string]: any;
};

export type UpdatePublicModelGroupsModelGroupMakePublicPostVariables = {
	body: Schemas.UpdatePublicModelGroupsRequest;
} & FetcherExtraProps;

/**
 * Update which model groups are public
 */
export const updatePublicModelGroupsModelGroupMakePublicPost = (
	variables: UpdatePublicModelGroupsModelGroupMakePublicPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdatePublicModelGroupsModelGroupMakePublicPostResponse,
		UpdatePublicModelGroupsModelGroupMakePublicPostError,
		Schemas.UpdatePublicModelGroupsRequest,
		{},
		{},
		{}
	>({ url: "/model_group/make_public", method: "post", ...variables, signal });

export type UpdateUsefulLinksModelHubUpdateUsefulLinksPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateUsefulLinksModelHubUpdateUsefulLinksPostResponse = {
	[key: string]: any;
};

export type UpdateUsefulLinksModelHubUpdateUsefulLinksPostVariables = {
	body: Schemas.UpdateUsefulLinksRequest;
} & FetcherExtraProps;

/**
 * Update useful links
 */
export const updateUsefulLinksModelHubUpdateUsefulLinksPost = (
	variables: UpdateUsefulLinksModelHubUpdateUsefulLinksPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateUsefulLinksModelHubUpdateUsefulLinksPostResponse,
		UpdateUsefulLinksModelHubUpdateUsefulLinksPostError,
		Schemas.UpdateUsefulLinksRequest,
		{},
		{},
		{}
	>({
		url: "/model_hub/update_useful_links",
		method: "post",
		...variables,
		signal,
	});

export type NewTagTagNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewTagTagNewPostResponse = {
	[key: string]: any;
};

export type NewTagTagNewPostVariables = {
	body: Schemas.TagNewRequest;
} & FetcherExtraProps;

/**
 * Create a new tag.
 *
 * Parameters:
 * - name: str - The name of the tag
 * - description: Optional[str] - Description of what this tag represents
 * - models: List[str] - List of either 'model_id' or 'model_name' allowed for this tag
 * - budget_id: Optional[str] - The id for a budget (tpm/rpm/max budget) for the tag
 *
 * ### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###
 * - max_budget: Optional[float] - Max budget for tag
 * - tpm_limit: Optional[int] - Max tpm limit for tag
 * - rpm_limit: Optional[int] - Max rpm limit for tag
 * - max_parallel_requests: Optional[int] - Max parallel requests for tag
 * - soft_budget: Optional[float] - Get a slack alert when this soft budget is reached
 * - model_max_budget: Optional[dict] - Max budget for a specific model
 * - budget_duration: Optional[str] - Frequency of resetting tag budget
 */
export const newTagTagNewPost = (variables: NewTagTagNewPostVariables, signal?: AbortSignal) =>
	fetch<NewTagTagNewPostResponse, NewTagTagNewPostError, Schemas.TagNewRequest, {}, {}, {}>({
		url: "/tag/new",
		method: "post",
		...variables,
		signal,
	});

export type UpdateTagTagUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateTagTagUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateTagTagUpdatePostVariables = {
	body: Schemas.TagUpdateRequest;
} & FetcherExtraProps;

/**
 * Update an existing tag.
 *
 * Parameters:
 * - name: str - The name of the tag to update
 * - description: Optional[str] - Updated description
 * - models: List[str] - Updated list of allowed LLM models
 * - budget_id: Optional[str] - The id for a budget to associate with the tag
 *
 * ### BUDGET UPDATE PARAMS ###
 * - max_budget: Optional[float] - Max budget for tag
 * - tpm_limit: Optional[int] - Max tpm limit for tag
 * - rpm_limit: Optional[int] - Max rpm limit for tag
 * - max_parallel_requests: Optional[int] - Max parallel requests for tag
 * - soft_budget: Optional[float] - Get a slack alert when this soft budget is reached
 * - model_max_budget: Optional[dict] - Max budget for a specific model
 * - budget_duration: Optional[str] - Frequency of resetting tag budget
 */
export const updateTagTagUpdatePost = (
	variables: UpdateTagTagUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateTagTagUpdatePostResponse,
		UpdateTagTagUpdatePostError,
		Schemas.TagUpdateRequest,
		{},
		{},
		{}
	>({ url: "/tag/update", method: "post", ...variables, signal });

export type InfoTagTagInfoPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type InfoTagTagInfoPostResponse = {
	[key: string]: any;
};

export type InfoTagTagInfoPostVariables = {
	body: Schemas.TagInfoRequest;
} & FetcherExtraProps;

/**
 * Get information about specific tags.
 *
 * Parameters:
 * - names: List[str] - List of tag names to get information for
 */
export const infoTagTagInfoPost = (variables: InfoTagTagInfoPostVariables, signal?: AbortSignal) =>
	fetch<InfoTagTagInfoPostResponse, InfoTagTagInfoPostError, Schemas.TagInfoRequest, {}, {}, {}>({
		url: "/tag/info",
		method: "post",
		...variables,
		signal,
	});

export type ListTagsTagListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListTagsTagListGetResponse = {
	[key: string]: any;
};

export type ListTagsTagListGetVariables = FetcherExtraProps;

/**
 * List all available tags with their budget information.
 */
export const listTagsTagListGet = (variables: ListTagsTagListGetVariables, signal?: AbortSignal) =>
	fetch<ListTagsTagListGetResponse, ListTagsTagListGetError, undefined, {}, {}, {}>({
		url: "/tag/list",
		method: "get",
		...variables,
		signal,
	});

export type DeleteTagTagDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteTagTagDeletePostResponse = {
	[key: string]: any;
};

export type DeleteTagTagDeletePostVariables = {
	body: Schemas.TagDeleteRequest;
} & FetcherExtraProps;

/**
 * Delete a tag.
 *
 * Parameters:
 * - name: str - The name of the tag to delete
 */
export const deleteTagTagDeletePost = (
	variables: DeleteTagTagDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteTagTagDeletePostResponse,
		DeleteTagTagDeletePostError,
		Schemas.TagDeleteRequest,
		{},
		{},
		{}
	>({ url: "/tag/delete", method: "post", ...variables, signal });

export type GetTagDailyActivityTagDailyActivityGetQueryParams = {
	tags?: string | null;
	start_date?: string | null;
	end_date?: string | null;
	model?: string | null;
	api_key?: string | null;
	/**
	 * @default 1
	 */
	page?: number;
	/**
	 * @default 10
	 */
	page_size?: number;
};

export type GetTagDailyActivityTagDailyActivityGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetTagDailyActivityTagDailyActivityGetVariables = {
	queryParams?: GetTagDailyActivityTagDailyActivityGetQueryParams;
} & FetcherExtraProps;

/**
 * Get daily activity for specific tags or all tags.
 *
 * Args:
 *     tags (Optional[str]): Comma-separated list of tags to filter by. If not provided, returns data for all tags.
 *     start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).
 *     end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).
 *     model (Optional[str]): Filter by model name.
 *     api_key (Optional[str]): Filter by API key.
 *     page (int): Page number for pagination.
 *     page_size (int): Number of items per page.
 *
 * Returns:
 *     SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 */
export const getTagDailyActivityTagDailyActivityGet = (
	variables: GetTagDailyActivityTagDailyActivityGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.SpendAnalyticsPaginatedResponse,
		GetTagDailyActivityTagDailyActivityGetError,
		undefined,
		{},
		GetTagDailyActivityTagDailyActivityGetQueryParams,
		{}
	>({ url: "/tag/daily/activity", method: "get", ...variables, signal });

export type GetCostDiscountConfigConfigCostDiscountConfigGetError = Fetcher.ErrorWrapper<undefined>;

export type GetCostDiscountConfigConfigCostDiscountConfigGetResponse = {
	[key: string]: any;
};

export type GetCostDiscountConfigConfigCostDiscountConfigGetVariables = FetcherExtraProps;

/**
 * Get current cost discount configuration.
 *
 * Returns the cost_discount_config from litellm_settings.
 */
export const getCostDiscountConfigConfigCostDiscountConfigGet = (
	variables: GetCostDiscountConfigConfigCostDiscountConfigGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetCostDiscountConfigConfigCostDiscountConfigGetResponse,
		GetCostDiscountConfigConfigCostDiscountConfigGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/config/cost_discount_config",
		method: "get",
		...variables,
		signal,
	});

export type UpdateCostDiscountConfigConfigCostDiscountConfigPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateCostDiscountConfigConfigCostDiscountConfigPatchRequestBody = {
	[key: string]: number;
};

export type UpdateCostDiscountConfigConfigCostDiscountConfigPatchVariables = {
	body?: UpdateCostDiscountConfigConfigCostDiscountConfigPatchRequestBody;
} & FetcherExtraProps;

/**
 * Update cost discount configuration.
 *
 * Updates the cost_discount_config in litellm_settings.
 * Discounts should be between 0 and 1 (e.g., 0.05 = 5% discount).
 *
 * Example:
 * ```json
 * {
 *     "vertex_ai": 0.05,
 *     "gemini": 0.05,
 *     "openai": 0.01
 * }
 * ```
 */
export const updateCostDiscountConfigConfigCostDiscountConfigPatch = (
	variables: UpdateCostDiscountConfigConfigCostDiscountConfigPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		UpdateCostDiscountConfigConfigCostDiscountConfigPatchError,
		UpdateCostDiscountConfigConfigCostDiscountConfigPatchRequestBody,
		{},
		{},
		{}
	>({
		url: "/config/cost_discount_config",
		method: "patch",
		...variables,
		signal,
	});

export type GetRouterSettingsRouterSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetRouterSettingsRouterSettingsGetVariables = FetcherExtraProps;

/**
 * Get router configuration and available settings.
 *
 * Returns:
 * - fields: List of all configurable router settings with their metadata (type, description, default, options)
 *           The routing_strategy field includes available options extracted from the Router class
 * - current_values: Current values of router settings from config
 */
export const getRouterSettingsRouterSettingsGet = (
	variables: GetRouterSettingsRouterSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.RouterSettingsResponse,
		GetRouterSettingsRouterSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/router/settings", method: "get", ...variables, signal });

export type GetCacheSettingsCacheSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetCacheSettingsCacheSettingsGetVariables = FetcherExtraProps;

/**
 * Get cache configuration and available settings.
 *
 * Returns:
 * - fields: List of all configurable cache settings with their metadata (type, description, default, options)
 * - current_values: Current values of cache settings from database
 */
export const getCacheSettingsCacheSettingsGet = (
	variables: GetCacheSettingsCacheSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CacheSettingsResponse,
		GetCacheSettingsCacheSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/cache/settings", method: "get", ...variables, signal });

export type UpdateCacheSettingsCacheSettingsPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateCacheSettingsCacheSettingsPostResponse = {
	[key: string]: any;
};

export type UpdateCacheSettingsCacheSettingsPostVariables = {
	body: Schemas.CacheSettingsUpdateRequest;
} & FetcherExtraProps;

/**
 * Save cache settings to database and initialize cache.
 *
 * This endpoint:
 * 1. Encrypts sensitive fields (passwords, etc.)
 * 2. Saves to LiteLLM_CacheConfig table
 * 3. Reinitializes cache with new settings
 */
export const updateCacheSettingsCacheSettingsPost = (
	variables: UpdateCacheSettingsCacheSettingsPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateCacheSettingsCacheSettingsPostResponse,
		UpdateCacheSettingsCacheSettingsPostError,
		Schemas.CacheSettingsUpdateRequest,
		{},
		{},
		{}
	>({ url: "/cache/settings", method: "post", ...variables, signal });

export type TestCacheConnectionCacheSettingsTestPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TestCacheConnectionCacheSettingsTestPostVariables = {
	body: Schemas.CacheTestRequest;
} & FetcherExtraProps;

/**
 * Test cache connection with provided credentials.
 *
 * Creates a temporary cache instance and uses its test_connection method
 * to verify the credentials work without affecting global state.
 */
export const testCacheConnectionCacheSettingsTestPost = (
	variables: TestCacheConnectionCacheSettingsTestPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.CacheTestResponse,
		TestCacheConnectionCacheSettingsTestPostError,
		Schemas.CacheTestRequest,
		{},
		{},
		{}
	>({ url: "/cache/settings/test", method: "post", ...variables, signal });

export type GetDistinctUserAgentTagsTagDistinctGetError = Fetcher.ErrorWrapper<undefined>;

export type GetDistinctUserAgentTagsTagDistinctGetVariables = FetcherExtraProps;

/**
 * Get all distinct user agent tags up to a maximum of {MAX_TAGS} tags.
 *
 * This endpoint returns all unique user agent tags found in the database,
 * sorted by frequency of usage.
 *
 * Returns:
 *     DistinctTagsResponse: List of distinct user agent tags
 */
export const getDistinctUserAgentTagsTagDistinctGet = (
	variables: GetDistinctUserAgentTagsTagDistinctGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.DistinctTagsResponse,
		GetDistinctUserAgentTagsTagDistinctGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/tag/distinct", method: "get", ...variables, signal });

export type GetDailyActiveUsersTagDauGetQueryParams = {
	/**
	 * Filter by specific tag (optional)
	 */
	tag_filter?: string | null;
	/**
	 * Filter by multiple specific tags (optional, takes precedence over tag_filter)
	 */
	tag_filters?: string[] | null;
};

export type GetDailyActiveUsersTagDauGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetDailyActiveUsersTagDauGetVariables = {
	queryParams?: GetDailyActiveUsersTagDauGetQueryParams;
} & FetcherExtraProps;

/**
 * Get Daily Active Users (DAU) by tags for the last {MAX_DAYS} days ending on UTC today + 1 day.
 *
 * This endpoint efficiently calculates unique users per tag for each of the last {MAX_DAYS} days
 * using a single optimized SQL query, perfect for dashboard time series visualization.
 *
 * Args:
 *     tag_filter: Optional filter to specific tag (legacy)
 *     tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 *     ActiveUsersAnalyticsResponse: DAU data by tag for each of the last {MAX_DAYS} days
 */
export const getDailyActiveUsersTagDauGet = (
	variables: GetDailyActiveUsersTagDauGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ActiveUsersAnalyticsResponse,
		GetDailyActiveUsersTagDauGetError,
		undefined,
		{},
		GetDailyActiveUsersTagDauGetQueryParams,
		{}
	>({ url: "/tag/dau", method: "get", ...variables, signal });

export type GetWeeklyActiveUsersTagWauGetQueryParams = {
	/**
	 * Filter by specific tag (optional)
	 */
	tag_filter?: string | null;
	/**
	 * Filter by multiple specific tags (optional, takes precedence over tag_filter)
	 */
	tag_filters?: string[] | null;
};

export type GetWeeklyActiveUsersTagWauGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetWeeklyActiveUsersTagWauGetVariables = {
	queryParams?: GetWeeklyActiveUsersTagWauGetQueryParams;
} & FetcherExtraProps;

/**
 * Get Weekly Active Users (WAU) by tags for the last {MAX_WEEKS} weeks ending on UTC today + 1 day.
 *
 * Shows week-by-week breakdown:
 * - Week 1 (Jan 1): Earliest week (7 weeks ago)
 * - Week 2 (Jan 8): Next week (6 weeks ago)
 * - Week 3 (Jan 15): Next week (5 weeks ago)
 * - ... and so on for {MAX_WEEKS} weeks total
 * - Week 7: Most recent week ending on UTC today + 1 day
 *
 * Args:
 *     tag_filter: Optional filter to specific tag (legacy)
 *     tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 *     ActiveUsersAnalyticsResponse: WAU data by tag for each of the last {MAX_WEEKS} weeks with descriptive week labels (e.g., "Week 1 (Jan 1)")
 */
export const getWeeklyActiveUsersTagWauGet = (
	variables: GetWeeklyActiveUsersTagWauGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ActiveUsersAnalyticsResponse,
		GetWeeklyActiveUsersTagWauGetError,
		undefined,
		{},
		GetWeeklyActiveUsersTagWauGetQueryParams,
		{}
	>({ url: "/tag/wau", method: "get", ...variables, signal });

export type GetMonthlyActiveUsersTagMauGetQueryParams = {
	/**
	 * Filter by specific tag (optional)
	 */
	tag_filter?: string | null;
	/**
	 * Filter by multiple specific tags (optional, takes precedence over tag_filter)
	 */
	tag_filters?: string[] | null;
};

export type GetMonthlyActiveUsersTagMauGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetMonthlyActiveUsersTagMauGetVariables = {
	queryParams?: GetMonthlyActiveUsersTagMauGetQueryParams;
} & FetcherExtraProps;

/**
 * Get Monthly Active Users (MAU) by tags for the last {MAX_MONTHS} months ending on UTC today + 1 day.
 *
 * Shows month-by-month breakdown:
 * - Month 1 (Nov): Earliest month (7 months ago, 30-day period)
 * - Month 2 (Dec): Next month (6 months ago)
 * - Month 3 (Jan): Next month (5 months ago)
 * - ... and so on for {MAX_MONTHS} months total
 * - Month 7: Most recent month ending on UTC today + 1 day
 *
 * Args:
 *     tag_filter: Optional filter to specific tag (legacy)
 *     tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 *     ActiveUsersAnalyticsResponse: MAU data by tag for each of the last {MAX_MONTHS} months with descriptive month labels (e.g., "Month 1 (Nov)")
 */
export const getMonthlyActiveUsersTagMauGet = (
	variables: GetMonthlyActiveUsersTagMauGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.ActiveUsersAnalyticsResponse,
		GetMonthlyActiveUsersTagMauGetError,
		undefined,
		{},
		GetMonthlyActiveUsersTagMauGetQueryParams,
		{}
	>({ url: "/tag/mau", method: "get", ...variables, signal });

export type GetTagSummaryTagSummaryGetQueryParams = {
	/**
	 * Start date in YYYY-MM-DD format
	 */
	start_date: string;
	/**
	 * End date in YYYY-MM-DD format
	 */
	end_date: string;
	/**
	 * Filter by specific tag (optional)
	 */
	tag_filter?: string | null;
	/**
	 * Filter by multiple specific tags (optional, takes precedence over tag_filter)
	 */
	tag_filters?: string[] | null;
};

export type GetTagSummaryTagSummaryGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetTagSummaryTagSummaryGetVariables = {
	queryParams: GetTagSummaryTagSummaryGetQueryParams;
} & FetcherExtraProps;

/**
 * Get summary analytics for tags including unique users, requests, tokens, and spend.
 *
 * Args:
 *     start_date: Start date for the analytics period (YYYY-MM-DD)
 *     end_date: End date for the analytics period (YYYY-MM-DD)
 *     tag_filter: Optional filter to specific tag (legacy)
 *     tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 *     TagSummaryResponse: Summary analytics data by tag
 */
export const getTagSummaryTagSummaryGet = (
	variables: GetTagSummaryTagSummaryGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.TagSummaryResponse,
		GetTagSummaryTagSummaryGetError,
		undefined,
		{},
		GetTagSummaryTagSummaryGetQueryParams,
		{}
	>({ url: "/tag/summary", method: "get", ...variables, signal });

export type GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams = {
	/**
	 * Filter by specific tag (optional)
	 */
	tag_filter?: string | null;
	/**
	 * Filter by multiple specific tags (optional, takes precedence over tag_filter)
	 */
	tag_filters?: string[] | null;
	/**
	 * Page number for pagination
	 *
	 * @minimum 1
	 * @default 1
	 */
	page?: number;
	/**
	 * Items per page
	 *
	 * @maximum 1000
	 * @minimum 1
	 * @default 50
	 */
	page_size?: number;
};

export type GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetVariables = {
	queryParams?: GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams;
} & FetcherExtraProps;

/**
 * Get per-user analytics including successful requests, tokens, and spend by individual users.
 *
 * This endpoint provides usage metrics broken down by individual users based on their
 * tag activity during the last 30 days ending on UTC today + 1 day.
 *
 * Args:
 *     tag_filter: Optional filter to specific tag (legacy)
 *     tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *     page: Page number for pagination
 *     page_size: Number of items per page
 *
 * Returns:
 *     PerUserAnalyticsResponse: Analytics data broken down by individual users for the last 30 days
 */
export const getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet = (
	variables: GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PerUserAnalyticsResponse,
		GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetError,
		undefined,
		{},
		GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetQueryParams,
		{}
	>({
		url: "/tag/user-agent/per-user-analytics",
		method: "get",
		...variables,
		signal,
	});

export type NewVectorStoreVectorStoreNewPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type NewVectorStoreVectorStoreNewPostResponse = {
	[key: string]: any;
};

export type NewVectorStoreVectorStoreNewPostVariables = {
	body?: Schemas.LiteLLMManagedVectorStore;
} & FetcherExtraProps;

/**
 * Create a new vector store.
 *
 * Parameters:
 * - vector_store_id: str - Unique identifier for the vector store
 * - custom_llm_provider: str - Provider of the vector store
 * - vector_store_name: Optional[str] - Name of the vector store
 * - vector_store_description: Optional[str] - Description of the vector store
 * - vector_store_metadata: Optional[Dict] - Additional metadata for the vector store
 */
export const newVectorStoreVectorStoreNewPost = (
	variables: NewVectorStoreVectorStoreNewPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		NewVectorStoreVectorStoreNewPostResponse,
		NewVectorStoreVectorStoreNewPostError,
		Schemas.LiteLLMManagedVectorStore,
		{},
		{},
		{}
	>({ url: "/vector_store/new", method: "post", ...variables, signal });

export type ListVectorStoresVectorStoreListGetQueryParams = {
	/**
	 * @default 1
	 */
	page?: number;
	/**
	 * @default 100
	 */
	page_size?: number;
};

export type ListVectorStoresVectorStoreListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListVectorStoresVectorStoreListGetVariables = {
	queryParams?: ListVectorStoresVectorStoreListGetQueryParams;
} & FetcherExtraProps;

/**
 * List all available vector stores with optional filtering and pagination.
 * Combines both in-memory vector stores and those stored in the database.
 *
 * Parameters:
 * - page: int - Page number for pagination (default: 1)
 * - page_size: int - Number of items per page (default: 100)
 */
export const listVectorStoresVectorStoreListGet = (
	variables: ListVectorStoresVectorStoreListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.LiteLLMManagedVectorStoreListResponse,
		ListVectorStoresVectorStoreListGetError,
		undefined,
		{},
		ListVectorStoresVectorStoreListGetQueryParams,
		{}
	>({ url: "/vector_store/list", method: "get", ...variables, signal });

export type DeleteVectorStoreVectorStoreDeletePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DeleteVectorStoreVectorStoreDeletePostResponse = {
	[key: string]: any;
};

export type DeleteVectorStoreVectorStoreDeletePostVariables = {
	body: Schemas.VectorStoreDeleteRequest;
} & FetcherExtraProps;

/**
 * Delete a vector store.
 *
 * Parameters:
 * - vector_store_id: str - ID of the vector store to delete
 */
export const deleteVectorStoreVectorStoreDeletePost = (
	variables: DeleteVectorStoreVectorStoreDeletePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DeleteVectorStoreVectorStoreDeletePostResponse,
		DeleteVectorStoreVectorStoreDeletePostError,
		Schemas.VectorStoreDeleteRequest,
		{},
		{},
		{}
	>({ url: "/vector_store/delete", method: "post", ...variables, signal });

export type GetVectorStoreInfoVectorStoreInfoPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetVectorStoreInfoVectorStoreInfoPostResponse = {
	[key: string]: any;
};

export type GetVectorStoreInfoVectorStoreInfoPostVariables = {
	body: Schemas.VectorStoreInfoRequest;
} & FetcherExtraProps;

/**
 * Return a single vector store's details
 */
export const getVectorStoreInfoVectorStoreInfoPost = (
	variables: GetVectorStoreInfoVectorStoreInfoPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		GetVectorStoreInfoVectorStoreInfoPostResponse,
		GetVectorStoreInfoVectorStoreInfoPostError,
		Schemas.VectorStoreInfoRequest,
		{},
		{},
		{}
	>({ url: "/vector_store/info", method: "post", ...variables, signal });

export type UpdateVectorStoreVectorStoreUpdatePostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateVectorStoreVectorStoreUpdatePostResponse = {
	[key: string]: any;
};

export type UpdateVectorStoreVectorStoreUpdatePostVariables = {
	body: Schemas.VectorStoreUpdateRequest;
} & FetcherExtraProps;

/**
 * Update vector store details
 */
export const updateVectorStoreVectorStoreUpdatePost = (
	variables: UpdateVectorStoreVectorStoreUpdatePostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		UpdateVectorStoreVectorStoreUpdatePostResponse,
		UpdateVectorStoreVectorStoreUpdatePostError,
		Schemas.VectorStoreUpdateRequest,
		{},
		{},
		{}
	>({ url: "/vector_store/update", method: "post", ...variables, signal });

export type GetEmailEventSettingsEmailEventSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetEmailEventSettingsEmailEventSettingsGetVariables = FetcherExtraProps;

/**
 * Get all email event settings
 */
export const getEmailEventSettingsEmailEventSettingsGet = (
	variables: GetEmailEventSettingsEmailEventSettingsGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.EmailEventSettingsResponse,
		GetEmailEventSettingsEmailEventSettingsGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/email/event_settings", method: "get", ...variables, signal });

export type UpdateEventSettingsEmailEventSettingsPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type UpdateEventSettingsEmailEventSettingsPatchVariables = {
	body: Schemas.EmailEventSettingsUpdateRequest;
} & FetcherExtraProps;

/**
 * Update the settings for email events
 */
export const updateEventSettingsEmailEventSettingsPatch = (
	variables: UpdateEventSettingsEmailEventSettingsPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		UpdateEventSettingsEmailEventSettingsPatchError,
		Schemas.EmailEventSettingsUpdateRequest,
		{},
		{},
		{}
	>({ url: "/email/event_settings", method: "patch", ...variables, signal });

export type ResetEventSettingsEmailEventSettingsResetPostError = Fetcher.ErrorWrapper<undefined>;

export type ResetEventSettingsEmailEventSettingsResetPostResponse = {
	[key: string]: any;
};

export type ResetEventSettingsEmailEventSettingsResetPostVariables = FetcherExtraProps;

/**
 * Reset all email event settings to default (new user invitations on, virtual key creation off)
 */
export const resetEventSettingsEmailEventSettingsResetPost = (
	variables: ResetEventSettingsEmailEventSettingsResetPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		ResetEventSettingsEmailEventSettingsResetPostResponse,
		ResetEventSettingsEmailEventSettingsResetPostError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/email/event_settings/reset",
		method: "post",
		...variables,
		signal,
	});

export type GetAuditLogsAuditGetQueryParams = {
	/**
	 * @minimum 1
	 * @default 1
	 */
	page?: number;
	/**
	 * @maximum 100
	 * @minimum 1
	 * @default 10
	 */
	page_size?: number;
	/**
	 * Filter by user or system that performed the action
	 */
	changed_by?: string | null;
	/**
	 * Filter by API key hash that performed the action
	 */
	changed_by_api_key?: string | null;
	/**
	 * Filter by action type (create, update, delete)
	 */
	action?: string | null;
	/**
	 * Filter by table name that was modified
	 */
	table_name?: string | null;
	/**
	 * Filter by ID of the object that was modified
	 */
	object_id?: string | null;
	/**
	 * Filter logs after this date
	 */
	start_date?: string | null;
	/**
	 * Filter logs before this date
	 */
	end_date?: string | null;
	/**
	 * Column to sort by (e.g. 'updated_at', 'action', 'table_name')
	 */
	sort_by?: string | null;
	/**
	 * Sort order ('asc' or 'desc')
	 *
	 * @default desc
	 */
	sort_order?: string;
};

export type GetAuditLogsAuditGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetAuditLogsAuditGetVariables = {
	queryParams?: GetAuditLogsAuditGetQueryParams;
} & FetcherExtraProps;

/**
 * Get all audit logs with filtering and pagination.
 *
 * Returns a paginated response of audit logs matching the specified filters.
 */
export const getAuditLogsAuditGet = (
	variables: GetAuditLogsAuditGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.PaginatedAuditLogResponse,
		GetAuditLogsAuditGetError,
		undefined,
		{},
		GetAuditLogsAuditGetQueryParams,
		{}
	>({ url: "/audit", method: "get", ...variables, signal });

export type GetAuditLogByIdAuditIdGetPathParams = {
	id: string;
};

export type GetAuditLogByIdAuditIdGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type GetAuditLogByIdAuditIdGetVariables = {
	pathParams: GetAuditLogByIdAuditIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get detailed information about a specific audit log entry by its ID.
 *
 * Args:
 *     id (str): The unique identifier of the audit log entry
 *
 * Returns:
 *     AuditLogResponse: Detailed information about the audit log entry
 *
 * Raises:
 *     HTTPException: If the audit log is not found or if there's a database connection error
 */
export const getAuditLogByIdAuditIdGet = (
	variables: GetAuditLogByIdAuditIdGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.AuditLogResponse,
		GetAuditLogByIdAuditIdGetError,
		undefined,
		{},
		{},
		GetAuditLogByIdAuditIdGetPathParams
	>({ url: "/audit/{id}", method: "get", ...variables, signal });

export type AvailableEnterpriseUsersUserAvailableUsersGetError = Fetcher.ErrorWrapper<undefined>;

export type AvailableEnterpriseUsersUserAvailableUsersGetResponse = {
	[key: string]: any;
};

export type AvailableEnterpriseUsersUserAvailableUsersGetVariables = FetcherExtraProps;

/**
 * For keys with `max_users` set, return the list of users that are allowed to use the key.
 */
export const availableEnterpriseUsersUserAvailableUsersGet = (
	variables: AvailableEnterpriseUsersUserAvailableUsersGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AvailableEnterpriseUsersUserAvailableUsersGetResponse,
		AvailableEnterpriseUsersUserAvailableUsersGetError,
		undefined,
		{},
		{},
		{}
	>({ url: "/user/available_users", method: "get", ...variables, signal });

export type GetRobotsRobotsTxtGetError = Fetcher.ErrorWrapper<undefined>;

export type GetRobotsRobotsTxtGetResponse = {
	[key: string]: any;
};

export type GetRobotsRobotsTxtGetVariables = FetcherExtraProps;

/**
 * Block all web crawlers from indexing the proxy server endpoints
 * This is useful for ensuring that the API endpoints aren't indexed by search engines
 */
export const getRobotsRobotsTxtGet = (
	variables: GetRobotsRobotsTxtGetVariables,
	signal?: AbortSignal,
) =>
	fetch<GetRobotsRobotsTxtGetResponse, GetRobotsRobotsTxtGetError, undefined, {}, {}, {}>({
		url: "/robots.txt",
		method: "get",
		...variables,
		signal,
	});

export type GetUiConfigLitellmWellKnownLitellmUiConfigGetError = Fetcher.ErrorWrapper<undefined>;

export type GetUiConfigLitellmWellKnownLitellmUiConfigGetVariables = FetcherExtraProps;

export const getUiConfigLitellmWellKnownLitellmUiConfigGet = (
	variables: GetUiConfigLitellmWellKnownLitellmUiConfigGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.UiDiscoveryEndpoints,
		GetUiConfigLitellmWellKnownLitellmUiConfigGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/litellm/.well-known/litellm-ui-config",
		method: "get",
		...variables,
		signal,
	});

export type GetUiConfigWellKnownLitellmUiConfigGetError = Fetcher.ErrorWrapper<undefined>;

export type GetUiConfigWellKnownLitellmUiConfigGetVariables = FetcherExtraProps;

export const getUiConfigWellKnownLitellmUiConfigGet = (
	variables: GetUiConfigWellKnownLitellmUiConfigGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Schemas.UiDiscoveryEndpoints,
		GetUiConfigWellKnownLitellmUiConfigGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/.well-known/litellm-ui-config",
		method: "get",
		...variables,
		signal,
	});

export type DynamicMcpRouteMcpServerNameMcpPatch4PathParams = {
	mcpServerName: string;
};

export type DynamicMcpRouteMcpServerNameMcpPatch4Error = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DynamicMcpRouteMcpServerNameMcpPatch4Variables = {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch4PathParams;
} & FetcherExtraProps;

/**
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpPatch4 = (
	variables: DynamicMcpRouteMcpServerNameMcpPatch4Variables,
	signal?: AbortSignal,
) =>
	fetch<
		void,
		DynamicMcpRouteMcpServerNameMcpPatch4Error,
		undefined,
		{},
		{},
		DynamicMcpRouteMcpServerNameMcpPatch4PathParams
	>({ url: "/{mcpServerName}/mcp", method: "patch", ...variables, signal });

export type DynamicMcpRouteMcpServerNameMcpPatch2PathParams = {
	mcpServerName: string;
};

export type DynamicMcpRouteMcpServerNameMcpPatch2Error = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DynamicMcpRouteMcpServerNameMcpPatch2Response = {
	[key: string]: any;
};

export type DynamicMcpRouteMcpServerNameMcpPatch2Variables = {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch2PathParams;
} & FetcherExtraProps;

/**
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpPatch2 = (
	variables: DynamicMcpRouteMcpServerNameMcpPatch2Variables,
	signal?: AbortSignal,
) =>
	fetch<
		DynamicMcpRouteMcpServerNameMcpPatch2Response,
		DynamicMcpRouteMcpServerNameMcpPatch2Error,
		undefined,
		{},
		{},
		DynamicMcpRouteMcpServerNameMcpPatch2PathParams
	>({ url: "/{mcpServerName}/mcp", method: "post", ...variables, signal });

export type DynamicMcpRouteMcpServerNameMcpPatch3PathParams = {
	mcpServerName: string;
};

export type DynamicMcpRouteMcpServerNameMcpPatch3Error = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DynamicMcpRouteMcpServerNameMcpPatch3Response = {
	[key: string]: any;
};

export type DynamicMcpRouteMcpServerNameMcpPatch3Variables = {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch3PathParams;
} & FetcherExtraProps;

/**
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpPatch3 = (
	variables: DynamicMcpRouteMcpServerNameMcpPatch3Variables,
	signal?: AbortSignal,
) =>
	fetch<
		DynamicMcpRouteMcpServerNameMcpPatch3Response,
		DynamicMcpRouteMcpServerNameMcpPatch3Error,
		undefined,
		{},
		{},
		DynamicMcpRouteMcpServerNameMcpPatch3PathParams
	>({ url: "/{mcpServerName}/mcp", method: "put", ...variables, signal });

export type DynamicMcpRouteMcpServerNameMcpPatchPathParams = {
	mcpServerName: string;
};

export type DynamicMcpRouteMcpServerNameMcpPatchError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DynamicMcpRouteMcpServerNameMcpPatchResponse = {
	[key: string]: any;
};

export type DynamicMcpRouteMcpServerNameMcpPatchVariables = {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatchPathParams;
} & FetcherExtraProps;

/**
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpPatch = (
	variables: DynamicMcpRouteMcpServerNameMcpPatchVariables,
	signal?: AbortSignal,
) =>
	fetch<
		DynamicMcpRouteMcpServerNameMcpPatchResponse,
		DynamicMcpRouteMcpServerNameMcpPatchError,
		undefined,
		{},
		{},
		DynamicMcpRouteMcpServerNameMcpPatchPathParams
	>({ url: "/{mcpServerName}/mcp", method: "get", ...variables, signal });

export type DynamicMcpRouteMcpServerNameMcpPatch5PathParams = {
	mcpServerName: string;
};

export type DynamicMcpRouteMcpServerNameMcpPatch5Error = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type DynamicMcpRouteMcpServerNameMcpPatch5Response = {
	[key: string]: any;
};

export type DynamicMcpRouteMcpServerNameMcpPatch5Variables = {
	pathParams: DynamicMcpRouteMcpServerNameMcpPatch5PathParams;
} & FetcherExtraProps;

/**
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpPatch5 = (
	variables: DynamicMcpRouteMcpServerNameMcpPatch5Variables,
	signal?: AbortSignal,
) =>
	fetch<
		DynamicMcpRouteMcpServerNameMcpPatch5Response,
		DynamicMcpRouteMcpServerNameMcpPatch5Error,
		undefined,
		{},
		{},
		DynamicMcpRouteMcpServerNameMcpPatch5PathParams
	>({ url: "/{mcpServerName}/mcp", method: "delete", ...variables, signal });

export type ListToolRestApiMcpRestToolsListGetQueryParams = {
	/**
	 * The server id to list tools for
	 */
	server_id?: string | null;
};

export type ListToolRestApiMcpRestToolsListGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type ListToolRestApiMcpRestToolsListGetVariables = {
	queryParams?: ListToolRestApiMcpRestToolsListGetQueryParams;
} & FetcherExtraProps;

/**
 * List all available tools with information about the server they belong to.
 *
 * Example response:
 * {
 *     "tools": [
 *         {
 *             "name": "create_zap",
 *             "description": "Create a new zap",
 *             "inputSchema": "tool_input_schema",
 *             "mcp_info": {
 *                 "server_name": "zapier",
 *                 "logo_url": "https://www.zapier.com/logo.png",
 *             }
 *         }
 *     ],
 *     "error": null,
 *     "message": "Successfully retrieved tools"
 * }
 */
export const listToolRestApiMcpRestToolsListGet = (
	variables: ListToolRestApiMcpRestToolsListGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		Record<string, any>,
		ListToolRestApiMcpRestToolsListGetError,
		undefined,
		{},
		ListToolRestApiMcpRestToolsListGetQueryParams,
		{}
	>({ url: "/mcp-rest/tools/list", method: "get", ...variables, signal });

export type CallToolRestApiMcpRestToolsCallPostError = Fetcher.ErrorWrapper<undefined>;

export type CallToolRestApiMcpRestToolsCallPostResponse = {
	[key: string]: any;
};

export type CallToolRestApiMcpRestToolsCallPostVariables = FetcherExtraProps;

/**
 * REST API to call a specific MCP tool with the provided arguments
 */
export const callToolRestApiMcpRestToolsCallPost = (
	variables: CallToolRestApiMcpRestToolsCallPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CallToolRestApiMcpRestToolsCallPostResponse,
		CallToolRestApiMcpRestToolsCallPostError,
		undefined,
		{},
		{},
		{}
	>({ url: "/mcp-rest/tools/call", method: "post", ...variables, signal });

export type TestConnectionMcpRestTestConnectionPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TestConnectionMcpRestTestConnectionPostResponse = {
	[key: string]: any;
};

export type TestConnectionMcpRestTestConnectionPostVariables = {
	body?: Schemas.NewMCPServerRequest;
} & FetcherExtraProps;

/**
 * Test if we can connect to the provided MCP server before adding it
 */
export const testConnectionMcpRestTestConnectionPost = (
	variables: TestConnectionMcpRestTestConnectionPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TestConnectionMcpRestTestConnectionPostResponse,
		TestConnectionMcpRestTestConnectionPostError,
		Schemas.NewMCPServerRequest,
		{},
		{},
		{}
	>({ url: "/mcp-rest/test/connection", method: "post", ...variables, signal });

export type TestToolsListMcpRestTestToolsListPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TestToolsListMcpRestTestToolsListPostResponse = {
	[key: string]: any;
};

export type TestToolsListMcpRestTestToolsListPostVariables = {
	body?: Schemas.NewMCPServerRequest;
} & FetcherExtraProps;

/**
 * Preview tools available from MCP server before adding it
 */
export const testToolsListMcpRestTestToolsListPost = (
	variables: TestToolsListMcpRestTestToolsListPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TestToolsListMcpRestTestToolsListPostResponse,
		TestToolsListMcpRestTestToolsListPostError,
		Schemas.NewMCPServerRequest,
		{},
		{},
		{}
	>({ url: "/mcp-rest/test/tools/list", method: "post", ...variables, signal });

export type AuthorizeAuthorizeGetQueryParams = {
	client_id: string;
	redirect_uri: string;
	/**
	 * @default
	 */
	state?: string;
	mcp_server_name?: string | null;
	code_challenge?: string | null;
	code_challenge_method?: string | null;
	response_type?: string | null;
	scope?: string | null;
};

export type AuthorizeAuthorizeGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AuthorizeAuthorizeGetResponse = {
	[key: string]: any;
};

export type AuthorizeAuthorizeGetVariables = {
	queryParams: AuthorizeAuthorizeGetQueryParams;
} & FetcherExtraProps;

export const authorizeAuthorizeGet = (
	variables: AuthorizeAuthorizeGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AuthorizeAuthorizeGetResponse,
		AuthorizeAuthorizeGetError,
		undefined,
		{},
		AuthorizeAuthorizeGetQueryParams,
		{}
	>({ url: "/authorize", method: "get", ...variables, signal });

export type AuthorizeMcpServerNameAuthorizeGetPathParams = {
	mcpServerName: string | null;
};

export type AuthorizeMcpServerNameAuthorizeGetQueryParams = {
	client_id: string;
	redirect_uri: string;
	/**
	 * @default
	 */
	state?: string;
	code_challenge?: string | null;
	code_challenge_method?: string | null;
	response_type?: string | null;
	scope?: string | null;
};

export type AuthorizeMcpServerNameAuthorizeGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type AuthorizeMcpServerNameAuthorizeGetResponse = {
	[key: string]: any;
};

export type AuthorizeMcpServerNameAuthorizeGetVariables = {
	pathParams: AuthorizeMcpServerNameAuthorizeGetPathParams;
	queryParams: AuthorizeMcpServerNameAuthorizeGetQueryParams;
} & FetcherExtraProps;

export const authorizeMcpServerNameAuthorizeGet = (
	variables: AuthorizeMcpServerNameAuthorizeGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		AuthorizeMcpServerNameAuthorizeGetResponse,
		AuthorizeMcpServerNameAuthorizeGetError,
		undefined,
		{},
		AuthorizeMcpServerNameAuthorizeGetQueryParams,
		AuthorizeMcpServerNameAuthorizeGetPathParams
	>({ url: "/{mcpServerName}/authorize", method: "get", ...variables, signal });

export type TokenEndpointTokenPostQueryParams = {
	mcp_server_name?: string | null;
};

export type TokenEndpointTokenPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TokenEndpointTokenPostResponse = {
	[key: string]: any;
};

export type TokenEndpointTokenPostVariables = {
	queryParams?: TokenEndpointTokenPostQueryParams;
} & FetcherExtraProps;

/**
 * Accept the authorization code from client and exchange it for OAuth token.
 * Supports PKCE flow by forwarding code_verifier to upstream provider.
 *
 * 1. Call the token endpoint with PKCE parameters
 * 2. Store the user's token in the db - and generate a LiteLLM virtual key
 * 3. Return the token
 * 4. Return a virtual key in this response
 */
export const tokenEndpointTokenPost = (
	variables: TokenEndpointTokenPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TokenEndpointTokenPostResponse,
		TokenEndpointTokenPostError,
		undefined,
		{},
		TokenEndpointTokenPostQueryParams,
		{}
	>({ url: "/token", method: "post", ...variables, signal });

export type TokenEndpointMcpServerNameTokenPostPathParams = {
	mcpServerName: string | null;
};

export type TokenEndpointMcpServerNameTokenPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type TokenEndpointMcpServerNameTokenPostResponse = {
	[key: string]: any;
};

export type TokenEndpointMcpServerNameTokenPostVariables = {
	pathParams: TokenEndpointMcpServerNameTokenPostPathParams;
} & FetcherExtraProps;

/**
 * Accept the authorization code from client and exchange it for OAuth token.
 * Supports PKCE flow by forwarding code_verifier to upstream provider.
 *
 * 1. Call the token endpoint with PKCE parameters
 * 2. Store the user's token in the db - and generate a LiteLLM virtual key
 * 3. Return the token
 * 4. Return a virtual key in this response
 */
export const tokenEndpointMcpServerNameTokenPost = (
	variables: TokenEndpointMcpServerNameTokenPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		TokenEndpointMcpServerNameTokenPostResponse,
		TokenEndpointMcpServerNameTokenPostError,
		undefined,
		{},
		{},
		TokenEndpointMcpServerNameTokenPostPathParams
	>({ url: "/{mcpServerName}/token", method: "post", ...variables, signal });

export type CallbackCallbackGetQueryParams = {
	code: string;
	state: string;
};

export type CallbackCallbackGetError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type CallbackCallbackGetResponse = {
	[key: string]: any;
};

export type CallbackCallbackGetVariables = {
	queryParams: CallbackCallbackGetQueryParams;
} & FetcherExtraProps;

export const callbackCallbackGet = (
	variables: CallbackCallbackGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		CallbackCallbackGetResponse,
		CallbackCallbackGetError,
		undefined,
		{},
		CallbackCallbackGetQueryParams,
		{}
	>({ url: "/callback", method: "get", ...variables, signal });

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams = {
	mcp_server_name?: string | null;
};

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetResponse = {
	[key: string]: any;
};

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetVariables = {
	queryParams?: OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams;
} & FetcherExtraProps;

export const oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet = (
	variables: OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetResponse,
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetError,
		undefined,
		{},
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetQueryParams,
		{}
	>({
		url: "/.well-known/oauth-protected-resource",
		method: "get",
		...variables,
		signal,
	});

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams =
	{
		mcpServerName: string | null;
	};

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetResponse = {
	[key: string]: any;
};

export type OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetVariables = {
	pathParams: OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams;
} & FetcherExtraProps;

export const oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet = (
	variables: OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetResponse,
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetError,
		undefined,
		{},
		{},
		OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetPathParams
	>({
		url: "/.well-known/oauth-protected-resource/{mcpServerName}/mcp",
		method: "get",
		...variables,
		signal,
	});

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams = {
	mcp_server_name?: string | null;
};

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetResponse = {
	[key: string]: any;
};

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetVariables = {
	queryParams?: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams;
} & FetcherExtraProps;

export const oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet = (
	variables: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetResponse,
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetError,
		undefined,
		{},
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetQueryParams,
		{}
	>({
		url: "/.well-known/oauth-authorization-server",
		method: "get",
		...variables,
		signal,
	});

export type OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams =
	{
		mcpServerName: string | null;
	};

export type OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetResponse = {
	[key: string]: any;
};

export type OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetVariables =
	{
		pathParams: OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams;
	} & FetcherExtraProps;

export const oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet = (
	variables: OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetResponse,
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetError,
		undefined,
		{},
		{},
		OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetPathParams
	>({
		url: "/.well-known/oauth-authorization-server/{mcpServerName}",
		method: "get",
		...variables,
		signal,
	});

export type OpenidConfigurationWellKnownOpenidConfigurationGetError =
	Fetcher.ErrorWrapper<undefined>;

export type OpenidConfigurationWellKnownOpenidConfigurationGetResponse = {
	[key: string]: any;
};

export type OpenidConfigurationWellKnownOpenidConfigurationGetVariables = FetcherExtraProps;

export const openidConfigurationWellKnownOpenidConfigurationGet = (
	variables: OpenidConfigurationWellKnownOpenidConfigurationGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OpenidConfigurationWellKnownOpenidConfigurationGetResponse,
		OpenidConfigurationWellKnownOpenidConfigurationGetError,
		undefined,
		{},
		{},
		{}
	>({
		url: "/.well-known/openid-configuration",
		method: "get",
		...variables,
		signal,
	});

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams =
	{
		mcpServerName: string | null;
	};

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetError =
	Fetcher.ErrorWrapper<{
		status: 422;
		payload: Schemas.HTTPValidationError;
	}>;

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetResponse =
	{
		[key: string]: any;
	};

export type OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetVariables =
	{
		pathParams: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams;
	} & FetcherExtraProps;

export const oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet = (
	variables: OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetVariables,
	signal?: AbortSignal,
) =>
	fetch<
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetResponse,
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetError,
		undefined,
		{},
		{},
		OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetPathParams
	>({
		url: "/.well-known/oauth-authorization-server/{mcpServerName}/mcp",
		method: "get",
		...variables,
		signal,
	});

export type RegisterClientRegisterPostQueryParams = {
	mcp_server_name?: string | null;
};

export type RegisterClientRegisterPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RegisterClientRegisterPostResponse = {
	[key: string]: any;
};

export type RegisterClientRegisterPostVariables = {
	queryParams?: RegisterClientRegisterPostQueryParams;
} & FetcherExtraProps;

export const registerClientRegisterPost = (
	variables: RegisterClientRegisterPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RegisterClientRegisterPostResponse,
		RegisterClientRegisterPostError,
		undefined,
		{},
		RegisterClientRegisterPostQueryParams,
		{}
	>({ url: "/register", method: "post", ...variables, signal });

export type RegisterClientMcpServerNameRegisterPostPathParams = {
	mcpServerName: string | null;
};

export type RegisterClientMcpServerNameRegisterPostError = Fetcher.ErrorWrapper<{
	status: 422;
	payload: Schemas.HTTPValidationError;
}>;

export type RegisterClientMcpServerNameRegisterPostResponse = {
	[key: string]: any;
};

export type RegisterClientMcpServerNameRegisterPostVariables = {
	pathParams: RegisterClientMcpServerNameRegisterPostPathParams;
} & FetcherExtraProps;

export const registerClientMcpServerNameRegisterPost = (
	variables: RegisterClientMcpServerNameRegisterPostVariables,
	signal?: AbortSignal,
) =>
	fetch<
		RegisterClientMcpServerNameRegisterPostResponse,
		RegisterClientMcpServerNameRegisterPostError,
		undefined,
		{},
		{},
		RegisterClientMcpServerNameRegisterPostPathParams
	>({ url: "/{mcpServerName}/register", method: "post", ...variables, signal });

export type WebsocketVertexAiLivePassthroughEndpointQueryParams = {
	model?: string;
	vertex_project?: string;
	vertex_location?: string;
};

export type WebsocketVertexAiLivePassthroughEndpointError = Fetcher.ErrorWrapper<undefined>;

export type WebsocketVertexAiLivePassthroughEndpointVariables = {
	queryParams?: WebsocketVertexAiLivePassthroughEndpointQueryParams;
} & FetcherExtraProps;

/**
 * WebSocket connection endpoint
 */
export const websocketVertexAiLivePassthroughEndpoint = (
	variables: WebsocketVertexAiLivePassthroughEndpointVariables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		WebsocketVertexAiLivePassthroughEndpointError,
		undefined,
		{},
		WebsocketVertexAiLivePassthroughEndpointQueryParams,
		{}
	>({ url: "/vertex_ai/live", method: "get", ...variables, signal });

export type WebsocketWebsocketEndpointQueryParams = {
	model: string;
	intent?: string;
};

export type WebsocketWebsocketEndpointError = Fetcher.ErrorWrapper<undefined>;

export type WebsocketWebsocketEndpointVariables = {
	queryParams: WebsocketWebsocketEndpointQueryParams;
} & FetcherExtraProps;

/**
 * WebSocket connection endpoint
 */
export const websocketWebsocketEndpoint = (
	variables: WebsocketWebsocketEndpointVariables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		WebsocketWebsocketEndpointError,
		undefined,
		{},
		WebsocketWebsocketEndpointQueryParams,
		{}
	>({ url: "/realtime", method: "get", ...variables, signal });

export type WebsocketWebsocketEndpoint2QueryParams = {
	model: string;
	intent?: string;
};

export type WebsocketWebsocketEndpoint2Error = Fetcher.ErrorWrapper<undefined>;

export type WebsocketWebsocketEndpoint2Variables = {
	queryParams: WebsocketWebsocketEndpoint2QueryParams;
} & FetcherExtraProps;

/**
 * WebSocket connection endpoint
 */
export const websocketWebsocketEndpoint2 = (
	variables: WebsocketWebsocketEndpoint2Variables,
	signal?: AbortSignal,
) =>
	fetch<
		undefined,
		WebsocketWebsocketEndpoint2Error,
		undefined,
		{},
		WebsocketWebsocketEndpoint2QueryParams,
		{}
	>({ url: "/v1/realtime", method: "get", ...variables, signal });

export const operationsByTag = {
	modelManagement: {
		modelListModelsGet,
		modelListV1ModelsGet,
		modelInfoModelsModelIdGet,
		modelInfoV1ModelsModelIdGet,
		modelInfoV1V1ModelInfoGet,
		modelInfoV1ModelInfoGet,
		modelGroupInfoModelGroupInfoGet,
		publicModelHubPublicModelHubGet,
		publicModelHubInfoPublicModelHubInfoGet,
		patchModelModelModelIdUpdatePatch,
		deleteModelModelDeletePost,
		addNewModelModelNewPost,
		updateModelModelUpdatePost,
		updatePublicModelGroupsModelGroupMakePublicPost,
		updateUsefulLinksModelHubUpdateUsefulLinksPost,
	},
	chatCompletions: {
		chatCompletionOpenaiDeploymentsModelChatCompletionsPost,
		chatCompletionEnginesModelChatCompletionsPost,
		chatCompletionChatCompletionsPost,
		chatCompletionV1ChatCompletionsPost,
	},
	completions: {
		completionOpenaiDeploymentsModelCompletionsPost,
		completionEnginesModelCompletionsPost,
		completionCompletionsPost,
		completionV1CompletionsPost,
	},
	embeddings: {
		embeddingsOpenaiDeploymentsModelEmbeddingsPost,
		embeddingsEnginesModelEmbeddingsPost,
		embeddingsEmbeddingsPost,
		embeddingsV1EmbeddingsPost,
	},
	moderations: { moderationsModerationsPost, moderationsV1ModerationsPost },
	audio: {
		audioSpeechAudioSpeechPost,
		audioSpeechV1AudioSpeechPost,
		audioTranscriptionsAudioTranscriptionsPost,
		audioTranscriptionsV1AudioTranscriptionsPost,
	},
	assistants: {
		getAssistantsAssistantsGet,
		createAssistantAssistantsPost,
		getAssistantsV1AssistantsGet,
		createAssistantV1AssistantsPost,
		deleteAssistantAssistantsAssistantIdDelete,
		deleteAssistantV1AssistantsAssistantIdDelete,
		createThreadsThreadsPost,
		createThreadsV1ThreadsPost,
		getThreadThreadsThreadIdGet,
		getThreadV1ThreadsThreadIdGet,
		addMessagesThreadsThreadIdMessagesPost,
		getMessagesThreadsThreadIdMessagesGet,
		addMessagesV1ThreadsThreadIdMessagesPost,
		getMessagesV1ThreadsThreadIdMessagesGet,
		runThreadThreadsThreadIdRunsPost,
		runThreadV1ThreadsThreadIdRunsPost,
	},
	llmUtils: {
		tokenCounterUtilsTokenCounterPost,
		supportedOpenaiParamsUtilsSupportedOpenaiParamsGet,
		transformRequestUtilsTransformRequestPost,
	},
	responses: {
		responsesApiOpenaiV1ResponsesPost,
		responsesApiResponsesPost,
		responsesApiV1ResponsesPost,
		getResponseOpenaiV1ResponsesResponseIdGet,
		deleteResponseOpenaiV1ResponsesResponseIdDelete,
		getResponseResponsesResponseIdGet,
		deleteResponseResponsesResponseIdDelete,
		getResponseV1ResponsesResponseIdGet,
		deleteResponseV1ResponsesResponseIdDelete,
		getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet,
		getResponseInputItemsResponsesResponseIdInputItemsGet,
		getResponseInputItemsV1ResponsesResponseIdInputItemsGet,
		cancelResponseOpenaiV1ResponsesResponseIdCancelPost,
		cancelResponseResponsesResponseIdCancelPost,
		cancelResponseV1ResponsesResponseIdCancelPost,
	},
	batch: {
		createBatchBatchesPost,
		listBatchesBatchesGet,
		createBatchV1BatchesPost,
		listBatchesV1BatchesGet,
		createBatchProviderV1BatchesPost,
		listBatchesProviderV1BatchesGet,
		retrieveBatchBatchesBatchIdGet,
		retrieveBatchV1BatchesBatchIdGet,
		retrieveBatchProviderV1BatchesBatchIdGet,
		cancelBatchBatchesBatchIdCancelPost,
		cancelBatchV1BatchesBatchIdCancelPost,
		cancelBatchProviderV1BatchesBatchIdCancelPost,
	},
	public: {
		publicModelHubPublicModelHubGet,
		publicModelHubInfoPublicModelHubInfoGet,
	},
	rerank: { rerankRerankPost, rerankV1RerankPost, rerankV2RerankPost },
	ocr: { ocrOcrPost, ocrV1OcrPost },
	videos: {
		videoListVideosGet,
		videoGenerationVideosPost,
		videoListV1VideosGet,
		videoGenerationV1VideosPost,
		videoStatusVideosVideoIdGet,
		videoStatusV1VideosVideoIdGet,
		videoContentVideosVideoIdContentGet,
		videoContentV1VideosVideoIdContentGet,
		videoRemixVideosVideoIdRemixPost,
		videoRemixV1VideosVideoIdRemixPost,
	},
	containers: {
		listContainersContainersGet,
		createContainerContainersPost,
		listContainersV1ContainersGet,
		createContainerV1ContainersPost,
		retrieveContainerContainersContainerIdGet,
		deleteContainerContainersContainerIdDelete,
		retrieveContainerV1ContainersContainerIdGet,
		deleteContainerV1ContainersContainerIdDelete,
	},
	search: {
		searchSearchPost,
		searchV1SearchPost,
		searchSearchSearchToolNamePost,
		searchV1SearchSearchToolNamePost,
	},
	images: {
		imageGenerationOpenaiDeploymentsModelImagesGenerationsPost,
		imageGenerationImagesGenerationsPost,
		imageGenerationV1ImagesGenerationsPost,
		imageEditApiOpenaiDeploymentsModelImagesEditsPost,
		imageEditApiImagesEditsPost,
		imageEditApiV1ImagesEditsPost,
	},
	fineTuning: {
		createFineTuningJobFineTuningJobsPost,
		listFineTuningJobsFineTuningJobsGet,
		createFineTuningJobV1FineTuningJobsPost,
		listFineTuningJobsV1FineTuningJobsGet,
		retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet,
		retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet,
		cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost,
		cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost,
	},
	credentialManagement: {
		getCredentialsCredentialsGet,
		createCredentialCredentialsPost,
		getCredentialCredentialsByModelModelIdGet,
		getCredentialCredentialsByNameCredentialNameGet,
		deleteCredentialCredentialsCredentialNameDelete,
		updateCredentialCredentialsCredentialNamePatch,
	},
	mcp: {
		getMcpToolsV1McpToolsGet,
		getMcpAccessGroupsV1McpAccessGroupsGet,
		healthCheckMcpServerV1McpServerServerIdHealthGet,
		healthCheckAllMcpServersV1McpServerHealthGet,
		fetchAllMcpServersV1McpServerGet,
		addMcpServerV1McpServerPost,
		editMcpServerV1McpServerPut,
		fetchMcpServerV1McpServerServerIdGet,
		removeMcpServerV1McpServerServerIdDelete,
		listToolRestApiMcpRestToolsListGet,
		callToolRestApiMcpRestToolsCallPost,
		testConnectionMcpRestTestConnectionPost,
		testToolsListMcpRestTestToolsListPost,
		authorizeAuthorizeGet,
		authorizeMcpServerNameAuthorizeGet,
		tokenEndpointTokenPost,
		tokenEndpointMcpServerNameTokenPost,
		callbackCallbackGet,
		oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet,
		oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet,
		oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet,
		oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet,
		openidConfigurationWellKnownOpenidConfigurationGet,
		oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet,
		registerClientRegisterPost,
		registerClientMcpServerNameRegisterPost,
	},
	betaAnthropicV1Messages: { anthropicResponseV1MessagesPost },
	betaAnthropicMessagesTokenCounting: { countTokensV1MessagesCountTokensPost },
	googleGenaiEndpoints: {
		googleGenerateContentModelsModelNameGenerateContentPost,
		googleGenerateContentV1betaModelsModelNameGenerateContentPost,
		googleStreamGenerateContentModelsModelNameStreamGenerateContentPost,
		googleStreamGenerateContentV1betaModelsModelNameStreamGenerateContentPost,
		googleCountTokensModelsModelNameCountTokensPost,
		googleCountTokensV1betaModelsModelNameCountTokensPost,
	},
	health: {
		testEndpointTestGet,
		healthServicesEndpointHealthServicesGet,
		healthEndpointHealthGet,
		healthCheckHistoryEndpointHealthHistoryGet,
		latestHealthChecksEndpointHealthLatestGet,
		sharedHealthCheckStatusEndpointHealthSharedStatusGet,
		activeCallbacksActiveCallbacksGet,
		activeCallbacksSettingsGet,
		healthReadinessHealthReadinessGet,
		healthLivelinessHealthLivenessGet,
		healthLivelinessHealthLivelinessGet,
		testModelConnectionHealthTestConnectionPost,
	},
	keyManagement: {
		generateKeyFnKeyGeneratePost,
		generateServiceAccountKeyFnKeyServiceAccountGeneratePost,
		updateKeyFnKeyUpdatePost,
		deleteKeyFnKeyDeletePost,
		infoKeyFnKeyInfoGet,
		regenerateKeyFnKeyRegeneratePost,
		regenerateKeyFnKeyKeyRegeneratePost,
		listKeysKeyListGet,
		keyAliasesKeyAliasesGet,
		blockKeyKeyBlockPost,
		unblockKeyKeyUnblockPost,
		keyHealthKeyHealthPost,
	},
	internalUserManagement: {
		newUserUserNewPost,
		userInfoUserInfoGet,
		userUpdateUserUpdatePost,
		bulkUserUpdateUserBulkUpdatePost,
		getUsersUserListGet,
		deleteUserUserDeletePost,
		getUserDailyActivityUserDailyActivityGet,
		getUserDailyActivityAggregatedUserDailyActivityAggregatedGet,
		availableEnterpriseUsersUserAvailableUsersGet,
	},
	budgetSpendTracking: {
		getUserDailyActivityUserDailyActivityGet,
		getUserDailyActivityAggregatedUserDailyActivityAggregatedGet,
		viewSpendTagsSpendTagsGet,
		getGlobalSpendReportGlobalSpendReportGet,
		globalViewSpendTagsGlobalSpendTagsGet,
		calculateSpendSpendCalculatePost,
		viewSpendLogsSpendLogsGet,
		globalSpendResetGlobalSpendResetPost,
		addAllowedIpAddAllowedIpPost,
		deleteAllowedIpDeleteAllowedIpPost,
	},
	teamManagement: {
		newTeamTeamNewPost,
		updateTeamTeamUpdatePost,
		teamMemberAddTeamMemberAddPost,
		teamMemberDeleteTeamMemberDeletePost,
		teamMemberUpdateTeamMemberUpdatePost,
		bulkTeamMemberAddTeamBulkMemberAddPost,
		deleteTeamTeamDeletePost,
		teamInfoTeamInfoGet,
		blockTeamTeamBlockPost,
		unblockTeamTeamUnblockPost,
		listTeamV2V2TeamListGet,
		listTeamTeamListGet,
		teamModelAddTeamModelAddPost,
		teamModelDeleteTeamModelDeletePost,
		teamMemberPermissionsTeamPermissionsListGet,
		updateTeamMemberPermissionsTeamPermissionsUpdatePost,
		getTeamDailyActivityTeamDailyActivityGet,
		addTeamCallbacksTeamTeamIdCallbackPost,
		getTeamCallbacksTeamTeamIdCallbackGet,
		disableTeamLoggingTeamTeamIdDisableLoggingPost,
	},
	"\u2728SCIMV2EnterpriseOnly": {
		getServiceProviderConfigScimV2ServiceProviderConfigGet,
		getUsersScimV2UsersGet,
		createUserScimV2UsersPost,
		getUserScimV2UsersUserIdGet,
		updateUserScimV2UsersUserIdPut,
		deleteUserScimV2UsersUserIdDelete,
		patchUserScimV2UsersUserIdPatch,
		getGroupsScimV2GroupsGet,
		createGroupScimV2GroupsPost,
		getGroupScimV2GroupsGroupIdGet,
		updateGroupScimV2GroupsGroupIdPut,
		deleteGroupScimV2GroupsGroupIdDelete,
		patchGroupScimV2GroupsGroupIdPatch,
	},
	organizationManagement: {
		newOrganizationOrganizationNewPost,
		updateOrganizationOrganizationUpdatePatch,
		deleteOrganizationOrganizationDeleteDelete,
		listOrganizationOrganizationListGet,
		infoOrganizationOrganizationInfoGet,
		deprecatedInfoOrganizationOrganizationInfoPost,
		organizationMemberAddOrganizationMemberAddPost,
		organizationMemberUpdateOrganizationMemberUpdatePatch,
		organizationMemberDeleteOrganizationMemberDeleteDelete,
	},
	customerManagement: {
		blockUserCustomerBlockPost,
		unblockUserCustomerUnblockPost,
		newEndUserCustomerNewPost,
		endUserInfoCustomerInfoGet,
		updateEndUserCustomerUpdatePost,
		deleteEndUserCustomerDeletePost,
		listEndUserCustomerListGet,
	},
	cloudZero: {
		getCloudzeroSettingsCloudzeroSettingsGet,
		updateCloudzeroSettingsCloudzeroSettingsPut,
		initCloudzeroSettingsCloudzeroInitPost,
		cloudzeroDryRunExportCloudzeroDryRunPost,
		cloudzeroExportCloudzeroExportPost,
	},
	caching: {
		cachePingCachePingGet,
		cacheDeleteCacheDeletePost,
		cacheRedisInfoCacheRedisInfoGet,
		cacheFlushallCacheFlushallPost,
	},
	guardrails: {
		listGuardrailsGuardrailsListGet,
		listGuardrailsV2V2GuardrailsListGet,
		createGuardrailGuardrailsPost,
		updateGuardrailGuardrailsGuardrailIdPut,
		deleteGuardrailGuardrailsGuardrailIdDelete,
		patchGuardrailGuardrailsGuardrailIdPatch,
		getGuardrailInfoGuardrailsGuardrailIdGet,
		getGuardrailInfoGuardrailsGuardrailIdInfoGet,
		getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet,
		validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost,
		getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet,
		applyGuardrailGuardrailsApplyGuardrailPost,
	},
	searchTools: {
		listSearchToolsSearchToolsListGet,
		createSearchToolSearchToolsPost,
		updateSearchToolSearchToolsSearchToolIdPut,
		deleteSearchToolSearchToolsSearchToolIdDelete,
		getSearchToolInfoSearchToolsSearchToolIdGet,
		testSearchToolConnectionSearchToolsTestConnectionPost,
		getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet,
	},
	promptManagement: {
		listPromptsPromptsListGet,
		getPromptInfoPromptsPromptIdInfoGet,
		getPromptInfoPromptsPromptIdGet,
		updatePromptPromptsPromptIdPut,
		deletePromptPromptsPromptIdDelete,
		patchPromptPromptsPromptIdPatch,
		createPromptPromptsPost,
	},
	prompts: { convertPromptFileToJsonUtilsDotpromptJsonConverterPost },
	utils: { convertPromptFileToJsonUtilsDotpromptJsonConverterPost },
	loggingCallbacks: { listCallbacksCallbacksListGet },
	sSOSettings: {
		getInternalUserSettingsGetInternalUserSettingsGet,
		getDefaultTeamSettingsGetDefaultTeamSettingsGet,
		updateInternalUserSettingsUpdateInternalUserSettingsPatch,
		updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch,
		getSsoSettingsGetSsoSettingsGet,
		updateSsoSettingsUpdateSsoSettingsPatch,
	},
	uIThemeSettings: {
		getUiThemeSettingsGetUiThemeSettingsGet,
		updateUiThemeSettingsUpdateUiThemeSettingsPatch,
		uploadLogoUploadLogoPost,
	},
	files: {
		createFileFilesPost,
		listFilesFilesGet,
		createFileV1FilesPost,
		listFilesV1FilesGet,
		createFileProviderV1FilesPost,
		listFilesProviderV1FilesGet,
		getFileContentFilesFileIdContentGet,
		getFileContentV1FilesFileIdContentGet,
		getFileContentProviderV1FilesFileIdContentGet,
		getFileFilesFileIdGet,
		deleteFileFilesFileIdDelete,
		getFileV1FilesFileIdGet,
		deleteFileV1FilesFileIdDelete,
		getFileProviderV1FilesFileIdGet,
		deleteFileProviderV1FilesFileIdDelete,
	},
	budgetManagement: {
		newBudgetBudgetNewPost,
		updateBudgetBudgetUpdatePost,
		infoBudgetBudgetInfoPost,
		budgetSettingsBudgetSettingsGet,
		listBudgetBudgetListGet,
		deleteBudgetBudgetDeletePost,
	},
	tagManagement: {
		newTagTagNewPost,
		updateTagTagUpdatePost,
		infoTagTagInfoPost,
		listTagsTagListGet,
		deleteTagTagDeletePost,
		getTagDailyActivityTagDailyActivityGet,
		getDistinctUserAgentTagsTagDistinctGet,
		getDailyActiveUsersTagDauGet,
		getWeeklyActiveUsersTagWauGet,
		getMonthlyActiveUsersTagMauGet,
		getTagSummaryTagSummaryGet,
		getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet,
	},
	costTracking: {
		getCostDiscountConfigConfigCostDiscountConfigGet,
		updateCostDiscountConfigConfigCostDiscountConfigPatch,
	},
	routerSettings: { getRouterSettingsRouterSettingsGet },
	cacheSettings: {
		getCacheSettingsCacheSettingsGet,
		updateCacheSettingsCacheSettingsPost,
		testCacheConnectionCacheSettingsTestPost,
	},
	userAgentAnalytics: {
		getDistinctUserAgentTagsTagDistinctGet,
		getDailyActiveUsersTagDauGet,
		getWeeklyActiveUsersTagWauGet,
		getMonthlyActiveUsersTagMauGet,
		getTagSummaryTagSummaryGet,
		getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet,
	},
	vectorStoreManagement: {
		newVectorStoreVectorStoreNewPost,
		listVectorStoresVectorStoreListGet,
		deleteVectorStoreVectorStoreDeletePost,
		getVectorStoreInfoVectorStoreInfoPost,
		updateVectorStoreVectorStoreUpdatePost,
	},
	emailManagement: {
		getEmailEventSettingsEmailEventSettingsGet,
		updateEventSettingsEmailEventSettingsPatch,
		resetEventSettingsEmailEventSettingsResetPost,
	},
	auditLogging: { getAuditLogsAuditGet, getAuditLogByIdAuditIdGet },
	webSocket: {
		websocketVertexAiLivePassthroughEndpoint,
		websocketWebsocketEndpoint,
		websocketWebsocketEndpoint2,
	},
};
