# OpenResponses Specification

> **Source**: [https://www.openresponses.org/specification](https://www.openresponses.org/specification)
> **OpenAPI Spec**: [openapi.json](../openapi.json) (also at [https://www.openresponses.org/openapi/openapi.json](https://www.openresponses.org/openapi/openapi.json))
> **API Reference**: [https://www.openresponses.org/reference](https://www.openresponses.org/reference)

---

## ⚠️ IMPORTANT: API Format Clarifications

### OpenResponses is NOT the Same As:

1. **OpenAI Chat Completions API** - Different endpoint, different schema
2. **Vercel AI SDK format** - The SDK is a _client library_ that abstracts over APIs; OpenResponses is the _wire protocol_
3. **OpenAI Responses API** - OpenResponses is _based on_ the OpenAI Responses API but is an independent, multi-provider specification

### When Implementing OpenResponses:

- Use the [OpenAPI specification](../openapi.json) as the source of truth
- Use the generated types from `openresponses-client` package
- Do NOT refer to OpenAI documentation for request/response formats
- Do NOT use Vercel AI SDK documentation for wire protocol details

---

## Overview

Open Responses is an open-source specification and ecosystem for building multi-provider, interoperable LLM interfaces. It defines a shared schema, client library, and tooling layer that enable a unified experience for calling language models, streaming results, and composing agentic workflows—independent of provider.

### Key Principles

1. **One spec, many providers**: Describe inputs/outputs once; run on OpenAI, Anthropic, Gemini, or local models
2. **Composable agentic loops**: Unified streaming, tool invocation, and message orchestration
3. **Easier evaluation and routing**: Compare providers, route requests, and log results through a shared schema
4. **Blueprints for provider APIs**: Labs and model providers wanting to expose their APIs in a common format can easily do so

---

## Core Concepts

### Items

Items are the fundamental unit of context in Open Responses. They represent an atomic unit of model output, tool invocation, or reasoning state. Items are **bidirectional** - they can be provided as inputs to the model, or as outputs from the model.

#### Item Types (discriminated by `type` field):

| Type                   | Description                                                   |
| ---------------------- | ------------------------------------------------------------- |
| `message`              | A message to/from the model (further discriminated by `role`) |
| `function_call`        | A tool call generated by the model                            |
| `function_call_output` | The result of a tool call                                     |
| `reasoning`            | The model's internal reasoning trace                          |
| `item_reference`       | A reference to a previous item by ID                          |

#### Message Roles (for `type: "message"`):

| Role        | Content Types                             |
| ----------- | ----------------------------------------- |
| `user`      | `input_text`, `input_image`, `input_file` |
| `assistant` | `output_text`, `refusal`                  |
| `system`    | `input_text`                              |
| `developer` | `input_text`                              |

### Content Types

There are two top-level content unions:

- **User Content** (`input_*`): structured data provided by the user/client
- **Model Content** (`output_*`): structured data returned by the model

This distinction reflects the asymmetric nature of conversation turns.

#### Input Content Types:

- `input_text` - Text input to the model
- `input_image` - Image input (URL or base64)
- `input_file` - File input

#### Output Content Types:

- `output_text` - Text output from the model
- `refusal` - Model refusal explanation

---

## HTTP Protocol

### Request

```http
POST /v1/responses
Content-Type: application/json
Authorization: Bearer <token>
```

### Request Body Schema

```typescript
{
  model: string;                    // e.g., "anthropic/claude-sonnet-4.5"
  input: ItemParam[];               // Array of input items
  stream?: boolean;                 // Enable streaming (default: false)
  temperature?: number;             // 0-2, higher = more random
  max_output_tokens?: number;       // Maximum tokens to generate
  tools?: FunctionToolParam[];      // Available tools
  tool_choice?: ToolChoiceParam;    // "auto" | "required" | "none" | specific
  instructions?: string;            // System-level instructions
  // ... and more (see OpenAPI spec)
}
```

### Response

Non-streaming: `Content-Type: application/json`
Streaming: `Content-Type: text/event-stream`

---

## Streaming Events

All streaming events follow Server-Sent Events (SSE) format. Events are typed by the `type` field.

### State Machine Events

| Event Type             | Description                               |
| ---------------------- | ----------------------------------------- |
| `response.created`     | Response object was created               |
| `response.queued`      | Response is queued for processing         |
| `response.in_progress` | Model is generating the response          |
| `response.completed`   | Response generation finished successfully |
| `response.failed`      | Response generation failed                |
| `response.incomplete`  | Response was truncated                    |

### Delta Events

| Event Type                               | Description                  |
| ---------------------------------------- | ---------------------------- |
| `response.output_item.added`             | A new output item was added  |
| `response.output_item.done`              | An output item is complete   |
| `response.content_part.added`            | A new content part was added |
| `response.content_part.done`             | A content part is complete   |
| `response.output_text.delta`             | Text was appended to output  |
| `response.output_text.done`              | Text output is complete      |
| `response.function_call_arguments.delta` | Tool call arguments appended |
| `response.function_call_arguments.done`  | Tool call arguments complete |

---

## Tools (Function Calling)

### FunctionToolParam Schema

```typescript
{
  type: "function";           // Required discriminator
  name: string;               // Function name (1-64 chars, ^[a-zA-Z0-9_-]+$)
  description?: string;       // What the function does
  parameters?: object;        // JSON Schema for parameters
  strict?: boolean;           // Enforce strict parameter validation
}
```

**Note**: This is a FLAT structure. The properties are at the top level, NOT nested under a `function` key.

### FunctionCallItemParam (Model Output)

```typescript
{
  type: "function_call";      // Discriminator
  call_id: string;            // Unique ID for this call
  name: string;               // Function name
  arguments: string;          // JSON-encoded arguments
  status?: "in_progress" | "completed" | "incomplete";
}
```

### FunctionCallOutputItemParam (Tool Result)

```typescript
{
  type: "function_call_output";  // Discriminator
  call_id: string;               // Must match the function_call's call_id
  output: string | ContentPart[];  // Result of the function
  status?: "in_progress" | "completed" | "incomplete";
}
```

---

## Error Handling

Errors are returned with a structured format:

```json
{
  "error": {
    "message": "The requested model 'fake-model' does not exist.",
    "type": "invalid_request_error",
    "param": "model",
    "code": "model_not_found"
  }
}
```

### Error Types

| Type                | HTTP Status | Description                  |
| ------------------- | ----------- | ---------------------------- |
| `invalid_request`   | 400         | Malformed or invalid request |
| `not_found`         | 404         | Resource doesn't exist       |
| `too_many_requests` | 429         | Rate limited                 |
| `server_error`      | 500         | Internal server error        |
| `model_error`       | 500         | Model processing failed      |

---

## References

- **OpenAPI Specification**: [openapi.json](../openapi.json)
- **Official Website**: [https://www.openresponses.org](https://www.openresponses.org)
- **API Reference**: [https://www.openresponses.org/reference](https://www.openresponses.org/reference)
- **Specification**: [https://www.openresponses.org/specification](https://www.openresponses.org/specification)
- **GitHub**: [https://github.com/openresponses/openresponses](https://github.com/openresponses/openresponses)
